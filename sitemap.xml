<search>
    
     <entry>
        <title>Go更细粒度的读写锁设计</title>
        <url>http://shanks.link/blog/2022/03/19/go%E6%9B%B4%E7%BB%86%E7%B2%92%E5%BA%A6%E7%9A%84%E8%AF%BB%E5%86%99%E9%94%81%E8%AE%BE%E8%AE%A1/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Go更细粒度的读写锁设计 在《Go精妙的互斥锁设计》一文中，我们详细地讲解了互斥锁的实现原理。互斥锁为了避免竞争条件，它只允许一个线程进入代码临界区，而由于锁竞争的存在，程序的执行效率会被降低。同时我们知道，只有多线程在共享资源中有写操作，才会引发竞态问题，只要资源没有发生变化，多线程读取相同的资源就是安全的。因此，我们引申出更细粒度的锁：读写锁。
什么是读写锁
读写锁是一种多读单写锁，分读和写两种锁，多个线程可以同时加读锁，但是写锁和写锁、写锁与读锁之间是互斥的。
读写锁对临界区的处理如上图所示。其中，t1时刻，由于线程1已加写锁，线程2被互斥等待写锁的释放；t2时刻，线程2已加读锁，线程3可以对其继续加读锁并进入临界区；t3时刻，线程3加了读锁，线程4被互斥等待读锁的释放。
饥饿问题
根据读写锁的性质，读者应该能猜到读写锁适用于读写分明的场景。根据优先级，可以分为读优先锁和写优先锁。读优先锁能允许最大并发，但是写线程可能被饿死；同理，写优先锁是优先服务写线程，这样读线程就可能被饿死。
相对而言，写锁饥饿的问题更为突出。因为读锁是共享的，如果当前临界区已经加了读锁，后续的线程继续加读锁是没问题的，但是如果一直有读锁的线程加锁，那尝试加写锁的线程则会一直获取不到锁，这样加写锁的线程一直被阻塞，导致了写锁饥饿。
同时，由于多读锁共享，可能会有读者问：为什么不直接去掉读锁，在写操作线程进来时只加写锁就好了呢，这样岂不是很好实现了。道理很简单，如果当前临界区加了写锁，在写锁解开之前又有新的写操作线程进来，等到写锁释放，新的写操作线程又上了写锁。这种情况如果连续不断，那整个程序就只能执行写操作线程，读操作线程就活活被饿死了。
所以，为了避免饥饿问题，通用的做法是实现公平读写锁，它将请求锁的线程用队列进行排队，保证了先入先出（FIFO）的原则进行加锁，这样就能有效地避免线程饥饿问题。
那Go语言的读写锁，对于饥饿问题，它是如何处理的呢？
Go读写锁设计
本文代码版本为Go 1.15.2。如下所示，sync.RWMutex结构体包含5个字段。
1type RWMutex struct { 2 w Mutex 3 writerSem uint32 4 readerSem uint32 5 readerCount int32 6 readerWait int32 7}  w 互斥锁sync.Mutex，用于互斥写操作。 writerSem 写操作goroutine阻塞等待信号量。最后一个阻塞写操作的读操作goroutine释放读锁时，会通知阻塞的写锁goroutine。 readerSem 读操作goroutine阻塞等待信号量。写锁goroutine释放写锁后，会通知阻塞的读锁goroutine。 readerCount 读操作goroutine数量。 readerWait 阻塞写操作goroutine的读操作goroutine数量。  对于互斥锁的几个字段，现在可能不好理解，先不用着急，看完我们对sync.RWMutex对外提供的四个方法接口解析，就自然明白了。
 RLock()：加读锁 RUnlock()：解读锁 Lock()：加写锁 Unlock()：解写锁  下面，我们来依次分析。
1. 加读锁 这里，需要说明一下的是，为了更好理解代码逻辑，本文所有的代码块均去除了竞态检测的逻辑部分，即if race.Enabled {}方法块。
1func (rw *RWMutex) RLock() { 2 if atomic.AddInt32(&amp;amp;rw.readerCount, 1) &amp;lt; 0 { 3 runtime_SemacquireMutex(&amp;amp;rw.readerSem, false, 0) 4 } 5} atomic.AddInt32是一个原子性操作，其底层通过硬件指令LOCK实现封装（详情可见文章《同步原语的基石》）。rw.readerCount代表读操作goroutine数量，如果将其&#43;1，还小于0，则通过用于同步库的sleep原语runtime_SemacquireMutex阻塞等待写锁释放。
简单地说，如果当前有写操作goroutine已经进来了，则新来的读操作goroutine会被排队阻塞等待。但是，读者肯定会觉得判断条件很奇怪，为什么rw.readerCount会是负值？不要急，下文会有答案。
当然，如果此时没有写锁，则仅仅将rw.readerCount数目加1，然后直接退出，代表加读锁成功。
2. 解读锁 1func (rw *RWMutex) RUnlock() { 2 if r := atomic.AddInt32(&amp;amp;rw.readerCount, -1); r &amp;lt; 0 { 3 rw.rUnlockSlow(r) 4 } 5} 将读操作goroutine数目-1，如果其数目r大于等于0，则直接退出，代表解读锁成功。否则，带着当前处于负值的数目r进入以下rUnlockSlow逻辑：
1func (rw *RWMutex) rUnlockSlow(r int32) { 2 if r&#43;1 == 0 || r&#43;1 == -rwmutexMaxReaders { 3 race.Enable() 4 throw(&amp;#34;sync: RUnlock of unlocked RWMutex&amp;#34;) 5 } 6 if atomic.AddInt32(&amp;amp;rw.readerWait, -1) == 0 { 7 runtime_Semrelease(&amp;amp;rw.writerSem, false, 1) 8 } 9} 如果r&#43;1==0，则证明在解读锁时，其实并没有读goroutine加读锁；rwmutexMaxReaders = 1 &amp;lt;&amp;lt; 30，这代表读写锁所能接收的最大读操作goroutine数量。至于这里为什么r&#43;1 == -rwmutexMaxReaders也代表并没有goroutine加读锁，同样留在下文解答。在没有加读锁的锁上解读锁，会抛出异常并panic。
rw.readerWait代表写操作被阻塞时，读操作goroutine数量。如果该值为1，代表当前是最后一个阻塞写操作的goroutine，则通过用于同步库的wakeup原语runtime_Semrelease唤醒阻塞的写操作goroutine。
读者此时只看了加解读锁的代码，理解上会有困难，不要急，我们接着看加解写锁的逻辑。
3. 加写锁 1func (rw *RWMutex) Lock() { 2 rw.w.Lock() 3 r := atomic.AddInt32(&amp;amp;rw.readerCount, -rwmutexMaxReaders) &#43; rwmutexMaxReaders 4 if r != 0 &amp;amp;&amp;amp; atomic.AddInt32(&amp;amp;rw.readerWait, r) != 0 { 5 runtime_SemacquireMutex(&amp;amp;rw.writerSem, false, 0) 6 } 7} 在加写锁时，首先会通过互斥锁加锁，这保证只会有一个写锁加锁成功。当互斥锁加锁成功之后，我们就能看到写操作是如何阻止读操作，读操作是如何感知到写操作的。
我们已经知道rw.readerCount是代表读操作goroutine数量，如果在不存在写操作的情况下，每次加读锁，该值就会&#43;1，每次解读锁该值就会-1，那么我们可以合理地认为rw.readerCount的取值范围是[0,rwmutexMaxReaders],即最大支持2^30个并发读，最小是0个。
然而，在当前写操作goroutine加互斥锁成功后，会通过原子操作atomic.AddInt32将readerCount减去2^30，此时readerCount会变成负值，那么如果之后再有读操作goroutine加读锁时，能通过该负值知道当前已经有写锁了，从而阻塞等待。这里也解释了加读锁和解读锁两小节中留下的问题。最后，为了持有真实的读操作goroutine数目，再加回2^30即可。
这里需要格外注意的是：互斥锁加锁成功并不意味着加写锁成功。我们需要知道读操作是如何阻止写操作，写操作是如何感知到读操作的。
r != 0 即代表当前读操作goroutine不为0，这意味着写操作要等待排在前面的读操作结束后才算是加上写锁。写操作获得互斥锁后，通过atomic.AddInt32把rw.readerCount值拷贝到rw.readerWait中，用于标记排在写操作goroutine前面的读操作goroutine个数。通过用于同步库的sleep原语runtime_SemacquireMutex阻塞等待这些读操作结束。在解读锁小结中我们知道，读操作结束时，除了会递减rw.readerCount，同时需要递减rw.readerWait值，当rw.readerWait值变为0时就会唤醒阻塞的写操作goroutine。
4. 解写锁  1func (rw *RWMutex) Unlock() {  2 r := atomic.AddInt32(&amp;amp;rw.readerCount, rwmutexMaxReaders)  3 if r &amp;gt;= rwmutexMaxReaders {  4 race.Enable()  5 throw(&amp;#34;sync: Unlock of unlocked RWMutex&amp;#34;)  6 }  7 for i := 0; i &amp;lt; int(r); i&#43;&#43; {  8 runtime_Semrelease(&amp;amp;rw.readerSem, false, 0)  9 } 10 rw.w.Unlock() 11} 在解写锁时，将负值的rw.readerCount变更为正值，解除对读锁的互斥，并唤醒r个因为写锁而阻塞的读操作goroutine。最后，通过调用互斥锁的Unlock方法，解除对写锁的互斥。
到这里，我们可以图解一下Go是如何解决饥饿问题的。
假设G1、G2、G3是正在共享读的goroutine，rw.readerCount值为3。此时写操作G4进来，把rw.readerCount值变为了负值，同时它发现rw.readerCount不为0，因此阻塞等待。但是在G4的等待期间又有新的读操作G5、G6和写操作G7进来。由于此时的rw.readerCount值为负，所以G5和G6是不能加读锁成功的，会陷入阻塞等待。G7由于G4加了互斥锁也会陷入等待。当排在写操作G4前面的最后一个读操作G3结束，G3会唤醒G4。当G4结束时，它将G5、G6和G7均唤醒。但是G7需要等待G5和G6退出（因为它在试图加写锁时，会发现rw.readerCount不为0，会再次陷入阻塞等待）才能加写锁成功。以此反复，保证了读写锁的相对公平，避免一方挨饿。
总结
读写锁基于互斥锁，提供了更细粒度的控制，它适用于读写分明的场景，准确而言是读操作远多于写操作的情况。在多读少写的场景中，使用读写锁替代互斥锁能有效地提高程序运行效率。
读读共享、读写互斥和写写互斥。在优先级方面，偏袒读锁或者写锁要分几种情况。
 锁空闲，此时是完全公平的，谁先进来谁就可以上锁。 如果没有读操作，均是写操作，读写锁会退化成互斥锁，只有在互斥锁处于饥饿模式下才会公平。 如果没有写操作，均是读操作，读操作均可以进来，读写锁退化成无锁设计（也并不是真正的无锁，因为加解锁均有原子操作atomic.AddInt32对读操作goroutine的统计）。 被加读锁时，写操作进来会被阻塞。在写操作阻塞期间，如果有读操作试图进来，它们也会被阻塞。当阻塞写操作的最后一个读操作解读锁时，它只会唤醒被阻塞的写操作，之后进来的读操作需要该写操作完成之后被唤醒。这些被唤醒的读操作会比新的写操作（可以是新来的，也可以是因互斥锁而被阻塞的）先拿到锁，等待这些读操作完成，新的写操作才能拿到写锁。  因为读写锁是基于互斥锁之上的设计，不可避免地多做了一些工作。因此，并不是说使用读写锁的收益一定会比互斥锁高。在选择何种锁时，需要综合考量读写操作的比例，临界区代码的耗时。性能比对的内容本文就不再讨论，读者可自行测试。
以上内容转载自机器铃砍柴刀
</content>
    </entry>
    
     <entry>
        <title>go语言调度器源代码情景分析之九：操作系统线程及线程调度</title>
        <url>http://shanks.link/blog/2022/03/19/go%E8%AF%AD%E8%A8%80%E8%B0%83%E5%BA%A6%E5%99%A8%E6%BA%90%E4%BB%A3%E7%A0%81%E6%83%85%E6%99%AF%E5%88%86%E6%9E%90%E4%B9%8B%E4%B9%9D%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%BA%BF%E7%A8%8B%E5%8F%8A%E7%BA%BF%E7%A8%8B%E8%B0%83%E5%BA%A6/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 爱写程序的阿波张 源码游记 2019-04-25 本文是《go调度器源代码情景分析》系列 第一章 预备知识的第九小节。
要深入理解goroutine的调度器，就需要对操作系统线程有个大致的了解，因为go的调度系统是建立在操作系统线程之上的，所以接下来我们对其做一个简单的介绍。
很难对线程下一个准确且易于理解的定义，特别是对于从未接触过多线程编程的读者来说，要搞懂什么是线程可能并不是很容易，所以下面我们抛开定义直接从一个C语言的程序开始来直观的看一下什么是线程。之所以使用C语言，是因为C语言中我们一般使用pthread线程库，而使用该线程库创建的用户态线程其实就是Linux操作系统内核所支持的线程，它与go语言中的工作线程是一样的，这些线程都由Linux内核负责管理和调度，然后go语言在操作系统线程之上又做了goroutine，实现了一个二级线程模型。
#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;pthread.h&amp;gt; #define N (1000 * 1000 * 1000)  volatile int g = 0;  void *start(void *arg) { int i;  for (i = 0; i &amp;lt; N; i&#43;&#43;) { g&#43;&#43;; }  return NULL; }  int main(int argc, char *argv[]) { pthread_t tid;  // 使用pthread_create函数创建一个新线程执行start函数 pthread_create(&amp;amp;tid, NULL, start, NULL);  for (;;) { usleep(1000 * 100 * 5); printf(&amp;#34;loop g: %d\n&amp;#34;, g); if (g == N) { break; } }  pthread_join(tid, NULL); // 等待子线程结束运行  return 0; } 该程序运行起来之后将会有2个线程，一个是操作系统把程序加载起来运行时创建的主线程，另一个是主线程调用pthread_create创建的start子线程，主线程在创建完子线程之后每隔500毫秒打印一下全局变量 g 的值直到 g 等于10亿，而start线程启动后就开始执行一个10亿次的对 g 自增加 1 的循环，这两个线程同时并发运行在系统中，操作系统负责对它们进行调度，我们无法精确预知某个线程在什么时候会运行。
关于操作系统对线程的调度，有两个问题需要搞清楚：
  什么时候会发生调度
  调度的时候会做哪些事情？
  首先来看第一个问题，操作系统什么时候会发起调度呢？总体来说操作系统必须要得到CPU的控制权后才能发起调度，那么当用户程序在CPU上运行时如何才能让CPU去执行操作系统代码从而让内核获得控制权呢？一般说来在两种情况下会从执行用户程序代码转去执行操作系统代码：
用户程序使用系统调用进入操作系统内核；
硬件中断。硬件中断处理程序由操作系统提供，所以当硬件发生中断时，就会执行操作系统代码。硬件中断有个特别重要的时钟中断，这是操作系统能够发起抢占调度的基础。
操作系统会在执行操作系统代码路径上的某些点检查是否需要调度，所以操作系统对线程的调度也会相应的发生在上述两种情况之下。
下面来看一下在笔者的单核电脑上运行该程序的输出：
bobo@ubuntu:~/study/c$ gcc thread.c -o thread -lpthread bobo@ubuntu:~/study/c$ ./thread loop g: 98938361 loop g: 198264794 loop g: 297862478 loop g: 396750048 loop g: 489684941 loop g: 584723988 loop g: 679293257 loop g: 777715939 loop g: 876083765 loop g: 974378774 loop g: 1000000000 从输出可以看出，主线程和start线程在轮流着运行，这是操作系统对它们进行了调度的结果，操作系统一会儿把start线程调度起来运行，一会儿又把主线程调度起来运行。
从程序的输出结果可以看到抢占调度的身影，因为主线程在start线程运行过程中得到了运行，而start线程执行的start函数根本没有系统调用，并且这个程序又运行在单核系统中，没有其它CPU来运行主线程，所以如果没有中断时发生的抢占调度，操作系统就无法获取到CPU的控制权，也就不可能发生线程调度。
接下来我们再来看看操作系统在调度线程时会做哪些事情。
如上所述，操作系统会把不同的线程调度到同一个CPU上运行，而每个线程运行时又都会使用CPU的寄存器，但每个CPU却只有一组寄存器，所以操作系统在把线程B调度到CPU上运行时需要首先把刚刚正在运行的线程A所使用到的寄存器的值全部保存在内存之中，然后再把保存在内存中的线程B的寄存器的值全部又放回CPU的寄存器，这样线程B就能恢复到之前运行的状态接着运行。
线程调度时操作系统需要保存和恢复的寄存器除了通用寄存器之外，还包括指令指针寄存器rip以及与栈相关的栈顶寄存器rsp和栈基址寄存器rbp，rip寄存器决定了线程下一条需要执行的指令，2个栈寄存器确定了线程执行时需要使用的栈内存。所以恢复CPU寄存器的值就相当于改变了CPU下一条需要执行的指令，同时也切换了函数调用栈，因此从调度器的角度来说，线程至少包含以下3个重要内容：
一组通用寄存器的值
将要执行的下一条指令的地址
栈
所以操作系统对线程的调度可以简单的理解为内核调度器对不同线程所使用的寄存器和栈的切换。
最后，我们对操作系统线程下一个简单且不准确的定义：操作系统线程是由内核负责调度且拥有自己私有的一组寄存器值和栈的执行流。
最后，如果你觉得本文对你有帮助的话，麻烦帮忙点一下文末右下角的 在看 或转发到朋友圈，非常感谢！
</content>
    </entry>
    
     <entry>
        <title></title>
        <url>http://shanks.link/blog/2022/03/19/</url>
        <categories>
          
        </categories>
        <tags>
          
        </tags>
        <content type="html"> #&amp;mdash; title: Go：defer 语句如何工作 date: 2021-04-05 11:55:28 tags: [go] categories: [go] 原文链接
Go：defer 语句如何工作
ℹ️ 这篇文章基于 Go 1.12。
defer 语句是在函数返回前执行一段代码的便捷方法，如 Golang 规范所描述：
 延迟函数（ deferred functions ）在所在函数返回前，以与声明相反的顺序立即被调用
 以下是 LIFO (后进先出)实现的例子：
func main() {  defer func() {  println(`defer 1`)  }()  defer func() {  println(`defer 2`)  }() } defer 2 &amp;lt;- 后进先出 defer 1 来看一下内部的实现，然后再看一个更复杂的案例。
内部实现 Go 运行时（runtime）使用一个链表来实现 LIFO。实际上，一个 defer 结构体持有一个指向下一个要被执行的 defer 结构体的指针：
type _defer struct {  siz int32  started bool  sp uintptr  pc uintptr  fn *funcval  _panic *_panic  link *_defer // 下一个要被执行的延迟函数 当一个新的 defer 方法被创建的时候，它被附加到当前的 Goroutine 上，然后之前的 defer 方法作为下一个要执行的函数被链接到新创建的方法上：
func newdefer(siz int32) *_defer {  var d *_defer  gp := getg() // 获取当前 goroutine  [...]  // 延迟列表现在被附加到新的 _defer 结构体  d.link = gp._defer  gp._defer = d // 新的结构现在是第一个被调用的  return d } 现在，后续调用会从栈的顶部依次出栈延迟函数：
func deferreturn(arg0 uintptr) {  gp := getg() // 获取当前 goroutine  d:= gp._defer // 拷贝延迟函数到一个变量上  if d == nil { // 如果不存在延迟函数就直接返回  return  }  [...]  fn := d.fn // 获取要调用的函数  d.fn = nil // 重置函数  gp._defer = d.link // 把下一个 _defer 结构体依附到 Goroutine 上  freedefer(d) // 释放 _defer 结构体  jmpdefer(fn, uintptr(unsafe.Pointer(&amp;amp;arg0))) // 调用该函数 } 如我们所见，并没有循环地去调用延迟函数，而是一个接一个地出栈。这一行为可以通过生成汇编代码得到验证：
// 第一个延迟函数 0x001d 00029 (main.go:6) MOVL $0, (SP) 0x0024 00036 (main.go:6) PCDATA $2, $1 0x0024 00036 (main.go:6) LEAQ &amp;#34;&amp;#34;.main.func1·f(SB), AX 0x002b 00043 (main.go:6) PCDATA $2, $0 0x002b 00043 (main.go:6) MOVQ AX, 8(SP) 0x0030 00048 (main.go:6) CALL runtime.deferproc(SB) 0x0035 00053 (main.go:6) TESTL AX, AX 0x0037 00055 (main.go:6) JNE 117 // 第二个延迟函数 0x0039 00057 (main.go:10) MOVL $0, (SP) 0x0040 00064 (main.go:10) PCDATA $2, $1 0x0040 00064 (main.go:10) LEAQ &amp;#34;&amp;#34;.main.func2·f(SB), AX 0x0047 00071 (main.go:10) PCDATA $2, $0 0x0047 00071 (main.go:10) MOVQ AX, 8(SP) 0x004c 00076 (main.go:10) CALL runtime.deferproc(SB) 0x0051 00081 (main.go:10) TESTL AX, AX 0x0053 00083 (main.go:10) JNE 101 // main 函数结束 0x0055 00085 (main.go:18) XCHGL AX, AX 0x0056 00086 (main.go:18) CALL runtime.deferreturn(SB) 0x005b 00091 (main.go:18) MOVQ 16(SP), BP 0x0060 00096 (main.go:18) ADDQ $24, SP 0x0064 00100 (main.go:18) RET 0x0065 00101 (main.go:10) XCHGL AX, AX 0x0066 00102 (main.go:10) CALL runtime.deferreturn(SB) 0x006b 00107 (main.go:10) MOVQ 16(SP), BP 0x0070 00112 (main.go:10) ADDQ $24, SP 0x0074 00116 (main.go:10) RET deferproc 方法被调用了两次，并且内部调用了 newdefer 方法，我们之前已经看到该方法将我们的函数注册为延迟函数。之后，在函数的最后，在 deferreturn 函数的帮助下，延迟方法会被一个接一个地调用。
Go 标准库向我们展示了结构体 _defer 同样链接了一个 _panic *_panic 属性。来通过另一个例子看下它在哪里会起作用。
延迟和返回值 如规范所描述，延迟函数访问返回的结果的唯一方法是使用命名返回参数：
 如果延迟函数是一个匿名函数（ function literal ），并且所在函数存在命名返回参数，同时该命名返回参数在匿名函数的作用域中，匿名函数可能会在返回参数返回前访问并修改它们。
 这里有个例子：
func main() {  fmt.Printf(&amp;#34;with named param, x: %d\n&amp;#34;, namedParam())  fmt.Printf(&amp;#34;without named param, x: %d\n&amp;#34;, notNamedParam()) } func namedParam() (x int) {  x = 1  defer func() { x = 2 }()  return x }  func notNamedParam() (int) {  x := 1  defer func() { x = 2 }()  return x } with named param, x: 2 without named param, x: 1 确实就像这篇“defer, panic 和 recover”博客所描述的一样，一旦确定这一行为，我们可以将其与 recover 函数混合使用：
 recover 函数 是一个用于重新获取对恐慌（panicking）goroutine 控制的内置函数。recover 函数仅在延迟函数内部时才有效。
 如我们所见，_defer 结构体链接了一个 _panic 属性，该属性在 panic 调用期间被链接。
func gopanic(e interface{}) {  [...]  var p _panic  [...]  d := gp._defer // 当前附加的 defer 函数  [...]  d._panic = (*_panic)(noescape(unsafe.Pointer(&amp;amp;p)))  [...] } 确实，在发生 panic 的情况下，调用延迟函数之前会调用 gopanic 方法：
0x0067 00103 (main.go:21) CALL runtime.gopanic(SB) 0x006c 00108 (main.go:21) UNDEF 0x006e 00110 (main.go:16) XCHGL AX, AX 0x006f 00111 (main.go:16) CALL runtime.deferreturn(SB) 这里是一个 recover 函数利用命名返回参数的例子：
func main() {  fmt.Printf(&amp;#34;error from err1: %v\n&amp;#34;, err1())  fmt.Printf(&amp;#34;error from err2: %v\n&amp;#34;, err2()) }  func err1() error {  var err error   defer func() {  if r := recover(); r != nil {  err = errors.New(&amp;#34;recovered&amp;#34;)  }  }()  panic(`foo`)   return err }  func err2() (err error) {  defer func() {  if r := recover(); r != nil {  err = errors.New(&amp;#34;recovered&amp;#34;)  }  }()  panic(`foo`)   return err } error from err1: &amp;lt;nil&amp;gt; error from err2: recovered 两者的结合是我们可以正常使用 recover 函数将我们希望的 error 返回给调用方。 作为这篇关于延迟函数的文章的总结，让我们来看看延迟函数的提升。
性能提升 Go 1.8是提升 defer 的最近的一个版本（译者注：目前 Go 1.14 才是提升 defer 性能的最近的一个版本），我们可以通过运行 Go 的基准测试来看到这些提升（在 1.7 和 1.8 之间进行对比）：
 name old time/op new time/op delta Defer-4 99.0ns ± 9% 52.4ns ± 5% -47.04% (p=0.000 n=9&#43;10) Defer10-4 90.6ns ± 13% 45.0ns ± 3% -50.37% (p=0.000 n=10&#43;10) 这样的提升得益于这个提升分配方式的 CL ，避免了栈的增长。  不带参数的 defer 语句避免内存拷贝也是一个优化。下面是带参数和不带参数的延迟函数的基准测试：
 name old time/op new time/op delta Defer-4 51.3ns ± 3% 45.8ns ± 1% -10.72% (p=0.000 n=10&#43;10) 由于第二个优化，现在速度也提高了 10%。  via: https://medium.com/a-journey-with-go/go-how-does-defer-statement-work-1a9492689b6e
作者：Vincent Blanchon 译者：dust347 校对：unknwon
本文由 GCTT 原创编译，Go语言中文网 荣誉推出
本文由 GCTT 原创翻译，Go语言中文网 首发。也想加入译者行列，为开源做一些自己的贡献么？欢迎加入 GCTT！ 翻译工作和译文发表仅用于学习和交流目的，翻译工作遵照 CC-BY-NC-SA 协议规定，如果我们的工作有侵犯到您的权益，请及时联系我们。 欢迎遵照 CC-BY-NC-SA 协议规定 转载，敬请在正文中标注并保留原文/译文链接和作者/译者等信息。
</content>
    </entry>
    
     <entry>
        <title>linux ucontext族函数的原理及使用</title>
        <url>http://shanks.link/blog/2021/10/28/linux-ucontext%E6%97%8F%E5%87%BD%E6%95%B0%E7%9A%84%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BD%BF%E7%94%A8/</url>
        <categories>
          <category>c</category>
        </categories>
        <tags>
          <tag>c</tag>
        </tags>
        <content type="html"> 原文链接
ucontext函数族 这里的context族是偏向底层的，其实底层就是通过汇编来实现的，但是我们使用的时候就和平常使用变量和函数一样使用就行，因为大佬们已经将它们封装成C库里了的
我们先来看看寄存器 寄存器：寄存器是CPU内部用来存放数据的一些小型存储区域，用来暂时存放参与运算的数据和运算结果 我们常用的寄存器是X86-64中的其中16个64位的寄存器，它们分别是 %rax, %rbx, %rcx, %rdx, %esi, %edi, %rbp, %rsp %r8, %r9, %r10, %r11, %r12, %r13, %r14, %r15 其中
 %rax作为函数返回值使用 %rsp栈指针寄存器， 指向栈顶 %rdi, %rsi, %rdx, %rcx, %r8, %r9用作函数的参数，从前往后依次对应第1、第2、…第n参数 %rbx, %rbp, %r12, %r13, %r14, %r15用作数据存储，遵循被调用这使用规- 则，调用子函数之前需要先备份，防止被修改。 %r10, %r11用作数据存储，遵循调用者使用规则，使用前需要保存原值  ucontext_t ucontext_t是一个结构体变量，其功能就是通过定义一个ucontext_t来保存当前上下文信息的。 ucontext_t结构体定义信息如下
typedef struct ucontext  {  unsigned long int uc_flags;  struct ucontext *uc_link;//后序上下文  __sigset_t uc_sigmask;// 信号屏蔽字掩码  stack_t uc_stack;// 上下文所使用的栈  mcontext_t uc_mcontext;// 保存的上下文的寄存器信息  long int uc_filler[5];  } ucontext_t;  //其中mcontext_t 定义如下 typedef struct  {  gregset_t __ctx(gregs);//所装载寄存器  fpregset_t __ctx(fpregs);//寄存器的类型 } mcontext_t;  //其中gregset_t 定义如下 typedef greg_t gregset_t[NGREG];//包括了所有的寄存器的信息 12345678910111213141516171819 getcontext() 函数：int getcontext(ucontext_t* ucp) 功能：将当前运行到的寄存器的信息保存在参数ucp中
函数底层汇编实现代码（部分）：
ENTRY(__getcontext)  /* Save the preserved registers, the registers used for passing args, and the return address. */  movq %rbx, oRBX(%rdi)  movq %rbp, oRBP(%rdi)  movq %r12, oR12(%rdi)  movq %r13, oR13(%rdi)  movq %r14, oR14(%rdi)  movq %r15, oR15(%rdi)   movq %rdi, oRDI(%rdi)  movq %rsi, oRSI(%rdi)  movq %rdx, oRDX(%rdi)  movq %rcx, oRCX(%rdi)  movq %r8, oR8(%rdi)  movq %r9, oR9(%rdi)   movq (%rsp), %rcx  movq %rcx, oRIP(%rdi)  leaq 8(%rsp), %rcx /* Exclude the return address. */  movq %rcx, oRSP(%rdi) 123456789101112131415161718192021 我们知道%rdi就是函数的第一个参数，这里指的就是ucp。我们取一段代码大概解释一下 下面代码就是将%rbx内存中的信息先备份然后再将值传递保存到%rdi中
movq %rbx, oRBX(%rdi) 1 我们上面部分代码就是将上下文信息和栈顶指针都保存到我们ucontext_t结构体中的gregset_t[NGREG]，而gregset_t也就是我们结构体中的uc_mcontext的成员，所有调用getcontext函数后，就能将当前的上下文信息都保存在ucp结构体变量中了
setcontext() 函数：int setcontext(const ucontext_t *ucp) 功能：将ucontext_t结构体变量ucp中的上下文信息重新恢复到cpu中并执行
函数底层汇编实现代码（部分）：
ENTRY(__setcontext)  movq oRSP(%rdi), %rsp  movq oRBX(%rdi), %rbx  movq oRBP(%rdi), %rbp  movq oR12(%rdi), %r12  movq oR13(%rdi), %r13  movq oR14(%rdi), %r14  movq oR15(%rdi), %r15   /* The following ret should return to the address set with getcontext. Therefore push the address on the stack. */  movq oRIP(%rdi), %rcx  pushq %rcx   movq oRSI(%rdi), %rsi  movq oRDX(%rdi), %rdx  movq oRCX(%rdi), %rcx  movq oR8(%rdi), %r8  movq oR9(%rdi), %r9   /* Setup finally %rdi. */  movq oRDI(%rdi), %rdi 12345678910111213141516171819202122 我们可以看到和getcontext中汇编代码类似，但是setcontext是将参数变量中的上下文信息重新保存到cpu中
使用演示 setcontext一般都是要配合getcontext来使用的，我们来看一下代码
#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;ucontext.h&amp;gt; int main() { 	int i = 0; 	ucontext_t ctx;//定义上下文结构体变量  	getcontext(&amp;amp;ctx);//获取当前上下文 	printf(&amp;#34;i = %d\n&amp;#34;, i&#43;&#43;); 	sleep(1);  	setcontext(&amp;amp;ctx);//回复ucp上下文 	return 0; } 1234567891011121314151617 执行结果：在getcontext(&amp;amp;ctx);中，我们会将下一条执行的指令环境保存到结构体ctx中，也就是printf(“i = %d\n”, i&#43;&#43;)指令。然后运行到setcontext(&amp;amp;ctx)时就会将ctx中的指令回复到cpu中，所以该代码就是让cpu去运行ctx所保存的上下文环境，所以又回到了打印的那一行代码中，所以运行是一个死循环，而i值不变是因为i是存在内存栈中的，不是存在寄存器中的，所以切换并不影响i的值 makecontext() 函数：void makecontext(ucontext_t *ucp, void (*func)(), int argc, ...) 功能：修改上下文信息，参数ucp就是我们要修改的上下文信息结构体；func是上下文的入口函数；argc是入口函数的参数个数，后面的…是具体的入口函数参数，该参数必须为整形值
函数底层汇编实现代码（部分）：
 void __makecontext (ucontext_t *ucp, void (*func) (void), int argc, ...)  {  extern void __start_context (void);  greg_t *sp;  unsigned int idx_uc_link;  va_list ap;  int i;   /* Generate room on stack for parameter if needed and uc_link. */  sp = (greg_t *) ((uintptr_t) ucp-&amp;gt;uc_stack.ss_sp  &#43; ucp-&amp;gt;uc_stack.ss_size);  sp -= (argc &amp;gt; 6 ? argc - 6 : 0) &#43; 1;  /* Align stack and make space for trampoline address. */  sp = (greg_t *) ((((uintptr_t) sp) &amp;amp; -16L) - 8);   idx_uc_link = (argc &amp;gt; 6 ? argc - 6 : 0) &#43; 1;   /* Setup context ucp. */  /* Address to jump to. */  ucp-&amp;gt;uc_mcontext.gregs[REG_RIP] = (uintptr_t) func;  /* Setup rbx.*/  ucp-&amp;gt;uc_mcontext.gregs[REG_RBX] = (uintptr_t) &amp;amp;sp[idx_uc_link];  ucp-&amp;gt;uc_mcontext.gregs[REG_RSP] = (uintptr_t) sp;   /* Setup stack. */  sp[0] = (uintptr_t) &amp;amp;__start_context;  sp[idx_uc_link] = (uintptr_t) ucp-&amp;gt;uc_link;   va_start (ap, argc);  /* Handle arguments. The standard says the parameters must all be int values. This is an historic accident and would be done differently today. For x86-64 all integer values are passed as 64-bit values and therefore extending the API to copy 64-bit values instead of 32-bit ints makes sense. It does not break existing functionality and it does not violate the standard which says that passing non-int values means undefined behavior. */  for (i = 0; i &amp;lt; argc; &#43;&#43;i)  switch (i)  {  case 0:  ucp-&amp;gt;uc_mcontext.gregs[REG_RDI] = va_arg (ap, greg_t);  break;  case 1:  ucp-&amp;gt;uc_mcontext.gregs[REG_RSI] = va_arg (ap, greg_t);  break;  case 2:  ucp-&amp;gt;uc_mcontext.gregs[REG_RDX] = va_arg (ap, greg_t);  break;  case 3:  ucp-&amp;gt;uc_mcontext.gregs[REG_RCX] = va_arg (ap, greg_t);  break;  case 4:  ucp-&amp;gt;uc_mcontext.gregs[REG_R8] = va_arg (ap, greg_t);  break;  case 5:  ucp-&amp;gt;uc_mcontext.gregs[REG_R9] = va_arg (ap, greg_t);  break;  default:  /* Put value on stack. */  sp[i - 5] = va_arg (ap, greg_t);  break;  }  va_end (ap);  } 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566 这里就是将func的地址保存到寄存器中，把ucp上下文结构体下一条要执行的指令rip改变为func函数的地址。并且将其所运行的栈改为用户自定义的栈
使用演示 #include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;ucontext.h&amp;gt; void fun() { 	printf(&amp;#34;fun()\n&amp;#34;); }  int main() { 	int i = 0; 	//定义用户的栈 	char* stack = (char*)malloc(sizeof(char)*8192);  	//定义两个上下文 	//一个是主函数的上下文，一个是fun函数的上下文 	ucontext_t ctx_main, ctx_fun;  	getcontext(&amp;amp;ctx_main); 	getcontext(&amp;amp;ctx_fun); 	printf(&amp;#34;i = %d\n&amp;#34;, i&#43;&#43;); 	sleep(1);  	//设置fun函数的上下文 	//使用getcontext是先将大部分信息初始化，我们到时候只需要修改我们所使用的部分信息即可 	ctx_fun.uc_stack.ss_sp = stack;//用户自定义的栈 	ctx_fun.uc_stack.ss_size = 8192;//栈的大小 	ctx_fun.uc_stack.ss_flags = 0;//信号屏蔽字掩码，一般设为0 	ctx_fun.uc_link = &amp;amp;ctx_main;//该上下文执行完后要执行的下一个上下文 	makecontext(&amp;amp;ctx_fun, fun, 0);//将fun函数作为ctx_fun上下文的下一条执行指令  	setcontext(&amp;amp;ctx_fun);  	printf(&amp;#34;main exit\n&amp;#34;); 	return 0; } 1234567891011121314151617181920212223242526272829303132333435363738 运行结果：当执行到setcontext(&amp;amp;ctx_fun)代码时会去运行我们之前makecontext时设置的上下文入口函数所以在打印i完后会打印fun()，然后我们设置ctx_fun上下文执行完后要执行的下一个上下文是ctx_main，所以执行完后会执行到getcontext(&amp;amp;ctx_fun)，所以最后也是一个死循环 swapcontext() 函数：int swapcontext(ucontext_t *oucp, ucontext_t *ucp) 功能：将当前cpu中的上下文信息保存带oucp结构体变量中，然后将ucp中的结构体的上下文信息恢复到cpu中 这里可以理解为调用了两个函数，第一次是调用了getcontext(oucp)然后再调用setcontext(ucp)
函数底层汇编实现代码（部分）：
ENTRY(__swapcontext)  /* Save the preserved registers, the registers used for passing args, and the return address. */  movq %rbx, oRBX(%rdi)  movq %rbp, oRBP(%rdi)  movq %r12, oR12(%rdi)  movq %r13, oR13(%rdi)  movq %r14, oR14(%rdi)  movq %r15, oR15(%rdi)   movq %rdi, oRDI(%rdi)  movq %rsi, oRSI(%rdi)  movq %rdx, oRDX(%rdi)  movq %rcx, oRCX(%rdi)  movq %r8, oR8(%rdi)  movq %r9, oR9(%rdi)   movq (%rsp), %rcx  movq %rcx, oRIP(%rdi)  leaq 8(%rsp), %rcx /* Exclude the return address. */  movq %rcx, oRSP(%rdi)      /* Load the new stack pointer and the preserved registers. */  movq oRSP(%rsi), %rsp  movq oRBX(%rsi), %rbx  movq oRBP(%rsi), %rbp  movq oR12(%rsi), %r12  movq oR13(%rsi), %r13  movq oR14(%rsi), %r14  movq oR15(%rsi), %r15   /* The following ret should return to the address set with getcontext. Therefore push the address on the stack. */  movq oRIP(%rsi), %rcx  pushq %rcx   /* Setup registers used for passing args. */  movq oRDI(%rsi), %rdi  movq oRDX(%rsi), %rdx  movq oRCX(%rsi), %rcx  movq oR8(%rsi), %r8  movq oR9(%rsi), %r9 123456789101112131415161718192021222324252627282930313233343536373839404142434445 我们一开始就知道%rdi就是我们函数中的第一参数，%rsi就是函数中的第二个参数。汇编代码中就是将当前cpu中的上下文信息保存到函数的第一个参数中，然后再将第二个参数的上下文信息恢复到cpu中
使用演示 #include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;ucontext.h&amp;gt; ucontext_t ctx_main, ctx_f1, ctx_f2;  void fun1() { 	printf(&amp;#34;fun1() start\n&amp;#34;); 	swapcontext(&amp;amp;ctx_f1, &amp;amp;ctx_f2); 	printf(&amp;#34;fun1() end\n&amp;#34;); }  void fun2() { 	printf(&amp;#34;fun2() start\n&amp;#34;); 	swapcontext(&amp;amp;ctx_f2, &amp;amp;ctx_f1); 	printf(&amp;#34;fun2 end\n&amp;#34;); }  int main() { 	char stack1[8192]; 	char stack2[8192];  	getcontext(&amp;amp;ctx_f1);//初始化ctx_f1 	getcontext(&amp;amp;ctx_f2);//初始化ctx_f2  	ctx_f1.uc_stack.ss_sp = stack1; 	ctx_f1.uc_stack.ss_size = 8192; 	ctx_f1.uc_stack.ss_flags = 0; 	ctx_f1.uc_link = &amp;amp;ctx_f2; 	makecontext(&amp;amp;ctx_f1, fun1, 0);//设置上下文变量  	ctx_f2.uc_stack.ss_sp = stack2; 	ctx_f2.uc_stack.ss_size = 8192; 	ctx_f2.uc_stack.ss_flags = 0; 	ctx_f2.uc_link = &amp;amp;ctx_main; 	makecontext(&amp;amp;ctx_f2, fun2, 0);  	//保存ctx_main的上下文信息，并执行ctx_f1所设置的上下文入口函数 	swapcontext(&amp;amp;ctx_main, &amp;amp;ctx_f1); 	printf(&amp;#34;main exit\n&amp;#34;); 	return 0; } 12345678910111213141516171819202122232425262728293031323334353637383940414243444546 运行结果：定义三个上下文变量，ctx_main、ctx_f1、ctx_f2。当执行到swapcontext(&amp;amp;ctx_main, &amp;amp;ctx_f1)时会执行fun1函数，然后打印fun1() start。再执行swapcontext(&amp;amp;ctx_f1, &amp;amp;ctx_f2)，也就是保存ctx_f1的上下文，然后去执行ctx_f2的上下文信息，也就是fun2函数，所以会打印fun2() start。执行到swapcontext(&amp;amp;ctx_f2, &amp;amp;ctx_f1);是会切换到fun1当时切换时的上下文环境，此时会打印fun1() end，ctx_f1上下文执行完后会执行之前设置的后继上下文，也就是ctx_f2，所以会打印fun2 end。fun2函数执行完会执行ctx_f2的后继上下文，其后继上下文为ctx_main，而此时的ctx_main的下一条指令就是printf(“main exit\n”)，所以会打印main exit </content>
    </entry>
    
     <entry>
        <title>数学之美每章小结</title>
        <url>http://shanks.link/blog/2021/10/09/%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E%E6%AF%8F%E7%AB%A0%E5%B0%8F%E7%BB%93/</url>
        <categories>
          <category>algorithm</category>
        </categories>
        <tags>
          <tag>algorithm</tag>
        </tags>
        <content type="html"> 原文链接
书评：本书讲的是道而不是术，真正的术还要自己细致的研究下去，目前看的第一遍总结的不是很好，后面再看会继续完善。
 第1章：文字和语言VS数字和信息 1.文字和数字 讲了一堆古代文字，其实就是为了引出下面两个概念用于翻译
1.信息的冗余是安全保障
2.古代语料的多样性（一个句子或者词多种写法）对翻译很有用
2.文字和语言背后的数学 1.古代人讲话宽信道，而传竹筒是窄信道，所以我们古时候就有压缩这个思想啦
2.圣经有90-100W字，犹太人很认真，但是还是会错误，所以出现校验码的思想（每个字都是一个数字，每行内相加都是一个固定值，能查出改行是否出错）
3.语言中的语法肯定会有人不精确，这个无法避免，最后实践表明，我们要从语言出发，而不是语法，因为语法我很难完全遵守
3.总结思考 ​ 1.通信原理
​ 2.最短编码（哈夫曼）,编码(文字和数字其实就是一种不同的编码)
​ 3.解码规则、语法
​ 4.聚类（相类的东西聚集在一起，类似K-means）
​ 5.校验 （检测信息错误）
​ 6.语义，语料，双语对照，机器翻译
​ 7.利用上下句和多意性消除歧义
​ 以上就是结合故事说明的与数学相关的规律啦
第2章：自然语言处理-规则到统计 回答了2个问题：计算机可以处理自然语言，且方法可以做到与人一样，所以有研究下去的意义。
 机器智能  1避免误区：机器不可能做到人脑那样学习语言，而是要通过数学模型和统计方法的实现的。
2.两个路线：语法分析和语义分析，英文通常语法分析，而中文以前通常是语义分析
3.机器分析句子：
1）普通的，主谓宾直接分，很简单
2）复杂的，可能主谓宾宾补，或者主语有同位语，普通机器根本没法分析，因为规则太多，就算规则都已经完备，但是目前计算机也计算不过来呀，所以完全语义规则分析不可行，需要过渡到结合下面的统计
4.规则到统计：语言机器很难用规则来翻译而是依赖于上下文，甚至常识，渐渐的过度到利用统计翻译机器语言（所以要打破常规，不要固执于一个思想，就像文章里面的老科学家的固执，表现出作者想在意识清晰（固执）之前退休）。
2.总结： ​ 自然语言的发展，从语法语义过度到现在的统计，不要墨守成规。
第3章：统计语言模型 1.最简单的统计模型： P(S) = P(w1)P(w2|w1)P(w3| w1 w2)…P(wn|w1 w2…wn-1)
这样的方式在计算上比较麻烦，而有了一个较为偷懒的假设“马尔科夫假设”，假设后一个词的出现只与前一个词相关，公式的形状如下：
P(S) = P(w1)P(w2|w1)P(w3|w2)…P(wi|wi-1)
最终是 P(wi | wi-1) = P(wi-1,wi)/P(wi-1)
这种假设的局限性在于：“在自然语言中，上下文之间的相关性跨度可能很大，甚至可以从一个段落跨到另一个段落。因此即便再怎么提高模型的阶数，对这种情况也无可奈何.”
2.解决跨度：
目前最高的是google的4元模型，上面是相邻的两个相关词，跨度为1，如果是跨度为2,3时即为3、4元模型，P(wi |w1，w2，········……… wi-1) = P(wi | wi-n&#43;1，wi-n&#43;2, ……….,wi-1)
3.训练模型：0概率（非平滑）和平滑方法： 1.使用语言模型需要知道模型中所有的条件概率，我们称之为模型的参数。通过对语料的统计，得到这些参数的过程称作模型的训练。
2.一般来说P(wi | wi-1)是有可能出现0和1概率的，而且很多时候不合理，增加数据量（大数定理就完全能解决，但是不可能完全的大数）虽然可以避免大多数这些情况，但是还是会出现，所以需要解决。这里使用了古德图灵估计的方法，把未看见事件分配一个不为0的概率从而使整体概率平。
第4章：谈谈中文分词 1.中文分词的演变： 一开始是以字典法进行分词，但是二义性太大啦，渐渐的也由规则演变成基于统计的分词方法，而且实践中他也非常有效。（动态规划和维特比算法），需要注意的是，在不同应用中需要用到不同的分词器
2.分词的一致性和粒度、层次问题： 不同的人分词粒度是不同的，比如北京大学，有些人可能会分为北京-大学，而有些人直接理解为一整个词，这就是分词粒度，和一致性的问题，所以对于不同层次的次，我们需要挖掘出更多的复合词，从而完善复合词词典。
第5章：隐含马尔可夫模型 １.通信模型： 语言输入（ｓ１，ｓ２，ｓ３……ｓｎ）编码―――》语言输出（ｏ１，ｏ２，ｏ３……ｏｎ）解码
２.马尔可夫链： 天气状态可假设为ｍ１，ｍ２，ｍ３，ｍ４之间的转换
​ 可以用概率来统计，比如有很多天的天气预报，我们知道ｍ２天为ｊ次，ｍ３天为ｋ次，以此类推，最后他们的比值除以总数就是他们的状态改变概率（其中每个状态只和前面一个有关）。
３.隐含马尔可夫模型： 是马尔可夫的一个拓展，我们根据前面的语音输入ｓ１，ｓ２，ｓ３……ｓｎ――》输出ｏ１，ｏ２，ｏ３……ｏｎ，其中ｓ１，ｓ２，ｓ３……ｓｎ的概率值我们是能计算的出来的，而ｏ１，ｏ２，ｏ３……ｏｎ，我们没法得知，他是一个不可见的状态，但是我们大概知道一个每个时刻的ｓｔ会输出特定的ｏｔ，也就是说他们之间有一个特定的函数，从而我们可以推导出ｏｔ的大概输出。
​ 所以通信的解码可以利用隐含马尔可夫模型来解决，完全没想到可以这样做·······…太牛了！
４.总结： 需要２种算法：训练算法（鲍姆－韦尔奇算法），解码算法（维特比算法）之后才能使用隐含马可夫模型这个工具
第6章：信息的度量和作用 1.信息熵 ，也就是，单位为比特。
2.信息的作用： 信息的作用是用于消除不确定性，自然语言处理的最大问题就是为了找到相关信息，比如我们根据前面章节可知一元模型，直接找信息，二元模型是根据上下文来找信息，所以可以把1的公式改为其中x在y的条件下得到的信息概率。
3.互信息： 书里有个句子，就是bush到底是总统还是灌木丛，这种二义性的问题很难用语法和规则等方法解决，但是根据上下文，如出现美国，华盛顿等字样就可以知道他是总统啦，如果是土壤，植物就可以证明他是灌木丛的意思，这就是互信息的作用，其中信息的条件熵差异为：，X,Y完全相关时取值为1，无关时为0
4.相对熵： ​ ​ 第7章：贾里尼克和现代语言处理 1.作者和贾里尼克教育观点： 学习不一定要学的早，晚点学也一样，因为错过了成长的乐趣反而更加不好，作者举例了一个中学学500小时，大学只需要100小时就能学完的例子（这里非常赞同）。
2.大师都只讲哪里不要做，而不是做什么： 这里跟第22章的布莱尔的想法很像，就是能根据已经有的经验快速否定掉一种不太可能的方案，防止别人走进岔路。
3.一个老实人的奇迹： 说了贾里尼克做了很多大事，同时主要讲到他是个很严格的人，作者可能认为他这样会经常得罪人，然而事实并非如此，所以作者下结论他是个公正的人，尽管他很严厉。
第8章 简单之美 布尔代数和搜索引擎 1搜索引擎三要素： *自动下载*尽可能多的网页；建立快速有效的索引；根据相关性对网页进行公平准确的排序**，其中主要讲索引
2.布尔运算： 比如搜索一篇文章为原子能而不要应用这个词的文章，先第一次全网搜索有原子能的文章比如10101010111100000····，1为出现，0为未出现，这个二进制串非常长，然后在同样找没有应用关键字的文章如10101111110000000···，然后在把上面两个进行布尔运算，最后就是结果啦。
3.索引： 根据上面的布尔，的前提就是要每个网页都有关键字的索引，否则会非常慢，同时就算有每个网页都有关键字索引，那这个索引表也会非常大，并且索引表的附加信息也会非常多，所以根据索引和布尔运算得到需要的结果就需要分布式来运算解决。
第9章：图论和网络爬虫 1.两种图遍历方法： DFS，BFS
2.网络爬虫： 其实就是根据上面的这两种遍历方法，遍历网页，并下载，但是这种下载量非常大，需要分布式进行操作
3.欧拉定理： 如果一个图从顶点出发，每条边不重复的遍历一遍回到这个顶点，那么需要每个顶点的度一定为偶数
4.网络爬虫搜索和下载方式： 网络爬虫一般BFS优于DFS，因为我们一般首选需要各个网站的首页，再要其其他页面，所以先广度搜索尽可能多的不同类型页面，再把页面进行广度搜索，当然不是简单的广度搜索，其次是下载方式，因为下载和搜索是分离的两个服务器，为了避免多次握手，所以先把一个下载完再下载另一个，而不是向电路交换一样一部分一部分的下载，这时就需要一个调度系统管理下载的调度问题。
第10章：pagerank—google的民主表决式网名，网页排序算法思想 1.pagerang的核心思想： 民主表决，其实就是如果一个网页被其他很多网页超链接，那么他普遍被承认和信赖，所以他的排名就高。同时还要分权处理，来自排名高的网页链接权重应该加大，但是这样的话想知道权重又得知道他们的排名（相当于先有鸡还是先有蛋问题），文章讲到用了二维矩阵相乘的思想，一开始权重都相同，计算一轮后再迭代一轮，得出二次排名即为可靠的，由于矩阵计算量非常大，他们使用了稀疏矩阵来解决，具体看书的延展阅读。
第11章：如何确定网页和查询的相关性 1.词频率： 如搜索“原子能的应用”在某一个1000词的网页中出现2、35、5次，那么词频率分别为0.002、0.035、0.005，相加就是总的词频率
2.去除暂停词： 一般来说，上面的“的”次出现次数高，且没什么意义，一般都不考虑这些词，即他的词权重为0
3.词权重作用： 上面的“原子能的应用”，我们看到原子能才是他的中心词，而应用这个词很泛，所以应该给他不同的权重
4. 词权重方法： 词权重一般使用“逆文本频率指数”即log(D/Dw)，其中D为所有网页数，Dw为命中网页数，带入公式后就是这个词所占的权重，然后词频率和权重交叉相乘后相加就能得到想要对应的TF-IDF值啦。
第12章：地图和本地搜索的最基本技术—有限状态机和动态规划 1.有限状态机： 从开始状态到终止状态，每个状态的转变都严格匹配，否则不匹配，
​ 由于自然语言比较随意，很难完全做到准确匹配，这时就要引入基于概率的有限状态机了，就跟马尔可夫模型一样。
2.动态规划： 1.划分子问题2.确定动态规划函数3.计算后填入表格4.重复操作
3.有限状态传感器： WFST模型他就是在有限状态机下加入不同的概率走势，也就是说他跟我们之前学的二元模型是类似的，每一个二元模型都能用有限状态传感器描述。
第13章：Google AK-47 的设计者——阿密特·辛格博士—寻求简单的哲学 1.简单的哲学思想： *做事可以简单解决就先解决，不一定完全的追寻效益问题，就比如文章所说的，作者写了个中文搜索算法，虽然速度快，但是消耗内存大，辛格博士他建议用拟合函数代替训练模型，但是效率会降低很多，作者一开始不赞同，但是他还是这么做了，最后证明出先简单解决问题，提供给用户使用，后面再继续优化才是最好的，而不应该一开始就急于求成，做到最好那种。*
*第**14**章：余弦定理和新闻分类* 1.新闻分类思想： *使用了前面的**TF-IDF**思想，确定新闻间的相关性，然后进行分类*
2.具体步骤： *1**）我们对于一个词表比如有**64000**个词，进行编号。*
​ *2**）某一篇文章进行**TF-IDF**值计算（方法看第**11**章）*
​ *3**）重复上面步奏，把其他文章进行运算计算其**TF-IDF**值，封装成向量。*
​ *4**）把上面的文章两两进行余弦运算：*
*因为我们知道每个文本的词数量不一样，可能有的**10000**词，有的**100**词，直接对比**TF**值是不合理的，因为对应的向量长度不一，但是他们的方向是可能一致的，所以只需要计算其两个向量的夹角就可以知道两篇新闻是否相类似了。*
​ ​ *5**）分类，根据字典一样把某一新闻归类到某一处，直接余弦相似度运算即可分类了*
*但是有一个问题，就是怎么知道有多少个类别呢？*
 *手动写，麻烦，容易错误* *自动生成：自底向上不断合并*  ​ 3.优化方法 ​ 1.可以先把每个文章的词频率计算好来封存，两两余弦计算时直接提取即可
​ 2.余弦内积时，由于大量的元素为0，所以我们只要计算非零元素。
​ 3.删除虚词的计算，比如‘的’、‘地’，这些词一般数量非0但是又是一种无用的干扰项， 同时还会影响权重，所以去除后计算会更合理更快
4.补充：位置加权，比如文章开头和结尾的权重应该高一些，也就是文章开头和结尾的词权重可以提高后再计算，类似TF-IDF模型。
第15章：矩阵运算和文本处理中的两个分类问题 1.本章解决一个问题： 如果使用第十四章中引入的向量距离的方法，对数以亿计的网页进行距离计算，计算量过于巨大，而引入了矩阵的运算来计算新闻之间的相似性，一次性把多个新闻的相似性计算出来。利用了矩阵运算中的奇异值分解。（有没有联想到《线性代数》中矩阵之间向量的线性相关的运算？）
这种方式，将多个新闻的向量组成的矩阵分解为三个小矩阵相乘，使得计算存储量和计算量小了三个数量级以上。
2.步骤： 1）有n个词，M篇文章，形成M*N矩阵，其中aij代表第j个词在第i篇文章（行词列文章）出现的 加权词频（比如TF-IDF值）
​ 2）奇异值分解，把上面的A大矩阵转化为3个小矩阵相乘
​ 其中，比如X矩阵中每行代表一个词(行)在词类（列）（语义相近的词类）的相关性
Y矩阵中每列对应一个文本，每行代表一个主题，即每一个主题（行）在文本（列）的相关性
B矩阵中即为每个词类（行）对应的主题（列）相关性。
3.效果： 只要对新闻关联性矩阵进行一次奇异值分解，既可同时完成近义词分类和文章的分类。
4.计算方法： 庞大的网页量，使得计算量非常大，因此需要很多的计算机并行处理。
第16章：信息指纹及其应用 1.信息指纹： 能唯一代替某一网络信息，比如之前的网页hash表存网址太浪费内存啦，直接用伪随机数代替该表中的地址能节省很多内存空间。同时网络传输也需要加密，比如MD5不能逆向破解就是一个很好的加密方式。
2.判断两集合相同： ​ 1）一一比较，O（N2），太慢
​ 2）两个集合先排序，再一一比较O（logN），相对慢
​ 3）先把一个集合放到hash表，再一一比较O（N）快，但是消耗多了N个内存
​ 4）直接用信息指纹，把每个集合内的元素都相加再比较即可（不需要排序就可以比较）
3.判断两集合基本相同： 1）比如用两个账号发送垃圾邮件，邮件大体相同，个别不同，所以我们可以抽取比如发送尾号为24的邮件，然后再用信息指纹的第四种方法就好啦（基本能鉴别出来）。
2）网页或者文章对比，可以先用IDF方法鉴别词频率（去除掉只出现一次或者少次的噪音词），然后再抽取关键字进行信息指纹识别就好啦，如果是文章的话把文章切成一小段一小段的，然后一样IDF方法选取特征词进行信息指纹鉴别即可。
4.Youtube反盗版： 他其实就是拿去视频的关键帧进行信息指纹对比，从而判断出哪些是盗版的，同时把广告收益给商家，而盗版的没收益，所以盗版的就少啦。
第17章：由电视剧《暗算》所想到的—密码学 1.公开密钥加密步骤： ​ 1）随便选一个密码转为3位的ASCII码数字
​ 2）加密：
​ 1.找2个很大的数P、Q然后计算N=P×Q M=（P-1）×（Q-1）
​ 2..找一个和M互素的整数E，即M和E除了1没有公约数
​ 3.找一个整数D，使得(E×D)%M==1
加密成功后D就是私钥（解密），E是公钥（加密），N是公开的
​ 2.总结： 信息论虽然能让我们知道信息越多，就能消除更多的不确定性从而解密，但是密码学就是让我们无论知道多少信息，都无法消除不确定因素从而解密
第18章：闪光的不一定是金子 — 谈谈搜索引擎 1.网页作弊： 就是根据搜索引擎的算法，得到更高的网站排名
2.两种作弊方式： 作弊1：比如可以提高网站相关词频数，然后隐蔽，这样就能得到较高的TF-IDF值啦，
解决1：对异常高的网页做一下分析就可以，比较简单
作弊2：出卖网站的出链接，由于我们前面章节知道网站被越多其他网站引用就会得到越高的排名
解决2：出链的网站到其他网站数目可以作为一个向量，也是这个网站固有的特征，既然是向量，就可以用余弦定理计算相似度，有些网站出链量相似度几乎为1,此时就是可以知道这些是卖链接的网站啦。
3.总结： 提高网站质量才是关键。
第19章：谈谈数学模型的重要性  一个正确的数学模型应当在形式上是简单的。（托勒密的模型显然太复杂。） 一个正确的模型在它开始的时候可能还不如一个精雕细琢过的错误的模型来的准确， 但是如果我们认定大方向是对的，就应该坚持下去。（日心说开始并没有地心说准确。） 大量准确的数据对研发很重要。 正确的模型也可能受噪音干扰，而显得不准确；这时我们不应该用一种凑合的修正方法来弥补它，而是要找到噪音的根源，这也许能通往重大发现  第20章：不要把鸡蛋放到一个篮子里—最大熵 1.最大熵原理： 说白了，就是要保留全部的不确定性，将风险降到最小。
“不要把鸡蛋放在一个篮子里，是最大熵原理的一种朴素说法。”
2.最大熵原理指出： 当我们需要对一个随机事件的概率分布进行预测时，我们的预测应当满足全部已知的条件，而对未知的情况不要做任何主观假设。（不做主观假设这 点很重要。）
 *最大熵模型存在的【证明】*****：****匈牙利著名数学家、信息论最高奖香农奖得主希萨（Csiszar）证明，对任何一组【不自相矛盾】的信息，这个最大熵模型不仅存在，而且是唯一的。而且它们都有同一个非常简单的形式 &amp;ndash; 指数函数。 书提到的最大熵原理【应用】：  拼音和汉字的转换：1.根据语言模型：wang-xiao-bo 可以转换为：王小波 和 王晓波两种情况。2.根据主题，王小波是作家《黄金时代》的作者，而王晓波是研究两岸关系的学者。根据这两种信息创建一个最大熵模型       - ![img](https://img-blog.csdnimg.cn/20200618191653569.jpeg) ![img](https://img-blog.csdnimg.cn/20200618191653571.jpeg) - ![img](https://img-blog.csdnimg.cn/20200618191653571.jpeg) ![img](https://img-blog.csdnimg.cn/20200618191653572.jpeg) - ![img](https://img-blog.csdnimg.cn/20200618191653575.jpeg)  最大熵模型应用于信息处理优势的第一次验证：
应用最大熵原理，创建了当时世界上最好的词性标识系统和句法分析器。其做法即为使用最大熵模型成功的将上下文信息、词性、名词、动词、形容词等句子成分、主谓宾统一了起来。
   2000年以后，句法分析、语言模型和机器翻译，都开始使用最大熵模型。 对冲基金使用最大熵。 孪生兄弟的达拉皮垂他们在九十年代初贾里尼克离开 IBM 后，也退出了学术界，而到在金融界大显身手。他们两人和很多 IBM 语音识别的同事一同到了一家当时还不大，但现在是世界上最成功对冲基金(hedge fund)公司&amp;mdash;-文艺复兴技术公司 (Renaissance Technologies)。我们知道，决定股票涨落的因素可能有几十甚至上百种，而最大熵方法恰恰能找到一个同时满足成千上万种不同条件的模型。达拉皮 垂兄弟等科学家在那里，用于最大熵模型和其他一些先进的数学工具对股票预测，获得了巨大的成功。    来源： http://www.cnblogs.com/KevinYang/archive/2009/02/01/1381798.html
 最大熵模型的【训练】：  计算量庞大的【*GIS**】*：GIS 最早是由 Darroch 和 Ratcliff 在七十年代提出的。 GIS 算法每次迭代的时间都很长，需要迭代很多次才能收敛，而且不太稳定，即使在 64 位计算机上都会出现溢出。因此，在实际应用中很少有人真正使用 GIS。大家只是通过它来了解最大熵模型的算法。    3.改进的迭代算法【IIS】： 八十年代，孪生兄弟的达拉皮垂(Della Pietra)在 IBM 对 GIS 算法进行了两方面的改进，提出了改进迭代算法 IIS（improved iterative scaling）这使得最大熵模型的训练时间缩短了一到两个数量级。这样最大熵模型才有可能变得实用。即使如此，在当时也只有 IBM 有条件是用最大熵模型。
4.吴军的改改进和他的论文：（链接在此） 发现一种数学变换，可以将大部分最大熵模型的训练时间在 IIS 的基础上减少两个数量级
第21章：拼音输入法的数学原理 1.汉字输入法的的快慢： 由击键次数乘以寻找这个键所需要的时间
2.编码速度的快慢： 由拼音编码和消除歧义性编码（数字键盘）快慢决定
3.双拼到全拼的转变： 前面双拼他虽然减少了击键次数，但是别人消除歧义以及击键的思考的时间都变长了，不利于学习以及速度总体慢，后来出现了全拼（也就是我们现在所用的拼音输入），虽然击键次数变多了，但是学习成本和思考成本降低，同时容错率也提高了，所以速度很快
4.主要引入的数学原理是：  *中文输入法的击键次数的数学原理* 【香农第一定理】指出：对于一个信息，任何【编码长度】都不小于它的【信息熵】。因此，上面的平均编码长度的最小值就是汉字的信息熵，任何输入法不能突破信息熵给定的极限。 【汉字信息熵的计算】在GB2312中一共有6700左右个常用汉字。 a. 假定每个汉字出现的相对频率为：b. 编码长度c. 平均编码长度：d. 得出汉字的信息熵：不考虑上下文的关系，信息熵的大小大约为【10bit】 e. 单个字母代表的信息熵：假定输入法只能要我26个字母来输入，那么每个字母可以代表log26 = 4.7 比特的信息，也就是说，一个汉字的输入，平均需要10/4.7 约为2.1 次击键。 f.组成词后信息熵减少： 如果把汉字组成词组，再以词为单位统计信息熵，那么每个汉字的平均信息熵就会减少。如果不考虑上下文关系，汉字的信息熵大约是8bit，以词为单位每个汉字平均只需要8/4.7 = 1.7次击键 g. 考虑上下文信息信息熵进一步减少：如果考虑上下文关系对汉语建立一个基于词的统计语言模型，可以将汉字的信息熵降低到6bit左右。此时平均需要的击键次数约为：6/4.7 1.3次击键 。如果一种输入法能够做到这一点那么汉字的输入就比英文快多了。（我觉得手机的9宫格汉字输入法挺给力的。） 【全拼输入法的信息熵】汉语全拼平均长度为2.98，只要基于上下文能彻底就解决一音多字的问题，平均每个汉字的输入应该在3个键以内。可以实现汉字拼音输入一部分后提示出相应的汉字。 如何利用上下文呢？  *思考总结：现在的输入法需要提升就是看谁能建立更好的语言模型以及转成汉字的算法。*
 *拼音转汉字的动态规划算法：* 【输入法做的事情】是：按照输入的序列，查找该条件下的句子。 图中 y 代表输入的拼音字符串，w代表输出候选汉字。每一个句子和途中的一条路径对应。 拼音输入法的问题，变成了一个寻找最优路径的问题。 【最优路径】 和计算城市间的最优路径不同，其中的距离是实际上的一个点到另一个点的距离，而在拼音输入法的路径中，两个候选词之间的距离是w伸向下一级w的概率。 实际上输入法作出的计算是这样，输入一串拼音字母字符，软件通过模型计算出与词拼音对应的出现概率最大的汉字候选结果。  3.训练一个用户特定模型：
​ ​ 大多数情况下M1,模型会比M0模型要好，但是如果输入偏僻字的时候反而M0模型比较好，
根据最大熵定理，我们都要把各种情况综合在一起才是最好的，同时这个模型训练时间也
比较长，所以下面引出了线性插入模型：
​ 第22章：自然语言处理的教父马库斯 1.马库斯： 1）他第一个考虑到了语料库的重要性，也第一个做出了很多LDC语料库
2）他不限制学生方向，而是根据独特的眼光给予支持
2.柯林斯： 数学之美一书都是讲简单为主，但是柯林斯却是个特例，他不是为了一个理论而研究，而是为了做到极致，比如他做的文法分析器。
3.布莱尔： 跟作者一样，都是以简单为美，虽然不能立刻知道某事该怎么做，但是能立刻否定掉一种不可能的方案，从而寻求简单的方法。代表算法：基于变换规则的机器学习算法：
​ 第23章：布隆过滤器 1.提出前提： 之前我们讲过垃圾邮件的识别，从一一对应到hash，这两种都不是很好，所以后来作者推荐用了信息指纹这个东西，也就是一个伪随机数，其中这个随机数是否出现过就需要用到布隆过滤器啦
2.步骤： 先建立一个16E位的二进制数组，全部置为0，对每一个邮件用随机数生成器（F1，F2，F3```F8）生成8位不同的信息指纹（f1，f2,·······…f8），然后把这8位随机数全部置为1后映射到刚才的16E位数去，当第二次又有同一个邮件时以同样的方式映射会发现映射的位置都置为1了，此时就可以判断该邮件出现过啦
​ 但是该模型有一定的缺陷，虽然很小的概率会识别错误，但是还是有可能识别错误的，此时可以建立一个白名单来解决
第24章：马尔可夫链的扩展 — 贝叶斯网络 1.贝叶斯网络： 假定马尔可夫链成立，也就是说每个状态和和他直接相连的状态有关，和间接状态没有关系，那么他就是贝叶斯网络，同时图中的弧可以有权重，其中A到C可能不是直接相关，但是不代表他没没有关系，他们可能可以由一个间接状态来关联，比如B
​ 具体内容他就是利用贝叶斯公式计算出每一个状态到另外一个状态转移的概率，具体可以看书本有个例子，不过需要一点概率基础，贝叶斯网络其实就是马尔可夫链的一个拓展，看似简单，但是实现起来非常复杂。
第25章：条件随机场和句法分析 1.条件随机场： 他其实是一个隐含马尔可夫的拓展，我们假定x1、x2、x3为观测值，y1、y2、y3表示隐含的序列，其中x2的状态由y2的状态决定，和y1、y3无关，但是实际中他们很有可能是有关的，如果把y1、y2、y3都考虑进来，那么他就是一个条件随机场啦，其中条件随机场还是遵循隐含马尔可夫链的原则的，比如y1、y2、y3还是一个马尔可夫链，x1和y1之间的关系是一个概率关系，跟前面一样。其中他与贝叶斯网络的区别是条件随机场是一个无向图，而贝叶斯是个有向图
​ 2.条件随机场的语句浅层分析： 这里看的不是太懂，后续看懂了再更新
第26章：维特比和他的维特比算法 1.维特比算法的提出： ​ 我们知道最短路径是由动态规划解决的，而篱笆网络有向图的最短路径则是由维特比算法来解决的，所以隐含马尔可夫算法里面的解码都可以用它来解决。
2.维特比算法详解： 这个算法的好处就在于把运算的复杂度从10^16降到了O(N*D²）(D宽度（列），N网长度（行）)10^3,降低了非常多。
第27章：再谈文本自动分类问题 — 期望最大化 1.文本自动收敛分类： ​ 假如有N个文本对应N个向量V1、V2……Vn，希望把他分到K个类中，这K个类的中心是C1、C2………Ck，分类步骤如下：
​ ​ ​ ​ 这样重复下去就可以自动分类啦。
2.期望最大化和收敛必然性： ​ 如果距离函数设计的好，那么d（各个文本向量到类中心平均距离）更小，而D（各个类中心的距离）更大，即从而多次迭代后得到最优分类。
在机器学习中，这D和d可以分为2个过程：
​ 其中根据现有模型计算结果为期望（E），通过模型多次计算（多次训练）最大化期望（M）,所以叫做EM算法。
第28章：逻辑回归和搜索广告 1.网站广告问题： 百度和雅虎就不说了，谁出钱多就谁的广告在前面，这里说google的广告竞争问题，一开始作者提出可以由用户搜索数，和广告点击数的比率来看该广告是否合理：
​ 但实际上并不那么简单，1，新广告没数据，不合理2，很有可能数据不足，比如只有各广告只被查询过一次，不能说点击过3就比2次的广告好。3，放在第一位的广告明显比第二位的好，排名自然高。
2.逻辑回归模型： ​ 其中里面的Xi为影响变量，比如广告展现位置，展现时间等等
Βi为为一个特殊的参数由人工神经网络训练未来的参数
第29章：各个击破算法和google 云计算的基础 1.分治法： 把一个大问题分解成若干个小问题，解决各个小问题，合并各小问题的解
2.从分治法到MapReduce: 文章先引入了归并排序的思想，其实就是分治法的思想，把一个待排序的数组进行分割后排序，然后排序后再合并就完成了，然后开始讲解一个大矩阵的相乘，比如：
​ ，如果A和B非常大时，一个计算机是计算不下来的，所以引出了云计算（分治法，MapReduce）的思想，先把A按行分割成N/10份，把B按列分成N/10份，然后两两相乘
​ 最后两两相乘就能得到各自的解，然后合并解即可，这就是把一个把问题分解到多个服务器上计算，从而节省了很多时间的方法。
</content>
    </entry>
    
     <entry>
        <title>两数字之和</title>
        <url>http://shanks.link/blog/2021/08/25/%E4%B8%A4%E6%95%B0%E5%AD%97%E4%B9%8B%E5%92%8C/</url>
        <categories>
          <category>算法题</category>
        </categories>
        <tags>
          <tag>算法题</tag>
        </tags>
        <content type="html"> 场景描述 给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target 的那 两个 整数，并返回它们的数组下标。
你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。
你可以按任意顺序返回答案。
实例 示例 1：
输入：nums = [2,7,11,15], target = 9 输出：[0,1] 解释：因为 nums[0] &#43; nums[1] == 9 ，返回 [0, 1] 。 示例 2：
输入：nums = [3,2,4], target = 6 输出：[1,2] 示例 3：
输入：nums = [3,3], target = 6 输出：[0,1]
解答 /** * Note: The returned array must be malloced, assume caller calls free(). */ int* twoSum(int* nums, int numsSize, int target, int* returnSize){  int *ret = malloc(sizeof(int)*2);  for (int i = 0; i &amp;lt; numsSize; &#43;&#43;i) {  for (int j = i&#43;1; j &amp;lt; numsSize; &#43;&#43;j) {  if (nums[i] &#43; nums[j] == target) {  ret[0] = i;  ret[1] = j;  *returnSize = 2;  return ret;  }  }  }   *returnSize = 0;  return NULL; } 上述转载自力扣
</content>
    </entry>
    
     <entry>
        <title>单链表-反转</title>
        <url>http://shanks.link/blog/2021/08/25/%E5%8D%95%E9%93%BE%E8%A1%A8-%E5%8F%8D%E8%BD%AC/</url>
        <categories>
          <category>算法题</category>
        </categories>
        <tags>
          <tag>算法题</tag>
        </tags>
        <content type="html"> 问题描述 给你单链表的头节点 head ，请你反转链表，并返回反转后的链表。 解答代码 /** * Definition for singly-linked list. * struct ListNode { * int val; * struct ListNode *next; * }; */  struct ListNode* reverseList(struct ListNode* head){  struct ListNode *pre = NULL, *cur = head, *next = NULL;  while (cur) {  next = cur-&amp;gt;next;  cur-&amp;gt;next = pre;  pre = cur;  cur = next;  }  return pre; } </content>
    </entry>
    
     <entry>
        <title>HyperLogLog 算法详解</title>
        <url>http://shanks.link/blog/2021/08/24/hyperloglog-%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3/</url>
        <categories>
          <category>algorithm</category>
        </categories>
        <tags>
          <tag>算法</tag>
        </tags>
        <content type="html"> 首发于技术猫开源俱乐部
HyperLogLog 算法详解 Abser Ari
基数计数基本概念 概率算法 实际上目前还没有发现更好的在大数据场景中准确计算基数的高效算法，因此在不追求绝对准确的情况下，使用概率算法算是一个不错的解决方案。概率算法不直接存储数据集合本身，通过一定的概率统计方法预估基数值，这种方法可以大大节省内存，同时保证误差控制在一定范围内。目前用于基数计数的概率算法包括:
 *Linear Counting(LC)*：早期的基数估计算法，LC在空间复杂度方面并不算优秀，实际上LC的空间复杂度与简单bitmap方法是一样的（但是有个常数项级别的降低），都是O(Nmax)； *LogLog Counting(LLC)*：LogLog Counting相比于LC更加节省内存，空间复杂度只有O(log2(log2(Nmax))) *HyperLogLog Counting(HLL)*：HyperLogLog Counting是基于LLC的优化和改进，在同样空间复杂度情况下，能够比LLC的基数估计误差更小。  HLL 直观演示 HLLDEMO
HLL的实际步骤 HLL是LLC的误差改进，实际是基于LLC。
算法来源（N次伯努利过程） 下面非正式的从直观角度描述LLC算法的思想来源。
设a为待估集合（哈希后）中的一个元素，由上面对H的定义可知，a可以看做一个长度固定的比特串（也就是a的二进制表示），设H哈希后的结果长度为L比特，我们将这L个比特位从左到右分别编号为1、2、…、L：
又因为a是从服从均与分布的样本空间中随机抽取的一个样本，因此a每个比特位服从如下分布且相互独立。
通俗说就是a的每个比特位为0和1的概率各为0.5，且相互之间是独立的。
解释 注意如下事实：
由于比特串每个比特都独立且服从0-1分布，因此从左到右扫描上述某个比特串寻找第一个“1”的过程从统计学角度看是一个伯努利过程，例如，可以等价看作不断投掷一个硬币（每次投掷正反面概率皆为0.5），直到得到一个正面的过程。在一次这样的过程中，投掷一次就得到正面的概率为1/2，投掷两次得到正面的概率是 回到基数统计的问题，我们需要统计一组数据中不重复元素的个数，
集合中每个元素的经过hash函数后可以表示成0和1构成的二进制数串，一个二进制串可以类比为一次抛硬币实验，1是抛到正面，0是反面。
二进制串中从低位开始第一个1出现的位置可以理解为抛硬币试验中第一次出现正面的抛掷次数k，
那么基于上面的结论，我们可以通过多次抛硬币实验的最大抛到正面的次数来预估总共进行了多少次实验，
同样可以可以通过第一个1出现位置的最大值 来预估总共有多少个不同的数字（整体基数）。
LogLogCounting 均匀随机化 与LC一样，在使用LLC之前需要选取一个哈希函数H应用于所有元素，然后对哈希值进行基数估计。H必须满足如下条件（定性的）：
1、H的结果具有很好的均匀性，也就是说无论原始集合元素的值分布如何，其哈希结果的值几乎服从均匀分布
（完全服从均匀分布是不可能的，D. Knuth已经证明不可能通过一个哈希函数将一组不服从均匀分布的数据映射为绝对均匀分布，但是很多哈希函数可以生成几乎服从均匀分布的结果，这里我们忽略这种理论上的差异，认为哈希结果就是服从均匀分布）。
2、H的碰撞几乎可以忽略不计。也就是说我们认为对于不同的原始值，其哈希结果相同的概率非常小以至于可以忽略不计。
3、H的哈希结果是固定长度的。
以上对哈希函数的要求是随机化和后续概率分析的基础。后面的分析均认为是针对哈希后的均匀分布数据进行。
分桶平均 上述分析给出了LLC的基本思想，不过如果直接使用上面的单一估计量进行基数估计会由于偶然性而存在较大误差。
因此，LLC采用了分桶平均的思想来消减误差。
具体来说，就是将哈希空间平均分成m份，每份称之为一个桶（bucket）。对于每一个元素，其哈希值的前k比特作为桶编号，其中 ，而后L-k个比特作为真正用于基数估计的比特串。
桶编号相同的元素被分配到同一个桶，在进行基数估计时，首先计算每个桶内元素最大的第一个“1”的位置，设为M[i]，然后对这m个值取平均后再进行估计，即：
这相当于物理试验中经常使用的多次试验取平均的做法，可以有效消减因偶然性带来的误差。
下面举一个例子说明分桶平均怎么做。
假设H的哈希长度为16bit，分桶数m定为32。
设一个元素哈希值的比特串为“0001001010001010”，由于m为32，因此前5个bit为桶编号，所以这个元素应该归入“00010”即2号桶（桶编号从0开始，最大编号为m-1）
而剩下部分是“01010001010”且显然ρ(01010001010)=2，所以桶编号为“00010”的元素最大的ρ即为M[2]的值。
偏差修正 上述经过分桶平均后的估计量看似已经很不错了，不过通过数学分析可以知道这并不是基数n的无偏估计。因此需要修正成无偏估计。这部分的具体数学分析在“Loglog Counting of Large Cardinalities”中，过程过于艰涩这里不再具体详述，有兴趣的朋友可以参考原论文。这里只简要提一下分析框架：
首先上文已经得出：
因此：
这是一个未知通项公式的递推数列，研究这种问题的常用方法是使用生成函数（generating function）。通过运用指数生成函数和poissonization得到上述估计量的Poisson期望和方差为：
最后通过depoissonization得到一个渐进无偏估计量：
其中：
其中m是分桶数。这就是LLC最终使用的估计量。
误差分析
不加证明给出如下结论：
算法应用 误差控制 在应用LLC时，主要需要考虑的是分桶数m，而这个m主要取决于误差。根据上面的误差分析，如果要将误差控制在ϵ之内，则：
内存使用分析 合并 与LC不同，LLC的合并是以桶为单位而不是bit为单位，由于LLC只需记录桶的
，因此合并时取相同桶编号数值最大者为合并后此桶的数值即可。
HyperLogLog Counting HyperLogLog Counting（以下简称HLLC）的基本思想也是在LLC的基础上做改进，具体细节请参考“HyperLogLog: the analysis of a near-optimal cardinality estimation algorithm”这篇论文。
基本算法
HLLC的第一个改进是使用调和平均数替代几何平均数。注意LLC是对各个桶取算数平均数，而算数平均数最终被应用到2的指数上，所以总体来看LLC取得是几何平均数。由于几何平均数对于离群值（例如这里的0）特别敏感，因此当存在离群值时，LLC的偏差就会很大，这也从另一个角度解释了为什么n不太大时LLC的效果不太好。这是因为n较小时，可能存在较多空桶，而这些特殊的离群值强烈干扰了几何平均数的稳定性。
因此，HLLC使用调和平均数来代替几何平均数，调和平均数的定义如下：
调和平均数可以有效抵抗离群值的扰动。使用调和平均数代替几何平均数后，估计公式变为如下：
其中：
偏差分析
根据论文中的分析结论，与LLC一样HLLC是渐近无偏估计，且其渐近标准差为：
因此在存储空间相同的情况下，HLLC比LLC具有更高的精度。例如，对于分桶数m为2^13（8k字节）时，LLC的标准误差为1.4%，而HLLC为1.1%。
分段偏差修正 在HLLC的论文中，作者在实现建议部分还给出了在n相对于m较小或较大时的偏差修正方案。具体来说，设E为估计值：
当
时，使用LC进行估计。
当
是，使用上面给出的HLLC公式进行估计。
当
时，估计公式如为
关于分段偏差修正效果分析也可以在原论文中找到。
结论 并行化 这些基数估计算法的一个好处就是非常容易并行化。对于相同分桶数和相同哈希函数的情况，多台机器节点可以独立并行的执行这个算法；最后只要将各个节点计算的同一个桶的最大值做一个简单的合并就可以得到这个桶最终的值。而且这种并行计算的结果和单机计算结果是完全一致的，所需的额外消耗仅仅是小于1k的字节在不同节点间的传输。
应用场景 基数估计算法使用很少的资源给出数据集基数的一个良好估计，一般只要使用少于1k的空间存储状态。这个方法和数据本身的特征无关，而且可以高效的进行分布式并行计算。估计结果可以用于很多方面，例如流量监控（多少不同IP访问过一个服务器）以及数据库查询优化（例如我们是否需要排序和合并，或者是否需要构建哈希表）。
参考阅读
Redis new data structure: the HyperLogLogantirez.com/news/75
HyperLogLog — Cornerstone of a Big Data Infrastructureresearch.neustar.biz/2012/10/25/sketch-of-the-day-hyperloglog-cornerstone-of-a-big-data-infrastructure/
算法
编程
Redis
文章被以下专栏收录   
  技术猫开源俱乐部   </content>
    </entry>
    
     <entry>
        <title>golang 中slice 、map、chan作为函数参数分析</title>
        <url>http://shanks.link/blog/2021/08/20/golang-%E4%B8%ADslice-mapchan%E4%BD%9C%E4%B8%BA%E5%87%BD%E6%95%B0%E5%8F%82%E6%95%B0%E5%88%86%E6%9E%90/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> golang 中slice 、map、chan作为函数参数分析 写这篇文章之前考虑一个问题：
 go里面都是值传递，不存在引用传递？ https://cloud.tencent.com/developer/article/1416563  先来总结一下slice、map、chan的特性： slice：
func makeslice64(et *_type, len64, cap64 int64) unsafe.Pointer  type slice struct { 	array unsafe.Pointer 	len int 	cap int }  12345678 其实makeslice64返回是的[]int
 slice本身是一个结构体，而不是一个指针，其底层实现是指向数组的指针。 三要素:type（指针）、len、cap  map：
func makemap(t *maptype, hint int, h *hmap) *hmap 1  makemap返回的一个指针 go map底层实现是hashmap，并采用链地址方法解决hash冲突的 map的扩容机制：2倍扩容，渐进式扩容。  slice作为参数 先看看例子：
package main  import ( 	&amp;#34;fmt&amp;#34; 	&amp;#34;reflect&amp;#34; )  func modify1(slice []int) { 	for i:=0;i&amp;lt;len(slice);i&#43;&#43;{ 	slice[i] = 0 	}  	fmt.Println(&amp;#34;Inside modify1 after append: &amp;#34;, len(slice)) 	fmt.Println(&amp;#34;Inside modify1 after append: &amp;#34;, cap(slice)) 	fmt.Println(&amp;#34;Inside modify1 after append: &amp;#34;, slice) }  func modify2(slice []int) { 	length := len(slice) 	for i:=0;i&amp;lt;length;i&#43;&#43;{ 	slice = append(slice, 1) 	}  	fmt.Println(&amp;#34;Inside modify2 after append: &amp;#34;, len(slice)) 	fmt.Println(&amp;#34;Inside modify2 after append: &amp;#34;, cap(slice)) 	fmt.Println(&amp;#34;Inside modify2 after append: &amp;#34;, slice) }  func main(){  	s1 := make([]int,10,10) 	for i:=0;i&amp;lt;10;i&#43;&#43;{ 	s1[i] = i 	} 	fmt.Println(&amp;#34;makeslcie return type: &amp;#34;, reflect.TypeOf(s1))  	fmt.Println(&amp;#34;before modify slice: &amp;#34;, s1)  	modify1(s1) 	fmt.Println(&amp;#34;after modify1 slice: &amp;#34;, s1)   for i:=0;i&amp;lt;10;i&#43;&#43;{ 	s1[i] = i 	} 	modify2(s1) 	fmt.Println(&amp;#34;after modify2 slice: &amp;#34;, len(s1)) 	fmt.Println(&amp;#34;after modify2 slice: &amp;#34;, cap(s1)) 	fmt.Println(&amp;#34;after modify2 slice: &amp;#34;, s1)  } 运行看看输出：
makeslcie return type: []int before modify slice: [0 1 2 3 4 5 6 7 8 9] Inside modify1 after append: 10 Inside modify1 after append: 10 Inside modify1 after append: [0 0 0 0 0 0 0 0 0 0] after modify1 slice: [0 0 0 0 0 0 0 0 0 0] Inside modify2 after append: 20 Inside modify2 after append: 20 Inside modify2 after append: [0 1 2 3 4 5 6 7 8 9 1 1 1 1 1 1 1 1 1 1] after modify2 slice: 10 after modify2 slice: 10 after modify2 slice: [0 1 2 3 4 5 6 7 8 9] modify1看，slice作为参数，在函数内部能修改slice，表面看确实能在函数内部修改slice
modify2看，在函数modify2内部用appen操作扩容了slice，len和cap都变成了20，但是再看看后面的输出，modify2并没有修改slice，外部的slice依然没变 len和cap都没变化。
这是怎么回事，函数内部修改slice并没有影响外部slice。 其实go里面都是值传递，makeslice返回的是[]int，传入函数内部会对其拷贝一份，slice内部实现是指向数组的指针的，拷贝的副本部分底层实现也是指向同一内存地址的指针数组。所以内部修改slice的值是能修改的，但是append的并没有修改传入的slice的数组，而是返回一个新的slice的，这要去看看slice的实现和其append的扩容机制。实际上当函数内部不扩容slice，如果修改slice也是修改其指向的底层数组。如果发生扩容会发生数据拷贝，并不会修改其指向的array数组。
如果想在函数内部修改可以传递数组指针就可以了，类似下面这样：
func modify2(slice *[]int) 1 参考资料：https://www.cnblogs.com/junneyang/p/6074786.html
map作为参数 func makemap(t *maptype, hint int, h *hmap) *hmap 1 在函数内部可以修改map
package main  import &amp;#34;fmt&amp;#34;  func modify1(m map[string]string){  	for key,_ := range m{ 	m[key] = &amp;#34;chen&amp;#34; 	}  	m[&amp;#34;chen&amp;#34;] = &amp;#34;xun&amp;#34; 	//fmt.Println(&amp;#34;修改之后的map：&amp;#34;, m) }   func main(){  	m := map[string]string{ // :=创建 	&amp;#34;name&amp;#34;: &amp;#34;小明&amp;#34;, 	&amp;#34;age&amp;#34;: &amp;#34;18&amp;#34;, 	}  	fmt.Println(&amp;#34;修改之前的map：&amp;#34;, len(m), m) 	modify1(m) 	fmt.Println(&amp;#34;修改之前的map：&amp;#34;, len(m), m)  } chan作为参数 func makechan(t *chantype, size int) *hchan 1 也就是make() chan的返回值为一个hchan类型的指针，因此当我们的业务代码在函数内对channel操作的同时，也会影响到函数外的数值。
package main  import &amp;#34;fmt&amp;#34;  func test_chan2(ch chan string){ 	fmt.Printf(&amp;#34;inner: %v, %v\n&amp;#34;,ch, len(ch)) 	ch&amp;lt;-&amp;#34;b&amp;#34; 	fmt.Printf(&amp;#34;inner: %v, %v\n&amp;#34;,ch, len(ch)) }  func main() { 	ch := make(chan string, 10) 	ch&amp;lt;- &amp;#34;a&amp;#34;  	fmt.Printf(&amp;#34;outer: %v, %v\n&amp;#34;,ch, len(ch)) 	test_chan2(ch) 	fmt.Printf(&amp;#34;outer: %v, %v\n&amp;#34;,ch, len(ch)) } 123456789101112131415161718 参考资料：https://zhuanlan.zhihu.com/p/54988753
</content>
    </entry>
    
     <entry>
        <title>linux环境内存分配原理</title>
        <url>http://shanks.link/blog/2021/08/18/linux%E7%8E%AF%E5%A2%83%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86/</url>
        <categories>
          <category>cs</category>
        </categories>
        <tags>
          <tag>cs</tag>
        </tags>
        <content type="html"> linux环境内存分配原理 mallocinfo Linux的虚拟内存管理有几个关键概念：
Linux 虚拟地址空间如何分布？malloc和free是如何分配和释放内存？如何查看堆内内存的碎片情况？既然堆内内存brk和sbrk不能直接释放，为什么不全部使用 mmap 来分配，munmap直接释放呢 ？
Linux 的虚拟内存管理有几个关键概念： 1、每个进程都有独立的虚拟地址空间，进程访问的虚拟地址并不是真正的物理地址； 2、虚拟地址可通过每个进程上的页表(在每个进程的内核虚拟地址空间)与物理地址进行映射，获得真正物理地址； 3、如果虚拟地址对应物理地址不在物理内存中，则产生缺页中断，真正分配物理地址，同时更新进程的页表；如果此时物理内存已耗尽，则根据内存替换算法淘汰部分页面至物理磁盘中。
一、Linux 虚拟地址空间如何分布？ Linux 使用虚拟地址空间，大大增加了进程的寻址空间，由低地址到高地址分别为： 1、只读段：该部分空间只能读，不可写；(包括：代码段、rodata 段(C常量字符串和#define定义的常量) ) 2、数据段：保存全局变量、静态变量的空间； 3、堆 ：就是平时所说的动态内存， malloc/new 大部分都来源于此。其中堆顶的位置可通过函数 brk 和 sbrk 进行动态调整。 4、文件映射区域：如动态库、共享内存等映射物理空间的内存，一般是 mmap 函数所分配的虚拟地址空间。 5、栈：用于维护函数调用的上下文空间，一般为 8M ，可通过 ulimit –s 查看。 6、内核虚拟空间：用户代码不可见的内存区域，由内核管理(页表就存放在内核虚拟空间)。 下图是 32 位系统典型的虚拟地址空间分布(来自《深入理解计算机系统》)。
32 位系统有4G 的地址空间::
其中 0x08048000~0xbfffffff 是用户空间，0xc0000000~0xffffffff 是内核空间，包括内核代码和数据、与进程相关的数据结构（如页表、内核栈）等。另外，%esp 执行栈顶，往低地址方向变化；brk/sbrk 函数控制堆顶_edata往高地址方向变化。
64位系统结果怎样呢？ 64 位系统是否拥有 2^64 的地址空间吗？ 事实上， 64 位系统的虚拟地址空间划分发生了改变： 1、地址空间大小不是2^32，也不是2^64，而一般是2^48。
因为并不需要 2^64 这么大的寻址空间，过大空间只会导致资源的浪费。64位Linux一般使用48位来表示虚拟地址空间，40位表示物理地址， 这可通过#cat /proc/cpuinfo 来查看： 2、其中，0x0000000000000000~0x00007fffffffffff 表示用户空间， 0xFFFF800000000000~ 0xFFFFFFFFFFFFFFFF 表示内核空间，共提供 256TB(2^48) 的寻址空间。 这两个区间的特点是，第 47 位与 48~63 位相同，若这些位为 0 表示用户空间，否则表示内核空间。 3、用户空间由低地址到高地址仍然是只读段、数据段、堆、文件映射区域和栈；
二、malloc和free是如何分配和释放内存？
如何查看进程发生缺页中断的次数？
用# ps -o majflt,minflt -C program 命令查看
majflt代表major fault，中文名叫大错误，minflt代表minor fault，中文名叫小错误。
这两个数值表示一个进程自启动以来所发生的缺页中断的次数。
可以用命令ps -o majflt minflt -C program来查看进程的majflt, minflt的值，这两个值都是累加值，从进程启动开始累加。在对高性能要求的程序做压力测试的时候，我们可以多关注一下这两个值。 如果一个进程使用了mmap将很大的数据文件映射到进程的虚拟地址空间，我们需要重点关注majflt的值，因为相比minflt，majflt对于性能的损害是致命的，随机读一次磁盘的耗时数量级在几个毫秒，而minflt只有在大量的时候才会对性能产生影响。
发成缺页中断后，执行了那些操作？
当一个进程发生缺页中断的时候，进程会陷入内核态，执行以下操作： 1、检查要访问的虚拟地址是否合法 2、查找/分配一个物理页 3、填充物理页内容（读取磁盘，或者直接置0，或者啥也不干） 4、建立映射关系（虚拟地址到物理地址） 重新执行发生缺页中断的那条指令 如果第3步，需要读取磁盘，那么这次缺页中断就是majflt，否则就是minflt。
内存分配的原理
从操作系统角度来看，进程分配内存有两种方式，分别由两个系统调用完成：brk和mmap（不考虑共享内存）。
1、brk是将数据段(.data)的最高地址指针_edata往高地址推；
2、mmap是在进程的虚拟地址空间中（堆和栈中间，称为文件映射区域的地方）找一块空闲的虚拟内存。
这两种方式分配的都是虚拟内存，没有分配物理内存。在第一次访问已分配的虚拟地址空间的时候，发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系。
在标准C库中，提供了malloc/free函数分配释放内存，这两个函数底层是由brk，mmap，munmap这些系统调用实现的。
下面以一个例子来说明内存分配的原理：
情况一、malloc小于128k的内存，使用brk分配内存，将_edata往高地址推(只分配虚拟空间，不对应物理内存(因此没有初始化)，第一次读/写数据时，引起内核缺页中断，内核才分配对应的物理内存，然后虚拟地址空间建立映射关系)，如下图：
1、进程启动的时候，其（虚拟）内存空间的初始布局如图1所示。
其中，mmap内存映射文件是在堆和栈的中间（例如libc-2.2.93.so，其它数据文件等），为了简单起见，省略了内存映射文件。
_edata指针（glibc里面定义）指向数据段的最高地址。 2、进程调用A=malloc(30K)以后，内存空间如图2：
malloc函数会调用brk系统调用，将_edata指针往高地址推30K，就完成虚拟内存分配。
你可能会问：只要把_edata&#43;30K就完成内存分配了？
事实是这样的，_edata&#43;30K只是完成虚拟地址的分配，A这块内存现在还是没有物理页与之对应的，等到进程第一次读写A这块内存的时候，发生缺页中断，这个时候，内核才分配A这块内存对应的物理页。也就是说，如果用malloc分配了A这块内容，然后从来不访问它，那么，A对应的物理页是不会被分配的。 3、进程调用B=malloc(40K)以后，内存空间如图3。
情况二、malloc大于128k的内存，使用mmap分配内存，在堆和栈之间找一块空闲内存分配(对应独立内存，而且初始化为0)，如下图：
4、进程调用C=malloc(200K)以后，内存空间如图4：
默认情况下，malloc函数分配内存，如果请求内存大于128K（可由M_MMAP_THRESHOLD选项调节），那就不是去推_edata指针了，而是利用mmap系统调用，从堆和栈的中间分配一块虚拟内存。
这样子做主要是因为::
brk分配的内存需要等到高地址内存释放以后才能释放（例如，在B释放之前，A是不可能释放的，这就是内存碎片产生的原因，什么时候紧缩看下面），而mmap分配的内存可以单独释放。
当然，还有其它的好处，也有坏处，再具体下去，有兴趣的同学可以去看glibc里面malloc的代码了。 5、进程调用D=malloc(100K)以后，内存空间如图5； 6、进程调用free(C)以后，C对应的虚拟内存和物理内存一起释放。
7、进程调用free(B)以后，如图7所示：
​ B对应的虚拟内存和物理内存都没有释放，因为只有一个_edata指针，如果往回推，那么D这块内存怎么办呢？
当然，B这块内存，是可以重用的，如果这个时候再来一个40K的请求，那么malloc很可能就把B这块内存返回回去了。 8、进程调用free(D)以后，如图8所示：
​ B和D连接起来，变成一块140K的空闲内存。
9、默认情况下：
当最高地址空间的空闲内存超过128K（可由M_TRIM_THRESHOLD选项调节）时，执行内存紧缩操作（trim）。在上一个步骤free的时候，发现最高地址空闲内存超过128K，于是内存紧缩，变成图9所示。
真相大白 说完内存分配的原理，那么被测模块在内核态cpu消耗高的原因就很清楚了：每次请求来都malloc一块2M的内存，默认情况下，malloc调用 mmap分配内存，请求结束的时候，调用munmap释放内存。假设每个请求需要6个物理页，那么每个请求就会产生6个缺页中断，在2000的压力下，每 秒就产生了10000多次缺页中断，这些缺页中断不需要读取磁盘解决，所以叫做minflt；缺页中断在内核态执行，因此进程的内核态cpu消耗很大。缺 页中断分散在整个请求的处理过程中，所以表现为分配语句耗时（10us）相对于整条请求的处理时间（1000us）比重很小。 解决办法 将动态内存改为静态分配，或者启动的时候，用malloc为每个线程分配，然后保存在threaddata里面。但是，由于这个模块的特殊性，静态分配，或者启动时候分配都不可行。另外，Linux下默认栈的大小限制是10M，如果在栈上分配几M的内存，有风险。 禁止malloc调用mmap分配内存，禁止内存紧缩。 在进程启动时候，加入以下两行代码： mallopt(M_MMAP_MAX, 0); // 禁止malloc调用mmap分配内存 mallopt(M_TRIM_THRESHOLD, -1); // 禁止内存紧缩 效果：加入这两行代码以后，用ps命令观察，压力稳定以后，majlt和minflt都为0。进程的系统态cpu从20降到10。
三、如何查看堆内内存的碎片情况 ？
glibc 提供了以下结构和接口来查看堆内内存和 mmap 的使用情况。 struct mallinfo { int arena; /* non-mmapped space allocated from system / int ordblks; / number of free chunks / int smblks; / number of fastbin blocks / int hblks; / number of mmapped regions / int hblkhd; / space in mmapped regions / int usmblks; / maximum total allocated space / int fsmblks; / space available in freed fastbin blocks / int uordblks; / total allocated space / int fordblks; / total free space / int keepcost; / top-most, releasable (via malloc_trim) space */ };
/*返回heap(main_arena)的内存使用情况，以 mallinfo 结构返回 */ struct mallinfo mallinfo();
/* 将heap和mmap的使用情况输出到stderr*/ void malloc_stats();
可通过以下例子来验证mallinfo和malloc_stats输出结果。 #include &amp;lt;stdlib.h&amp;gt; #include &amp;lt;stdio.h&amp;gt; #include &amp;lt;string.h&amp;gt; #include &amp;lt;unistd.h&amp;gt; #include &amp;lt;sys/mman.h&amp;gt; #include &amp;lt;malloc.h&amp;gt;
size_t heap_malloc_total, heap_free_total,mmap_total, mmap_count;
void print_info() { struct mallinfo mi = mallinfo(); printf(&amp;ldquo;count by itself:\n&amp;rdquo;); printf(&amp;quot;\theap_malloc_total=%lu heap_free_total=%lu heap_in_use=%lu\n\tmmap_total=%lu mmap_count=%lu\n&amp;quot;, heap_malloc_total1024, heap_free_total1024, heap_malloc_total1024-heap_free_total1024, mmap_total*1024, mmap_count); printf(&amp;ldquo;count by mallinfo:\n&amp;rdquo;); printf(&amp;quot;\theap_malloc_total=%lu heap_free_total=%lu heap_in_use=%lu\n\tmmap_total=%lu mmap_count=%lu\n&amp;quot;, mi.arena, mi.fordblks, mi.uordblks, mi.hblkhd, mi.hblks); printf(&amp;ldquo;from malloc_stats:\n&amp;rdquo;); malloc_stats(); }
#define ARRAY_SIZE 200 int main(int argc, char** argv) { char** ptr_arr[ARRAY_SIZE]; int i; for( i = 0; i &amp;lt; ARRAY_SIZE; i&#43;&#43;) { ptr_arr[i] = malloc(i * 1024); if ( i &amp;lt; 128) //glibc默认128k以上使用mmap { heap_malloc_total &#43;= i; } else { mmap_total &#43;= i; mmap_count&#43;&#43;; } } print_info();
for( i = 0; i &amp;lt; ARRAY_SIZE; i&#43;&#43;) { if ( i % 2 == 0) continue; free(ptr_arr[i]);
​ if ( i &amp;lt; 128) ​ { ​ heap_free_total &#43;= i; ​ } ​ else ​ { ​ mmap_total -= i; ​ mmap_count&amp;ndash;; ​ } } printf(&amp;quot;\nafter free\n&amp;quot;); print_info();
return 1; }
该例子第一个循环为指针数组每个成员分配索引位置 (KB) 大小的内存块，并通过 128 为分界分别对 heap 和 mmap 内存分配情况进行计数； 第二个循环是 free 索引下标为奇数的项，同时更新计数情况。通过程序的计数与mallinfo/malloc_stats 接口得到结果进行对比，并通过 print_info打印到终端。
下面是一个执行结果： count by itself: heap_malloc_total=8323072 heap_free_total=0 heap_in_use=8323072 mmap_total=12054528 mmap_count=72 count by mallinfo: heap_malloc_total=8327168 heap_free_total=2032 heap_in_use=8325136 mmap_total=12238848 mmap_count=72
from malloc_stats: Arena 0: system bytes = 8327168 in use bytes = 8325136 Total (incl. mmap): system bytes = 20566016 in use bytes = 20563984 max mmap regions = 72 max mmap bytes = 12238848
after free count by itself: heap_malloc_total=8323072 heap_free_total=4194304 heap_in_use=4128768 mmap_total=6008832 mmap_count=36
count by mallinfo: heap_malloc_total=8327168 heap_free_total=4197360 heap_in_use=4129808 mmap_total=6119424 mmap_count=36
from malloc_stats: Arena 0: system bytes = 8327168 in use bytes = 4129808 Total (incl. mmap): system bytes = 14446592 in use bytes = 10249232 max mmap regions = 72 max mmap bytes = 12238848
由上可知，程序统计和mallinfo 得到的信息基本吻合，其中 heap_free_total 表示堆内已释放的内存碎片总和。 如果想知道堆内究竟有多少碎片，可通过 mallinfo 结构中的 fsmblks 、smblks 、ordblks 值得到，这些值表示不同大小区间的碎片总个数，这些区间分别是 0~80 字节，80~512 字节，512~128k。如果 fsmblks 、 smblks 的值过大，那碎片问题可能比较严重了。 不过， mallinfo 结构有一个很致命的问题，就是其成员定义全部都是 int ，在 64 位环境中，其结构中的 uordblks/fordblks/arena/usmblks 很容易就会导致溢出，应该是历史遗留问题，使用时要注意！
四、既然堆内内存brk和sbrk不能直接释放，为什么不全部使用 mmap 来分配，munmap直接释放呢？ 既然堆内碎片不能直接释放，导致疑似“内存泄露”问题，为什么 malloc 不全部使用 mmap 来实现呢(mmap分配的内存可以会通过 munmap 进行 free ，实现真正释放)？而是仅仅对于大于 128k 的大块内存才使用 mmap ？
其实，进程向 OS 申请和释放地址空间的接口 sbrk/mmap/munmap 都是系统调用，频繁调用系统调用都比较消耗系统资源的。并且， mmap 申请的内存被 munmap 后，重新申请会产生更多的缺页中断。例如使用 mmap 分配 1M 空间，第一次调用产生了大量缺页中断 (1M/4K 次 ) ，当munmap 后再次分配 1M 空间，会再次产生大量缺页中断。缺页中断是内核行为，会导致内核态CPU消耗较大。另外，如果使用 mmap 分配小内存，会导致地址空间的分片更多，内核的管理负担更大。 同时堆是一个连续空间，并且堆内碎片由于没有归还 OS ，如果可重用碎片，再次访问该内存很可能不需产生任何系统调用和缺页中断，这将大大降低 CPU 的消耗。 因此， glibc 的 malloc 实现中，充分考虑了 sbrk 和 mmap 行为上的差异及优缺点，默认分配大块内存 (128k) 才使用 mmap 获得地址空间，也可通过 mallopt(M_MMAP_THRESHOLD, ) 来修改这个临界值。
五、如何查看进程的缺页中断信息？ 可通过以下命令查看缺页中断信息 ps -o majflt,minflt -C &amp;lt;program_name&amp;gt; ps -o majflt,minflt -p 其中:: majflt 代表 major fault ，指大错误；
​ minflt 代表 minor fault ，指小错误。
这两个数值表示一个进程自启动以来所发生的缺页中断的次数。 其中 majflt 与 minflt 的不同是::
​ majflt 表示需要读写磁盘，可能是内存对应页面在磁盘中需要load 到物理内存中，也可能是此时物理内存不足，需要淘汰部分物理页面至磁盘中。
参看:: http://blog.163.com/xychenbaihu@yeah/blog/static/132229655201210975312473/
六、除了 glibc 的 malloc/free ，还有其他第三方实现吗？
其实，很多人开始诟病 glibc 内存管理的实现，特别是高并发性能低下和内存碎片化问题都比较严重，因此，陆续出现一些第三方工具来替换 glibc 的实现，最著名的当属 google 的tcmalloc和facebook 的jemalloc 。 网上有很多资源，可以自己查(只用使用第三方库，代码不用修改，就可以使用第三方库中的malloc)。
参考资料： 《深入理解计算机系统》第 10 章 http://www.kernel.org/doc/Documentation/x86/x86_64/mm.txt
https://www.ibm.com/developerworks/cn/linux/l-lvm64/
http://www.kerneltravel.net/journal/v/mem.htm
http://blog.csdn.net/baiduforum/article/details/6126337
http://www.nosqlnotes.net/archives/105
http://www.man7.org/linux/man-pages/man3/mallinfo.3.html
原文地址：http://blog.163.com/xychenbaihu@yeah/blog/static/132229655201210975312473/
测试程序代码
#include &amp;lt;malloc.h&amp;gt;#include &amp;lt;string.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;iostream&amp;gt; static void display_mallinfo(void) {  struct mallinfo mi;   mi = mallinfo();   printf(&amp;#34;Total non-mmapped bytes (arena): %d\n&amp;#34;, mi.arena);  printf(&amp;#34;# of free chunks (ordblks): %d\n&amp;#34;, mi.ordblks);  printf(&amp;#34;# of free fastbin blocks (smblks): %d\n&amp;#34;, mi.smblks);  printf(&amp;#34;# of mapped regions (hblks): %d\n&amp;#34;, mi.hblks);  printf(&amp;#34;Bytes in mapped regions (hblkhd): %d\n&amp;#34;, mi.hblkhd);  printf(&amp;#34;Max. total allocated space (usmblks): %d\n&amp;#34;, mi.usmblks);  printf(&amp;#34;Free bytes held in fastbins (fsmblks): %d\n&amp;#34;, mi.fsmblks);  printf(&amp;#34;Total allocated space (uordblks): %d\n&amp;#34;, mi.uordblks);  printf(&amp;#34;Total free space (fordblks): %d\n&amp;#34;, mi.fordblks);  printf(&amp;#34;Topmost releasable block (keepcost): %d\n&amp;#34;, mi.keepcost); }  int main(int argc, char *argv[]) { #define MAX_ALLOCS 2000000  char *alloc[MAX_ALLOCS];  int numBlocks, j, freeBegin, freeEnd, freeStep;  size_t blockSize;   if (argc &amp;lt; 3 || strcmp(argv[1], &amp;#34;--help&amp;#34;) == 0)  {  printf(&amp;#34;%s num-blocks block-size [free-step [start-free &amp;#34;  &amp;#34;[end-free]]]\n&amp;#34;, argv[0]);  return 0;  }  numBlocks = atoi(argv[1]);  blockSize = atoi(argv[2]);  freeStep = (argc &amp;gt; 3) ? atoi(argv[3]) : 1;  freeBegin = (argc &amp;gt; 4) ? atoi(argv[4]) : 0;  freeEnd = (argc &amp;gt; 5) ? atoi(argv[5]) : numBlocks;   printf(&amp;#34;============== Before allocating blocks ==============\n&amp;#34;);  display_mallinfo();   for (j = 0; j &amp;lt; numBlocks; j&#43;&#43;) {  if (numBlocks &amp;gt;= MAX_ALLOCS)  std::cout&amp;lt;&amp;lt;&amp;#34;Too many allocations&amp;#34;&amp;lt;&amp;lt;std::endl;   alloc[j] = (char *)malloc(blockSize);  if (alloc[j] == NULL)  std::cout&amp;lt;&amp;lt;&amp;#34;malloc&amp;#34;&amp;lt;&amp;lt;std::endl;  }   printf(&amp;#34;\n============== After allocating blocks ==============\n&amp;#34;);  display_mallinfo();   for (j = freeBegin; j &amp;lt; freeEnd; j &#43;= freeStep)  {  free(alloc[j]);  }  printf(&amp;#34;\n============== After freeing blocks ==============\n&amp;#34;);  display_mallinfo();   exit(EXIT_SUCCESS); } </content>
    </entry>
    
     <entry>
        <title>数据库事务的四大原则</title>
        <url>http://shanks.link/blog/2021/08/18/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%9B%9B%E5%A4%A7%E5%8E%9F%E5%88%99/</url>
        <categories>
          <category>db</category>
        </categories>
        <tags>
          <tag>db</tag>
        </tags>
        <content type="html"> 数据库的事务四大原则 说到数据库，以前我老师有一句很经典的话。你可以不会写SQL，但是一定不能不知道ACID。
在工业领域，SQL可以说是应用最广泛的技术。从后端到算法，从数据到DBA，再到产品，甚至连一些运营也会基本的SQL。所以如果你现在还不太会的话，我建议你用一个下午的时间找个网站好好学一下。
原本我是想直接写些Hbase相关的内容，但是我发现要想讲清楚Hbase，必须要讲noSQL数据库。如果将noSQL，则又离不开最传统的关系型数据库。所以我们一步一步来，先从基础的关系型数据库讲起。或许我这么说并不准确，因为数据库并不基础，相反它十分复杂。从索引到各种优化和设计原理，再到内部的各种算法和数据结构，涉及到的内容非常多。我们先把浩如烟海的知识放一放，先从最核心的数据库四大原则开始说起。
数据库事务ACID四大原则，A代表Atomicity，即原子性。C表示Consistency，即一致性。I表示Isolation，即隔离性。D表示Durability，即持久性。
这四个原则了解过数据库的应该都如雷贯耳。可是真正面试的时候被问起来，能一个不落说得上来，并且讲得清楚原委的就不多了。我觉得主要是因为我们的翻译过于文雅，不像英文那么直观，所以很难顾名思义。另一个原因是我们在学习的时候理解不够深入，只知道原因，不知道原因的究竟。所谓知其然，不知其所以然。
原子性
让我们先从其中最简单的原子性开始。
原子性理解起来最简单，也最常用。我就在面试当中遇见过不止一次，还有一次让我用Java写一个转账的功能，其实就是想看看我知不知道原子性。
原子两个字看起来一头雾水，其实这里不是指物理学上的基本粒子，而是指的不可分割的意思。也就是说在一个事务当中的所有操作应该被视为一个不可分割的整体，要么全成功，要么全部失败。这点用转账这个问题举例最合适。A将银行卡里的钱转100给B，很明显，数据库需要做两件事情，一件事A账户扣款100，另一件是B账户收入100。但问题来了，计算机系统并不是100%可靠的，可能会存在极小的可能失败。如果A扣款之后，发生网络延迟或者系统down机，导致B账户的钱没有增加，那怎么办？A不是白白扣了钱？
A白白扣了钱是小事，一个金融系统如此不稳定，显然是不能接受的。所以，在数据库的事务当中，应该保证原子性。扣钱和收钱虽然是两个操作，但是应该被视为一个。要么一起成功，要么一起失败。失败了还可以重试，如果成功了一半，那都不知道该怎么修复了。
事务的一种实现方法是在执行的时候先不将最终的结果更新到数据库，而是先写在事务日志上。等整个事务执行成功之后，再将事务日志上的内容同步到数据库当中。如果失败了，则将事务日志删除，完成回滚。
持久性
第二个要介绍的是持久性。
持久性指的是数据的持久性，指的是事务完成了之后，这个事务对数据库所作出的修改就被持久地保存进了数据库当中，不会再被回滚操作影响。即使出现了各种事故，比如机房断电、网络故障等等意外情况，数据库当中的数据也不能丢失。
但是前文当中说了，计算机系统很难做到100%可靠。如果万一的情况发生了，数据库当中的数据丢了，那么应该怎么办呢？
没关系，之前在介绍原子性的时候介绍过了。所有的事务操作在执行之前，都会先把数据记录到事务日志当中，再同步到数据库。即使是数据库里的数据丢失了，那么只要根据事务日志重新执行一遍对应的操作，就可以恢复数据库当中的数据，维持数据库的持久性。实际上，现在的数据库默认会将所有的操作都当做事务来执行，因此基本上不用担心数据丢失的情况。
隔离性
最后，介绍的是隔离性。
在我们理解了原子性之后，隔离性就很好理解了。当我们同时有多个事务一起执行的时候，如果隔离性做得不好，很有可能导致很多问题。
以下四种问题最常见：
1. 脏读
脏读是指一个事务读到了另一个事务执行的中间结果。还用我们刚才的转账的例子举例：
当我们转账的事务没有执行完，另一个事务就读取了它的中间结果，很有可能就造成脏读。因为万一之前的事务回滚，那么新读取到的结果就是错的，和A账号回滚之后的余额不一致。如果这个数据应用在其他的系统当中，就会引起大规模的数据问题。
2. 不可重复读
不可重复读的意思是说，如果在一个事务当中，我们读取了某个数据两次。刚好在这中间，有另一个事务修改了这条数据，那么同样会引起数据错误，因为这两次读取到的结果不一致。
比如我们对A账户的一个事务还没有结束，这时候它的结果就被其他事务修改了。那么程序就会发生错乱，因为读到了它没有预料到的修改。
解决方法是针对当前修改的数据进行隔离，同一时刻只允许一个事务对该条数据进行修改，以保证数据的一致性。
3. 幻读
幻读的概念也很简单，就是一个事务读取两次，读到的数据条数不一致。这点和不可重复读非常类似，不过不同的是不可重复读针对的是确定的某一条数据，而幻读指的是对整个数据库或者是整个表而言。
要解决也很简单，因为幻读是其他事务修改新增或者修改其他数据产生的，所以要排除掉这种情况，只针对我们修改的数据进行加锁和隔离是不够的。我们需要将整个数据库，或者是分区进行隔离，同一时刻，只允许一个事务对一个分片或者是数据表进行修改。
4. 更新丢失
更新丢失的定义很直观，当我们针对一条数据进行修改的时候。同时也有另一个事务在修改同一条内容，会导致后者覆盖前者的内容。比如说账户里原本100元，A事务往账户里添加10元，B事务往账户里扣除20元。A修改成110的同时，被B事务的80所覆盖，导致A的操作就像是没有执行过一样，引起更新丢失。这个问题在并发场景当中也最为经典。
解决的办法同样是做好隔离操作，在一个写入完成之前，禁止其他事务的读入。事实上更新丢失是并发场景下最容易出现的错误，而且如果设计不合理，出现了错误也会非常难排查。
数据库解决隔离性问题的办法就是设置不同的隔离级别，不同的隔离级别对应不同的隔离策略，可以保证不同级别下的隔离性。不同的隔离级别意味着使用不同级别的锁，显然隔离级别越高意味着性能越差。所以这就需要数据库管理员（DBA）对于当前的应用场景，以及并发量和数据风险有一个非常清楚的认知。能够在性能和安全性之间做一个权衡。这里，我们不多做具体的探究，观察一下下图，简单了解一下即可：
从上到下以此是四种隔离级别，越往下隔离级别越高，能够解决的隔离性问题也就越多。同样的，用到的锁也就越多，系统的性能也就越差。
最上面未提交读是最低的隔离级别，在读取的时候并不会判断是否可能会读取到没有提交的数据。所以它的隔离性最差，连最简单的脏读都无法解决。
已提交读则是通过锁限制了只会读取已经提交的数据，读数据的时候使用的共享锁，在读取完成之后立即释放。这种隔离级别只能够解决最常见的脏读问题，它也是SQL server数据库的默认隔离级别。
可重复读的读取过程和已提交级别一样，但是在读取的时候会保持共享锁，一直到事务结束。也就是说只要一个事务没有结束，锁就不会释放。其他的事务无法更新数据，保证了不会出现不可重复读的情况。
最后是可串行读，它是在可重复读的基础上进一步加强了隔离性。在事务进行当中，不仅会锁定受影响的数据本身，而且还会锁定整个范围。这就阻止了其他事务影响整体的情况出现。在这个隔离级别下，保证了事务之间不会有任何踩踏。
到这里，数据库事务四大原则当中的三个就介绍完了，内容看起来不少，但其实还没有结束，关于隔离的实现会牵扯到锁的使用，这块深挖下去，又会牵扯许多内容。不过对于我们算法从业者而言，能够了解到这一层，也差不多够了。
四原则当中还剩下一个一致性原则，一致性这个单词在很多地方都出现过，比如分布式存储系统、多副本的一致性等等。但是这些概念的意思并不相同，不可以简单地理解成同一回事。数据库的一致性表示数据的状态是正确的，在转移的时候，是从一个正确的状态转移到了另一个正确的状态。正确的状态其实就是指不出错的状态，也就是和程序员预期一致的状态。之前在介绍隔离性时谈到的种种问题，总结起来都是数据和程序员的预期不一致。也就是说如果和程序员的预期一致，就可以认为满足了一致性。
虽然一致性是数据库的四原则之一，但数据库系统当中并没有专门针对一致性的部分。其实在数据库眼中，满足了其他三原则，那么自然也就达成了一致性。一致性是目的，并不是手段。举个例子，还是以刚刚转账的情景距离。A向B转账100，我们都知道，前提条件是A的账户里的金额大于等于100，如果A账户里小于100，我们开发的时候没有做校验还强行转账成功。那么这个结果显然是错误的，也是和我们预期不一致的，但是这个问题发生的原因并不是因为数据库没有做好一致性，而是开发人员忽略了限制条件。
所以数据库的教材上才会写着“Ensuring the consistency is the responsibility of user, not DBMS.&amp;quot;, &amp;ldquo;DBMS assumes that consistency holds for each transaction”。
“保证一致性是开发的责任，而不是数据库的，数据库假设每一个事务都符合 一致性。”
到这里，数据库事务的四原则就介绍完了，衷心祝大家，日拱一卒，每天都有收获。
</content>
    </entry>
    
     <entry>
        <title>跌宕起伏是常态</title>
        <url>http://shanks.link/blog/2021/08/18/%E8%B7%8C%E5%AE%95%E8%B5%B7%E4%BC%8F%E6%98%AF%E5%B8%B8%E6%80%81/</url>
        <categories>
          <category>[daily]</category>
        </categories>
        <tags>
          <tag>daily</tag>
        </tags>
        <content type="html">  昨天三面，今早得知没过，过几天再问原因，可能是学历，也可能是专业方面沾边的不多。 没过面试，一下子让人冷静了下来。 手上计划待做的事情很多，一件一件来，从半休息状态转为全力工作状态。 生活里跌宕起伏是常态，继续前行。
</content>
    </entry>
    
     <entry>
        <title>常见的10种排序算法</title>
        <url>http://shanks.link/blog/2021/08/12/%E5%B8%B8%E8%A7%81%E7%9A%8410%E7%A7%8D%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/</url>
        <categories>
          <category>algorithm</category>
        </categories>
        <tags>
          <tag>面试</tag><tag>排序</tag><tag>算法</tag>
        </tags>
        <content type="html"> [常见的排序算法——常见的10种排序] 常见算法可以分为两大类： 　非线性时间比较类排序：通过比较来决定元素间的相对次序，由于其时间复杂度不能突破O(nlogn)，因此称为非线性时间比较类排序。
　线性时间非比较类排序：不通过比较来决定元素间的相对次序，它可以突破基于比较排序的时间下界，以线性时间运行，因此称为线性时间非比较类排序。 算法复杂度：
1、冒泡排序 思路：外层循环从1到n-1，内循环从当前外层的元素的下一个位置开始，依次和外层的元素比较，出现逆序就交换，通过与相邻元素的比较和交换来把小的数交换到最前面。
 for(int i=0;i&amp;lt;arr.length-1;i&#43;&#43;){//外层循环控制排序趟数  for(int j=0;j&amp;lt;arr.length-1-i;j&#43;&#43;){//内层循环控制每一趟排序多少次  if(arr[j]&amp;gt;arr[j&#43;1]){  int temp=arr[j];  arr[j]=arr[j&#43;1];  arr[j&#43;1]=temp;  }  }  } 2、选择排序 思路：冒泡排序是通过相邻的比较和交换，每次找个最小值。选择排序是：首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。
private static void sort(int[] array) {  int n = array.length;  for (int i = 0; i &amp;lt; n-1; i&#43;&#43;) {  int min = i;  for (int j = i&#43;1; j &amp;lt; n; j&#43;&#43;) {  if (array[j] &amp;lt; array[min]){//寻找最小数  min = j; //将最小数的索引赋值  }  }  int temp = array[i];  array[i] = array[min];  array[min] = temp;   }  } 3、插入排序 思路：通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。可以理解为玩扑克牌时的理牌；
private static void sort(int[] array) {  int n = array.length;  /** *从第二位数字开始，每一个数字都试图跟它的前一个比较并交换，并重复；直到前一个数字不存在或者比它小或相等时停下来 **/  for (int i = 1; i &amp;lt; n; i&#43;&#43;) {//从第二个数开始  int key = array[i];  int j = i -1;  while (j &amp;gt;= 0 &amp;amp;&amp;amp; array[j]&amp;gt;key) {  array[j &#43; 1] = array[j]; //交换  j--; //下标向前移动  }  array[j&#43;1] = key;  }  } 4、希尔排序 思路：希尔排序是插入排序的一种高效率的实现，也叫缩小增量排序。先将整个待排记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录基本有序时再对全体记录进行一次直接插入排序。 问题：增量的序列取法？ 关于取法，没有统一标准，但最后一步必须是1；因为不同的取法涉及时间复杂度不一样，具体了解可以参考《数据结构与算法分析》；一般以length/2为算法。（再此以gap=gap*3&#43;1为公式） 问题2:为什么不一开始就直接采用插入排序对整个数组排一次呢? 插入排序在数据无规律时，复杂度高，先分组排序后，后面进行插入排序时，元素已经相对有序了,此时插入排序效率会高很多 相关视频
private static void sort(int[] array) {  int n = array.length;  int h = 1;  while (h&amp;lt;n/3) { //动态定义间隔序列  h = 3*h &#43;1;  }  while (h &amp;gt;= 1) {  for (int i = h; i &amp;lt; n; i&#43;&#43;) {  for (int j = i; j &amp;gt;= h &amp;amp;&amp;amp; (array[j] &amp;lt; array[j - h]); j -= h) {  int temp = array[j];  array[j] = array[j - h];  array[j-h]= temp;  }  }  h /=3;  }  } 5、归并排序 思路：将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为2-路归并。它使用了递归分治的思想；相当于：左半边用尽，则取右半边元素；右半边用尽，则取左半边元素；右半边的当前元素小于左半边的当前元素，则取右半边元素；右半边的当前元素大于左半边的当前元素，则取左半边的元素。 自顶向下： 相关视频
private static void mergeSort(int[] array) {  int[] aux = new int[array.length];  sort(array, aux, 0, array.length - 1);  }   private static void sort(int[] array, int[] aux, int lo, int hi) {  if (hi&amp;lt;=lo) return;  int mid = lo &#43; (hi - lo)/2;  sort(array, aux, lo, mid);  sort(array, aux, mid &#43; 1, hi);  merge(array, aux, lo, mid, hi);  }   private static void merge(int[] array, int[] aux, int lo, int mid, int hi) {  System.arraycopy(array,0,aux,0,array.length);  int i = lo, j = mid &#43; 1;  for (int k = lo; k &amp;lt;= hi; k&#43;&#43;) {  if (i&amp;gt;mid) array[k] = aux[j&#43;&#43;];  else if (j &amp;gt; hi) array[k] = aux[i&#43;&#43;];  else if (aux[j]&amp;lt;aux[i]) array[k] = aux[j&#43;&#43;];  else array[k] = aux[i&#43;&#43;];  }  } 　自底向上：
public static void sort(int[] array) {  int N = a.length;  int[] aux = new int[N];  for (int n = 1; n &amp;lt; N; n = n&#43;n) {  for (int i = 0; i &amp;lt; N-n; i &#43;= n&#43;n) {  int lo = i;  int m = i&#43;n-1;  int hi = Math.min(i&#43;n&#43;n-1, N-1);  merge(array, aux, lo, m, hi);  }  }  }   private static void merge(int[] array, int[] aux, int lo, int mid, int hi) {  for (int k = lo; k &amp;lt;= hi; k&#43;&#43;) {  aux[k] = array[k];  }  // merge back to a[]  int i = lo, j = mid&#43;1;  for (int k = lo; k &amp;lt;= hi; k&#43;&#43;) {  if (i &amp;gt; mid) array[k] = aux[j&#43;&#43;]; // this copying is unneccessary  else if (j &amp;gt; hi) array[k] = aux[i&#43;&#43;];  else if (aux[j]&amp;lt;aux[i]) array[k] = aux[j&#43;&#43;];  else array[k] = aux[i&#43;&#43;];  }  } 缺点：因为是Out-place sort，因此相比快排，需要很多额外的空间。
为什么归并排序比快速排序慢？
　答：虽然渐近复杂度一样，但是归并排序的系数比快排大。
对于归并排序有什么改进？
　答：就是在数组长度为k时，用插入排序，因为插入排序适合对小数组排序。在算法导论思考题2-1中介绍了。复杂度为O(nk&#43;nlg(n/k)) ，当k=O(lgn)时，复杂度为O(nlgn)
例子：
private static int mark = 0;  /** * 归并排序 */  private static int[] sort(int[] array, int low, int high) {  int mid = (low &#43; high) / 2;  if (low &amp;lt; high) {  mark&#43;&#43;;  System.out.println(&amp;#34;正在进行第&amp;#34; &#43; mark &#43; &amp;#34;次分隔，得到&amp;#34;);  System.out.println(&amp;#34;[&amp;#34; &#43; low &#43; &amp;#34;-&amp;#34; &#43; mid &#43; &amp;#34;] [&amp;#34; &#43; (mid &#43; 1) &#43; &amp;#34;-&amp;#34; &#43; high &#43; &amp;#34;]&amp;#34;);  // 左边数组  sort(array, low, mid);  // 右边数组  sort(array, mid &#43; 1, high);  // 左右归并  merge(array, low, mid, high);  }  return array;  }   /** * 对数组进行归并 * * @param array * @param low * @param mid * @param high */  private static void merge(int[] array, int low, int mid, int high) {  System.out.println(&amp;#34;合并:[&amp;#34; &#43; low &#43; &amp;#34;-&amp;#34; &#43; mid &#43; &amp;#34;] 和 [&amp;#34; &#43; (mid &#43; 1) &#43; &amp;#34;-&amp;#34; &#43; high &#43; &amp;#34;]&amp;#34;);  int[] temp = new int[high - low &#43; 1];  int i = low;// 左指针  int j = mid &#43; 1;// 右指针  int k = 0;  // 把较小的数先移到新数组中  while (i &amp;lt;= mid &amp;amp;&amp;amp; j &amp;lt;= high) {  if (array[i] &amp;lt; array[j]) {  temp[k&#43;&#43;] = array[i&#43;&#43;];  } else {  temp[k&#43;&#43;] = array[j&#43;&#43;];  }  }  // 两个数组之一可能存在剩余的元素  // 把左边剩余的数移入数组  while (i &amp;lt;= mid) {  temp[k&#43;&#43;] = array[i&#43;&#43;];  }  // 把右边边剩余的数移入数组  while (j &amp;lt;= high) {  temp[k&#43;&#43;] = array[j&#43;&#43;];  }  // 把新数组中的数覆盖array数组  for (int m = 0; m &amp;lt; temp.length; m&#43;&#43;) {  array[m &#43; low] = temp[m];  }  }   /** * 归并排序 */  public static int[] sort(int[] array) {  return sort(array, 0, array.length - 1);  }   public static void main(String[] args) {  int[] array = { 3, 5, 2, 6, 2 };  int[] sorted = sort(array);  System.out.println(&amp;#34;最终结果&amp;#34;);  for (int i : sorted) {  System.out.print(i &#43; &amp;#34; &amp;#34;);  }  } 6、快速排序 思路：通过一趟排序将待排记录分隔成独立的两部分，其中一部分记录的关键字均比另一部分的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序。
private static void sort(int[] array) {  shuffle(array);  sort(array, 0, array.length - 1);  }  private static void sort(int[] array, int lo, int hi) {  if(hi&amp;lt;=lo&#43;M) {  Insert.sort(a,lo,hi);  return;  }  int lt = lo, gt = hi;  int v = array[lo];  int i = lo;  while (i &amp;lt;= gt) {  if (array[i]&amp;lt;v) exch(array, lt&#43;&#43;, i&#43;&#43;);  else if (array[i]&amp;gt;v) exch(array, i, gt--);  else i&#43;&#43;;  }  // a[lo..lt-1] &amp;lt; v = a[lt..gt] &amp;lt; a[gt&#43;1..hi].  sort(array, lo, lt-1);  sort(array, gt&#43;1, hi);  }   private static void exch(int[] a, int i, int j) {  int swap = a[i];  a[i] = a[j];  a[j] = swap;  }   /** *打乱数组 */  private static void shuffle(int[] array) {  Random random = new Random(System.currentTimeMillis());  if (array == null) throw new NullPointerException(&amp;#34;argument array is null&amp;#34;);  int n = array.length;  for (int i = 0; i &amp;lt; n; i&#43;&#43;) {  int r = i &#43; random.nextInt(n-i); // between i and n-1  int temp = array[i];  array[i] = array[r];  array[r] = temp;  }  }  代码例子： package test;  public class s {  public static void main(String[] args) {  int[] arr = { 5,2,4,9,7 };  sort(arr, 0, arr.length - 1);  }  public static void sort(int arr[], int low, int high) {  int l = low;  int h = high;  int k = arr[low];  while (l &amp;lt; h) {  // 从后往前比较  while (l &amp;lt; h &amp;amp;&amp;amp; arr[h] &amp;gt;= k ){ // 如果没有比关键值小的，比较下一个，直到有比关键值小的交换位置，然后又从前往后比较  h--;// h=6  }  if (l &amp;lt; h) {  int temp = arr[h];  arr[h] = arr[l];  arr[l] = temp;  //进行过一次替换后，没必要将替换后的两值再次比较，所以i&#43;&#43;直接下一位与k对比  l&#43;&#43;;  }  // 从前往后比较  while (l &amp;lt; h &amp;amp;&amp;amp; arr[l] &amp;lt;= k) { // 如果没有比关键值大的，比较下一个，直到有比关键值大的交换位置  l&#43;&#43;;  }  if (l &amp;lt; h) {  int temp = arr[h];  arr[h] = arr[l];  arr[l] = temp;  h--;  }  // 此时第一次循环比较结束，关键值的位置已经确定了。左边的值都比关键值小，右边的值都比关键值大，但是两边的顺序还有可能是不一样的，进行下面的递归调用  }  print(arr);  System.out.print(&amp;#34;l=&amp;#34; &#43; (l &#43; 1) &#43; &amp;#34;h=&amp;#34; &#43; (h &#43; 1) &#43; &amp;#34;k=&amp;#34; &#43; k &#43; &amp;#34;\n&amp;#34;);  // 递归  if (l &amp;gt; low)//先判断l&amp;gt;low再次经行左边排序  sort(arr, low, l - 1);// 左边序列。第一个索引位置到关键值索引-1  if (h &amp;lt; high)//左边依次排序执行完递归后，弹栈进行右边排序  sort(arr, l &#43; 1, high);// 右边序列。从关键值索引&#43;1到最后一个  }  // 打印数组的方法  private static void print(int[] arr) {  System.out.print(&amp;#34;[&amp;#34;);  for (int i = 0; i &amp;lt; arr.length; i&#43;&#43;) {  if (i != (arr.length - 1)) {  System.out.print(arr[i] &#43; &amp;#34;,&amp;#34;);  } else {  System.out.print(arr[i] &#43; &amp;#34;]&amp;#34;);  System.out.println();  }  }  } } package test;  public class s {  public static void main(String[] args) {  int[] arr = { 5,2,4,9,7 };  sort(arr, 0, arr.length - 1);  }  public static void sort(int arr[], int low, int high) {  int l = low;  int h = high;  int k = arr[low];  while (l &amp;lt; h) {  // 从后往前比较  while (l &amp;lt; h &amp;amp;&amp;amp; arr[h] &amp;gt;= k ){ // 如果没有比关键值小的，比较下一个，直到有比关键值小的交换位置，然后又从前往后比较  h--;// h=6  }  if (l &amp;lt; h) {  int temp = arr[h];  arr[h] = arr[l];  arr[l] = temp;  //进行过一次替换后，没必要将替换后的两值再次比较，所以i&#43;&#43;直接下一位与k对比  l&#43;&#43;;  }  // 从前往后比较  while (l &amp;lt; h &amp;amp;&amp;amp; arr[l] &amp;lt;= k) { // 如果没有比关键值大的，比较下一个，直到有比关键值大的交换位置  l&#43;&#43;;  }  if (l &amp;lt; h) {  int temp = arr[h];  arr[h] = arr[l];  arr[l] = temp;  h--;  }  // 此时第一次循环比较结束，关键值的位置已经确定了。左边的值都比关键值小，右边的值都比关键值大，但是两边的顺序还有可能是不一样的，进行下面的递归调用  }  print(arr);  System.out.print(&amp;#34;l=&amp;#34; &#43; (l &#43; 1) &#43; &amp;#34;h=&amp;#34; &#43; (h &#43; 1) &#43; &amp;#34;k=&amp;#34; &#43; k &#43; &amp;#34;\n&amp;#34;);  // 递归  if (l &amp;gt; low)//先判断l&amp;gt;low再次经行左边排序  sort(arr, low, l - 1);// 左边序列。第一个索引位置到关键值索引-1  if (h &amp;lt; high)//左边依次排序执行完递归后，弹栈进行右边排序  sort(arr, l &#43; 1, high);// 右边序列。从关键值索引&#43;1到最后一个  }  // 打印数组的方法  private static void print(int[] arr) {  System.out.print(&amp;#34;[&amp;#34;);  for (int i = 0; i &amp;lt; arr.length; i&#43;&#43;) {  if (i != (arr.length - 1)) {  System.out.print(arr[i] &#43; &amp;#34;,&amp;#34;);  } else {  System.out.print(arr[i] &#43; &amp;#34;]&amp;#34;);  System.out.println();  }  }  } } 7、堆排序 思路：堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。
public static void sort(int[] a){  int N = a.length;  int[] keys = new int[N&#43;1];  //注意，堆的数据结构是从1开始的，0不用  for (int i = 1; i &amp;lt; keys.length; i&#43;&#43;) {  keys[i] = a[i-1];  } // //构造堆,使得堆是有序的  for(int k = N/2;k&amp;gt;=1;k--) sink(keys,k,N);  //排序，相当于毁掉堆  while(N&amp;gt;1){  exch(keys,1,N--);  sink(keys,1,N);  }  //重新写回数组  for (int i = 0; i &amp;lt; a.length; i&#43;&#43;) {  a[i] = keys[i&#43;1];  }  }   private static void sink(int[] a, int k, int N) {  // TODO Auto-generated method stub  while(2*k&amp;lt;=N){  int j = 2*k;  if (j &amp;lt; N &amp;amp;&amp;amp; less(a[j], a[j&#43;1])) j&#43;&#43;;  if (less(a[j], a[k])) break;  exch(a, k, j);  k = j;  }  }   private static boolean less(int k, int j) {  // TODO Auto-generated method stub  return k &amp;lt; j;  }   private static void exch(int[] a, int i, int n) {  // TODO Auto-generated method stub  int temp = a[i];  a[i] = a[n];  a[n] = temp;  } 代码例子：
package test;  public class dui {  /** * 调整为小顶堆（排序后结果为从大到小） * * @param array是待调整的堆数组 * @param s是待调整的数组元素的位置 * @param length是数组的长度 * */  public static void heapAdjustS(int[] array, int s, int length) {  int tmp = array[s];  int child = 2 * s &#43; 1;// 左孩子结点的位置  System.out.println(&amp;#34;待调整结点为：array[&amp;#34; &#43; s &#43; &amp;#34;] = &amp;#34; &#43; tmp);  while (child &amp;lt; length) {  // child &#43; 1 是当前调整结点的右孩子  // 如果有右孩子且小于左孩子，使用右孩子与结点进行比较，否则使用左孩子  if (child &#43; 1 &amp;lt; length &amp;amp;&amp;amp; array[child] &amp;gt; array[child &#43; 1]) {  child&#43;&#43;;  }  System.out.println(&amp;#34;将与子孩子 array[&amp;#34; &#43; child &#43; &amp;#34;] = &amp;#34; &#43; array[child] &#43; &amp;#34; 进行比较&amp;#34;);  // 如果较小的子孩子比此结点小  if (array[s] &amp;gt; array[child]) {  System.out.println(&amp;#34;子孩子比其小，交换位置&amp;#34;);  array[s] = array[child];// 把较小的子孩子向上移动，替换当前待调整结点  s = child;// 待调整结点移动到较小子孩子原来的位置  array[child] = tmp;  child = 2 * s &#43; 1;// 继续判断待调整结点是否需要继续调整   if (child &amp;gt;= length) {  System.out.println(&amp;#34;没有子孩子了，调整结束&amp;#34;);  } else {  System.out.println(&amp;#34;继续与新的子孩子进行比较&amp;#34;);  }  // continue;  } else {  System.out.println(&amp;#34;子孩子均比其大，调整结束&amp;#34;);  break;// 当前待调整结点小于它的左右孩子，不需调整，直接退出  }  }  }   /** * 调整为大顶堆（排序后结果为从小到大） * * @param array是待调整的堆数组 * @param s是待调整的数组元素的位置 * @param length是数组的长度 * */  public static void heapAdjustB(int[] array, int s, int length) {  int tmp = array[s];  int child = 2 * s &#43; 1;// 左孩子结点的位置  System.out.println(&amp;#34;待调整结点为：array[&amp;#34; &#43; s &#43; &amp;#34;] = &amp;#34; &#43; tmp);  while (child &amp;lt; length) {  // child &#43; 1 是当前调整结点的右孩子  // 如果有右孩子且大于左孩子，使用右孩子与结点进行比较，否则使用左孩子  if (child &#43; 1 &amp;lt; length &amp;amp;&amp;amp; array[child] &amp;lt; array[child &#43; 1]) {  child&#43;&#43;;  }  System.out.println(&amp;#34;将与子孩子 array[&amp;#34; &#43; child &#43; &amp;#34;] = &amp;#34; &#43; array[child] &#43; &amp;#34; 进行比较&amp;#34;);  // 如果较大的子孩子比此结点大  if (array[s] &amp;lt; array[child]) {  System.out.println(&amp;#34;子孩子比其大，交换位置&amp;#34;);  array[s] = array[child];// 把较大的子孩子向上移动，替换当前待调整结点  s = child;// 待调整结点移动到较大子孩子原来的位置  array[child] = tmp;  child = 2 * s &#43; 1;// 继续判断待调整结点是否需要继续调整   if (child &amp;gt;= length) {  System.out.println(&amp;#34;没有子孩子了，调整结束&amp;#34;);  } else {  System.out.println(&amp;#34;继续与新的子孩子进行比较&amp;#34;);  }  // continue;  } else {  System.out.println(&amp;#34;子孩子均比其小，调整结束&amp;#34;);  break;// 当前待调整结点大于它的左右孩子，不需调整，直接退出  }  }  }   /** * 堆排序算法 * * @param array * @param inverse true 为倒序排列，false 为正序排列 */  public static void heapSort(int[] array, boolean inverse) {  // 初始堆  // 最后一个有孩子的结点位置 i = (length - 1) / 2, 以此向上调整各结点使其符合堆  System.out.println(&amp;#34;初始堆开始&amp;#34;);  for (int i = (array.length - 1) / 2; i &amp;gt;= 0; i--) {  if (inverse) {  heapAdjustS(array, i, array.length);  } else {  heapAdjustB(array, i, array.length);  }  }  System.out.println(&amp;#34;初始堆结束&amp;#34;);  for (int i = array.length - 1; i &amp;gt; 0; i--) {  // 交换堆顶元素H[0]和堆中最后一个元素  int tmp = array[i];  array[i] = array[0];  array[0] = tmp;  // 每次交换堆顶元素和堆中最后一个元素之后，都要对堆进行调整  if (inverse) {  heapAdjustS(array, 0, i);  } else {  heapAdjustB(array, 0, i);  }  }  }   public static void main(String[] args) {  int[] array = { 49, 38, 65, 97, 76, 13, 27, 49 };  heapSort(array, false);  for (int i : array) {  System.out.print(i &#43; &amp;#34; &amp;#34;);  }  }  } 8、计数排序 思路：将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。
　找出待排序的数组中最大和最小的元素； 统计数组中每个值为i的元素出现的次数，存入数组C的第i项； 对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加）； 反向填充目标数组：将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1。
/** * 输入数组的元素都是介于0..k之间的 * @param data 待排序数组 * @param k 最大元素 * @return 排序结果 */  public static int[] sort(int[] data, int k) {  // 存放临时数据的数组tmp，初始元素都是0；k为数组中最大元素  int[] tmp = new int[k &#43; 1];   // 计算数组中每个元素i出现的次数，存入数组tmp中的第i项，即原数组中的元素值为tmp数组中的下标  for (int i = 0; i &amp;lt;= data.length - 1; i&#43;&#43;) {  tmp[data[i]]&#43;&#43;;  }  // 计算数组中小于等于每个元素的个数,即从tmp中的第一个元素开始，每一项和前一项相加  for (int j = 1; j &amp;lt;= k; j&#43;&#43;) {  tmp[j] = tmp[j] &#43; tmp[j - 1];  }  // result数组用来来存放排序结果  int[] result = new int[data.length];  for (int i = data.length - 1; i &amp;gt;= 0; i--) {  result[tmp[data[i]] - 1] = data[i];  tmp[data[i]]--;  }  return result;  } 代码例子：
package test;  public class jishu {  public static int[] countingSort(int[] theArray) {  int[] lastArray = new int[theArray.length];  for(int i = 0; i &amp;lt; theArray.length; i&#43;&#43;) {  int count = 0;  for(int j = 0; j &amp;lt; theArray.length; j&#43;&#43;) {  if(theArray[i] &amp;gt; theArray[j]) {  count&#43;&#43;;  }  }  lastArray[count] = theArray[i];  }  return lastArray;  }  public static void main(String[] args) {  int []theArray = {6, 4, 5, 1, 8, 7, 2, 3};  System.out.print(&amp;#34;之前的排序：&amp;#34;);  for(int i = 0; i &amp;lt; theArray.length; i&#43;&#43;) {  System.out.print(theArray[i] &#43; &amp;#34; &amp;#34;);  }   int []resultArray = countingSort(theArray);   System.out.print(&amp;#34;计数排序：&amp;#34;);  for(int i = 0; i &amp;lt; resultArray.length; i&#43;&#43;) {  System.out.print(resultArray[i] &#43; &amp;#34; &amp;#34;);  }  }  } 9、桶排序 思路：桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。桶排序 (Bucket sort)的工作的原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排）。
　设置一个定量的数组当作空桶； 遍历输入数据，并且把数据一个一个放到对应的桶里去； 对每个不是空的桶进行排序； 从不是空的桶里把排好序的数据拼接起来。 视频介绍
public static void bucketSort(double array[]) {  int length = array.length;  ArrayList arrList[] = new ArrayList[length];  for (int i = 0; i &amp;lt; length; i&#43;&#43;) {  //0.7到0.79放在第8个桶里,编号7；第一个桶放0到0.09  int temp = (int) Math.floor(10 * array[i]);  if (null == arrList[temp])  arrList[temp] = new ArrayList();  arrList[temp].add(array[i]);  }  // 对每个桶中的数进行插入排序  for (int i = 0; i &amp;lt; length; i&#43;&#43;) {  if (null != arrList[i]) {  Collections.sort(arrList[i]);  }  }  int count = 0;  for (int i = 0; i &amp;lt; length; i&#43;&#43;) {  if (null != arrList[i]) {  Iterator iter = arrList[i].iterator();  while (iter.hasNext()) {  Double d = (Double) iter.next();  array[count] = d;  count&#43;&#43;;  }  }  }  } 代码例子：
 package test;  public class tong {  private int[] buckets;  private int[] array;   public tong(int range,int[] array){  this.buckets = new int[range];  this.array = array;  }   /*排序*/  public void sort(){  if(array!=null &amp;amp;&amp;amp; array.length&amp;gt;1){  for(int i=0;i&amp;lt;array.length;i&#43;&#43;){  buckets[array[i]]&#43;&#43;;  }  }  }   /*排序输出*/  public void sortOut(){  //倒序输出数据  for (int i=buckets.length-1; i&amp;gt;=0; i--){  for(int j=0;j&amp;lt;buckets[i];j&#43;&#43;){  System.out.print(i&#43;&amp;#34;\t&amp;#34;);  }  }  }    public static void main(String[] args) {  testBucketsSort();  }   private static void testBucketsSort(){  int[] array = {5,7,3,5,4,8,6,4,1,2};  tong bs = new tong(10, array);  bs.sort();  bs.sortOut();//输出打印排序  }  } 10、基数排序 思路：基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序。最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。
　取得数组中的最大数，并取得位数； arr为原始数组，从最低位开始取每个位组成radix数组； 对radix进行计数排序（利用计数排序适用于小范围数的特点）；
 private static void radixSort(int[] array,int radix, int distance) {  int length = array.length;  int[] temp = new int[length];  int[] count = new int[radix];  int divide = 1;   for (int i = 0; i &amp;lt; distance; i&#43;&#43;) {   System.arraycopy(array, 0,temp, 0, length);  Arrays.fill(count, 0);   for (int j = 0; j &amp;lt; length; j&#43;&#43;) {  int tempKey = (temp[j]/divide)%radix;  count[tempKey]&#43;&#43;;  }   for (int j = 1; j &amp;lt; radix; j&#43;&#43;) {  count [j] = count[j] &#43; count[j-1];  }  for (int j = length - 1; j &amp;gt;= 0; j--) {  int tempKey = (temp[j]/divide)%radix;  count[tempKey]--;  array[count[tempKey]] = temp[j];  }  divide = divide * radix;  }  } 代码例子：
 package test; package test;   /** * 基数排序 * 平均O(d(n&#43;r)),最好O(d(n&#43;r)),最坏O(d(n&#43;r));空间复杂度O(n&#43;r);稳定;较复杂 * d为位数,r为分配后链表的个数 * * */  public class ji_shu {  //pos=1表示个位，pos=2表示十位  public static int getNumInPos(int num, int pos) {  int tmp = 1;  for (int i = 0; i &amp;lt; pos - 1; i&#43;&#43;) {  tmp *= 10;  }  return (num / tmp) % 10;  }  //求得最大位数d  public static int getMaxWeishu(int[] a) {  int max = a[0];  for (int i = 0; i &amp;lt; a.length; i&#43;&#43;) {  if (a[i] &amp;gt; max)  max = a[i];  }  int tmp = 1, d = 1;  while (true) {  tmp *= 10;  if (max / tmp != 0) {  d&#43;&#43;;  } else  break;  }  return d;  }  public static void radixSort(int[] a, int d) {  int[][] array = new int[10][a.length &#43; 1];  for (int i = 0; i &amp;lt; 10; i&#43;&#43;) {  array[i][0] = 0;  // array[i][0]记录第i行数据的个数  }  for (int pos = 1; pos &amp;lt;= d; pos&#43;&#43;) {  for (int i = 0; i &amp;lt; a.length; i&#43;&#43;) {  // 分配过程  int row = getNumInPos(a[i], pos);  int col = &#43;&#43;array[row][0];  array[row][col] = a[i];  }  for (int row = 0, i = 0; row &amp;lt; 10; row&#43;&#43;) {  // 收集过程  for (int col = 1; col &amp;lt;= array[row][0]; col&#43;&#43;) {  a[i&#43;&#43;] = array[row][col];  }  array[row][0] = 0;  // 复位，下一个pos时还需使用  }  }  }  public static void main(String[] args) {  int[] a = { 49, 38, 65, 197, 76, 213, 27, 50 };  radixSort(a, getMaxWeishu(a));  for (int i : a)  System.out.print(i &#43; &amp;#34; &amp;#34;);  }  } 小结 排序算法要么简单有效，要么是利用简单排序的特点加以改进，要么是以空间换取时间在特定情况下的高效排序。但是这些排序方法都不是固定不变的，需要结合具体的需求和场景来选择甚至组合使用。才能达到高效稳定的目的。没有最好的排序，只有最适合的排序。 下面就总结一下排序算法的各自的使用场景和适用场合。   从平均时间来看，快速排序是效率最高的，但快速排序在最坏情况下的时间性能不如堆排序和归并排序。而后者相比较的结果是，在n较大时归并排序使用时间较少，但使用辅助空间较多。
  上面说的简单排序包括除希尔排序之外的所有冒泡排序、插入排序、简单选择排序。其中直接插入排序最简单，但序列基本有序或者n较小时，直接插入排序是好的方法，因此常将它和其他的排序方法，如快速排序、归并排序等结合在一起使用。
  基数排序的时间复杂度也可以写成O(d*n)。因此它最使用于n值很大而关键字较小的的序列。若关键字也很大，而序列中大多数记录的最高关键字均不同，则亦可先按最高关键字不同，将序列分成若干小的子序列，而后进行直接插入排序。
  从方法的稳定性来比较，基数排序是稳定的内排方法，所有时间复杂度为O(n^2)的简单排序也是稳定的。但是快速排序、堆排序、希尔排序等时间性能较好的排序方法都是不稳定的。稳定性需要根据具体需求选择。
  上面的算法实现大多数是使用线性存储结构，像插入排序这种算法用链表实现更好，省去了移动元素的时间。具体的存储结构在具体的实现版本中也是不同的。
  </content>
    </entry>
    
     <entry>
        <title>任何时候都要保持冷静</title>
        <url>http://shanks.link/blog/2021/08/12/%E4%BB%BB%E4%BD%95%E6%97%B6%E5%80%99%E9%83%BD%E8%A6%81%E4%BF%9D%E6%8C%81%E5%86%B7%E9%9D%99/</url>
        <categories>
          <category>daily</category>
        </categories>
        <tags>
          <tag>daily</tag>
        </tags>
        <content type="html">  昨天面试聊的还不错，就飘飘然起来，不可。冷静啊，冷静，切记，切记。
</content>
    </entry>
    
     <entry>
        <title>Golang知识小结</title>
        <url>http://shanks.link/blog/2021/08/10/golang%E7%9F%A5%E8%AF%86%E5%B0%8F%E7%BB%93/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> string  string类型采用UTF-8编码，且不可修的，len返回byte数量而不是字符数量，eg(len(你好)==6  数组和slice  数组在函数调用的参数传递模式是独立复制一份数据给被调用函数 slice以及map,chan对应的的函数传参知识参考这里Golang函数参数传递  map  初始化： h := map[int]string{} 显示构造，或者 h = make(map[int]string), 空值 h := map[int]string 将构造一个nil的map，可以调用range, len, 读，但不能写值 map是指针数据结构，即当作函数参数传递时，函数内部修改了其值，会影响函数外部原始的map var = map[k],若对应的k不存在，则返回零值，故而要判断时候存在，需引入第二个参数eg: val, exist := map[k] 不可对map中的元素取地址eg:&amp;amp;tbl[k]是非法的（map的大小可能随时调整故取地址无意义)。 可以采用range风格对其轮询，顺序是随机的（设计如此）。如果需要按照一定的规则读取map，一个办法是先把key排好序，再用map[key]的的方法读写  struct  导出规则与模块一样 一般而言一行定义一个成员 不能递归定义自己，但可以在内部使用自己类型的指针 其零值是每个成员的零值，如果内部有(map,chan)，还需要在struct{}构造后，显式的对其初始化  type sh struct { 	m map[int]int } var st = sh{} st.m = make(map[int]int) function  参数是传值模式，没有默认值，数量可以是可变模式 可以递归调用自己 函数名是第一类值，可以和nil比较，但不能作为map的key 支持闭包(closures)，这点和lua中的函数一致，与之对应，C语言不支持闭包  方法 </content>
    </entry>
    
     <entry>
        <title>Go学习建议</title>
        <url>http://shanks.link/blog/2021/08/04/go%E5%AD%A6%E4%B9%A0%E5%BB%BA%E8%AE%AE/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 如果学习 Go 整理了目前市面上的各类图书，特别是开源的图书，阅读学习建议分享给你
入门建议 Go 语言入门图书挺多的，根据我的了解和大家的反馈、讨论，比较推荐如下图书，选择一本认真看即可，没必要那么多。
1. 《The Way to Go》，有无闻组织翻译了中文版，我为你准备了中文版 PDF； 2. 雨痕的 《Go 语言学习笔记》第四版的第一部分语言。我也为你准备了 PDF； 3. 《Go 语言圣经》中文版；我为你准备了 PDF；  系统的看了一本入门书籍后，可以有针对性的看一些官方文档，查漏补缺，同时避免一些书上的东西过时或有误，毕竟官方的最权威。
文档：英文好的可以看英文 https://docs.studygolang.com/ 或者看如下列出的中文翻译版）有四个文档推荐阅读：（可以根据情况快速过一遍） 1. Go 语言之旅 Go 指南：http://tour.studygolang.com/ 2. 语言规范 Go编程语言规范：https://hao.studygolang.com/golang_spec.html 3. Effective Go：http://docscn.studygolang.com/doc/effective_go.html 4. FAQ：http://docscn.studygolang.com/doc/faq
在学习的过程中，针对里面的代码一定要实际动手敲，这样能够加深印象。
另外，可以通过练手 https://books.studygolang.com/gobyexample 上的例子加深印象。
进阶建议 《Go语言实战》即经典的 In Action 系列。这本书有部分基础内容，但有一定难度，适合有了一定基础再看。
项目实战，可以看《Go语言编程之旅：一起用Go做项目》。
柴大 《Go语言高级编程》、雨痕的Go语言学习笔记源码解析部分、左大的《Go 语言设计与实现》 饶大的《Go 语言问题集(Go Questions)》、欧神的Go语言原本：https://golang.design/under-the-hood/
其他开源图书根据你的需要尽情享用吧。
</content>
    </entry>
    
     <entry>
        <title>要不断的提高思维的层次</title>
        <url>http://shanks.link/blog/2021/07/28/%E8%A6%81%E4%B8%8D%E6%96%AD%E7%9A%84%E6%8F%90%E9%AB%98%E6%80%9D%E7%BB%B4%E7%9A%84%E5%B1%82%E6%AC%A1/</url>
        <categories>
          <category>[daily]</category>
        </categories>
        <tags>
          <tag>daily</tag>
        </tags>
        <content type="html"> ​ 要不断的提高自己思维的层次，不要总是纠结在细节，打个比方，修一栋高楼大厦，更多的是要关注框架设计，而不要总是纠结这一块砖有没有码好。
</content>
    </entry>
    
     <entry>
        <title>gdb 提示 coredump 文件 truncated 问题排查</title>
        <url>http://shanks.link/blog/2021/07/27/gdb-%E6%8F%90%E7%A4%BA-coredump-%E6%96%87%E4%BB%B6-truncated-%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> gdb 提示 coredump 文件 truncated 问题排查  本文选自“字节跳动基础架构实践”系列文章。
“字节跳动基础架构实践”系列文章是由字节跳动基础架构部门各技术团队及专家倾力打造的技术干货内容，和大家分享团队在基础架构发展和演进过程中的实践经验与教训，与各位技术同学一起交流成长。
coredump 我们日常开发中经常会遇到，能够帮助我们辅助定位问题，但如果 coredump 出现 truncate 会给排查问题带来不便。本文以线上问题为例，借助这个Case我们深入了解一下这类问题的排查思路，以及如何使用一些调试工具、阅读内核源代码，更清晰地了解coredump的处理过程。希望能为大家在排查这类问题的时候，提供一个清晰的脉络。
 问题背景 在 c/cpp 类的程序开发中进程遇到 coredump，偶尔会遇到 coredump truncate 问题，影响 core 后的问题排查。coredump truncate 大部分是由于 core limits 和剩余磁盘空间引发的。这种比较好排查和解决。今天我们要分析的一种特殊的 case。
借助这个 Case 我们深入了解一下这类问题的排查思路，使用一些调试工具和阅读内核源代码能更清晰的了解 coredump 的处理过程。能够在排查这类问题的时候有个清晰的脉络。
业务同学反馈在容器内的服务出 core 后 gdb 调试报错。业务的服务运行在 K8S&#43;Docker 的环境下，服务在容器内最终由 system 托管。在部分机器上的 coredump 文件在 gdb 的时候出现如下警告，导致排查问题受影响。报错信息如下：
BFD: Warning: /tmp/coredump.1582242674.3907019.dp-b9870a84ea -867bccccdd-5hb7h is truncated: expected core file size &amp;gt;= 89036038144, found: 31395205120. 导致的结果是 gdb 无法继续调试。我们登录机器后排查不是磁盘空间和 core ulimit 的问题。需要进一步排查。
名词约定 GDB：UNIX 及 UNIX-like 下的二进制调试工具。
Coredump： 核心转储，是操作系统在进程收到某些信号而终止运行时，将此时进程地址空间的内容以及有关进程状态的其他信息写出的一个磁盘文件。这种信息往往用于调试。
ELF： 可执行与可链接格式（Executable and Linkable Format），用于可执行文件、目标文件、共享库和核心转储的标准文件格式。x86 架构上的类 Unix 操作系统的二进制文件格式标准。
BFD： 二进制文件描述库(Binary File Descriptor library)是 GNU 项目用于解决不同格式的目标文件的可移植性的主要机制。
VMA： 虚拟内存区域（Virtual Memory Area），VMA 是用户进程里的一段 virtual address space 区块，内核使用 VMA 来跟踪进程的内存映射。
排查过程 用户态排查 开始怀疑是自研的 coredump handler 程序有问题。于是还原系统原本的 coredump。手动触发一次 Coredump。结果问题依然存在。现在排除 coredump handler 的问题。说明问题可能发生在 kernel 层或 gdb 的问题。
需要确定是 gdb 问题还是 kernel 吐 core 的问题。先从 gdb 开始查起，下载 gdb 的源代码找到报错的位置（为了方便阅读，源代码的缩进进行了调整）。
目前看不是 gdb 的问题。coredump 文件写入不完整。coredump 的写入是由内核完成的。需要从内核侧排查。
在排查之前观察这个 coredump 的程序使用的内存使用非常大，几十 G 规模。怀疑是否和其过大有关，于是做一个实验。写一个 50G 内存的程序模拟，并对其 coredump。
#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;string.h&amp;gt;  int main(void){  for( int i=0; i&amp;lt;1024; i&#43;&#43; ){  void* test = malloc(1024*1024*50); // 50MB  memset(test, 0, 1);  }  sleep(3600); } 经过测试正常吐 core。gdb 正常，暂时排除 core 大体积问题。
所以初步判断是 kernel 在吐的 core 文件自身的问题。需要在进一步跟进。
查看内核代码发现一处可疑点:
/* * Ensures that file size is big enough to contain the current file * postion. This prevents gdb from complaining about a truncated file * if the last &amp;#34;write&amp;#34; to the file was dump_skip. */ void dump_truncate(struct coredump_params *cprm) {  struct file *file = cprm-&amp;gt;file;  loff_t offset;    if (file-&amp;gt;f_op-&amp;gt;llseek &amp;amp;&amp;amp; file-&amp;gt;f_op-&amp;gt;llseek != no_llseek) {  offset = file-&amp;gt;f_op-&amp;gt;llseek(file, 0, SEEK_CUR);  if (i_size_read(file-&amp;gt;f_mapping-&amp;gt;host) &amp;lt; offset)  do_truncate(file-&amp;gt;f_path.dentry, offset, 0, file);  } } 这段代码的注释引起了我们的注意。
现在怀疑在出现这个 case 的时候没有执行到这个 dump_truncate 函数。于是尝试把 dump_truncate 移到第二个位置处。重新编译内核尝试。重新打了测试内核测试后问题依然存在。于是继续看代码。
这段代码引起了注意。怀疑某个时刻执行 get_dump_page 的时候返回了 NULL。然后走到了 dump_skip 函数，dump_skip 返回 0，导致 goto end_coredump。于是 stap 抓下。
不出所料，dump_skip 返回 0 后 coredump 停止。也就是说第二阶段只 dump 了一部分 vma 就停止了。导致 coredump 写入不完整。
VMA 部分 dump 分析 再看下 dump_skip 函数。
int dump_skip(struct coredump_params *cprm, size_t nr) {  static char zeroes[PAGE_SIZE];  struct file *file = cprm-&amp;gt;file;  if (file-&amp;gt;f_op-&amp;gt;llseek &amp;amp;&amp;amp; file-&amp;gt;f_op-&amp;gt;llseek != no_llseek) {  if (dump_interrupted() ||  file-&amp;gt;f_op-&amp;gt;llseek(file, nr, SEEK_CUR) &amp;lt; 0)  return 0;  cprm-&amp;gt;pos &#43;= nr;  return 1;  } else {  while (nr &amp;gt; PAGE_SIZE) {  if (!dump_emit(cprm, zeroes, PAGE_SIZE))  return 0;  nr -= PAGE_SIZE;  }  return dump_emit(cprm, zeroes, nr);  } } 因为 coredump 是 pipe 的，所以是没有 llseek 操作的，因此会走到 else 分支里。也就是 dump_emit 返回 0 导致的。于是 stap 抓下 dump_emit 函数 。
function func:string(task:long) %{  snprintf(STAP_RETVALUE, MAXSTRINGLEN, &amp;#34;%s&amp;#34;, signal_pending(current) ? &amp;#34;true&amp;#34; : &amp;#34;false&amp;#34;); %}   probe kernel.function(&amp;#34;dump_emit&amp;#34;).return {  printf(&amp;#34;return: %d, cprm-&amp;gt;limit:%d, cprm-&amp;gt;written: %d, signal: %s\n&amp;#34;, $return, @entry($cprm-&amp;gt;limit), @entry($cprm-&amp;gt;written), func($return)); } 结果如下：
return: 1, cprm-&amp;gt;limit:-1, cprm-&amp;gt;written: 0, signal: false return: 1, cprm-&amp;gt;limit:-1, cprm-&amp;gt;written: 64, signal: false return: 1, cprm-&amp;gt;limit:-1, cprm-&amp;gt;written: 120, signal: false ... 省略9221238行 ... return: 1, cprm-&amp;gt;limit:-1, cprm-&amp;gt;written: 37623402496, signal: false return: 1, cprm-&amp;gt;limit:-1, cprm-&amp;gt;written: 37623406592, signal: false return: 1, cprm-&amp;gt;limit:-1, cprm-&amp;gt;written: 37623410688, signal: false return: 0, cprm-&amp;gt;limit:-1, cprm-&amp;gt;written: 37623414784, signal: true 不出意外和怀疑的一致，dump_emit 返回 0 了，此时写入到 core 文件的有 37623414784 字节。主要因为 dump_interrupted 检测条件为真。(cprm-&amp;gt;limit = -1 不会进入 if 逻辑，kernrel_wirte 写 pipe 也没有出错)。
下面我们看 dump_interrupted 函数。为了方便阅读，整理出相关的函数。
static bool dump_interrupted(void){  /*  * SIGKILL or freezing() interrupt the coredumping. Perhaps we  * can do try_to_freeze() and check __fatal_signal_pending(),  * but then we need to teach dump_write() to restart and clear  * TIF_SIGPENDING.  */  return signal_pending(current); }   static inline int signal_pending(struct task_struct *p){  return unlikely(test_tsk_thread_flag(p,TIF_SIGPENDING)); } static inline int test_tsk_thread_flag(struct task_struct *tsk, int flag){  return test_ti_thread_flag(task_thread_info(tsk), flag); } static inline int test_ti_thread_flag(struct thread_info *ti, int flag){  return test_bit(flag, (unsigned long *)&amp;amp;ti-&amp;gt;flags); }   /**  * test_bit - Determine whether a bit is set  * @nr: bit number to test  * @addr: Address to start counting from  */ static inline int test_bit(int nr, const volatile unsigned long *addr){  return 1UL &amp;amp; (addr[BIT_WORD(nr)] &amp;gt;&amp;gt; (nr &amp;amp; (BITS_PER_LONG-1))); } 相关的宏：
#ifdef CONFIG_64BIT#define BITS_PER_LONG 64#else#define BITS_PER_LONG 32#endif /* CONFIG_64BIT */#define TIF_SIGPENDING 2 /* signal pending */ 平台相关。以X64架构为例。 有上面的代码就很清楚 dump_interrupted 函数就是检测 task 的 thread_info-&amp;gt;flags 是否 TIF_SIGPENDING 置位。
目前怀疑还是和用户的内存 vma 有关。但什么场景会触发 TIF_SIGPENDING 置位是个问题。dump_interrupted 函数的注释中已经说明了，一个是接收到了 KILL 信号，一个是 freezing()。freezing()一般和 cgroup 有关，一般是 docker 在使用。KILL 有可能是 systemd 发出的。于是做了 2 个实验：
实验一： systemd启动实例，bash裸起服务，不接流量。 测试结果gdb正常... 然后再用systemd起来，不接流量。测试结果也是正常的。 这就奇怪了。但是不能排除systemd。 回想接流量和不接流量的区别是coredump的压缩后的体积大小不同，不接流 量vma大都是空，空洞比较多，因此coredump非常快，有流量vma不是空 的，coredump比较慢。因此怀疑和coredump时间有关系，超过某个时间就 有TIF_SIGPENDING被置位。 实验二： 是产生一个50G的内存。代码如最上方。 在容器内依然使用systemd启动一个测试程序 （直接在问题容器内替换这个bin。然后systemctl重启服务） 然后发送SEGV信号。stap抓一下。 coredump很漫长。等待结果 结果很意外。core正常，gdb也正常。 这个 TIF_SIGPENDING 信号源是个问题。
还有个排查方向就是 get_dump_page 为啥会返回 NULL。所以现在有 2 个排查方向：
 需要确定 TIF_SIGPENDING 信号源。 get_dump_page 返回 NULL 的原因。  get_dump_page 返回 NULL 分析 首先看 get_dump_page 这个返回 NULL 的 case：
* Returns NULL on any kind of failure - a hole must then be inserted into  * the corefile, to preserve alignment with its headers; and also returns  * NULL wherever the ZERO_PAGE, or an anonymous pte_none, has been found -  * allowing a hole to be left in the corefile to save diskspace. 看注释返回 NULL，一个是 page 是 ZERO_PAGE，一个是 pte_none 问题。
首先看 ZREO 问题，于是构造一个 ZERO_PAGE 的程序来测试：
#include &amp;lt;stdio.h&amp;gt; #include &amp;lt;unistd.h&amp;gt; #include &amp;lt;sys/mman.h&amp;gt;   const int BUFFER_SIZE = 4096 * 1000; int main(void){  int i = 0;  unsigned char* buffer;  for( int n=0; n&amp;lt;10240; n&#43;&#43; ){  buffer = mmap(NULL, BUFFER_SIZE, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0);  for (i = 0; i &amp;lt; BUFFER_SIZE - 3 * 4096; i &#43;= 4096){  buffer[i] = 0;  }  }  // zero page  for (i=0; i &amp;lt; BUFFER_SIZE - 4096; i &#43;= 4096) {  char dirty = buffer[i];  printf(&amp;#34;%c&amp;#34;, dirty);  }  printf(&amp;#34;ok...\n&amp;#34;);    sleep(3600); } 测试结果是 coredump 正常，同时 trace 一下 get_dump_page 的返回值。结果和预想的有些不同，返回了很多个 NULL。说明和 get_dump_page 函数的因素不大。
于是转向到 TIF_SIGPENDING 信号发生源。
TIF_SIGPENDING 信号来源分析 bpftrace 抓一下看看：
#!/usr/bin/env bpftrace #include &amp;lt;linux/sched.h&amp;gt;  kprobe:__send_signal {  $t = (struct task_struct *)arg2;  if ($t-&amp;gt;pid == $1) {  printf(&amp;#34;comm:%s(pid: %d) send sig: %d to %s\n&amp;#34;, comm, pid, arg0, $t-&amp;gt;comm);  } } 结果如下：
结果比较有趣。kill 和 systemd 打断了 coredump 进程。信号 2(SIGINT)和信号 9(SIGKILL)都足以打断进程。现在问题变为 kill 和 systemd 为什么会发送这 2 个信号。一个怀疑是超时。coredump 进程为 not running 太久会不会触发 systemd 什么机制呢。
于是查看了 systemd service 的 doc 发现这样一段话：
 TimeoutAbortSec= This option configures the time to wait for the service to terminate when it was aborted due to a watchdog timeout (see WatchdogSec=). If the service has a short TimeoutStopSec= this option can be used to give the system more time to write a core dump of the service. Upon expiration the service will be forcibly terminated by SIGKILL (see KillMode= in systemd.kill(5)). The core file will be truncated in this case. Use TimeoutAbortSec= to set a sensible timeout for the core dumping per service that is large enough to write all expected data while also being short enough to handle the service failure in due time.
Takes a unit-less value in seconds, or a time span value such as &amp;ldquo;5min 20s&amp;rdquo;. Pass an empty value to skip the dedicated watchdog abort timeout handling and fall back TimeoutStopSec=. Pass &amp;ldquo;infinity&amp;rdquo; to disable the timeout logic. Defaults to DefaultTimeoutAbortSec= from the manager configuration file (see systemd-system.conf(5)).
If a service of Type=notify handles SIGABRT itself (instead of relying on the kernel to write a core dump) it can send &amp;ldquo;EXTEND_TIMEOUT_USEC=…&amp;rdquo; to extended the abort time beyond TimeoutAbortSec=. The first receipt of this message must occur before TimeoutAbortSec= is exceeded, and once the abort time has exended beyond TimeoutAbortSec=, the service manager will allow the service to continue to abort, provided the service repeats &amp;ldquo;EXTEND_TIMEOUT_USEC=…&amp;rdquo; within the interval specified, or terminates itself (see sd_notify(3)).
 标红的字引起了注意，于是调大一下(TimeoutAbortSec=&amp;ldquo;10min&amp;rdquo;) 再试。无效&amp;hellip;
无效后就很奇怪，难道 system 都不是信号的发起者，是信号的&amp;quot;传递者&amp;quot;? 现在有 2 个怀疑，一个是 systemd 是信号的发起者，一个是 systemd 不是信号的发起者，是信号的“传递者”。于是这次同时抓业务进程和 systemd 进程看看。结果如下：
其中 3533840 是容器的 init 进程 systemd。3533916 是业务进程。和预想的一样，systemd 并不是信号的第一个发起者。systemd 是接收到 runc 的信号 15（SIGTERM）而停止的，停止前会对子进程发起 kill 行为。也就是最后的 systemd send sig。
有个疑问就来了，之前用程序 1 测试了 system&#43;docker 的场景，没有复现，回想一下 coredump 的过程应该是这样的，程序 1 没有对每个 page 都写，只写了一个 malloc 之后的第一个 page 的第一个一个字节。coredump 在遍历每个 vma 的时候耗时要比都写了 page 要快很多（因为没有那么多空洞，VMA 不会那么零碎）。coredump 体积虽然大，但时间短，因此没有触发这个问题，对于排查这个问题带来一定的曲折。
于是排查方向转到 kill 命令和 runc 经过排查发现 K8S 的一个 lifecycle 中的 prestop 脚本有 kill 行为。把这个脚本停到后再次抓一下：
这次没有 kill 行为，但是 systemd 还是被 runc 杀死了，发送了 2 个信号，一个是 SIGTERM，一个是 SIGKILL 现在解释通了 kill 信号的来源，这也就解释了 kill 的信号来源。其实 kill 和 systemd 的信号根源间接或直接都是 runc。runc 的销毁指令来自 k8s。
于是根据 K8S 的日志继续排查。经过排查发现最终的触发逻辑是来自字节内部实现的 Load 驱逐。该机制当容器的 Load 过高时则会把这个实例驱逐掉，避免影响其他实例。因为 coredump 的时候 CPU 会长期陷入到内核态，导致 load 升高。所以 I 引发了 Pod 驱逐。
coredump 期间实例的负载很高，导致 k8s 的组件 kubelet 的触发了 load 高驱逐实例的行为。删除 pod。停止 systemd。杀死正在 coredump 的进程，最终导致 coredump 第二阶段写 vma 数据未完成。
验证问题 在做一个简单的验证，停止 K8S 组件 kubelet，然后对服务发起 core。最后 gdb。验证正常，gdb 正常读取数据。至此这个问题就排查完毕了。最后修改内部实现 cgroup 级的 Load（和整机 load 近似的采集数据的方案）采集功能，过滤 D 状态的进程（coredump 进程在用户态表现为 D 状态）后，这个问题彻底解决。
总结 本次 coredump 文件 truncate 是因为 coredump 的进程被杀死（SIGKILL 信号）导致 VMA 没有写入完全（只写入了一部分）导致，。解决这个问题通过阅读内核源代码加以使用 bpftrace、systemtap 工具追踪 coredump 的过程。打印出关心的数据，借助源代码最终分析出问题的原因。同时我们对内核的 coredump 过程有了一定的了解。
最后，欢迎加入字节跳动基础架构团队，一起探讨、解决问题，一起变强！
附：coredump 文件简单分析
在排查这个问题期间也阅读了内核处理 coredump 的相关源代码，简单总结一下:
coredump 文件其实是一个精简版的 ELF 文件。coredump 过程并不复杂。coredump 的过程分为 2 个阶段，一个阶段是写 program header（第一个 program header 是 Note Program Header）,每个 program header 包含了 VMA 的大小和在文件的偏移量。gdb 也是依此来确定每个 VMA 的位置的。另一个阶段是写 vma 的数据，遍历进程的所有 vma。然后写入文件。一个 coredump 文件的结构可以简单的用如下图的结构表示。
参考文献  Binary_File_Descriptor_library (https://en.wikipedia.org/wiki/Binary_File_Descriptor_library) systemd.service — Service unit configuration (https://www.freedesktop.org/software/systemd/man/systemd.service.html) Kubernets Pod Lifecycle (https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/)  更多分享 字节跳动在 RocksDB 存储引擎上的改进实践
深入理解 Linux 内核&amp;ndash;jemalloc 引起的 TLB shootdown 及优化
字节跳动自研万亿级图数据库 &amp;amp; 图计算实践
 字节跳动基础架构团队 字节跳动基础架构团队是支撑字节跳动旗下包括抖音、今日头条、西瓜视频、火山小视频在内的多款亿级规模用户产品平稳运行的重要团队，为字节跳动及旗下业务的快速稳定发展提供了保证和推动力。
公司内，基础架构团队主要负责字节跳动私有云建设，管理数以万计服务器规模的集群，负责数万台计算/存储混合部署和在线/离线混合部署，支持若干 EB 海量数据的稳定存储。
文化上，团队积极拥抱开源和创新的软硬件架构。我们长期招聘基础架构方向的同学，具体可参见 job.bytedance.com （文末“阅读原文”），感兴趣可以联系邮箱 guoxinyu.0372@bytedance.com 。
</content>
    </entry>
    
     <entry>
        <title>go的一次故障排除</title>
        <url>http://shanks.link/blog/2021/07/27/go%E7%9A%84%E4%B8%80%E6%AC%A1%E6%95%85%E9%9A%9C%E6%8E%92%E9%99%A4/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> “���”引发的线上事故 最近遇到了一起依赖升级 &#43; 异常数据引发的线上事故，教训惨痛，本文对此进行回故和总结。
背景 起因是我们使用的服务框架版本比较老，GC 次数的 metrics 打点一直为 0，咨询了相关同学后，决定升级框架。升级的过程中，出现了 useofinternalpackagexxxnotallowed 的报错，又咨询了一下相关同学后，尝试使用 go mod 解决。
从 go vendor 到 go mod 的升级的过程也不太顺利，这里按下不表，最终是升级成功了。一同升级的还有 Go 版本，从 1.11 升级到 1.13。
周四上完线后，一切都看似很不错：内存占用、GC 消耗的 CPU 有了优化，GC 次数的监控也有了。因为涉及到公司内部数据，图我就不放了。
周五、周六都平安度过，周日出问题了，小组的同学从下午 12 点左右一直肝到凌晨 12 点，才松了一口气。可怜我们来之不易的一个周日！
现象 周日 11 点 45 左右，端口的调用失败率报警，同时有业务方反馈调用接口报错。
同志们，关键时刻，完善的报警能给事故的处理和恢复赢得时间啊！
By case 排查，发现服务 shard3 集群的机器报 i/o timeout 错误。服务共有 4 个分片集群（根据 ID hash 到对应分片），其他 3 个集群完全正常。接着发现 shard3 集群的机器内存正常、端口还在，但 in/out 流量全部掉到几十 KB/s，看日志也没有发现任何异常。
重启 shard3 集群的服务，重启后的服务恢复正常，访问 debug 端口，也是正常的。然而，十几分钟后，恢复的服务再次出现异常：in/out 流量再次掉到几十 KB/s，访问 debug 端口也没有任何响应，开始慌了。
处理  上线出问题，第一时间回滚！
 稳定性里面很重要的一条就是：有问题，先回滚。先止损，将事故影响降到最低，事后再来追查根因，总结复盘。
于是开始操作回滚， reset 到周四上线之前的一个 commit，重新打包，上线 shard3 集群。之后，对外接口完全恢复，操作回滚其他集群。
服务启动之前，需要先加载几十个 G 左右的数据，启动过程长达 10&#43; min。我申请了一台线上问题机器的 root 权限，执行了 strace-p 命令：
发现服务卡在 futex 系统调用上，这很明显是一个 timer，但是 timer 为何会卡住？正常情况下，会有各种像 write，read 的系统调用，至少打日志、上报 mertrics 打点数据都会有 write 系统调用吧，哈？再执行 perf top 命令：
相关的只有 codec 函数，再看服务进程：
看 perf 输出的结果，全部聚焦到 codec 这个第三方库上，主要的两个函数竟然是 codec.quoteStr 和 utf8.DecodeRuneInString。而我们用 codec 的地方是在程序启动时加载数据文件以及定时的 dump 文件到本地。现在程序已经启动了，只可能是 dump 文件出问题了。查看相关日志，果然有开始 dump 文件的日志记录，却一直没有 dump 成功的记录。
追查 事后追查阶段尝试在 test 集群上重现故障，因为只有单个分片出问题，说明此故障和特定数据有关，是 hash 到分片 3 的数据引起的问题。
又因为 test 集群并没有分片，所以强行（改代码 &amp;amp;&amp;amp; 改环境变量）将其伪装成 shard3 集群，然则并没有复现，猜测可能是计划下线了。
周二的时候，终于在 test 集群上模拟分片 1 时重现了线上故障。
对比 codec 的版本问题，果然有问题：周四上线前， vendor.json 里的版本是 v1.1.7，上线后，升级到了 v1.1.8，看来找到问题了！修改 codec 的版本，重新编译、部署，问题依然存在！
这时，组里其他同学反馈 2018 年的时候也出过 codec 的问题，当时也是出现了异常数据导致重启时加载文件不成功。于是我直接将周四上线前 vendor 文件夹里 codec.quoteStr 函数的代码和 codec 的 v1.1.7 代码进行对比，并不相同！vendor.json 里的版本并没有正确反应 vendor 里实际的 codec 版本！！！
进一步查看提交记录，发现在 2017 年 11 月份的时候有一次提交，修改了 vendor 文件夹里的代码，但这时 vendor.json 并没有 codec 记录。而在 2019 年 11 月的一次提交，则只在 vendor.json 里增加了一条 codec 记录，vendor 文件夹里的代码并没有更改：
{     &amp;#34;checksumSHA1&amp;#34;: &amp;#34;wfboMqCTVImg0gW31jvyvCymJPE=&amp;#34;,     &amp;#34;path&amp;#34;: &amp;#34;github.com/ugorji/go/codec&amp;#34;,     &amp;#34;revision&amp;#34;: &amp;#34;e118e2d506a6b252f6b85f2e2f2ac1bfed82f1b8&amp;#34;,     &amp;#34;revisionTime&amp;#34;: &amp;#34;2019-07-23T09:17:30Z&amp;#34;,     &amp;#34;tree&amp;#34;: true    } 仔细比对代码，主要差异在这：
从现象及源码看，大概率是在 codec.quoteStr 里死循环了！由于 Go 1.14 前都无法抢占正在执行无限循环且没有任何函数调用的 goroutine，因此一旦出现死循环，将要进行 GC 的时候，其他所有 goroutine 都会停止，并且都在等着无限循环的 goroutine 停下来，遗憾的是，由于 for{} 循环里没有进行函数调用，无法插入抢占标记并进行抢占。于是，就出现了这样一幕：
只有 dump 数据文件这一个 goroutine 在干活，而且做的又是无限循环，服务整体对外表现就像是“死机”了一样。并且这个 goroutine 由一个 timer 触发工作，所以一开始我们看到的卡在一个 futex 调用上就可以解释得通。因为 runtime 都停止工作了，timer 自然就没法“到期”了。
接着，使用 Go 1.14 去编译有问题的代码版本，上到 test 集群，果然问题“消失”。服务状态完全恢复正常，唯一不正常的是数据文件无法 dump 下来了，因为即使是 Go 1.14，也依然在执行无限循环，不干“正事”。
接下来的问题就是找到异常的数据了。使用上线前的版本（使用 go vendor），将 codec 替换为最新的 v1.1.8 版本，并且在 quoteStr 函数里打上了几行日志：
部署到 test 集群，问题复现：
异常数据就是：“孙���雷”：
为什么会引发死循环，在调用 utf8.DecodeRuneInString 函数后：
c == utf8.RuneError    size == 3 再看 RuneError 的定义：
const RuneError = &amp;#39;\uFFFD&amp;#39; 看一下两个版本的代码不同之处：
老版本的代码，不会进入 if 分支，而新版本的代码，由于 c==utf8.RuneError，所以先进入 if 分支，之后， size==3，不满足里层分支，直接 continue 了，因此 i 值并没有发生变化，死循环就这么发生了。
最后就是找到异常数据到底属于哪个计划。我尝试去每个集群的机器上，从数据文件里寻找“孙���雷”。但文件太大了，几十个 G， grep 搞不定，没关系，使用 dd 工具：
dd if=model_20200423155728 bs=1024 skip=3600000 count=1200 | grep &amp;#39;孙���雷&amp;#39; ‍使用二分法找到了“孙���雷”！关于 dd&#43;grep 的用法，总结了几点：
 每次从文件开头先跳过 skip*bs 大小的内容，复制 count*bs 大小的内容过来用 grep 查询。 如果不设置 count，就会查找整个文件，如果查到，则会有输出；否则无。 对于特别大的文件，可以先把 count 设为跳过一半文件大小的值，采用二分法查找。如果找到，则限定在了前半范围，否则在后半部分。使用类似的方法继续查找…… 如果找到，最后会输出 count*bs 大小的内容。  反思  服务重大版本更新，至少在线下跑一周。 有问题，第一时间回滚。 对于工具的使用要规范。如不要随意更改 vendor 文件夹的内容而不同步更新 vendor.json 文件，反之亦然。 因为 go mod 的版本选择以及不遵守开源规范的第三方库作者会让使用者不知不觉、被动地引入一些难以发现的问题。可以使用 go mod vendor 代替，如果要锁死版本的话，使用 replace。  </content>
    </entry>
    
     <entry>
        <title>字节跳动在 Go 网络库上的实践</title>
        <url>http://shanks.link/blog/2021/07/27/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8%E5%9C%A8-go-%E7%BD%91%E7%BB%9C%E5%BA%93%E4%B8%8A%E7%9A%84%E5%AE%9E%E8%B7%B5/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 字节跳动在 Go 网络库上的实践  本文选自“字节跳动基础架构实践”系列文章。
“字节跳动基础架构实践”系列文章是由字节跳动基础架构部门各技术团队及专家倾力打造的技术干货内容，和大家分享团队在基础架构发展和演进过程中的实践经验与教训，与各位技术同学一起交流成长。
RPC 框架作为研发体系中重要的一环，承载了几乎所有的服务流量。本文将简单介绍字节跳动自研网络库 netpoll 的设计及实践；以及我们实际遇到的问题和解决思路，希望能为大家提供一些参考。
 前言 字节跳动框架组主要负责公司内 RPC 框架的开发与维护。RPC 框架作为研发体系中重要的一环，承载了几乎所有的服务流量。随着公司内 Go 语言使用越来越广，业务对框架的要求越来越高，而 Go 原生 net 网络库却无法提供足够的性能和控制力，如无法感知连接状态、连接数量多导致利用率低、无法控制协程数量等。为了能够获取对于网络层的完全控制权，同时先于业务做一些探索并最终赋能业务，框架组推出了全新的基于 epoll 的自研网络库 —— netpoll，并基于其之上开发了字节内新一代 Golang 框架 KiteX。
由于 epoll 原理已有较多文章描述，本文将仅简单介绍 netpoll 的设计；随后，我们会尝试梳理一下我们基于 netpoll 所做的一些实践；最后，我们将分享一个我们遇到的问题，以及我们解决的思路。同时，欢迎对于 Go 语言以及框架感兴趣的同学加入我们！
新型网络库设计 Reactor - 事件监听和调度核心 netpoll 核心是 Reactor 事件监听调度器，主要功能为使用 epoll 监听连接的文件描述符（fd），通过回调机制触发连接上的 读、写、关闭 三种事件。
Server - 主从 Reactor 实现 netpoll 将 Reactor 以 1:N 的形式组合成主从模式。
 MainReactor 主要管理 Listener，负责监听端口，建立新连接； SubReactor 负责管理 Connection，监听分配到的所有连接，并将所有触发的事件提交到协程池里进行处理。 netpoll 在 I/O Task 中引入了主动的内存管理，向上层提供 NoCopy 的调用接口，由此支持 NoCopy RPC。 使用协程池集中处理 I/O Task，减少 goroutine 数量和调度开销。  Client - 共享 Reactor 能力 client 端和 server 端共享 SubReactor，netpoll 同样实现了 dialer，提供创建连接的能力。client 端使用上和 net.Conn 相似，netpoll 提供了 write -&amp;gt; wait read callback 的底层支持。
Nocopy Buffer 为什么需要 Nocopy Buffer ? 在上述提及的 Reactor 和 I/O Task 设计中，epoll 的触发方式会影响 I/O 和 buffer 的设计，大体来说分为两种方式：
 采用水平触发(LT)，则需要同步的在事件触发后主动完成 I/O，并向上层代码直接提供 buffer。 采用边沿触发(ET)，可选择只管理事件通知(如 go net 设计)，由上层代码完成 I/O 并管理 buffer。  两种方式各有优缺，netpoll 采用前者策略，水平触发时效性更好，容错率高，主动 I/O 可以集中内存使用和管理，提供 nocopy 操作并减少 GC。事实上一些热门开源网络库也是采用方式一的设计，如 easygo、evio、gnet 等。
但使用 LT 也带来另一个问题，即底层主动 I/O 和上层代码并发操作 buffer，引入额外的并发开销。比如：I/O 读数据写 buffer 和上层代码读 buffer 存在并发读写，反之亦然。为了保证数据正确性，同时不引入锁竞争，现有的开源网络库通常采取 同步处理 buffer(easygo, evio) 或者将 buffer 再 copy 一份提供给上层代码(gnet) 等方式，均不适合业务处理或存在 copy 开销。
另一方面，常见的 bytes、bufio、ringbuffer 等 buffer 库，均存在 growth 需要 copy 原数组数据，以及只能扩容无法缩容，占用大量内存等问题。因此我们希望引入一种新的 Buffer 形式，一举解决上述两方面的问题。
Nocopy Buffer 设计和优势 Nocopy Buffer 基于链表数组实现，如下图所示，我们将 []byte 数组抽象为 block，并以链表拼接的形式将 block 组合为 Nocopy Buffer，同时引入了引用计数、nocopy API 和对象池。
Nocopy Buffer 相比常见的 bytes、bufio、ringbuffer 等有以下优势：
 读写并行无锁，支持 nocopy 地流式读写    读写分别操作头尾指针，相互不干扰。
  高效扩缩容
   扩容阶段，直接在尾指针后添加新的 block 即可，无需 copy 原数组。  缩容阶段，头指针会直接释放使用完毕的 block 节点，完成缩容。每个 block 都有独立的引用计数，当释放的 block 不再有引用时，主动回收 block 节点。      灵活切片和拼接 buffer (链表特性)
   支持任意读取分段(nocopy)，上层代码可以 nocopy 地并行处理数据流分段，无需关心生命周期，通过引用计数 GC。  支持任意拼接(nocopy)，写 buffer 支持通过 block 拼接到尾指针后的形式，无需 copy，保证数据只写一次。      Nocopy Buffer 池化，减少 GC
    将每个 []byte 数组视为 block 节点，构建对象池维护空闲 block，由此复用 block，减少内存占用和 GC。
基于该 Nocopy Buffer，我们实现了 Nocopy Thrift，使得编解码过程内存零分配零拷贝。
连接多路复用 RPC 调用通常采用短连接或者长连接池的形式，一次调用绑定一个连接，那么当上下游规模很大的情况下，网络中存在的连接数以 MxN 的速度扩张，带来巨大的调度压力和计算开销，给服务治理造成困难。因此，我们希望引入一种 &amp;ldquo;在单一长连接上并行处理调用&amp;rdquo; 的形式，来减少网络中的连接数，这种方案即称为 &amp;ldquo;连接多路复用&amp;rdquo;。
当前业界也存在一些开源的连接多路复用方案，掣肘于代码层面的束缚，这些方案均需要 copy buffer 来实现数据分包和合并，导致实际性能并不理想。而上述 Nocopy Buffer 基于其灵活切片和拼接的特性，很好的支持了 nocopy 的数据分包和合并，使得实现高性能连接多路复用方案成为可能。
基于 netpoll 的连接多路复用设计如下图所示，我们将 Nocopy Buffer(及其分片) 抽象为虚拟连接，使得上层代码保持同 net.Conn 相同的调用体验。与此同时，在底层代码上通过协议分包将真实连接上的数据灵活的分配到虚拟连接上；或通过协议编码合并发送虚拟连接数据。
连接多路复用方案包含以下核心要素：
 虚拟连接   实质上是 Nocopy Buffer，目的是替换真正的连接，规避内存 copy。 上层的业务逻辑/编解码 均在虚拟连接上完成，上层逻辑可以异步独立并行执行。      Shared map
   引入分片锁来减少锁力度。  在调用端使用 sequence id 来标记请求，并使用分片锁存储 id 对应的回调。 在接收响应数据后，根据 sequence id 来找到对应回调并执行。      协议分包和编码
    如何识别完整的请求响应数据包是连接多路复用方案可行的关键，因此需要引入协议。
 这里采用 thrift header protocol 协议，通过消息头判断数据包完整性，通过 sequence id 标记请求和响应的对应关系。  ZeroCopy 这里所说的 ZeroCopy，指的是 Linux 所提供的 ZeroCopy 的能力。上一章中我们说了业务层的零拷贝，而众所周知，当我们调用 sendmsg 系统调用发包的时候，实际上仍然是会产生一次数据的拷贝的，并且在大包场景下这个拷贝的消耗非常明显。以 100M 为例，perf 可以看到如下结果：
这还仅仅是普通 tcp 发包的占用，在我们的场景下，大部分服务都会接入 Service Mesh，所以在一次发包中，一共会有 3 次拷贝：业务进程到内核、内核到 sidecar、sidecar 再到内核。这使得有大包需求的业务，拷贝所导致的 cpu 占用会特别明显，如下图：
为了解决这个问题，我们选择了使用 Linux 提供的 ZeroCopy API（在 4.14 以后支持 send；5.4 以后支持 receive）。但是这引入了一个额外的工程问题：ZeroCopy send API 和原先调用方式不兼容，无法很好地共存。这里简单介绍一下 ZeroCopy send 的工作方式：业务进程调用 sendmsg 之后，sendmsg 会记录下 iovec 的地址并立即返回，这时候业务进程不能释放这段内存，需要通过 epoll 等待内核回调一个信号表明某段 iovec 已经发送成功之后才能释放。由于我们并不希望更改业务方的使用方法，需要对上层提供同步收发的接口，所以很难基于现有的 API 同时提供 ZeroCopy 和非 ZeroCopy 的抽象；而由于 ZeroCopy 在小包场景下是有性能损耗的，所以也不能将这个作为默认的选项。
于是，字节跳动框架组和字节跳动内核组合作，由内核组提供了同步的接口：当调用 sendmsg 的时候，内核会监听并拦截内核原先给业务的回调，并且在回调完成后才会让 sendmsg 返回。这使得我们无需更改原有模型，可以很方便地接入 ZeroCopy send。同时，字节跳动内核组还实现了基于 unix domain socket 的 ZeroCopy，可以使得业务进程与 Mesh sidecar 之间的通信也达到零拷贝。
在使用了 ZeroCopy send 后，perf 可以看到内核不再有 copy 的占用：
从 cpu 占用数值上看，大包场景下 ZeroCopy 能够比非 ZeroCopy 节省一半的 cpu。
Go 调度导致的延迟问题分享 在我们实践过程中，发现我们新写的 netpoll 虽然在 avg 延迟上表现胜于 Go 原生的 net 库，但是在 p99 和 max 延迟上要普遍略高于 Go 原生的 net 库，并且尖刺也会更加明显，如下图（Go 1.13，蓝色为 netpoll &#43; 多路复用，绿色为 netpoll &#43; 长连接，黄色为 net 库 &#43; 长连接）：
我们尝试了很多种办法去优化，但是收效甚微。最终，我们定位出这个延迟并非是由于 netpoll 本身的开销导致的，而是由于 go 的调度导致的，比如说：
 由于在 netpoll 中，SubReactor 本身也是一个 goroutine，受调度影响，不能保证 EpollWait 回调之后马上执行，所以这一块会有延迟； 同时，由于用来处理 I/O 事件的 SubReactor 和用来处理连接监听的 MainReactor 本身也是 goroutine，所以实际上很难保证在多核情况之下，这些 Reactor 能并行执行；甚至在最极端情况之下，可能这些 Reactor 会挂在同一个 P 下，最终变成了串行执行，无法充分利用多核优势； 由于 EpollWait 回调之后，SubReactor 内是串行处理 I/O 事件的，导致排在最后的事件可能会有长尾问题； 在连接多路复用场景下，由于每个连接绑定了一个 SubReactor，故延迟完全取决于这个 SubReactor 的调度，导致尖刺会更加明显。  由于 Go 在 runtime 中对于 net 库有做特殊优化，所以 net 库不会有以上情况；同时 net 库是 goroutine-per-connection 的模型，所以能确保请求能并行执行而不会相互影响。
对于以上这个问题，我们目前解决的思路有两个：
 修改 Go runtime 源码，在 Go runtime 中注册一个回调，每次调度时调用 EpollWait，把获取到的 fd 传递给回调执行； 与字节跳动内核组合作，支持同时批量读/写多个连接，解决串行问题。另外，经过我们的测试，Go 1.14 能够使得延迟略有降低同时更加平稳，但是所能达到的极限 QPS 更低。希望我们的思路能够给业界同样遇到此问题的同学提供一些参考。  后记 希望以上的分享能够对社区有所帮助。同时，我们也在加速建设 netpoll 以及基于 netpoll 的新框架 KiteX。欢迎各位感兴趣的同学加入我们，共同建设 Go 语言生态！
参考资料  http://man7.org/linux/man-pages/man7/epoll.7.html https://golang.org/src/runtime/proc.go https://github.com/panjf2000/gnet https://github.com/tidwall/evio  更多分享 Kernel trace tools（二）：内核态执行时间跟踪
字节跳动混沌工程实践总结
gdb 提示 coredump 文件 truncated 问题排查
字节跳动基础架构团队 字节跳动基础架构团队是支撑字节跳动旗下包括抖音、今日头条、西瓜视频、火山小视频在内的多款亿级规模用户产品平稳运行的重要团队，为字节跳动及旗下业务的快速稳定发展提供了保证和推动力。
公司内，基础架构团队主要负责字节跳动私有云建设，管理数以万计服务器规模的集群，负责数万台计算/存储混合部署和在线/离线混合部署，支持若干 EB 海量数据的稳定存储。
文化上，团队积极拥抱开源和创新的软硬件架构。我们长期招聘基础架构方向的同学，具体可参见 job.bytedance.com （文末“阅读原文”），感兴趣可以联系邮箱 guoxinyu.0372@bytedance.com 。
     </content>
    </entry>
    
     <entry>
        <title>人类全部智慧就包含在两个词中：等待和希望</title>
        <url>http://shanks.link/blog/2021/07/21/%E4%BA%BA%E7%B1%BB%E5%85%A8%E9%83%A8%E6%99%BA%E6%85%A7%E5%B0%B1%E5%8C%85%E5%90%AB%E5%9C%A8%E4%B8%A4%E4%B8%AA%E8%AF%8D%E4%B8%AD%E7%AD%89%E5%BE%85%E5%92%8C%E5%B8%8C%E6%9C%9B/</url>
        <categories>
          <category>daily</category>
        </categories>
        <tags>
          <tag>daily</tag>
        </tags>
        <content type="html"> </content>
    </entry>
    
     <entry>
        <title>C&#43;&#43;面试常见问题</title>
        <url>http://shanks.link/blog/2021/07/20/c-%E9%9D%A2%E8%AF%95%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</url>
        <categories>
          <category>c</category>
        </categories>
        <tags>
          <tag>c</tag>
        </tags>
        <content type="html"> extern关键字的作用 置于变量或函数前，用于标示变量或函数的定义在别的文件中，提示编译器遇到此变量和函数时在其他模块中寻找其定义。它只要有两个作用：
 当它与“C”一起连用的时候，如：extern &amp;ldquo;C&amp;rdquo; void fun(int a,int b);则告诉编译器在编译fun这个函数时候按着C的规矩去翻译，而不是C&#43;&#43;的（这与C&#43;&#43;的重载有关，C&#43;&#43;语言支持函数重载，C语言不支持函数重载，函数被C&#43;&#43;编译器编译后在库中的名字与C语言的不同） 当extern不与“C”在一起修饰变量或函数时，如：extern int g_Int；它的作用就是声明函数或全局变量的作用范围的关键字，其声明的函数和变量可以在本模块或其他模块中使用。记住它是一个声明不是定义!也就是说B模块(编译单元)要是引用模块(编译单元)A中定义的全局变量或函数时，它只要包含A模块的头文件即可,在编译阶段，模块B虽然找不到该函数或变量，但它不会报错，它会在连接时从模块A生成的目标代码中找到此函数。
static关键字的作用 修饰局部变量 static修饰局部变量时，使得被修饰的变量成为静态变量，存储在静态区。存储在静态区的数据生命周期与程序相同，在main函数之前初始化，在程序退出时销毁。（无论是局部静态还是全局静态）
修饰全局变量 全局变量本来就存储在静态区，因此static并不能改变其存储位置。但是，static限制了其链接属性。被static修饰的全局变量只能被该包含该定义的文件访问（即改变了作用域）。
修饰函数 static修饰函数使得函数只能在包含该函数定义的文件中被调用。对于静态函数，声明和定义需要放在同一个文件夹中。
修饰成员变量 用static修饰类的数据成员使其成为类的全局变量，会被类的所有对象共享，包括派生类的对象，所有的对象都只维持同一个实例。 因此，static成员必须在类外进行初始化(初始化格式：int base::var=10;)，而不能在构造函数内进行初始化，不过也可以用const修饰static数据成员在类内初始化。 修饰成员函数 用static修饰成员函数，使这个类只存在这一份函数，所有对象共享该函数，不含this指针，因而只能访问类的static成员变量。静态成员是可以独立访问的，也就是说，无须创建任何对象实例就可以访问。例如可以封装某些算法，比如数学函数，如ln，sin，tan等等，这些函数本就没必要属于任何一个对象，所以从类上调用感觉更好，比如定义一个数学函数类Math，调用Math::sin(3.14);还可以实现某些特殊的设计模式：如Singleton；
最重要的特性：隐藏
 当同时编译多个文件时，所有未加static前缀的全局变量和函数都具有全局可见性，其它的源文件也能访问。利用这一特性可以在不同的文件中定义同名函数和同名变量，而不必担心命名冲突。static可以用作函数和变量的前缀，对于函数来讲，static的作用仅限于隐藏。
不可以同时用const和static修饰成员函数。
 C&#43;&#43;编译器在实现const的成员函数的时候为了确保该函数不能修改类的实例的状态，会在函数中添加一个隐式的参数const this*。但当一个成员为static的时候，该函数是没有this指针的。也就是说此时const的用法和static是冲突的。我们也可以这样理解：两者的语意是矛盾的。static的作用是表示该函数只作用在类型的静态变量上，与类的实例没有关系；而const的作用是确保函数不能修改类的实例的状态，与类型的静态变量没有关系。因此不能同时用它们。
volatile的作用  用来修饰变量的，表明某个变量的值可能会随时被外部改变，因此这些变量的存取不能被缓存到寄存器，每次使用需要重新读取。
 假如有一个对象A里面有一个boolean变量a，值为true,现在有两个线程T1，T2访问变量a，T1把a改成了false后T2读取a，T2这时读到的值可能不是false，即T1修改a的这一操作，对T2是不可见的。发生的原因可能是，针对T2线程，为了提升性能，虚拟机把a变量置入了寄存器（即C语言中的寄存器变量），这样就会导致，无论T2读取多少次a，a的值始终为true，因为T2读取了寄存器而非内存中的值。声明了volatile或synchronized 后，就可以保证可见性，确保T2始终从内存中读取变量，T1始终在内存中修改变量。总结：防止脏读，增加内存屏障。 也可参考该地址19问答案：http://www.sohu.com/a/166382914_538662
const的作用 定义变量为只读变量，不可修改 修饰函数的参数和返回值（后者应用比较少，一般为值传递） const成员函数（只需要在成员函数参数列表后加上关键字const，如char get() const;）可以访问const成员变量和非const成员变量，但不能修改任何变量。在声明一个成员函数时，若该成员函数并不对数据成员进行修改操作，应尽可能将该成员函数声明为const成员函数。 const对象只能访问const成员函数,而非const对象可以访问任意的成员函数,包括const成员函数.即对于class A，有const A a；那么a只能访问A的const成员函数。而对于：A b；b可以访问任何成员函数。
 使用const关键字修饰的变量，一定要对变量进行初始化
指针与引用的区别  指针只是一个变量，只不过这个变量存储的是一个地址；而引用跟原来的变量实质上是同一个东西，只不过是原变量的一个别名而已，不占用内存空间。 引用必须在定义的时候初始化，而且初始化后就不能再改变；而指针不必在定义的时候初始化，初始化后可以改变。 指针可以为空，但引用不能为空（这就意味着我们拿到一个引用的时候，是不需要判断引用是否为空的，而拿到一个指针的时候，我们则需要判断它是否为空。这点经常在判断函数参数是否有效的时候使用。） “sizeof 引用&amp;quot; = 指向变量的大小 ， &amp;ldquo;sizeof 指针&amp;rdquo;= 指针本身的大小 指针可以有多级，而引用只能是一级
new与malloc的区别  malloc与free是C&#43;&#43;/C语言的标准库函数，new/delete是C&#43;&#43;的运算符。它们都可用于申请动态内存和释放内存。 对于非内部数据类型的对象而言，光用malloc/free无法满足动态对象的要求。对象在创建的同时要自动执行构造函数，对象在消亡之前要自动执行析构函数。 new可以认为是malloc加构造函数的执行。new出来的指针是直接带类型信息的。而malloc返回的都是void指针。
C&#43;&#43;的多态性  多态性可以简单地概括为“一个接口，多种方法”，程序在运行时才决定调用的函数 。C&#43;&#43;多态性主要是通过虚函数实现的，虚函数允许子类重写override(注意和overload的区别，overload是重载，是允许同名函数的表现，这些函数参数列表/类型不同）
 多态与非多态的实质区别就是函数地址是早绑定还是晚绑定。如果函数的调用，在编译器编译期间就可以确定函数的调用地址，并生产代码，是静态的，就是说地址是早绑定的。而如果函数调用的地址不能在编译器期间确定，需要在运行时才确定，这就属于晚绑定。
 在绝大多数情况下，程序的功能是在编译的时候就确定下来的，我们称之为静态特性。反之，如果程序的功能是在运行时刻才能确定下来的，则称之为动态特性。C&#43;&#43;中，虚函数，抽象基类，动态绑定和多态构成了出色的动态特性。
 最常见的用法就是声明基类的指针，利用该指针指向任意一个子类对象，调用相应的虚函数，可以根据指向的子类的不同而实现不同的方法。
 a、编译时多态性：通过重载函数实现 b、运行时多态性：通过虚函数实现 有关重载，重写，覆盖的区别请移步：https://www.cnblogs.com/LUO77/p/5771237.html  虚函数表  请移步：https://www.cnblogs.com/LUO77/p/5771237.html  动态绑定与静态绑定  静态绑定发生在编译期，动态绑定发生在运行期； 对象的动态类型可以更改，但是静态类型无法更改； 要想实现动态，必须使用动态绑定； 在继承体系中只有虚函数使用的是动态绑定，其他的全部是静态绑定； 静态多态是指通过模板技术或者函数重载技术实现的多态，其在编译器确定行为。动态多态是指通过虚函数技术实现在运行期动态绑定的技术 动态绑定：有一个基类，两个派生类，基类有一个virtual函数，两个派生类都覆盖了这个虚函数。现在有一个基类的指针或者引用，当该基类指针或者引用指向不同的派生类对象时，调用该虚函数，那么最终调用的是该被指向对象对应的派生类自己实现的虚函数。
虚函数表是针对类的还是针对对象的？同一个类的两个对象的虚函数表是怎么维护的？  编译器为每一个类维护一个虚函数表（本质是一个函数指针数组，数组里面存放了一系列函数地址 ），每个对象的首地址保存着该虚函数表的指针，同一个类的不同对象实际上指向同一张虚函数表。调用形式：*(this指针&#43;调整量)虚函数在vftable内的偏移
 在类内部添加一个虚拟函数表指针，该指针指向一个虚拟函数表，该虚拟函数表包含了所有的虚拟函数的入口地址，每个类的虚拟函数表都不一样，在运行阶段可以循此脉络找到自己的函数入口。纯虚函数相当于占位符， 先在虚函数表中占一个位置由派生类实现后再把真正的函数指针填进去。除此之外和普通的虚函数没什么区别。
 在单继承形式下，子类的完全获得父类的虚函数表和数据。子类如果重写了父类的虚函数（如fun），就会把虚函数表原本fun对应的记录（内容MyClass::fun）覆盖为新的函数地址（内容MyClassA::fun），否则继续保持原本的函数地址记录。
 使用这种方式，就可以实现多态的特性。假设我们使用如下语句：
MyClass*pc=new MyClassA; pc-&amp;gt;fun();
因为虚函数表内的函数地址已经被子类重写的fun函数地址覆盖了，因此该处调用的函数正是MyClassA::fun，而不是基类的MyClass::fun。
 如果使用MyClassA对象直接访问fun，则不会出发多态机制，因为这个函数调用在编译时期是可以确定的，编译器只需要直接调用MyClassA::fun即可。
 注：对象不包含虚函数表，只有虚指针，类才包含虚函数表，派生类会生成一个兼容基类的虚函数表
 详情可以参考：http://www.cnblogs.com/fanzhidongyzby/archive/2013/01/14/2859064.html
智能指针怎么实现？什么时候改变引用计数？  构造函数中计数初始化为1； 拷贝构造函数中计数值加1； 赋值运算符中，左边的对象引用计数减一，右边的对象引用计数加一； 析构函数中引用计数减一； 在赋值运算符和析构函数中，如果减一后为0，则调用delete释放对象。
内联函数，宏定义和普通函数的区别  内联函数要做参数类型检查，这是内联函数跟宏相比的优势 宏定义是在预编译的时候把所有的宏名用宏体来替换，简单的说就是字符串替换， 内联函数则是在编译的时候进行代码插入，编译器会在每处调用内联函数的地方直接把内联函数的内容展开，这样可以省去函数的调用的压栈出栈的开销，提高效率。 内联函数是指嵌入代码，就是在调用函数的地方不是跳转，而是把代码直接写到那里去。对于短小简单的代码来说，内联函数可以带来一定的效率提升，而且和C时代的宏函数相比，内联函数 更安全可靠。可是这个是以增加空间消耗为代价的 const与#define的区别：宏在预处理阶段替换，const在编译阶段替换；宏没有类型，不做安全检查，const有类型，在编译阶段进行安全检查
C&#43;&#43;内存管理  栈: 存放函数参数以及局部变量 , 在出作用域时 , 将自动被释放 . 栈内存分配运算内置于处理器的指令集中 , 效率 很 高 , 但分配的内存容量有限 . 堆 :new 分配的内存块 ( 包括数组 , 类实例等 ), 需 delete 手动释放 . 如果未释放 , 在整个程序结束后 ,OS 会帮你回收掉 . 自由存储区: malloc 分配的内存块 , 需 free 手动释放 . 它和堆有些相似 . 全局/静态区: 保存自动全局变量和static变量（包括static全局和局部变量）。静态区的内容在整个程序的生命周期内都存在，有编译器在编译的时候分配（数据段（存储全局数据和静态数据）和代码段（可执行的代码/只读常量））。 常量存储区: 常量 (const) 存于此处 , 此存储区不可修改 . 栈与堆的区别： 管理方式不同: 栈是编译器自动管理的,堆需手动释放 空间大小不同: 在32位OS下,堆内存可达到4GB的的空间,而栈就小得可怜.(VC6中,栈默认大小是1M,当然,你可以修改它) 能否产生碎片不同:对于栈来说,进栈/出栈都有着严格的顺序(先进后出),不会产生碎片;而堆频繁的new/delete,会造成内存空间的不连续,容易产生碎片. 生长方向不同:栈向下生长,以降序分配内存地址;堆向上生长,以升序分配内在地址. 分配方式不同:堆动态分配,无静态分配;栈分为静态分配和动态分配,比如局部变量的分配,就是动态分配(alloca函数),函数参数的分配就是动态分配(我想的…). 分配效率不同:栈是系统提供的数据结构,计算机会在底层对栈提供支持,进栈/出栈都有专门的指令,这就决定了栈的效率比较高.堆则不然,它由C/C&#43;&#43;函数库提供,机制复杂,堆的效率要比栈低得多. 可以看出,栈的效率要比堆高很多,所以,推荐大家尽量用栈.不过,虽然栈有如此多的好处,但远没有堆使用灵活.
常用的设计模式  单例模式：保证一个类仅有一个实例，并提供一个访问它的全局访问点；
 工厂模式：定义一个用于创建对象的接口，让子类决定实例化哪一个类。
 参考：https://www.cnblogs.com/Y1Focus/p/6707121.html https://www.zhihu.com/question/34574154?sort=created
手写strcpy，memcpy，strcat，strcmp等函数 https://blog.csdn.net/gao1440156051/article/details/51496782
https://blog.csdn.net/wilsonboliu/article/details/7919773
i&#43;&#43;是否为原子操作？  不是。操作系统原子操作是不可分割的，在执行完毕不会被任何其它任务或事件中断，分为两种情况（两种都应该满足）
 （1） 在单线程中， 能够在单条指令中完成的操作都可以认为是&amp;quot; 原子操作&amp;quot;，因为中断只能发生于指令之间。
 （2） 在多线程中，不能被其它进程（线程）打断的操作就叫原子操作。
 i&#43;&#43;分为三个阶段：
 内存到寄存器 寄存器自增 写回内存 这三个阶段中间都可以被中断分离开.
有关数组，指针，函数的三者结合问题  数组指针和指针数组的区别：https://blog.csdn.net/men_wen/article/details/52694069
 右左法则的说明：http://www.cnblogs.com/zhangjing0502/archive/2012/06/08/2542059.html
 指针常量和常量指针：https://www.zhihu.com/question/19829354
 https://blog.csdn.net/xingjiarong/article/details/47282563
 注意：所谓指向常量的指针或引用（即常量引用、常量指针），不过是指针或引用“自以为是”罢了，它们觉得自己指向了常量，所以自觉地不去改变所指对象的值，但这些对象却可以通过其他途径改变。
 const int *a; 等价于int const *a; const在前面所以内容不可以改变，但是指针指向可以改变。也就是常量指针
 int *const a; 表示的是指针指向不可改变，但是指针所存放的内容可以改变，也即是指针常量
C&#43;&#43;中类与结构体的区别？  最本质的一个区别就是默认的访问控制： struct作为数据结构的实现体，它默认的数据访问控制是public的，而class作为对象的实现体，它默认的成员变量访问控制是private的。 “class”这个关键字还用于定义模板参数，就像“typename”。但关键字“struct”不用于定义模板参数。
析构函数的作用？  析构函数是用来释放所定义的对象中使用的指针，默认的析构函数不用显示调用，自建的析构函数要在程序末尾调用。 如果你的类里面只用到的基本类型，如int char double等，系统的默认析构函数其实什么都没有做 但如果你使用了其他的类如vector，string等，系统的默认析构函数就会调用这些类对象的析构函数 如果是自己写析构函数的话，如果你的类里面分配了系统资源，如new了内存空间，打开了文件等，那么在你的析构函数中就必须释放相应的内存空间和关闭相关的文件；这样系统就会自动调用你的析构函数释放资源，避免内存泄漏
例如：
class A { private:  char *data; public:  A()  {  data = new char[10];  }  ~A()  {  delete[] data;  } }; A a; a 中将 new 10个 char 当 a 这个变量消亡的时候，将自动执行 ~A()，释放空间 对象消亡时，自动被调用，用来释放对象占用的空间，避免内存泄漏
虚函数的作用？  虚函数可以让成员函数操作一般化，用基类的指针指向不同的派生类的对象时，基类指针调用其虚成员函数，则会调用其真正指向对象的成员函数，而不是基类中定义的成员函数（只要派生类改写了该成员函数）。若不是虚函数，则不管基类指针指向的哪个派生类对象，调用时都会调用基类中定义的那个函数。虚函数是C&#43;&#43;多态的一种表现，可以进行灵活的动态绑定。 重点可参考：https://www.cnblogs.com/wangxiaobao/p/5850949.html http://www.cnblogs.com/fanzhidongyzby/archive/2013/01/14/2859064.html
操作系统和编译器如何区分全局变量和局部变量？  操作系统只管调度进程，编译器通过内存分配的位置来知道的，全局变量分配在全局数据段并且在程序开始运行的时候被加载。局部变量则分配在栈里面 。
Makefile文件的作用？  makefile关系到了整个工程的编译规则。一个工程中的源文件不计数，其按类型、功能、模块分别放在若干个目录中，makefile定义了一系列的规则来指定，哪些文件需要先编译，哪些文件需要后编译，哪些文件需要重新编译，甚至于进行更复杂的功能操作，因为makefile就像一个Shell脚本一样，其中也可以执行操作系统的命令。
 结构体和联合体的区别？ #### 结构和联合都是由多个不同的数据类型成员组成, 但在任何同一时刻, 联合中只存放了一个被选中的成员（所有成员共用一块地址空间）, 而结构的所有成员都存在（不同成员的存放地址不同）。 对于联合的不同成员赋值, 将会对其它成员重写, 原来成员的值就不存在了, 而对于结构的不同成员赋值是互不影响的。
列表初始化问题？  使用初始化列表主要是基于性能问题，对于内置类型，如int, float等，使用初始化列表和在构造函数体内初始化差别不是很大；但是对于类类型来说，最好使用初始化列表。这样就可以直接调用拷贝构造函数初始化，省去了一次调用默认构造函数的过程。
struct Test1 {  Test1() // 无参构造函数  {  cout &amp;lt;&amp;lt; &amp;#34;Construct Test1&amp;#34; &amp;lt;&amp;lt; endl ;  }   Test1(const Test1&amp;amp; t1) // 拷贝构造函数  {  cout &amp;lt;&amp;lt; &amp;#34;Copy constructor for Test1&amp;#34; &amp;lt;&amp;lt; endl ;  this-&amp;gt;a = t1.a ;  }   Test1&amp;amp; operator = (const Test1&amp;amp; t1) // 赋值运算符  {  cout &amp;lt;&amp;lt; &amp;#34;assignment for Test1&amp;#34; &amp;lt;&amp;lt; endl ;  this-&amp;gt;a = t1.a ;  return *this;  }   int a ; };  struct Test2 //普通初始化 {  Test1 test1 ;  Test2(Test1 &amp;amp;t1)  {  test1 = t1 ;  } }; struct Test2 //2.列表初始化 {  Test1 test1 ;  Test2(Test1 &amp;amp;t1):test1(t1){} } Test1 t1 ; //调用 Test2 t2(t1) ; 普通初始化： 列表初始化： 下列情况一定要使用初始化成员列表 常量成员，因为常量只能初始化不能赋值，所以必须放在初始化列表里面 引用类型，引用必须在定义的时候初始化，并且不能重新赋值，所以也要写在初始化列表里面 需要初始化的数据成员是对象的情况 参考地址：https://www.cnblogs.com/weizhixiang/p/6374430.html
重载与重写的区别？  从定义上来说：重载：是指允许存在多个同名函数，而这些函数的参数表不同（或许参数个数不同，或许参数类型不同，或许两者都不同）。重写：是指子类重新定义父类虚函数的方法。 从实现原理上来说：重载：编译器根据函数不同的参数表，对同名函数的名称做修饰，然后这些同名函数就成了不同的函数。重写：当子类重新定义了父类的虚函数后，父类指针根据赋给它的不同的子类指针，动态的调用属于子类的该函数，这样的函数调用在编译期间是无法确定的（调用的子类的虚函数的地址无法给出）。 补充：“隐藏”是指派生类的函数屏蔽了与其同名的基类函数。规则如下： （1）如果派生类的函数与基类的函数同名，但是参数不同。此时，不论有无virtual关键字，基类的函数将被隐藏（注意别与重载混淆）。 （2）如果派生类的函数与基类的函数同名，并且参数也相同，但是基类函数没有virtual 关键字。此时，基类的函数被隐藏（注意别与覆盖混淆）。
类型安全以及C&#43;&#43;中的类型转换？  类型安全很大程度上可以等价于内存安全，类型安全的代码不会试图访问自己没被授权的内存区域。C只在局部上下文中表现出类型安全，比如试图从一种结构体的指针转换成另一种结构体的指针时，编译器将会报告错误，除非使用显式类型转换。然而，C中相当多的操作是不安全的。 详情可以移步：https://blog.csdn.net/chengonghao/article/details/50974022 四种类型转换：
 static_cast &amp;lt;T*&amp;gt; (content) 静态转换.在编译期间处理，可以实现C&#43;&#43;中内置基本数据类型之间的相互转换。如果涉及到类的话，static_cast只能在有相互联系的类型中进行相互转换,不一定包含虚函数。 dynamic_cast&amp;lt;T*&amp;gt;(content) 动态类型转换;也是向下安全转型;是在运行的时候执行;基类中一定要有虚函数，否则编译不通过。在类层次间进行上行转换时（如派生类指针转为基类指针），dynamic_cast和static_cast的效果是一样的。在进行下行转换时（如基类指针转为派生类指针），dynamic_cast具有类型检查的功能，比static_cast更安全。 const_cast&amp;lt;T*&amp;gt;(content) 去常转换;编译时执行; reinterpret_cast&amp;lt;T*&amp;gt;(content) 重解释类型转换; 详情可以移步：https://blog.csdn.net/u010025211/article/details/48626687 https://blog.csdn.net/xtzmm1215/article/details/46475565 https://blog.csdn.net/xingkongfenqi/article/details/49148885
内存对齐的原则以及作用？  结构体内的成员按自身长度自对齐（32位机器上，如char=1，short=2，int=4，double=8），所谓自对齐是指该成员的起始地址必须是它自身长度的整数倍。如int只能以0,4,8这类地址开始。 结构体的总大小为结构体的有效对齐值的整数倍（默认以结构体中最长的成员长度为有效值的整数倍，当用#pragrma pack（n）指定时，以n和结构体中最长的成员的长度中较小者为其值）。即sizeof的值，必须是其内部最大成员的整数倍，不足的要补齐。 例如：
class A {  char c;  int a;  char d; };  cout &amp;lt;&amp;lt; sizeof(A) &amp;lt;&amp;lt; endl;  class B {  char c;  char d;  int a; };  cout &amp;lt;&amp;lt; sizeof(B) &amp;lt;&amp;lt; endl; sizeof（A）=12，sizeof（B）=8；  因为左边是1&#43;（3）&#43;4&#43;1&#43;（3）=12，而右边是1&#43;1&#43;（2）&#43;4=8。括号中为补齐的字节。 内存对齐的作用： 1、平台原因(移植原因)：不是所有的硬件平台都能访问任意地址上的任意数据的；某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常。 2、性能原因：经过内存对齐后，CPU的内存访问速度大大提升。 详情可以移步：https://blog.csdn.net/chy19911123/article/details/48894579
关键字registr，typdef的作用？  register关键字的作用： 请求CPU尽可能让变量的值保存在CPU内部的寄存器中，减去CPU从内存中抓取数据的时间，提高程序运行效率。 使用register关键字应注意什么？ 1.只有局部变量才可以被声明用register修饰 （register不能修饰全局变量和函数的原因：全局变量可能被多个进程访问，而用register修饰的变量，只能被当前进程访问） 2.不能用取地址获取用register修饰的变量的地址（原因：变量保存在寄存器中，而取地址获取的地址的是内存的地址） 3. 用register修饰的变量一定要是CPU所接受的数据类型 typedef关键字的作用： 给数据类型定义一个新名字， 1. 提高了移植性 2. 简化复杂的类型声明，提高编码效率 3. 解释数据类型的作用
什么情况下需要将析构函数定义为虚函数？  当基类指针指向派生类的对象（多态性）时。如果定义为虚函数，则就会先调用该指针指向的派生类析构函数，然后派生类的析构函数再又自动调用基类的析构函数，这样整个派生类的对象完全被释放。如果析构函数不被声明成虚函数，则编译器实施静态绑定，在删除基类指针时，只会调用基类的析构函数而不调用派生类析构函数，这样就会造成派生类对象析构不完全。所以，将析构函数声明为虚函数是十分必要的。 详情可以移步：https://blog.csdn.net/jiadebin890724/article/details/7951461 有关纯虚函数的理解？ 纯虚函数是为你的程序制定一种标准，纯虚函数只是一个接口，是个函数的声明而已，它要留到子类里去实现。
class A{ protected: void foo();//普通类函数 virtual void foo1();//虚函数 virtual void foo2() = 0;//纯虚函数 }  带纯虚函数的类抽象类，这种类不能直接生成对象，而只有被继承，并重写其虚函数后，才能使用。 虚函数是为了继承接口和默认行为 纯虚函数只是继承接口，行为必须重新定义 在很多情况下，基类本身生成对象是不合情理的。例如，动物作为一个基类可以派生出老虎、孔雀等子类，但动物本身生成对象明显不合常 理。所以引入了纯虚函数的概念） 详情可以参考：https://blog.csdn.net/ybhjx/article/details/51788396
基类指针指向派生类，派生类指针指向基类？  基类指针可以指向派生类对象，从而实现多态，例如：
#include &amp;lt;iostream&amp;gt; using namespace std; class Shape { public:  virtual double area() const = 0; //纯虚函数 };  class Square : public Shape {  double size; public:  Square(double s) {  size = s;  }  virtual double area() const {  return size * size;  } };  class Circle : public Shape {  double radius; public:  Circle(double r) {  radius = r;  }  virtual double area() const {  return 3.14159 * radius * radius;  } };  int main()  {  Shape* array[2]; //定义基类指针数组  Square Sq(2.0);  Circle Cir(1.0);  array[0] = &amp;amp;Sq;  array[1] =&amp;amp;Cir;  for (int i = 0; i &amp;lt; 2; i&#43;&#43;) /  {  cout &amp;lt;&amp;lt; array[i]-&amp;gt;area() &amp;lt;&amp;lt; endl;  }  return 0; }  上面的不同对象Sq,Cir(来自继承同一基类的不同派生类)接受同一消息（求面积，来自基类的成员函数area()）,但是却根据自身情况调用不同的面积公式（执行了不同的行为，它是通过虚函数实现的）。我们可以理解为，继承同一基类的不同派生对象，对来自基类的同一消息执行了不同的行为，这就是多态，它是通过继承和虚函数实现的。而接受同一消息的实现就是基于基类指针。 但是要注意的是，这个指针只能用来调用基类的成员函数。 为了避免这种错误，必须将基类指针强制转化为派生类指针。然后派生类指针可以用来调用派生类的功能。这称为向下强制类型转换，这是一种潜在的危险操作。 派生类指针不可以指向基类对象,例如： 有个people类是基类，成员有姓名和身份证号，有个派生类学生student，添加了成员学号，现在如果你说的这个情况成立student的指针&amp;mdash;-pt让他指向people成员t，则t只有两个成员变量，而*pt有3个，现在pt-&amp;gt;学号这个变量在pt下是可以使用的，但它指向的实体却没有这个变量，所以出错，于是C&#43;&#43;直接就避免了这样的隐式转换。 所以根据上述信息我们可以知道： 进行上行转换（把派生类的指针或引用转换成基类表示）是安全的； 进行下行转换（把基类指针或引用转换成派生类表示）是不安全的。 参考链接：https://blog.csdn.net/flyingbird_sxf/article/details/41358737 https://www.cnblogs.com/rednodel/p/5800142.html
继承机制中引用和指针之间如何转换？  基类——&amp;gt;派生类：用dynamic_cast转换（显示转换），首先检查基类指针（引用）是否真正指向一个派生类对象，然后再做相应处理，对指针进行dynamic_cast，成功返回派生类对象，失败返回空指针，对引用进行dynamic_cast，成功返回派生类对象，失败抛出一个异常。 不允许隐式转换。 派生类——&amp;gt;基类：可以用dynamic_cast或者直接进行类型转换（直接赋值）。
c语言和c&#43;&#43;有什么区别？  C语言是结构化的编程语言，它是面向过程的，而C&#43;&#43;是面向对象的。 封装：将数据和函数等集合在一个单元中（即类）。被封装的类通常称为抽象数据类型。封装的意义在于保护或者防止代码（数据）被我们无意中破坏。 继承：继承主要实现重用代码，节省开发时间。它可以使用现有类的所有功能，并在无需重新编写原来的类的情况下对这些功能进行扩展。 多态：同一操作作用于不同的对象，可以有不同的解释，产生不同的执行结果。在运行时，可以通过指向派生类的基类指针，来调用实现派生类中的方法。有编译时多态和运行时多态。
C&#43;&#43;中的公有，私有，保护的问题？ √：代表可以访问，X代表不能访问。
参考链接：https://zhidao.baidu.com/question/551075894.html
如何实现类对象只能静态分配或动态分配？  C&#43;&#43;中建立类的对象有两种方式： （1）静态建立，例如 A a; 静态建立一个类对象，就是由编译器为对象在栈空间中分配内存。使用这种方法，是直接调用类的构造函数。 （2）动态建立，例如 A* p = new A(); 动态建立一个类对象，就是使用new运算符为对象在堆空间中分配内存。这个过程分为两步：第一步执行operator new( )函数，在堆空间中搜索一块内存并进行分配；第二步调用类的构造函数构造对象。这种方法是间接调用类的构造函数。 只能动态分配：
其实，编译器在为类对象分配栈空间时，会先检查类的析构函数的访问性（其实不光是析构函数，只要是非静态的函数，编译器都会进行检查）。如果类的析构函数在类外部无法访问，则编译器拒绝在栈空间上为类对象分配内存。 因此，可以将析构函数设为private，这样就无法在栈上建立类对象了。但是为了子类可以继承，最好设置成protected。
class A { protected:  A(){}  ~A(){} public:  static A* create(){return new A();}  void destory(){delete this;} };  只能静态分配： 只有使用new运算符，对象才会被建立在堆上。因此只要限制new运算符就可以实现类对象只能建立在栈上。可以将new运算符设为私有。
class A { private:  void* operator new(size_t t){} //注意函数的第一个参数和返回值都是固定的  void operator delete(void* ptr)() //重载了new就需要重载delete public:  A(){}  ~A(){} };  #### explicit关键字的作用？ #### C&#43;&#43;中， 一个参数的 构造函数(或者除了第一个参数外其余参数都有默认值的多参构造函数)， 承担了两个角色。 1 是个 构造器 ，2 是个默认且隐含的类型转换操作符。 所以， 有时候在我们写下如 AAA = XXX， 这样的代码， 且恰好XXX的类型正好是AAA单参数构造器的参数类型， 这时候 编译器就自动调用这个构造器， 创建一个AAA的对象。 这样看起来好象很酷， 很方便。 但在某些情况下（见下面权威的例子）， 却违背了我们（程序员）的本意。 这时候就要在这个构造器前面加上explicit修饰， 指定这个构造器只能被明确的调用/使用， 不能作为类型转换操作符被隐含的使用。
class Test1 { public:  Test1(int n)  {  num=n;  }//普通构造函数 private:  int num; }; class Test2 { public:  explicit Test2(int n)  {  num=n;  }//explicit(显式)构造函数 private:  int num; }; int main() {  Test1 t1=12;//隐式调用其构造函数,成功  Test2 t2=12;//编译错误,不能隐式调用其构造函数  Test2 t2(12);//显式调用成功  return 0; }  Test1的 构造函数带一个int型的参数，代码23行会隐式转换成调用Test1的这个构造函数。而Test2的构造函数被声明为explicit（显式），这表示不能通过隐式转换来调用这个构造函数，因此代码24行会出现编译错误。 普通构造函数能够被 隐式调用。而explicit构造函数只能被显式调用。
内存溢出，内存泄漏的原因？  内存溢出是指程序在申请内存时，没有足够的内存空间供其使用。原因可能如下： 内存中加载的数据量过于庞大，如一次从数据库取出过多数据 代码中存在死循环或循环产生过多重复的对象实体 递归调用太深，导致堆栈溢出等 内存泄漏最终导致内存溢出 内存泄漏是指向系统申请分配内存进行使用（new），但是用完后不归还（delete），导致占用有效内存。常见的几种情况： （1） 在类的构造函数和析构函数中没有匹配的调用new和delete函数 两种情况下会出现这种内存泄露：一是在堆里创建了对象占用了内存，但是没有显示地释放对象占用的内存；二是在类的构造函数中动态的分配了内存，但是在析构 函数中没有释放内存或者没有正确的释放内存 （2） 在释放对象数组时在delete中没有使用方括号 方括号是告诉编译器这个指针指向的是一个对象数组，同时也告诉编译器正确的对象地址值病调用对象的析构函数，如果没有方括号，那么这个指针就被默认为只指向一个对象，对象数组中的其他对象的析构函数就不会被调用，结果造成了内存泄露。 （3）没有将基类的析构函数定义为虚函数 当基类指针指向子类对象时，如果基类的析构函数不是virtual，那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄露 参考链接： https://blog.csdn.net/hyqwmxsh/article/details/52813307 缓冲区溢出（栈溢出） 程序为了临时存取数据的需要，一般会分配一些内存空间称为缓冲区。如果向缓冲区中写入缓冲区无法容纳的数据，机会造成缓冲区以外的存储单元被改写，称为缓冲区溢出。而栈溢出是缓冲区溢出的一种，原理也是相同的。分为上溢出和下溢出。其中，上溢出是指栈满而又向其增加新的数据，导致数据溢出；下溢出是指空栈而又进行删除操作等，导致空间溢出。
auto_ptr类与shared_ptr类？  从c&#43;&#43;11开始, auto_ptr已经被标记为弃用, 常见的替代品为shared_ptr。shared_ptr的不同之处在于引用计数, 在复制(或赋值)时不会像auto_ptr那样直接转移所有权。 两者都是模板类，却可以像指针一样去使用。只是在指针上面的一层封装。 auto_ptr实际也是一种类, 拥有自己的析构函数, 生命周期结束时能自动释放资源，正因为能自动释放资源, 特别适合在单个函数内代替new/delete的调用, 不用自己调用delete，也不用担心意外退出造成内存的泄漏。 atuo_ptr的缺陷： auto_ptr不能共享所有权，即不要让两个auto_ptr指向同一个对象（因为它采用的是转移语义的拷贝，原指针会变为NULL）。 auto_ptr不能管理对象数组（因为它内部的析构函数调用的是delete而不是delete[]）。 auto_ptr不能作为容器对象，STL容器中的元素经常要支持拷贝，赋值等操作，在这过程中auto_ptr会传递所有权。 详情原因可以参考：https://blog.csdn.net/uestclr/article/details/51316001 https://blog.csdn.net/kezunhai/article/details/38514823 shared_ptr 使用引用计数的方式来实现对指针资源的管理。同一个指针资源，可以被多个 shared_ptr 对象所拥有，直到最后一个 shared_ptr 对象析构时才释放所管理的对象资源。 可以说，shared_ptr 是最智能的智能指针，因为其特点最接近原始的指针。不仅能够自由的赋值和拷贝，而且可以安全的用在标准容器中。
有4种情况，编译器必须为未声明的constructor的classes合成一个default ####constructor：  l “带有默认构造函数”的成员对象 l “带有默认构造函数”的基类 l “带有虚函数”的类 l “带有虚拟基类”的类 被合成的构造函数只能满足编译器（而非程序员）的需要。在合成默认的构造函数中，只有基类的子对象和成员对象会被初始化，其他非静态的数据成员（如整数，指针等）都不会被初始化。 所以并不是任何的类如果没有定义默认的构造函数，都会被合成一个出来。
虚基类  在C&#43;&#43;中,如果在多条继承路径上有一个公共的基类,那么在这些路径中的某几条路径的汇合处,这个公共的基类就会产生多个实例（从而造成二义性）.如果想使这个公共的基类只产生一个实例,则可将这个基类说明为虚基类. 这要求在从base类派生新类时,使用关键字virtual将base类说明为虚基类. 用例子说明吧。
class base{protected:int b}; clase base1:public base{..}; clase base2:public base{..}; clase derived:public base1,public base2 {..}; derived d; d.b //错误. d.base::b //错误. 因为不知是用d.base1::b还是d.base2::b ================================================= class base{protected:int b..}; clase base1:virtual public base{..}; //说明base为base1虚基类 clase base2:virtual public base{..}; //说明base为base2虚基类 clase derived:public base1,public base2 {..}; derived d; d.b //对. d.base::b //对. 因为d.base::b和d.base1::b还是d.base2::b都是引用同一虚基类成员b,具有相同的值. 模板的特例化  引入原因：编写单一的模板，它能适应大众化，使每种类型都具有相同的功能，但对于某种特定类型，如果要实现其特有的功能，单一模板就无法做到，这时就需要模板特例化。 定义：是对单一模板提供的一个特殊实例，它将一个或多个模板参数绑定到特定的类型或值上。 函数模板特例化：必须为原函数模板的每个模板参数都提供实参，且使用关键字template后跟一个空尖括号对&amp;lt;&amp;gt;,表明将原模板的所有模板参数提供实参。
1. template &amp;lt;typename T&amp;gt;  2. void fun(T a)  3. {  4. cout &amp;lt;&amp;lt; &amp;#34;The main template fun(): &amp;#34; &amp;lt;&amp;lt; a &amp;lt;&amp;lt; endl;  5. }  6.  7. template &amp;lt;&amp;gt; // 对int型特例化  8. void fun(int a)  9. {  10. cout &amp;lt;&amp;lt; &amp;#34;Specialized template for int type: &amp;#34; &amp;lt;&amp;lt; a &amp;lt;&amp;lt; endl;  11. }  12.  13. int main()  14. {  15. fun&amp;lt;char&amp;gt;(&amp;#39;a&amp;#39;);  16. fun&amp;lt;int&amp;gt;(10);  17. fun&amp;lt;float&amp;gt;(9.15);  18. return 0;  19. }  对于除int型外的其他数据类型，都会调用通用版本的函数模板fun(T a)；对于int型，则会调用特例化版本的fun(int a)。注意，一个特例化版本的本质是一个实例，而非函数的重载。因此，特例化不影响函数匹配。 类模板的特例化：
1. template &amp;lt;typename T&amp;gt; 2. class Test{ 3. public: 4. void print(){ 5. cout &amp;lt;&amp;lt; &amp;#34;General template object&amp;#34; &amp;lt;&amp;lt; endl; 6. } 7. }; 8. 9. template&amp;lt;&amp;gt; // 对int型特例化 10. class Test&amp;lt;int&amp;gt;{ 11. public: 12. void print(){ 13. cout &amp;lt;&amp;lt; &amp;#34;Specialized template object&amp;#34; &amp;lt;&amp;lt; endl; 14. } 15. };  另外，与函数模板不同，类模板的特例化不必为所有模板参数提供实参。我们可以只指定一部分而非所有模板参数，这种叫做类模板的偏特化 或部分特例化（partial specialization）。例如，C&#43;&#43;标准库中的类vector的定义：
1. template &amp;lt;typename T, typename Allocator&amp;gt; 2. class vector 3. { 4. /*......*/ 5. };  6.  7. // 部分特例化  8. template &amp;lt;typename Allocator&amp;gt;  9. class vector&amp;lt;bool, Allocator&amp;gt;  10. {  11. /*......*/  12. };  在vector这个例子中，一个参数被绑定到bool类型，而另一个参数仍未绑定需要由用户指定。注意，一个类模板的部分特例化版本仍然是一个模板，因为使用它时用户还必须为那些在特例化版本中未指定的模板参数提供实参。
参考链接：https://blog.csdn.net/lisonglisonglisong/article/details/38057367 ———————————————— 版权声明：本文为CSDN博主「炫辰0927」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。 原文链接：https://blog.csdn.net/u012864854/article/details/79777991
</content>
    </entry>
    
     <entry>
        <title>golang 的channels 行为</title>
        <url>http://shanks.link/blog/2021/07/19/golang-%E7%9A%84channels-%E8%A1%8C%E4%B8%BA/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 简介 当我第一次使用 Go 的 channels 工作的时候，我犯了一个错误，把 channels 考虑为一个数据结构。我把 channels 看作为 goroutines 之间提供自动同步访问的队列。这种结构上的理解导致我写了很多不好且结构复杂的并发代码。
随着时间的推移，我认识到最好的方式是忘记 channels 是数据结构，转而关注它的行为。所以现在谈论到 channels，我只考虑一件事情：signaling（信号）。一个 channel 允许一个 goroutine 给另外一个发特定事件的信号。信号是使用 channel 做一切事情的核心。将 channel 看作是一种信号机制，可以让你写出明确定义和精确行为的更好代码。
为了理解信号怎样工作，我们必须理解以下三个特性：
 交付保证 状态 有数据或无数据  这三个特性共同构成了围绕信号的设计哲学，在讨论这些特性之后，我将提供一系列代码示例，这些示例将演示使用这些属性的信号。
交付保证 交付保证基于一个问题：“我是否需要保证由特定的 goroutine 发送的信号已经被接收？”
换句话说，我们可以给出清单1的示例：
清单1
01 go func() { 02 p := &amp;lt;-ch // Receive 03 }() 04 05 ch &amp;lt;- &amp;#34;paper&amp;#34; // Send 发送的 goroutine 是否需要保证在第五行中发送给 channel 的 paper，在继续执行前， 会被第二行的 goroutine 接收。
基于这个问题的答案，你将知道使用两种类型的 channels 中的哪种：无缓冲或有缓冲。每个channel围绕交付保证提供不同的行为。
图1
保证很重要，并且如果你不这样认为，我有很多东西兜售给你。当然，我想开个玩笑，当你的生活没有保障的时候你不会害怕吗？在编写并发代码时，对是否需要一项保证有很强的理解是至关重要的。随着继续，你将学会如何做决策。
状态 一个 channel 的行为直接被它当前的状态所影响。一个channel 的状态是：nil，open 或 closed。
下面的清单2展示了怎样声明或把一个 channel放进这三个状态。
清单2
// ** nil channel  // A channel is in a nil state when it is declared to its zero value var ch chan string  // A channel can be placed in a nil state by explicitly setting it to nil. ch = nil   // ** open channel  // A channel is in a open state when it’s made using the built-in function make. ch := make(chan string)   // ** closed channel  // A channel is in a closed state when it’s closed using the built-in function close. close(ch) 状态决定了怎样send（发送）和receive（接收）操作行为。
信号通过一个 channel 发送和接收。不要说读和写，因为 channels 不执行 I/O。
图2
当一个 channel 是 nil 状态，任何试图在 channel 的发送或接收都将会被阻塞。当一个 channel 是在 open 状态，信号可以被发送和接收。当一个 channel 被置为 closed 状态，信号将不在被发送，但是依然可以接收信号。
这些状态将在你遭遇不同的情况的时候可以提供不同的行为。当结合状态和交付保证，作为你设计选择的结果，你可以分析你承担的成本/收益。你也可以仅仅通过读代码快速发现错误，因为你懂得 channel 将表现出什么行为。
有数据和无数据 最后的信号特性需要考虑你是否需要信号有数据或者无数据。
在一个 channel 中有数据的信号被执行一个发送。
清单3
01 ch &amp;lt;- &amp;#34;paper&amp;#34; 当你的信号有数据，它通常是因为：
 一个 goroutine 被要求启动一个新的 task。 一个 goroutine 传达一个结果。  无数据信号通过关闭一个 channel。
清单4
01 close(ch) 当信号没有数据的时候，它通常是因为：
 一个 goroutine 被告知停止它正在做的事情。 一个 goroutine 报告它们已经完成，没有结果。 一个 goroutine 报告它已经完成处理并且关闭。  这些规则也有例外，但这些都是主要的用例，并且我们将在本文中重点讨论这些问题。我认为这些规则例外的情况是最初的代码味道。
无数据信号的一个好处是一个单独的 goroutine 可以立刻给很多 goroutines 信号。有数据的信号通常是在 goroutines 之间一对一的交换数据。
有数据信号 当你使用有数据信号的时候，依赖于你需要保证的类型，有三个channel配置选项可以选择。
图3：有数据信号
这三个 channel 选项是：Unbuffered, Buffered &amp;gt;1 或 Buffered =1。
 有保证  一个无缓冲的channel给你保证被发送的信号已经被接收。  因为信号接收发生在信号发送完成之前。     无保证  一个 size &amp;gt; 1 的有缓冲的 channel 不会保证发送的信号已经被接收。  因为信号发送发生在信号接送完成之前。     延迟保证  一个 size = 1 的有缓冲 channel 提供延迟保证。它可以保证先前发送的信号已经被接收。  因为第一个接收信号，发生在第二个完成的发送信号之前。      缓冲大小绝对不能是一个随机数字，它必须是为一些定义好的约束而计算出来的。在计算中没有无穷大，无论是空间还是时间，所有的东西都必须要有良好的定义约束。
无数据信号 无数据信号主要用于取消，它允许一个 goroutine 发送信号给另外一个来取消它们正在做的事情。取消可以被有缓冲和无缓冲的channels实现，但是在没有数据发送的情况下使用缓冲 channel 会更好。
图4：无数据信号
内建的函数 close 被用于无数据信号。正如上面状态章节所解释的那样，你依然可以在channel关闭的时候接收信号。实际上，在一个关闭的channel上的任何接收都不会被阻塞，并且接收操作将一直返回。
在大多数情况下，你想使用标准的库 context 包来实现无数据信号。context 包使用一个无缓冲channel传递信号以及内建函数close发送无数据信号。
如果你选择使用你自己的 channel 而不是 context包来取消，你的channel 应该是chan struct{} 类型，这是一种零空间的惯用方式，用来表示一个信号仅仅用于信号传递。
场景 有了这些特性，更进一步理解它们在实践中怎样工作的最好方式就是运行一系列的代码场景。当我在读写 channel 基础代码的时候，我喜欢把goroutines想像成人。这个形象对我非常有帮助，我将把它用作下面的辅助工具。
有数据信号 - 保证 - 无缓冲 Channels 当你需要知道一个被发送的信号已经被接收的时候，有两种情况需要考虑。它们是 等待任务和等待结果。
场景1 - 等待任务 考虑一下作为一名经理，需要雇佣一名新员工。在本场景中，你想你的新员工执行一个任务，但是他们需要等待直到你准备好。这是因为在他们开始前你需要递给他们一份报告。
清单5
在线演示地址
01 func waitForTask() { 02 ch := make(chan string) 03 04 go func() { 05 p := &amp;lt;-ch 06 07 // Employee performs work here. 08 09 // Employee is done and free to go. 10 }() 11 12 time.Sleep(time.Duration(rand.Intn(500)) * time.Millisecond) 13 14 ch &amp;lt;- &amp;#34;paper&amp;#34; 15 } 在清单5的第2行，一个带有属性的无缓冲channel被创建，string 数据将与信号一起被发送。在第4行，一名员工被雇佣并在开始工作前，被告诉等待你的信号【在第5行】。第5行是一个 channel 接收，引起员工阻塞直到等到你发送的报告。一旦报告被员工接收，员工将执行工作并在完成的时候可以离开。
你作为经理正在并发的与你的员工工作。因此在第4行你雇佣员工之后，你发现你自己需要做什么来解锁并且发信号给员工（第12行）。值得注意的是，不知道要花费多长的时间来准备这份报告（paper）。
最终你准备好给员工发信号，在第14行，你执行一个有数据信号，数据就是那份报告。由于一个无缓冲的channel被使用，你得到一个保证就是一旦你操作完成，员工就已经接收到了这份报告。接收发生在发送之前。
技术上你所知道的一切就是在你的channel发送操作完成的同时员工接收到了这份报告。在两个channel操作之后，调度器可以选择执行它想要执行的任何语句。下一行被执行的代码是被你还是员工是不确定的。这意味着使用print语句会欺骗你关于事件的执行顺序。
场景2 - 等待结果 在下一个场景中，事情是相反的。这时你想你的员工一被雇佣就立即执行他们的任务。然后你需要等待他们工作的结果。你需要等待是因为在你继续前你需要他们发来的报告。
清单6 在线演示地址
01 func waitForResult() { 02 ch := make(chan string) 03 04 go func() { 05 time.Sleep(time.Duration(rand.Intn(500)) * time.Millisecond) 06 07 ch &amp;lt;- &amp;#34;paper&amp;#34; 08 09 // Employee is done and free to go. 10 }() 11 12 p := &amp;lt;-ch 13 } 成本/收益 无缓冲 channel 提供了信号被发送就会被接收的保证，这很好，但是没有任何东西是没有代价的。这个成本就是保证是未知的延迟。在等待任务场景中，员工不知道你要花费多长时间发送你的报告。在等待结果场景中，你不知道员工会花费多长时间把报告发送给你。
在以上两个场景中，未知的延迟是我们必须面对的，因为它需要保证。没有这种保证行为，逻辑就不会起作用。
有数据信号 - 无保证 - 缓冲 Channels &amp;gt; 1 场景1 - 扇出（Fan Out） 扇出模式允许你抛出明确定义数量的员工在同时工作的问题上。由于你每个任务都有一个员工，你很明确的知道你会接收多少个报告。你可能需要确保你的盒子有适量的空间来接收所有的报告。这就是你员工的收益，不需要等待你来提交他们的报告。但是他们确实需要轮流把报告放进你的盒子，如果他们几乎同一时间到达盒子。
再次假设你是经理，但是这次你雇佣一个团队的员工，你有一个单独的任务，你想每个员工都执行它。作为每个单独的员工完成他们的任务，他们需要给你提供一张报告放进你桌子上的盒子里面。
清单7 演示地址
01 func fanOut() { 02 emps := 20 03 ch := make(chan string, emps) 04 05 for e := 0; e &amp;lt; emps; e&#43;&#43; { 06 go func() { 07 time.Sleep(time.Duration(rand.Intn(200)) * time.Millisecond) 08 ch &amp;lt;- &amp;#34;paper&amp;#34; 09 }() 10 } 11 12 for emps &amp;gt; 0 { 13 p := &amp;lt;-ch 14 fmt.Println(p) 15 emps-- 16 } 17 } 在清单7的第3行，一个带有属性的有缓冲channel被创建，string 数据将与信号一起被发送。这时，由于在第2行声明的 emps 变量，将创建有 20个缓冲的 channel。
在第5行和第10行之间，20 个员工被雇佣，并且他们立即开始工作。在第7行你不知道每个员工将花费多长时间。这时在第8行，员工发送他们的报告，但这一次发送不会阻塞等待接收。因为在盒子里为每位员工准备的空间，在 channel 上的发送仅仅与其他在同一时间想发送他们报告的员工竞争。
在 12 行和16行之间的代码全部是你的操作。在这里你等待20个员工来完成他们的工作并且发送报告。在12行，你在一个循环中，在 13 行你被阻塞在一个 channel 等待接收你的报告。一旦报告接收完成，报告在14被打印，并且本地的计数器变量被消耗来表明一个员工意见完成了他的工作。
场景2 - Drop Drop模式允许你在你的员工在满负荷的时候丢掉工作。这有利于继续接受客户端的工作，并且从不施加压力或者是这项工作可接受的延迟。这里的关键是知道你什么时候是满负荷的，因此你不承担或过度承诺你将尝试完成的工作量。通常集成测试或度量可以帮助你确定这个数字。
假设你是经理，你雇佣了单个员工来完成工作。你有一个单独的任务想员工去执行。当员工完成他们任务时，你不在乎知道他们已经完成了。最重要的是你能或不能把新工作放入盒子。如果你不能执行发送，这时你知道你的盒子满了并且员工是满负荷的。这时候，新工作需要丢弃以便让事情继续进行。
清单8 演示地址
01 func selectDrop() { 02 const cap = 5 03 ch := make(chan string, cap) 04 05 go func() { 06 for p := range ch { 07 fmt.Println(&amp;#34;employee : received :&amp;#34;, p) 08 } 09 }() 10 11 const work = 20 12 for w := 0; w &amp;lt; work; w&#43;&#43; { 13 select { 14 case ch &amp;lt;- &amp;#34;paper&amp;#34;: 15 fmt.Println(&amp;#34;manager : send ack&amp;#34;) 16 default: 17 fmt.Println(&amp;#34;manager : drop&amp;#34;) 18 } 19 } 20 21 close(ch) 22 } 在清单8的第3行，一个有属性的有缓冲 channel 被创建，string 数据将与信号一起被发送。由于在第2行声明的cap 常量，这时创建了有5个缓冲的 channel。
从第5行到第9行，一个单独的员工被雇佣来处理工作，一个 for range被用于循环处理 channel 的接收。每次一份报告被接收，在第7行被处理。
在第11行和19行之间，你尝试发送20分报告给你的员工。这时一个 select语句在第14行的第一个case被用于执行发送。因为default从句被用于第16行的select语句。如果发送被堵塞，是因为缓冲中没有多余的空间，通过执行第17行发送被丢弃。
最后在第21行，内建函数close被调用来关闭channel。这将发送没有数据的信号给员工表明他们已经完成，并且一旦他们完成分派给他们的工作可以立即离开。
成本/收益 有缓冲的 channel 缓冲大于1提供无保证发送的信号被接收到。离开保证是有好处的，在两个goroutine之间通信可以降低或者是没有延迟。在扇出场景，这有一个有缓冲的空间用于存放员工将被发送的报告。在Drop场景，缓冲是测量能力的，如果容量满，工作被丢弃以便工作继续。
在两个选择中，这种缺乏保证是我们必须面对的，因为延迟降低非常重要。0到最小延迟的要求不会给系统的整体逻辑造成问题。
有数据信号 - 延迟保证- 缓冲1的channel 场景1 - 等待任务 清单9 演示地址
01 func waitForTasks() { 02 ch := make(chan string, 1) 03 04 go func() { 05 for p := range ch { 06 fmt.Println(&amp;#34;employee : working :&amp;#34;, p) 07 } 08 }() 09 10 const work = 10 11 for w := 0; w &amp;lt; work; w&#43;&#43; { 12 ch &amp;lt;- &amp;#34;paper&amp;#34; 13 } 14 15 close(ch) 16 } 在清单9的第2行，一个带有属性的一个缓冲大小的 channel 被创建，string 数据将与信号一起被发送。在第4行和第8行之间，一个员工被雇佣来处理工作。for range被用于循环处理 channel 的接收。在第6行每次一份报告被接收就被处理。
在第10行和13行之间，你开始发送你的任务给员工。如果你的员工可以跑的和你发送的一样快，你们之间的延迟会降低。但是每次发送你成功执行，你需要保证你提交的最后一份工作正在被进行。
在最后的第15行，内建函数close 被调用关闭channel，这将会发送无数据信号给员工告知他们工作已经完成，可以离开了。尽管如此，你提交的最后一份工作将在 for range中断前被接收。
无数据信号 - Context 在最后这个场景中，你将看到从 Context 包中使用 Context 值怎样取消一个正在运行的goroutine。这所有的工作是通过改变一个已经关闭的无缓冲channel来执行一个无数据信号。
最后一次你是经理，你雇佣了一个单独的员工来完成工作，这次你不会等待员工未知的时间完成他的工作。你分配了一个截止时间，如果你的员工没有按时完成工作，你将不会等待。
清单10 演示地址
01 func withTimeout() { 02 duration := 50 * time.Millisecond 03 04 ctx, cancel := context.WithTimeout(context.Background(), duration) 05 defer cancel() 06 07 ch := make(chan string, 1) 08 09 go func() { 10 time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond) 11 ch &amp;lt;- &amp;#34;paper&amp;#34; 12 }() 13 14 select { 15 case p := &amp;lt;-ch: 16 fmt.Println(&amp;#34;work complete&amp;#34;, p) 17 18 case &amp;lt;-ctx.Done(): 19 fmt.Println(&amp;#34;moving on&amp;#34;) 20 } 21 } 在清单10的第2行，一个时间值被声明，它代表了员工将花费多长时间完成他们的工作。这个值被用在第4行来创建一个50毫秒超时的 context.Context 值。context 包的WithTimeout函数返回一个 Context 值和一个取消函数。
context包创建一个goroutine，一旦时间值到期，将关闭与Context 值关联的无缓冲channels。不管事情如何发生，你需要负责调用cancel 函数。这将清理被Context创建的东西。cancel被调用不止一次是可以的。
在第5行，一旦函数中断，cancel函数被 deferred 执行。在第7行，1个缓冲的channels被创建，它被用于被员工发送他们工作的结果给你。在第09行和12行，员工被雇佣兵立即投入工作，你不需要指定员工花费多长时间完成他们的工作。
在第14行和20行之间，你使用 select 语句来在两个channels接收。在第15行的接收，你等待员工发送他们的结果。在第18行的接收，你等待看context 包是否正在发送信号50毫秒的时间到了。无论你首先收到哪个信号，都将有一个被处理。
这个算法的一个重要方面是使用一个缓冲的channels。如果员工没有按时完成，你将离开而不会给员工任何通知。对于员工而言，在第11行他将一直发送他的报告，你在或者不在那里接收，他都是盲目的。如果你使用一个无缓冲channels，如果你离开，员工将一直阻塞在那尝试你给发送报告。这会引起goroutine泄漏。因此一个缓冲的channels用来防止这个问题发生。
总结 当使用 channels（或并发） 时，在保证，channel状态和发送过程中信号属性是非常重要的。它们将帮助你实现你并发程序需要的更好的行为以及你写的算法。它们将帮助你找出bug和闻出潜在的坏代码。
在本文中，我分享了一些程序示例来展示信号属性工作在不同的场景中。凡事都有例外，但是这些模式是非常良好的开端。
作为总结回顾下这些要点，何时，如何有效地思考和使用channels：
语言机制  使用 channels 来编排和协作 goroutines：  关注信号属性而不是数据共享 有数据信号和无数据信号 询问它们用于同步访问共享数据的用途  有些情况下，对于这个问题，通道可以更简单一些，但是最初的问题是。     无缓冲 channels：  接收发生在发送之前 收益：100%保证信号被接收 成本：未知的延迟，不知道信号什么时候将被接收。   有缓冲 channels：  发送发生在接收之前。 收益：降低信号之间的阻塞延迟。 成本：不保证信号什么时候被接收。  缓冲越大，保证越少。 缓冲为1可以给你一个延迟发送保证。     关闭的 channels：  关闭发生在接收之前（像缓冲）。 无数据信号。 完美的信号取消或截止。   nil channels：  发送和接收都阻塞。 关闭信号。 完美的速度限制或短时停工。    设计哲学  如果在 channel上任何给定的发送能引起发送 goroutine 阻塞：  不允许使用大于1的缓冲channels。  缓冲大于1必须有原因/测量。   必须知道当发送 goroutine阻塞的时候发生了什么。   如果在 channel 上任何给定的发送不会引起发送阻塞：  每个发送必须有确切的缓冲数字。  扇出模式。   有缓冲测量最大的容量。  Drop 模式。     对于缓冲而言，少即是多。  当考虑缓冲的时候，不要考虑性能。 缓冲可以帮助降低信号之间的阻塞延迟。  降低阻塞延迟到0并不一定意味着更好的吞吐量。 如果一个缓冲可以给你足够的吞吐量，那就保持它。 缓冲大于1的问题需要测量大小。 尽可能找到提供足够吞吐量的最小缓冲      </content>
    </entry>
    
     <entry>
        <title>GO 开发者对 GO 初学者的建议</title>
        <url>http://shanks.link/blog/2021/07/19/go-%E5%BC%80%E5%8F%91%E8%80%85%E5%AF%B9-go-%E5%88%9D%E5%AD%A6%E8%80%85%E7%9A%84%E5%BB%BA%E8%AE%AE/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html">  注：原文地址为 Advise from Go developers to Go programming newbies
 以促进 India 的 go 编程作为 GopherConIndia 承诺的一部分。我们采访了 40 位 Gophers（一个 Gopher 代表一个 GO 项目或是任何地方的 GO 程序员），得到了他们关于 GO 的意见。从 2014 年的八月到十一月，我们将每个星期发表两篇采访稿。
如果你正好刚刚开始 go 编程，他们对于我们一些问题的答案可能会对你有非常有用。看看这些。
应该做：
 通读 the Go standard library 和 Effective Go，为了学习 GO 的规范，Effective Go 是被高度推荐的，尤其是如果你有其他语言的背景。 在 Go tour 上做练习 看完语言参考 练习 Go by Example，而不仅仅是复制粘贴！ 坚持编写 GO 代码，在几周内你将会在这门语言上变得高效 理解接口的功能，他们是 GO 最大的礼物之一，可能比 channels 和 goroutines 还重要。这个关于接口的文章 article on interfaces 和 Andrew Gerrand 在 GopherCon 2014 上的 keynote 接口的描述 会对你非常有帮助。 抛弃你的 OO 的思想包袱，如果你来自于其他语言，比如动态语言 Python 或是 Ruby，或者是一个编译型语言如 Java 或 C#。GO 是一个面向对象的语言，但是它不是一个基于 class 的语言和不支持继承。 了解继承从 GO 语言中移除了。实践组合的用法而不是继承的机会显现了，并且纠结于继承只会导致你沮丧 不要以其他语言的风格编写 GO 寻找更加有经验的 Gophers，他们能帮助你 review 代码片段和给你反馈。在 GO 社区能得到真正的支持和帮助 用 GO 实现你想法中的一个项目或是找到一个项目来工作。然后随着你学习的更多，不断重构你的应用。利用邮件列表和参加 Gopher Academy Slack group 来见其他的 Gophers 来得到帮助。Dave Cheney 的博客和 GoingGo 的博客也是一个非常好的开始 不要等待泛型和函数式被添加进语言；屏住呼吸并学习爱上我们在今天拥有的这门语言   注：私人添加，可以订阅 Newspaper.io 的 Golang Daily，以及 @ASTA谢 的 《Go Web 编程》 【作者也出了实体书，大家可以购买】和 订阅 Golang Ask News，社区 http://golanghome.com/，@无闻Unknown 的 《Go编程基础》，《Go Web基础》 和 《Go名库讲解》
 给 go 初学者分享的一些问题
 对于任何人来说学习一门新语言可能都是令人挫折的。GO 社区是不可置信的活跃，你不是孤单的。利用所有的文档，博客，本地的 Meetups 和用户组，比如 Slack。不要害怕问问题和参与 如果你对 GO 感兴趣，使用它的一侧涉足，或是专业的使用它，如果本地有 Go meetup，考虑参与。如果你有货，考虑去分享它 如果你有计划旅行，并且有能力，努力去访问 GO 社区目的地 来访的用户群体是个证明这个社区有众多的用户，支持者和雇员的途径 不要浪费时间去和其他语言比较，如果你喜欢 GO，就爱上他并且去使用它 接受 Go 的文化和 GO 做事情的方式。你的代码会感谢你，如果你这样做了，你会得到很多 不要冲动的引入依赖 简单是 GO 最重要的特征。避免过分设计，使用简单的代码片段而不是单一的庞大的代码库 从其他语言移植库到 GO 是一个很好的做法，它允许你剥离他人的代码并且以符合 GO 语言的方式粘合起来。   注：How do you see the market for Go Programmers in the work place? What is the future for Go 这部分不翻译，请读者自己看
 </content>
    </entry>
    
     <entry>
        <title>Go 为什么这么快 GPM模型简介</title>
        <url>http://shanks.link/blog/2021/07/08/go-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB-gpm%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 作者：joellwang，腾讯 CSIG 后台开发工程师
 本文主要介绍了 Go 程序为了实现极高的并发性能，其内部调度器的实现架构（G-P-M 模型），以及为了最大限度利用计算资源，Go 调度器是如何处理线程阻塞的场景。
 怎么让我们的系统更快 随着信息技术的迅速发展，单台服务器处理能力越来越强，迫使编程模式由从前的串行模式升级到并发模型。
并发模型包含 IO 多路复用、多进程以及多线程，这几种模型都各有优劣，现代复杂的高并发架构大多是几种模型协同使用，不同场景应用不同模型，扬长避短，发挥服务器的最大性能。
而多线程，因为其轻量和易用，成为并发编程中使用频率最高的并发模型，包括后衍生的协程等其他子产品，也都基于它。
并发 ≠ 并行 并发 (concurrency) 和 并行 ( parallelism) 是不同的。
在单个 CPU 核上，线程通过时间片或者让出控制权来实现任务切换，达到 &amp;ldquo;同时&amp;rdquo; 运行多个任务的目的，这就是所谓的并发。但实际上任何时刻都只有一个任务被执行，其他任务通过某种算法来排队。
多核 CPU 可以让同一进程内的 &amp;ldquo;多个线程&amp;rdquo; 做到真正意义上的同时运行，这才是并行。
进程、线程、协程 进程：进程是系统进行资源分配的基本单位，有独立的内存空间。
线程：线程是 CPU 调度和分派的基本单位，线程依附于进程存在，每个线程会共享父进程的资源。
协程：**协程是一种用户态的轻量级线程，**协程的调度完全由用户控制，协程间切换只需要保存任务的上下文，没有内核的开销。
线程上下文切换 由于中断处理，多任务处理，用户态切换等原因会导致 CPU 从一个线程切换到另一个线程，切换过程需要保存当前线程的状态并恢复另一个线程的状态。
上下文切换的代价是高昂的，因为在核心上交换线程会花费很多时间。上下文切换的延迟取决于不同的因素，大概在在 50 到 100 纳秒之间。考虑到硬件平均在每个核心上每纳秒执行 12 条指令，那么一次上下文切换可能会花费 600 到 1200 条指令的延迟时间。实际上，上下文切换占用了大量程序执行指令的时间。
如果存在跨核上下文切换（Cross-Core Context Switch），可能会导致 CPU 缓存失效（CPU 从缓存访问数据的成本大约 3 到 40 个时钟周期，从主存访问数据的成本大约 100 到 300 个时钟周期），这种场景的切换成本会更加昂贵。
Golang 为并发而生 Golang 从 2009 年正式发布以来，依靠其极高运行速度和高效的开发效率，迅速占据市场份额。Golang 从语言级别支持并发，通过轻量级协程 Goroutine 来实现程序并发运行。
Goroutine 非常轻量，主要体现在以下两个方面：
上下文切换代价小： Goroutine 上下文切换只涉及到三个寄存器（PC / SP / DX）的值修改；而对比线程的上下文切换则需要涉及模式切换（从用户态切换到内核态）、以及 16 个寄存器、PC、SP…等寄存器的刷新；
**内存占用少：**线程栈空间通常是 2M，Goroutine 栈空间最小 2K；
Golang 程序中可以轻松支持10w 级别的 Goroutine 运行，而线程数量达到 1k 时，内存占用就已经达到 2G。
Go 调度器实现机制： Go 程序通过调度器来调度**Goroutine 在内核线程上执行，**但是 Goroutine 并不直接绑定 OS 线程 M - Machine运行，而是由 Goroutine Scheduler 中的 P - Processor （逻辑处理器）来作获取内核线程资源的『中介』。
Go 调度器模型我们通常叫做G-P-M 模型，他包括 4 个重要结构，分别是G、P、M、Sched：
**G:Goroutine，**每个 Goroutine 对应一个 G 结构体，G 存储 Goroutine 的运行堆栈、状态以及任务函数，可重用。
G 并非执行体，每个 G 需要绑定到 P 才能被调度执行。
**P: Processor，**表示逻辑处理器，对 G 来说，P 相当于 CPU 核，G 只有绑定到 P 才能被调度。对 M 来说，P 提供了相关的执行环境(Context)，如内存分配状态(mcache)，任务队列(G)等。
P 的数量决定了系统内最大可并行的 G 的数量（前提：物理 CPU 核数 &amp;gt;= P 的数量）。
P 的数量由用户设置的 GoMAXPROCS 决定，但是不论 GoMAXPROCS 设置为多大，P 的数量最大为 256。
**M: Machine，**OS 内核线程抽象，代表着真正执行计算的资源，在绑定有效的 P 后，进入 schedule 循环；而 schedule 循环的机制大致是从 Global 队列、P 的 Local 队列以及 wait 队列中获取G。
**M 的数量是不定的，由 Go Runtime 调整，**为了防止创建过多 OS 线程导致系统调度不过来，目前默认最大限制为 10000 个。
M 并不保留 G 状态，这是 G 可以跨 M 调度的基础。
**Sched：Go 调度器，**它维护有存储 M 和 G 的队列以及调度器的一些状态信息等。
调度器循环的机制大致是从各种队列、P 的本地队列中获取 G，切换到 G 的执行栈上并执行 G 的函数，调用 Goexit 做清理工作并回到 M，如此反复。
理解 M、P、G 三者的关系，可以通过经典的地鼠推车搬砖的模型来说明其三者关系：
地鼠(Gopher)的工作任务是：工地上有若干砖头，地鼠借助小车把砖头运送到火种上去烧制。M 就可以看作图中的地鼠，P 就是小车，G 就是小车里装的砖。
弄清楚了它们三者的关系，下面我们就开始重点聊地鼠是如何在搬运砖块的。
Processor（P）：
根据用户设置的 GoMAXPROCS 值来创建一批小车(P)。
Goroutine(G)：
通过 Go 关键字就是用来创建一个 Goroutine，也就相当于制造一块砖(G)，然后将这块砖(G)放入当前这辆小车(P)中。
Machine (M)：
地鼠(M)不能通过外部创建出来，只能砖(G)太多了，地鼠(M)又太少了，实在忙不过来，刚好还有空闲的小车(P)没有使用，那就从别处再借些地鼠(M)过来直到把小车(P)用完为止。
这里有一个地鼠(M)不够用，从别处借地鼠(M)的过程，这个过程就是创建一个内核线程(M)。
**需要注意的是：**地鼠(M) 如果没有小车(P)是没办法运砖的，小车(P)的数量决定了能够干活的地鼠(M)数量，在 Go 程序里面对应的是活动线程数；
在 Go 程序里我们通过下面的图示来展示 G-P-M 模型：
P 代表可以“并行”运行的逻辑处理器，每个 P 都被分配到一个系统线程 M，G 代表 Go 协程。
Go 调度器中有两个不同的运行队列：全局运行队列(GRQ)和本地运行队列(LRQ)。
每个 P 都有一个 LRQ，用于管理分配给在 P 的上下文中执行的 Goroutines，这些 Goroutine 轮流被和 P 绑定的 M 进行上下文切换。GRQ 适用于尚未分配给 P 的 Goroutines。
**从上图可以看出，G 的数量可以远远大于 M 的数量，换句话说，Go 程序可以利用少量的内核级线程来支撑大量 Goroutine 的并发。**多个 Goroutine 通过用户级别的上下文切换来共享内核线程 M 的计算资源，但对于操作系统来说并没有线程上下文切换产生的性能损耗。
为了更加充分利用线程的计算资源，Go 调度器采取了以下几种调度策略：
任务窃取（work-stealing）
我们知道，现实情况有的 Goroutine 运行的快，有的慢，那么势必肯定会带来的问题就是，忙的忙死，闲的闲死，Go 肯定不允许摸鱼的 P 存在，势必要充分利用好计算资源。
为了提高 Go 并行处理能力，调高整体处理效率，当每个 P 之间的 G 任务不均衡时，调度器允许从 GRQ，或者其他 P 的 LRQ 中获取 G 执行。
减少阻塞
如果正在执行的 Goroutine 阻塞了线程 M 怎么办？P 上 LRQ 中的 Goroutine 会获取不到调度么？
在 Go 里面阻塞主要分为一下 4 种场景：
场景 1：由于原子、互斥量或通道操作调用导致 Goroutine 阻塞，调度器将把当前阻塞的 Goroutine 切换出去，重新调度 LRQ 上的其他 Goroutine；
场景 2：由于网络请求和 IO 操作导致 Goroutine 阻塞，这种阻塞的情况下，我们的 G 和 M 又会怎么做呢？
Go 程序提供了**网络轮询器（NetPoller）**来处理网络请求和 IO 操作的问题，其后台通过 kqueue（MacOS），epoll（Linux）或 iocp（Windows）来实现 IO 多路复用。
通过使用 NetPoller 进行网络系统调用，调度器可以防止 Goroutine 在进行这些系统调用时阻塞 M。这可以让 M 执行 P 的 LRQ 中其他的 Goroutines，而不需要创建新的 M。有助于减少操作系统上的调度负载。
**下图展示它的工作原理：**G1 正在 M 上执行，还有 3 个 Goroutine 在 LRQ 上等待执行。网络轮询器空闲着，什么都没干。
接下来，G1 想要进行网络系统调用，因此它被移动到网络轮询器并且处理异步网络系统调用。然后，M 可以从 LRQ 执行另外的 Goroutine。此时，G2 就被上下文切换到 M 上了。
最后，异步网络系统调用由网络轮询器完成，G1 被移回到 P 的 LRQ 中。一旦 G1 可以在 M 上进行上下文切换，它负责的 Go 相关代码就可以再次执行。这里的最大优势是，执行网络系统调用不需要额外的 M。网络轮询器使用系统线程，它时刻处理一个有效的事件循环。
这种调用方式看起来很复杂，值得庆幸的是，Go 语言将该“复杂性”隐藏在 Runtime 中：Go 开发者无需关注 socket 是否是 non-block 的，也无需亲自注册文件描述符的回调，只需在每个连接对应的 Goroutine 中以“block I/O”的方式对待 socket 处理即可，实现了 goroutine-per-connection 简单的网络编程模式（但是大量的 Goroutine 也会带来额外的问题，比如栈内存增加和调度器负担加重）。
用户层眼中看到的 Goroutine 中的“block socket”，实际上是通过 Go runtime 中的 netpoller 通过 Non-block socket &#43; I/O 多路复用机制“模拟”出来的。Go 中的 net 库正是按照这方式实现的。
**场景 3：**当调用一些系统方法的时候，如果系统方法调用的时候发生阻塞，这种情况下，网络轮询器（NetPoller）无法使用，而进行系统调用的 Goroutine 将阻塞当前 M。
让我们来看看同步系统调用（如文件 I/O）会导致 M 阻塞的情况：G1 将进行同步系统调用以阻塞 M1。
调度器介入后：识别出 G1 已导致 M1 阻塞，此时，调度器将 M1 与 P 分离，同时也将 G1 带走。然后调度器引入新的 M2 来服务 P。此时，可以从 LRQ 中选择 G2 并在 M2 上进行上下文切换。
阻塞的系统调用完成后：G1 可以移回 LRQ 并再次由 P 执行。如果这种情况再次发生，M1 将被放在旁边以备将来重复使用**。**
**场景 4：**如果在 Goroutine 去执行一个 sleep 操作，导致 M 被阻塞了。
Go 程序后台有一个监控线程 sysmon，它监控那些长时间运行的 G 任务然后设置可以强占的标识符，别的 Goroutine 就可以抢先进来执行。
只要下次这个 Goroutine 进行函数调用，那么就会被强占，同时也会保护现场，然后重新放入 P 的本地队列里面等待下次执行。
小结 本文主要从 Go 调度器架构层面上介绍了 G-P-M 模型，通过该模型怎样实现少量内核线程支撑大量 Goroutine 的并发运行。以及通过 NetPoller、sysmon 等帮助 Go 程序减少线程阻塞，充分利用已有的计算资源，从而最大限度提高 Go 程序的运行效率。
参考文档：
https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part1.html
https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part2.html
https://www.ardanlabs.com/blog/2018/12/scheduling-in-go-part3.html
https://segmentfault.com/a/1190000016038785
https://segmentfault.com/a/1190000016611742
https://segmentfault.com/a/1190000017333717
https://segmentfault.com/a/1190000015352983
https://segmentfault.com/a/1190000015464889
https://www.cnblogs.com/lxmhhy/p/6041001.html
https://www.cnblogs.com/mokafamily/p/9975980.html
https://studyGolang.com/articles/9211
https://www.zhihu.com/question/20862617
https://codeburst.io/why-Goroutines-are-not-lightweight-threads-7c460c1f155f
https://blog.csdn.net/tiandyoin/article/details/76556702
https://www.jianshu.com/p/cc3c0fefee43
https://www.jianshu.com/p/a315224886d2
本文分享自微信公众号 - 腾讯技术工程（Tencent_TEG），作者：joellwang
原文出处及转载信息见文内详细说明，如有侵权，请联系 yunjia_community@tencent.com 删除。
原始发表时间：2020-02-26
本文参与腾讯云自媒体分享计划，欢迎正在阅读的你也加入，一起分享。
</content>
    </entry>
    
     <entry>
        <title>哈希表</title>
        <url>http://shanks.link/blog/2021/06/26/%E5%93%88%E5%B8%8C%E8%A1%A8/</url>
        <categories>
          <category>algorithm</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 哈希表 什么是哈希表 哈希表就是一个元素有一一对应位置的一个表，如下图，哈希表也叫散列表，和函数的一个x对应一个y类似，不存在多个y对应一个x，当然哈希表可能有多个数对应一个下标，我们后面讲，这里暂且理解为和函数一样，是一种映射。 在图中，哈希表存的数据位整形，如果我们存手机号，可以将后四位作为key，或者是后四位经过一个算数处理，当作key也可以。
哈希表作为一个查找时间复杂度只有O(1)的数据接结构，可以说效率非常高。 对于二叉搜索树而言，二叉搜索树中的元素存储位置和其值没有直接对应关系，需要多次将关键码进行比较来查询。 相比二叉搜索树，哈希表有一对一对应的映射关系，不需要多次比较来查找。 我认为这是典型的空间换时间的数据结构，通过一对一映射的方式，必将有空间为空，说明其空间利用率其实不是100%，像java中，哈希表的存储利用率为0.75，超过0.75这个预设值，哈希表将被扩容，我在这篇文章中所用的开放定址法的代码将这个值控制在0.7，而拉链法的比例控制为1。
哈希冲突 如上图一样，11和22在哈希表容量为11的时候，他们对应的都是0，这就有了冲突，解决冲突有两种办法，开散列和闭散列。
开散列 开散列又叫开放定址法，一个位置只存一个元素，如果新来的元素发现该位置有冲突，就向后寻找，直至找到一个空位为止，存入数据，但是很多时候这种方法很不好，容易造成过多的冲突，于是有了二次线性探测，和直接探测不同，二次探测是依次往后探测n的平方个，第一次往后一个，第二次往后4个，第三次往后9个。
闭散列（用此种方法实现的哈希表称之为哈希桶） 闭散列又称拉链法，当有数冲突的时候，不是往后找，而是直接挂在这个位置的下面，像链表一样挂起来，这个方式一容量和元素个数的比例一般控制为1，多了会影响查找效率。
但是这种方法也有个坏处，假如有人恶意将其所有元素均存在一个位置，然后进行访问，就会出现访问速度过慢的问题，假如这被应用在网站的话，就会造成网站崩溃，无法访问。
负载因子 负载因子我在上面也有带着提到过，这里详细说一下。 负载因子α = 表中元素个数 / 散列表的长度 由于表长是定值，所以α和填入表中的元素个数成正比，α越大，表明表中数据越多，冲突的可能性越大，反之冲突越小。 实际上，散列表的平均查找长度是载荷因子α 的函数，只是不同处理冲突的方法有不同的函数。 对于开放定址法，负载因子是特别中原的因素，应严格控制在0.7~0.8以下，超过0.8，查表时CPU的缓存不命中（cache missing）按照指数曲线上升，因此一些采用开放定址法的库比如java就是限制负载因子为0.75，超过则resize。 ———————————————— 版权声明：本文为CSDN博主「无聊星期三」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。 原文链接：https://blog.csdn.net/Boring_Wednesday/article/details/80316884
</content>
    </entry>
    
     <entry>
        <title>如何避免Go变量被GC</title>
        <url>http://shanks.link/blog/2021/06/15/%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8Dgo%E5%8F%98%E9%87%8F%E8%A2%ABgc/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Illustration created for “A Journey With Go”, made from the original Go Gopher, created by Renee French.
本文基于 Go 1.13。
在 Go 中，我们不需要自己管理内存分配和释放。然而，有些时候我们需要对程序进行更细粒度的控制。Go 运行时提供了很多种控制运行时状态及其与内存管理器之间相互影响的方式。本文中，我们来审查让变量不被 GC 回收的能力。
场景 我们来看一个基于 Go 官方文档[1] 的例子：
type File struct { d int }  func main() {  p := openFile(&amp;#34;t.txt&amp;#34;)  content := readFile(p.d)   println(&amp;#34;Here is the content: &amp;#34;&#43;content) }  func openFile(path string) *File {  d, err := syscall.Open(path, syscall.O_RDONLY, 0)  if err != nil {  panic(err)  }   p := &amp;amp;File{d}  runtime.SetFinalizer(p, func(p *File) {  syscall.Close(p.d)  })   return p }  func readFile(descriptor int) string {  doSomeAllocation()   var buf [1000]byte  _, err := syscall.Read(descriptor, buf[:])  if err != nil {  panic(err)  }   return string(buf[:]) }  func doSomeAllocation() {  var a *int   // memory increase to force the GC  for i:= 0; i &amp;lt; 10000000; i&#43;&#43; {  i := 1  a = &amp;amp;i  }   _ = a } 源码地址[2]
这个程序中一个函数打开文件，另一个函数读取文件。代表文件的结构体注册了一个 finalizer，在 gc 释放结构体时自动关闭文件。运行这个程序，会出现 panic：
panic: bad file descriptor  goroutine 1 [running]: main.readFile(0x3, 0x5, 0xc000078008) main.go:42 &#43;0x103 main.main() main.go:14 &#43;0x4b exit status 2 下面是流程图：
 打开文件，返回一个文件描述符 这个文件描述符被传递给读取文件的函数 这个函数首先做一些繁重的工作：  图 01
allocate 函数触发 gc：
因为文件描述符是个整型，并以副本传递，所以打开文件的函数返回的结构体 *File* 不再被引用。Gc 把它标记为可以被回收的。之后触发这个变量注册的 finalizer，关闭文件。
然后，主协程读取文件：
因为文件已经被 finalizer 关闭，所以会出现 panic。
让变量不被回收 runtime 包暴露了一个方法，用来在 Go 程序中避免出现这种情况，并显式地声明了让变量不被回收。在运行到这个调用这个方法的地方之前，gc 不会清除指定的变量。下面是加了对这个方法的调用的新代码：
在运行到 keepAlive 方法之前，gc 不能回收变量 p。如果你再运行一次程序，它会正常读取文件并成功终止。
追本逐源 keepAlive 方法本身没有做什么：
运行时，Go 编译器会以很多种方式优化代码：函数内联，死码消除，等等。这个函数不会被内联，Go 编译器可以轻易地探测到哪里调用了 keepAlive。编译器很容易追踪到调用它的地方，它会发出一个特殊的 SSA 指令，以此来确保它不会被 gc 回收。
在生成的 SSA 代码中也可以看到这个 SSA 指令：
在我的文章 Go 编译器概述[3] 中你可以看到更多关于 Go 编译器和 SSA 的信息。
 via: https://medium.com/a-journey-with-go/go-keeping-a-variable-alive-c28e3633673a
作者：Vincent Blanchon[4]译者：lxbwolf[5]校对：polaris1119[6]
本文由 GCTT[7] 原创编译，Go 中文网[8] 荣誉推出
参考资料 [1]Go 官方文档: https://golang.org/pkg/runtime/#KeepAlive
[2]源码地址: https://gist.githubusercontent.com/blanchonvincent/a247b6c2af559b62f93377b5d7581b7f/raw/6488ec2a36c28c46f942b7ac8f24af4e75c19a2f/main.go
[3]Go 编译器概述: https://medium.com/a-journey-with-go/go-overview-of-the-compiler-4e5a153ca889
[4]Vincent Blanchon: https://medium.com/@blanchon.vincent
[5]lxbwolf: https://github.com/lxbwolf
[6]polaris1119: https://github.com/polaris1119
[7]GCTT: https://github.com/studygolang/GCTT
[8]Go 中文网: https://studygolang.com/
 </content>
    </entry>
    
     <entry>
        <title>Go内存分配器的核心思想</title>
        <url>http://shanks.link/blog/2021/05/06/go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%99%A8%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 1、内存分配器的核心思想 Go 的内存分配器核心思想是将内存使用多级管理，降低锁的粒度。每个线程都有自己的本地内存，使用时先从线程本地的内存池进行分配，当内存池不足时，才会从全局内存池中进行申请。
2、内存分配器的初始化 Go在启动的时候，会向系统申请一大块内存块（只是一段虚拟地址，不会真正地分配内存）。申请的内存块会划分成三个部分「mspans」，「bitmap」，「arena」。
 arena就是堆，Go 中所有动态分配的内存都是来自这里的 bitmap是一个位图，用于标识 arena 中哪些地址保存了对象，并且保存了这个对象是否是否包含指针，还有一些GC信息 mspans保存了 mspan 们的指针。mspan 是 GO 中内存管理的基本单元，有由一组 8k 的连续内存块组成的双向链表，mspan 可以按照一定大小划分成 object。（内存对齐）。mspan 的大小等级有 67 种。  3、内存分配器的组件有什么 Go的内存分配器的组件由「线程缓存 mcache」，「中心缓存 mcentral」，「页堆 mheap」
 线程缓存 mcache在程序刚启动时是没有分配任何内存的，在运行时才会动态向「中心缓存 central」申请（有锁）并缓存下来。由于每个时刻只能有一个 P 独占 M，所以线程缓存没有存在多个 P 竞争申请内存的问题 中心缓存 mcentral是带锁的全局缓存，被全部线程共享，每个 central 管理一种大小的 mspan，并且会同个大小的 mspan 会创建两个 central 进行管理，一个是有指针另一个是无指针（无指针在垃圾回收中无需进一步扫描是否引用活跃对象） 页堆 mheap管理全部的 「中心缓存 mcentral」，一些 arena 、bit map 相关的属性，除此之外还有两个二叉搜索树，分别是 free 和 scav。free 中保存着新从 OS 中刚申请的 mspan 和非垃圾回收后的 span。scav 中保存的是被垃圾回收后的 span。  4、Go 的内存分配器的初始化以及分配内存的过程 Go 会将运行中的使用到的对象划分为三种，微对象（0到16B），小对象（16B到32K），大对象（32K以上）
微小对象申请过程： 如果是创建一个微或者小对象，就会向 mcache 进行申请。mcache 如果没有空闲的 span 的话，会向 mcentral 申请。mcentral 管理着两个 spanlist，一个是 nonempty（里面有空闲的 span），一个是 empty（无空闲的链表），mcentral 会从 nonempty 找到可用的 span，将其移至 empty list，并将其返回给线程。当 mcentral 也没有空闲时 span，会向 mheap 申请。mheap 维护着两个二叉搜索树，分别是 scav（垃圾回收后会还的） 和 free（从 OS 申请的），mheap 会优先从 scav 中分配，无则从 free 中分配。若两者都没有空闲的，则会从 OS 中申请，之后再次遍历两颗二叉搜索树。
大对象申请过程： 大对象不经过 mcache 和 mcentral，直接从 mheap 申请内存，分配在 mheap 的 arena 中
参考链接以及延伸阅读 •draveness-Go 语言设计与实现-7.1 内存分配器[1]
•图解Go内存管理器的内存分配策略[2]
•详解Go中内存分配源码实现[3]
•TCMalloc : Thread-Caching Malloc[4]
•详解Go语言的内存模型及堆的分配管理[5]
•图解Go语言内存分配[6]
•Go语言原本-第 7 章 内存分配[7]
•栈内存管理[8]
5、epoll 用到了哪些数据结构 红黑树和双端链表
struct eventpoll{  ....  /*红黑树的根节点，这颗树中存储着所有添加到epoll中的需要监控的事件*/  struct rb_root rbr;  /*双链表中则存放着将要通过epoll_wait返回给用户的满足条件的事件*/  struct list_head rdlist; .... } 扩展阅读  epoll的内部实现 看了就会懂[9] linux epoll机制[10]  6、在使用 map 时尽量不要在 big map 中保存指针？为什么 Go 语言的 GC 会递归遍历并标记所有可触达的对象，标记完成之后将所有没有引用的对象进行清理。扫描到指针就会往下接着寻找，一直到结束。
Go 语言中 map 是基于数组和链表的数据结构实现的，通过链地址法解决哈希冲突，每个 bucket 可以保存 8对键值，在 8 个键值对数据后面有一个 overflow 指针，因为桶中最多只能装 8 个键值对，如果有多余的键值对落到了当前桶（哈希冲突），那么就需要再构建一个桶（称为溢出桶），通过 overflow 指针链接起来。
因为 overflow 指针的缘故，所以无论 map 保存的是什么，GC 的时候就会把所有的 bmap 扫描一遍，带来巨大的 GC 开销。官方 issues 就有关于这个问题的讨论，runtime: Large maps cause significant GC pauses #9477[11]
// If we have a map[k]v where both k and v does not contain pointers and we want to improve scan performance, then we can do the following. // 如果我们有一个map [k] v，其中k和v都不包含指针，并且我们想提高扫描性能，则可以执行以下操作。 //Add &amp;#39;allOverflow []unsafe.Pointer&amp;#39; to hmap and store all overflow buckets in it. Then mark bmap as noScan. This will make scanning very fast, as we won&amp;#39;t scan any user data. // 将&amp;#39;allOverflow [] unsafe.Pointer&amp;#39;添加到 hmap 并将所有溢出存储桶存储在其中。 然后将 bmap 标记为noScan。 这将使扫描非常快，因为我们不会扫描任何用户数据。 // In reality it will be somewhat more complex, because we will need to remove old overflow buckets from allOverflow. And also it will increase size of hmap, so it may require some reshuffling of data as well. // 实际上，它将有些复杂，因为我们需要从allOverflow中删除旧的溢出桶。 并且它还会增加 hmap 的大小，因此也可能需要重新整理数据。 最终官方在 hmap 中增加了 overflow 相关字段完成了上面的优化，这是具体的 commit[12] 地址。
下面看下具体是如何实现的,基于最新Go1.16 ，源码位置在https://github.com/golang/go/blob/dev.boringcrypto.go1.16/src/cmd/compile/internal/gc/reflect.go
// bmap makes the map bucket type given the type of the map. func bmap(t *types.Type) *types.Type {  ...  // The first field is: uint8 topbits[BUCKETSIZE].  ...   // If keys and elems have no pointers, the map implementation  // can keep a list of overflow pointers on the side so that  // buckets can be marked as having no pointers.  // Arrange for the bucket to have no pointers by changing  // the type of the overflow field to uintptr in this case.  // See comment on hmap.overflow in runtime/map.go.  otyp := types.NewPtr(bucket)  if !elemtype.HasPointers() &amp;amp;&amp;amp; !keytype.HasPointers() {  otyp = types.Types[TUINTPTR]  }  overflow := makefield(&amp;#34;overflow&amp;#34;, otyp)  field = append(field, overflow)   // link up fields  ...   // Check invariants that map code depends on.  ...   // Double-check that overflow field is final memory in struct,  // with no padding at end.  ... } 通过注释可以看出，如果 map 中保存的键值都不包含指针（通过 Haspointers 判断），就使用一个 uintptr 类型代替 bucket 的指针用于溢出桶 overflow 字段，uintptr 类型在 Go 语言中就是个大小可以保存得下指针的整数，不是指针，就相当于实现了 将 bmap 标记为 noScan， GC 的时候就不会遍历完整个 map 了。
参考资料 [1] draveness-Go 语言设计与实现-7.1 内存分配器: https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-memory-allocator/#71-%e5%86%85%e5%ad%98%e5%88%86%e9%85%8d%e5%99%a8
[2] 图解Go内存管理器的内存分配策略: https://blog.csdn.net/kevin_tech/article/details/108426871
[3] 详解Go中内存分配源码实现: https://www.cnblogs.com/luozhiyun/p/14349331.html
[4] TCMalloc : Thread-Caching Malloc: http://goog-perftools.sourceforge.net/doc/tcmalloc.html
[5] 详解Go语言的内存模型及堆的分配管理: https://zhuanlan.zhihu.com/p/76802887
[6] 图解Go语言内存分配: https://zhuanlan.zhihu.com/p/59125443
[7] Go语言原本-第 7 章 内存分配: https://golang.design/under-the-hood/zh-cn/part2runtime/ch07alloc/
[8] 栈内存管理: https://studygolang.com/articles/25547
[9] epoll的内部实现 看了就会懂: https://blog.csdn.net/tianjing0805/article/details/76021440
[10] linux epoll机制: https://blog.csdn.net/u010657219/article/details/44061629
[11] runtime: Large maps cause significant GC pauses #9477: https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fgolang%2Fgo%2Fissues%2F9477
[12] commit: https://links.jianshu.com/go?to=https%3A%2F%2Fgo-review.googlesource.com%2Fc%2Fgo%2F%2B%2F3288
[13] Go语言使用 map 时尽量不要在 big map 中保存指针: https://www.jianshu.com/p/5903323a7110
转载自他人blog
</content>
    </entry>
    
     <entry>
        <title>Go工具之generate</title>
        <url>http://shanks.link/blog/2021/05/06/go%E5%B7%A5%E5%85%B7%E4%B9%8Bgenerate/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Go语言提供了一系列强大的工具，灵活使用这些工具，能够让我们的项目开发更加容易，工具集包含如下。
bug start a bug report build compile packages and dependencies clean remove object files and cached files doc show documentation for package or symbol env print Go environment information fix update packages to use new APIs fmt gofmt (reformat) package sources generate generate Go files by processing source get add dependencies to current module and install them install compile and install packages and dependencies list list packages or modules mod module maintenance run compile and run Go program test test packages tool run specified go tool version print Go version vet report likely mistakes in packages 工具的源码位于$GOPATH/src/cmd/internal，本篇文章主要讨论Go工具generate。
Go语言的自动化工具
go generate常用于自动生成代码，它可以在代码编译之前根据源代码生成代码。当运行go generate时，它将扫描与当前包相关的源代码文件，找出所有包含&amp;quot;// go:generate&amp;quot;的注释语句，提取并执行该注释后的命令，命令为可执行程序。该过程类似于调用执行shell脚本。
使用方法
 添加特殊注释  //go:generate command argument...  执行generate命令  $ go generate [-run regexp] [-n] [-v] [-x] [build flags] [file.go... | packages] 注意事项
 该特殊注释必须包含在.go源码文件中。 每个源码文件可以包含多个generate特殊注释。 go generate不会被类似go build，go get，go test等命令触发执行，必须由开发者显式使用。 命令执行是串行的，如果出错，后续命令不再执行。 特殊注释必须以“//go:generate”开头，双斜线之后没有空格。 执行命令必须是系统PATH（echo $PATH）下的可执行程序。  使用示例
package main  import &amp;#34;fmt&amp;#34;  //go:generate echo GoGoGo! //go:generate go run main.go //go:generate echo $GOARCH $GOOS $GOFILE $GOLINE $GOPACKAGE  func main() {  fmt.Println(&amp;#34;go rum main.go!&amp;#34;) } 执行go generate命令
$ go generate GoGoGo! go rum main.go! amd64 darwin main.go 7 main 为枚举常量实现String方法
看完上述generate的简单介绍，可能读者并没有感受到该工具的强大之处，小菜刀提供一个该工具的经典应用场景：为枚举常量实现String方法。
这里需要提及官方的另外一个工具stringer，它可以自动为整数常量集编写String()方法。由于stringer并不在Go官方发行版的工具集里，我们需要自行安装，执行如下命令。
go get golang.org/x/tools/cmd/stringer 这里引用stringer文档中的一个示例。代码如下，其定义了一组不同Pill类型的整数常量。
package painkiller  type Pill int  const (  Placebo Pill = iota  Aspirin  Ibuprofen  Paracetamol  Acetaminophen = Paracetamol ) 为了进行调试或者其他原因，我们希望这些常量能够打印出来，这意味着Pill要有一个带有签名的方法。
func (p Pill) String() string ** **
要实现它，非常简单。
** **
func (p Pill) String() string {  switch p {  case Placebo:  return &amp;#34;Placebo&amp;#34;  case Aspirin:  return &amp;#34;Aspirin&amp;#34;  case Ibuprofen:  return &amp;#34;Ibuprofen&amp;#34;  case Paracetamol: // == Acetaminophen  return &amp;#34;Paracetamol&amp;#34;  }  return fmt.Sprintf(&amp;#34;Pill(%d)&amp;#34;, p) } 试想，如果我们的Pill名单里新增了一批药品名，每次增加或修改药品名，在相应的签名函数里，也都需要进行更改。这样岂不是很麻烦且很可能遗漏或出错？这时，我们可以通过 go generate &#43; stringer的方案解决该问题。很简单，只需在定义Pill的代码中，增加一句注释语句即可。
//go:generate stringer -type=Pill 上面的命令，代表运行stringer工具来为Pill类型生成String方法，默认输出到pill_string.go文件中，执行如下。
$ go generate $ cat pill_string.go // Code generated by stringer -type Pill pill.go; DO NOT EDIT.  package painkiller  import &amp;#34;fmt&amp;#34;  const _Pill_name = &amp;#34;PlaceboAspirinIbuprofenParacetamol&amp;#34;  var _Pill_index = [...]uint8{0, 7, 14, 23, 34}  func (i Pill) String() string {  if i &amp;lt; 0 || i&#43;1 &amp;gt;= Pill(len(_Pill_index)) {  return fmt.Sprintf(&amp;#34;Pill(%d)&amp;#34;, i)  }  return _Pill_name[_Pill_index[i]:_Pill_index[i&#43;1]] } 这样，每次我们对Pill类型有修改时，我们所需要做的就是运行以下语句即可。
$ go generate 当然，你要是觉得这样麻烦，或者担心忘记执行generate语句。那么，可以将go generate语句写入Makefile之中，置于go build命令之前，实现代码生成与编译的自动化。
值得一提的是，在Go源码文档中，大量采用了go generate&#43;stringer的方案实现对枚举常量的String方法。在小菜刀本机Go 1.14.1的源码下，一共有23处使用，具体如下。
总结
本文主要介绍generate是什么，能做什么，如果想深入理解其内在实现逻辑，可以去看Go源码中生成代码的详细过程，例如sort包下通过genzfunc.go实现zfuncversion.go的生成。在Go源码宝库中，可以找到很多相似的实现逻辑，参照如下。
它们利用Go编译器提供的库，包括定义抽象语法树的 go/ast、解析抽象语法树的go/parser、解析用于格式化代码的 go/format、用于Go词法标记的go/token等。解析源文件并按照已有的模板生成新的代码，这一过程和Web 服务中利用模板生成 HTML 文件类似。
总结：减少代码的重复编写，保护头发！！
** **
参考
https://golang.org/cmd/go/
https://blog.golang.org/generate
https://godoc.org/golang.org/x/tools/cmd/stringer
https://docs.google.com/document/d/1V03LUfjSADDooDMhe-_K59EgpTEm3V8uvQRuNMAEnjg/edit#
   </content>
    </entry>
    
     <entry>
        <title>Go是如何设计Map的</title>
        <url>http://shanks.link/blog/2021/05/06/go%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1map%E7%9A%84/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 由于本文篇幅较长，故将目录整理如下 ** **
什么是Map
 维基百科的定义  In computer science, an associative array, map, symbol table, or dictionary is an abstract data type composed of a collection of (key, value) pairs, such that each possible key appears at most once in the collection.
说明：在计算机科学中，包含键值对（key-value）集合的抽象数据结构（关联数组、符号表或字典），其每个可能的键在该集合中最多出现一次，这样的数据结构就是一种Map。
01
操作
对Map的操作主要是增删改查：
  在集合中增加键值对
  在集合中移除键值对
  修改某个存在的键值对
  根据特定的键寻找对应的值
  02
实现
Map的实现主要有两种方式：哈希表（hash table）和搜索树（search tree）。例如Java中的hashMap是基于哈希表实现，而C&#43;&#43;中的Map是基于一种平衡搜索二叉树——红黑树而实现的。以下是不同实现方式的时间复杂度对比。
可以看到，对于元素查找而言，二叉搜索树的平均和最坏效率都是O(log n)，哈希表实现的平均效率是O(1)，但最坏情况下能达到O(n)，不过如果哈希表设计优秀，最坏情况基本不会出现（所以，读者不想知道Go是如何设计的Map吗）。另外二叉搜索树返回的key是有序的，而哈希表则是乱序。
哈希表
 由于Go中map的基于哈希表（也被称为散列表）实现，本文不探讨搜索树的map实现。以下是Go官方博客对map的说明。
One of the most useful data structures in computer science is the hash table. Many hash table implementations exist with varying properties, but in general they offer fast lookups, adds, and deletes. Go provides a built-in map type that implements a hash table.
学习哈希表首先要理解两个概念：哈希函数和哈希冲突。
01
哈希函数
哈希函数（常被称为散列函数）是可以用于将任意大小的数据映射到固定大小值的函数，常见的包括MD5、SHA系列等。
一个设计优秀的哈希函数应该包含以下特性：
 均匀性：一个好的哈希函数应该在其输出范围内尽可能均匀地映射，也就是说，应以大致相同的概率生成输出范围内的每个哈希值。 效率高：哈希效率要高，即使很长的输入参数也能快速计算出哈希值。 可确定性：哈希过程必须是确定性的，这意味着对于给定的输入值，它必须始终生成相同的哈希值。 雪崩效应：微小的输入值变化也会让输出值发生巨大的变化。 不可逆：从哈希函数的输出值不可反向推导出原始的数据。  02
哈希冲突
重复一遍，哈希函数是将任意大小的数据映射到固定大小值的函数。那么，我们可以预见到，即使哈希函数设计得足够优秀，几乎每个输入值都能映射为不同的哈希值。但是，当输入数据足够大，大到能超过固定大小值的组合能表达的最大数量数，冲突将不可避免！（参见抽屉原理）
抽屉原理：桌上有十个苹果，要把这十个苹果放到九个抽屉里，无论怎样放，我们会发现至少会有一个抽屉里面放不少于两个苹果。抽屉原理有时也被称为鸽巢原理。
  如何解决哈希冲突   比较常用的Has冲突解决方案有链地址法和开放寻址法。
在讲链地址法之前，先说明两个概念。
 哈希桶。哈希桶（也称为槽，类似于抽屉原理中的一个抽屉）可以先简单理解为一个哈希值，所有的哈希值组成了哈希空间。 装载因子。装载因子是表示哈希表中元素的填满程度。它的计算公式：装载因子=填入哈希表中的元素个数/哈希表的长度。装载因子越大，填入的元素越多，空间利用率就越高，但发生哈希冲突的几率就变大。反之，装载因子越小，填入的元素越少，冲突发生的几率减小，但空间浪费也会变得更多，而且还会提高扩容操作的次数。装载因子也是决定哈希表是否进行扩容的关键指标，在java的HashMap的中，其默认装载因子为0.75；Python的dict默认装载因子为2/3。  A
链地址法
链地址法的思想就是将映射在一个桶里的所有元素用链表串起来。
下面以一个简单的哈希函数 H(key) = key MOD 7（除数取余法）对一组元素 [50, 700, 76, 85, 92, 73, 101] 进行映射，通过图示来理解链地址法处理Hash冲突的处理逻辑。
链地址法解决冲突的方式与图的邻接表存储方式在样式上很相似，发生冲突，就用单链表组织起来。
B
开放寻址法
 对于链地址法而言，槽位数m与键的数目n是没有直接关系的。但是对于开放寻址法而言，所有的元素都是存储在Hash表当中的，所以无论任何时候都要保证哈希表的槽位数m大于或等于键的数据n（必要时，需要对哈希表进行动态扩容）。
开放寻址法有多种方式：线性探测法、平方探测法、随机探测法和双重哈希法。这里以线性探测法来帮助读者理解开放寻址法思想。
 线性探测法  设 Hash(key) 表示关键字 key 的哈希值， 表示哈希表的槽位数（哈希表的大小）。
线性探测法则可以表示为：
如果 Hash(x) % M 已经有数据，则尝试 (Hash(x) &#43; 1) % M ;
如果 (Hash(x) &#43; 1) % M 也有数据了，则尝试 (Hash(x) &#43; 2) % M ;
如果 (Hash(x) &#43; 2) % M 也有数据了，则尝试 (Hash(x) &#43; 3) % M ;
……
我们同样以哈希函数 H(key) = key MOD 7 （除数取余法）对 [50, 700, 76, 85, 92, 73, 101] 进行映射，通过图示来理解线性探测法处理 Hash 碰撞。
其中，empty代表槽位为空，occupied代表槽位已被占（后续映射到该槽，则需要线性向下继续探测），而lazy delete则代表将槽位里面的数据清除，并不释放存储空间。
C
两种解决方案比较
对于开放寻址法而言，它只有数组一种数据结构就可完成存储，继承了数组的优点，对CPU缓存友好，易于序列化操作。但是它对内存的利用率不如链地址法，且发生冲突时代价更高。当数据量明确、装载因子小，适合采用开放寻址法。
链表节点可以在需要时再创建，不必像开放寻址法那样事先申请好足够内存，因此链地址法对于内存的利用率会比开方寻址法高。链地址法对装载因子的容忍度会更高，并且适合存储大对象、大数据量的哈希表。而且相较于开放寻址法，它更加灵活，支持更多的优化策略，比如可采用红黑树代替链表。但是链地址法需要额外的空间来存储指针。
值得一提的是，在Python中dict在发生哈希冲突时采用的开放寻址法，而java的HashMap采用的是链地址法。
Go Map 实现
同python与java一样，Go语言中的map是也基于哈希表实现的，它解决哈希冲突的方式是链地址法，即通过使用数组&#43;链表的数据结构来表达map。
注意：本文后续出现的map统一代指Go中实现的map类型。
01
map数据结构
map中的数据被存放于一个数组中的，数组的元素是桶（bucket），每个桶至多包含8个键值对数据。哈希值低位（low-order bits）用于选择桶，哈希值高位（high-order bits）用于在一个独立的桶中区别出键**。**哈希值高低位示意图如下
本文基于go 1.15.2 darwin/amd64分析，源码位于src/runtime/map.go.
 map的结构体为hmap   1// A header for a Go map.  2type hmap struct {  3 count int // 代表哈希表中的元素个数，调用len(map)时，返回的就是该字段值。  4 flags uint8 // 状态标志，下文常量中会解释四种状态位含义。  5 B uint8 // buckets（桶）的对数log_2（哈希表元素数量最大可达到装载因子*2^B）  6 noverflow uint16 // 溢出桶的大概数量。  7 hash0 uint32 // 哈希种子。  8  9 buckets unsafe.Pointer // 指向buckets数组的指针，数组大小为2^B，如果元素个数为0，它为nil。 10 oldbuckets unsafe.Pointer // 如果发生扩容，oldbuckets是指向老的buckets数组的指针，老的buckets数组大小是新的buckets的1/2。非扩容状态下，它为nil。 11 nevacuate uintptr // 表示扩容进度，小于此地址的buckets代表已搬迁完成。 12 13 extra *mapextra // 这个字段是为了优化GC扫描而设计的。当key和value均不包含指针，并且都可以inline时使用。extra是指向mapextra类型的指针。  mapextra的结构体   1// mapextra holds fields that are not present on all maps.  2type mapextra struct {  3 // 如果 key 和 value 都不包含指针，并且可以被 inline(&amp;lt;=128 字节)  4 // 就使用 hmap的extra字段 来存储 overflow buckets，这样可以避免 GC 扫描整个 map  5 // 然而 bmap.overflow 也是个指针。这时候我们只能把这些 overflow 的指针  6 // 都放在 hmap.extra.overflow 和 hmap.extra.oldoverflow 中了  7 // overflow 包含的是 hmap.buckets 的 overflow 的 buckets  8 // oldoverflow 包含扩容时的 hmap.oldbuckets 的 overflow 的 bucket  9 overflow *[]*bmap 10 oldoverflow *[]*bmap 11 12 // 指向空闲的 overflow bucket 的指针 13 nextOverflow *bmap 14}  bmap结构体  1// A bucket for a Go map. 2type bmap struct { 3 // tophash包含此桶中每个键的哈希值最高字节（高8位）信息（也就是前面所述的high-order bits）。 4 // 如果tophash[0] &amp;lt; minTopHash，tophash[0]则代表桶的搬迁（evacuation）状态。 5 tophash [bucketCnt]uint8 6} bmap也就是bucket（桶）的内存模型图解如下（相关代码逻辑可查看src/cmd/compile/internal/gc/reflect.go中的bmap()函数）。
在以上图解示例中，该桶的第7位cell和第8位cell还未有对应键值对。需要注意的是，key和value是各自存储起来的，并非想象中的key/value/key/value…的形式。这样做虽然会让代码组织稍显复杂，但是它的好处是能让我们消除例如map[int64]int所需要的填充（padding）。此外，在8个键值对数据后面有一个overflow指针，因为桶中最多只能装8个键值对，如果有多余的键值对落到了当前桶，那么就需要再构建一个桶（称为溢出桶），通过overflow指针链接起来。
 重要常量标志   1const (  2 // 一个桶中最多能装载的键值对（key-value）的个数为8  3 bucketCntBits = 3  4 bucketCnt = 1 &amp;lt;&amp;lt; bucketCntBits  5  6 // 触发扩容的装载因子为13/2=6.5  7 loadFactorNum = 13  8 loadFactorDen = 2  9 10 // 键和值超过128个字节，就会被转换为指针 11 maxKeySize = 128 12 maxElemSize = 128 13 14 // 数据偏移量应该是bmap结构体的大小，它需要正确地对齐。 15 // 对于amd64p32而言，这意味着：即使指针是32位的，也是64位对齐。 16 dataOffset = unsafe.Offsetof(struct { 17 b bmap 18 v int64 19 }{}.v) 20 21 22 // 每个桶（如果有溢出，则包含它的overflow的链桶）在搬迁完成状态（evacuated* states）下，要么会包含它所有的键值对，要么一个都不包含（但不包括调用evacuate()方法阶段，该方法调用只会在对map发起write时发生，在该阶段其他goroutine是无法查看该map的）。简单的说，桶里的数据要么一起搬走，要么一个都还未搬。 23 // tophash除了放置正常的高8位hash值，还会存储一些特殊状态值（标志该cell的搬迁状态）。正常的tophash值，最小应该是5，以下列出的就是一些特殊状态值。 24 emptyRest = 0 // 表示cell为空，并且比它高索引位的cell或者overflows中的cell都是空的。（初始化bucket时，就是该状态） 25 emptyOne = 1 // 空的cell，cell已经被搬迁到新的bucket 26 evacuatedX = 2 // 键值对已经搬迁完毕，key在新buckets数组的前半部分 27 evacuatedY = 3 // 键值对已经搬迁完毕，key在新buckets数组的后半部分 28 evacuatedEmpty = 4 // cell为空，整个bucket已经搬迁完毕 29 minTopHash = 5 // tophash的最小正常值 30 31 // flags 32 iterator = 1 // 可能有迭代器在使用buckets 33 oldIterator = 2 // 可能有迭代器在使用oldbuckets 34 hashWriting = 4 // 有协程正在向map写人key 35 sameSizeGrow = 8 // 等量扩容 36 37 // 用于迭代器检查的bucket ID 38 noCheck = 1&amp;lt;&amp;lt;(8*sys.PtrSize) - 1 39) 综上，我们以B等于4为例，展示一个完整的map结构图。
 02
创建map
map初始化有以下两种方式
1make(map[k]v) 2// 指定初始化map大小为hint 3make(map[k]v, hint) 对于不指定初始化大小，和初始化值hint&amp;lt;=8（bucketCnt）时，go会调用makemap_small函数（源码位置src/runtime/map.go），并直接从堆上进行分配。
1func makemap_small() *hmap { 2 h := new(hmap) 3 h.hash0 = fastrand() 4 return h 5} 当hint&amp;gt;8时，则调用makemap函数
 1// 如果编译器认为map和第一个bucket可以直接创建在栈上，h和bucket可能都是非空  2// 如果h != nil，那么map可以直接在h中创建  3// 如果h.buckets != nil，那么h指向的bucket可以作为map的第一个bucket使用  4func makemap(t *maptype, hint int, h *hmap) *hmap {  5 // math.MulUintptr返回hint与t.bucket.size的乘积，并判断该乘积是否溢出。  6 mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size)  7// maxAlloc的值，根据平台系统的差异而不同，具体计算方式参照src/runtime/malloc.go  8 if overflow || mem &amp;gt; maxAlloc {  9 hint = 0 10 } 11 12// initialize Hmap 13 if h == nil { 14 h = new(hmap) 15 } 16 // 通过fastrand得到哈希种子 17 h.hash0 = fastrand() 18 19 // 根据输入的元素个数hint，找到能装下这些元素的B值 20 B := uint8(0) 21 for overLoadFactor(hint, B) { 22 B&#43;&#43; 23 } 24 h.B = B 25 26 // 分配初始哈希表 27 // 如果B为0，那么buckets字段后续会在mapassign方法中lazily分配 28 if h.B != 0 { 29 var nextOverflow *bmap 30 // makeBucketArray创建一个map的底层保存buckets的数组，它最少会分配h.B^2的大小。 31 h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) 32 if nextOverflow != nil { 33 h.extra = new(mapextra) 34 h.extra.nextOverflow = nextOverflow 35 } 36 } 37 38 return h 39} 分配buckets数组的makeBucketArray函数
 1// makeBucket为map创建用于保存buckets的数组。  2func makeBucketArray(t *maptype, b uint8, dirtyalloc unsafe.Pointer) (buckets unsafe.Pointer, nextOverflow *bmap) {  3 base := bucketShift(b)  4 nbuckets := base  5 // 对于小的b值（小于4），即桶的数量小于16时，使用溢出桶的可能性很小。对于此情况，就避免计算开销。  6 if b &amp;gt;= 4 {  7 // 当桶的数量大于等于16个时，正常情况下就会额外创建2^(b-4)个溢出桶  8 nbuckets &#43;= bucketShift(b - 4)  9 sz := t.bucket.size * nbuckets 10 up := roundupsize(sz) 11 if up != sz { 12 nbuckets = up / t.bucket.size 13 } 14 } 15 16 // 这里，dirtyalloc分两种情况。如果它为nil，则会分配一个新的底层数组。如果它不为nil，则它指向的是曾经分配过的底层数组，该底层数组是由之前同样的t和b参数通过makeBucketArray分配的，如果数组不为空，需要把该数组之前的数据清空并复用。 17 if dirtyalloc == nil { 18 buckets = newarray(t.bucket, int(nbuckets)) 19 } else { 20 buckets = dirtyalloc 21 size := t.bucket.size * nbuckets 22 if t.bucket.ptrdata != 0 { 23 memclrHasPointers(buckets, size) 24 } else { 25 memclrNoHeapPointers(buckets, size) 26 } 27} 28 29 // 即b大于等于4的情况下，会预分配一些溢出桶。 30 // 为了把跟踪这些溢出桶的开销降至最低，使用了以下约定： 31 // 如果预分配的溢出桶的overflow指针为nil，那么可以通过指针碰撞（bumping the pointer）获得更多可用桶。 32 // （关于指针碰撞：假设内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式称为“指针碰撞”） 33 // 对于最后一个溢出桶，需要一个安全的非nil指针指向它。 34 if base != nbuckets { 35 nextOverflow = (*bmap)(add(buckets, base*uintptr(t.bucketsize))) 36 last := (*bmap)(add(buckets, (nbuckets-1)*uintptr(t.bucketsize))) 37 last.setoverflow(t, (*bmap)(buckets)) 38 } 39 return buckets, nextOverflow 40} 根据上述代码，我们能确定在正常情况下，正常桶和溢出桶在内存中的存储空间是连续的，只是被hmap 中的不同字段引用而已。
03
哈希函数
在初始化go程序运行环境时（src/runtime/proc.go中的schedinit），就需要通过alginit方法完成对哈希的初始化。
 1func schedinit() {  2 lockInit(&amp;amp;sched.lock, lockRankSched)  3  4 ...  5  6 tracebackinit()  7 moduledataverify()  8 stackinit()  9 mallocinit() 10 fastrandinit() // must run before mcommoninit 11 mcommoninit(_g_.m, -1) 12 cpuinit() // must run before alginit 13 // 这里调用alginit() 14 alginit() // maps must not be used before this call 15 modulesinit() // provides activeModules 16 typelinksinit() // uses maps, activeModules 17 itabsinit() // uses activeModules 18 19 ... 20 21 goargs() 22 goenvs() 23 parsedebugvars() 24 gcinit() 25 26 ... 27} 对于哈希算法的选择，程序会根据当前架构判断是否支持AES，如果支持就使用AES hash，其实现代码位于src/runtime/asm_{386,amd64,arm64}.s中；若不支持，其hash算法则根据xxhash算法（https://code.google.com/p/xxhash/）和cityhash算法（https://code.google.com/p/cityhash/）启发而来，代码分别对应于32位（src/runtime/hash32.go）和64位机器（src/runtime/hash32.go）中，对这部分内容感兴趣的读者可以深入研究。
 1func alginit() {  2 // Install AES hash algorithms if the instructions needed are present.  3 if (GOARCH == &amp;#34;386&amp;#34; || GOARCH == &amp;#34;amd64&amp;#34;) &amp;amp;&amp;amp;  4 cpu.X86.HasAES &amp;amp;&amp;amp; // AESENC  5 cpu.X86.HasSSSE3 &amp;amp;&amp;amp; // PSHUFB  6 cpu.X86.HasSSE41 { // PINSR{D,Q}  7 initAlgAES()  8 return  9 } 10 if GOARCH == &amp;#34;arm64&amp;#34; &amp;amp;&amp;amp; cpu.ARM64.HasAES { 11 initAlgAES() 12 return 13 } 14 getRandomData((*[len(hashkey) * sys.PtrSize]byte)(unsafe.Pointer(&amp;amp;hashkey))[:]) 15 hashkey[0] |= 1 // make sure these numbers are odd 16 hashkey[1] |= 1 17 hashkey[2] |= 1 18 hashkey[3] |= 1 19} 上文在创建map的时候，我们可以知道map的哈希种子是通过h.hash0 = fastrand()得到的。它是在以下maptype中的hasher中被使用到，在下文内容中会看到hash值的生成。
 1type maptype struct {  2 typ _type  3 key *_type  4 elem *_type  5 bucket *_type  6 // hasher的第一个参数就是指向key的指针，h.hash0 = fastrand()得到的hash0，就是hasher方法的第二个参数。  7 // hasher方法返回的就是hash值。  8 hasher func(unsafe.Pointer, uintptr) uintptr  9 keysize uint8 // size of key slot 10 elemsize uint8 // size of elem slot 11 bucketsize uint16 // size of bucket 12 flags uint32 13} 14 04
map操作
假定key经过哈希计算后得到64bit位的哈希值。如果B=5，buckets数组的长度，即桶的数量是32（2的5次方）。
例如，现要置一key于map中，该key经过哈希后，得到的哈希值如下：
前面我们知道，哈希值低位（low-order bits）用于选择桶，哈希值高位（high-order bits）用于在一个独立的桶中区别出键。当B等于5时，那么我们选择的哈希值低位也是5位，即01010，它的十进制值为10，代表10号桶。再用哈希值的高8位，找到此key在桶中的位置。最开始桶中还没有key，那么新加入的key和value就会被放入第一个key空位和value空位。
注意：对于高低位的选择，该操作的实质是取余，但是取余开销很大，在实际代码实现中采用的是位操作。以下是tophash的实现代码。
1func tophash(hash uintptr) uint8 { 2 top := uint8(hash &amp;gt;&amp;gt; (sys.PtrSize*8 - 8)) 3 if top &amp;lt; minTopHash { 4 top &#43;= minTopHash 5 } 6 return top 7} 当两个不同的key落在了同一个桶中，这时就发生了哈希冲突。go的解决方式是链地址法（这里为了让读者更好理解，只描述非扩容且该key是第一次添加的情况）：在桶中按照顺序寻到第一个空位并记录下来，后续在该桶和它的溢出桶中均未发现存在的该key，将key置于第一个空位；否则，去该桶的溢出桶中寻找空位，如果没有溢出桶，则添加溢出桶，并将其置溢出桶的第一个空位（因为是第一次添加，所以不描述已存在该key的情况）。
上图中的B值为5，所以桶的数量为32。通过哈希函数计算出待插入key的哈希值，低5位哈希00110，对应于6号桶；高8位10010111，十进制为151，由于桶中前6个cell已经有正常哈希值填充了(遍历)，所以将151对应的高位哈希值放置于第7位cell（第8个cell为empty Rest，表明它还未使用），对应将key和value分别置于相应的第七个空位。
如果是查找key，那么我们会根据高位哈希值去桶中的每个cell中找，若在桶中没找到，并且overflow不为nil，那么继续去溢出桶中寻找，直至找到，如果所有的cell都找过了，还未找到，则返回key类型的默认值（例如key是int类型，则返回0）。
A
查找Key
对于map的元素查找，其源码实现如下
 1func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer {  2 // 如果开启了竞态检测 -race  3 if raceenabled &amp;amp;&amp;amp; h != nil {  4 callerpc := getcallerpc()  5 pc := funcPC(mapaccess1)  6 racereadpc(unsafe.Pointer(h), callerpc, pc)  7 raceReadObjectPC(t.key, key, callerpc, pc)  8 }  9 // 如果开启了memory sanitizer -msan 10 if msanenabled &amp;amp;&amp;amp; h != nil { 11 msanread(key, t.key.size) 12 } 13 // 如果map为空或者元素个数为0，返回零值 14 if h == nil || h.count == 0 { 15 if t.hashMightPanic() { 16 t.hasher(key, 0) // see issue 23734 17 } 18 return unsafe.Pointer(&amp;amp;zeroVal[0]) 19 } 20 // 注意，这里是按位与操作 21 // 当h.flags对应的值为hashWriting（代表有其他goroutine正在往map中写key）时，那么位计算的结果不为0，因此抛出以下错误。 22 // 这也表明，go的map是非并发安全的 23 if h.flags&amp;amp;hashWriting != 0 { 24 throw(&amp;#34;concurrent map read and map write&amp;#34;) 25 } 26 // 不同类型的key，会使用不同的hash算法，可详见src/runtime/alg.go中typehash函数中的逻辑 27 hash := t.hasher(key, uintptr(h.hash0)) 28 m := bucketMask(h.B) 29 // 按位与操作，找到对应的bucket 30 b := (*bmap)(add(h.buckets, (hash&amp;amp;m)*uintptr(t.bucketsize))) 31 // 如果oldbuckets不为空，那么证明map发生了扩容 32 // 如果有扩容发生，老的buckets中的数据可能还未搬迁至新的buckets里 33 // 所以需要先在老的buckets中找 34 if c := h.oldbuckets; c != nil { 35 if !h.sameSizeGrow() { 36 m &amp;gt;&amp;gt;= 1 37 } 38 oldb := (*bmap)(add(c, (hash&amp;amp;m)*uintptr(t.bucketsize))) 39 // 如果在oldbuckets中tophash[0]的值，为evacuatedX、evacuatedY，evacuatedEmpty其中之一 40 // 则evacuated()返回为true，代表搬迁完成。 41 // 因此，只有当搬迁未完成时，才会从此oldbucket中遍历 42 if !evacuated(oldb) { 43 b = oldb 44 } 45 } 46 // 取出当前key值的tophash值 47 top := tophash(hash) 48 // 以下是查找的核心逻辑 49 // 双重循环遍历：外层循环是从桶到溢出桶遍历；内层是桶中的cell遍历 50 // 跳出循环的条件有三种：第一种是已经找到key值；第二种是当前桶再无溢出桶； 51 // 第三种是当前桶中有cell位的tophash值是emptyRest，这个值在前面解释过，它代表此时的桶后面的cell还未利用，所以无需再继续遍历。 52bucketloop: 53 for ; b != nil; b = b.overflow(t) { 54 for i := uintptr(0); i &amp;lt; bucketCnt; i&#43;&#43; { 55 // 判断tophash值是否相等 56 if b.tophash[i] != top { 57 if b.tophash[i] == emptyRest { 58 break bucketloop 59 } 60 continue 61 } 62 // 因为在bucket中key是用连续的存储空间存储的，因此可以通过bucket地址&#43;数据偏移量（bmap结构体的大小）&#43; keysize的大小，得到k的地址 63 // 同理，value的地址也是相似的计算方法，只是再要加上8个keysize的内存地址 64 k := add(unsafe.Pointer(b), dataOffset&#43;i*uintptr(t.keysize)) 65 if t.indirectkey() { 66 k = *((*unsafe.Pointer)(k)) 67 } 68 // 判断key是否相等 69 if t.key.equal(key, k) { 70 e := add(unsafe.Pointer(b), dataOffset&#43;bucketCnt*uintptr(t.keysize)&#43;i*uintptr(t.elemsize)) 71 if t.indirectelem() { 72 e = *((*unsafe.Pointer)(e)) 73 } 74 return e 75 } 76 } 77 } 78 // 所有的bucket都未找到，则返回零值 79 return unsafe.Pointer(&amp;amp;zeroVal[0]) 80} 以下是mapaccess1的查找过程图解
map的元素查找，对应go代码有两种形式
1 // 形式一 2 v := m[k] 3 // 形式二 4 v, ok := m[k] 形式一的代码实现，就是上述的mapaccess1方法。此外，在源码中还有个mapaccess2方法，它的函数签名如下。
1func mapaccess2(t *maptype, h *hmap, key unsafe.Pointer) (unsafe.Pointer, bool) {} 与mapaccess1相比，mapaccess2多了一个bool类型的返回值，它代表的是是否在map中找到了对应的key。因为和mapaccess1基本一致，所以详细代码就不再贴出。
同时，源码中还有mapaccessK方法，它的函数签名如下。
1func mapaccessK(t *maptype, h *hmap, key unsafe.Pointer) (unsafe.Pointer, unsafe.Pointer) {} 与mapaccess1相比，mapaccessK同时返回了key和value，其代码逻辑也一致。
B
赋值Key
对于写入key的逻辑，其源码实现如下
 1func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer {  2 // 如果h是空指针，赋值会引起panic  3 // 例如以下语句  4 // var m map[string]int  5 // m[&amp;#34;k&amp;#34;] = 1  6 if h == nil {  7 panic(plainError(&amp;#34;assignment to entry in nil map&amp;#34;))  8 }  9 // 如果开启了竞态检测 -race  10 if raceenabled {  11 callerpc := getcallerpc()  12 pc := funcPC(mapassign)  13 racewritepc(unsafe.Pointer(h), callerpc, pc)  14 raceReadObjectPC(t.key, key, callerpc, pc)  15 }  16 // 如果开启了memory sanitizer -msan  17 if msanenabled {  18 msanread(key, t.key.size)  19 }  20 // 有其他goroutine正在往map中写key，会抛出以下错误  21 if h.flags&amp;amp;hashWriting != 0 {  22 throw(&amp;#34;concurrent map writes&amp;#34;)  23 }  24 // 通过key和哈希种子，算出对应哈希值  25 hash := t.hasher(key, uintptr(h.hash0))  26  27 // 将flags的值与hashWriting做按位或运算  28 // 因为在当前goroutine可能还未完成key的写入，再次调用t.hasher会发生panic。  29 h.flags ^= hashWriting  30  31 if h.buckets == nil {  32 h.buckets = newobject(t.bucket) // newarray(t.bucket, 1)  33}  34  35again:  36 // bucketMask返回值是2的B次方减1  37 // 因此，通过hash值与bucketMask返回值做按位与操作，返回的在buckets数组中的第几号桶  38 bucket := hash &amp;amp; bucketMask(h.B)  39 // 如果map正在搬迁（即h.oldbuckets != nil）中,则先进行搬迁工作。  40 if h.growing() {  41 growWork(t, h, bucket)  42 }  43 // 计算出上面求出的第几号bucket的内存位置  44 // post = start &#43; bucketNumber * bucketsize  45 b := (*bmap)(unsafe.Pointer(uintptr(h.buckets) &#43; bucket*uintptr(t.bucketsize)))  46 top := tophash(hash)  47  48 var inserti *uint8  49 var insertk unsafe.Pointer  50 var elem unsafe.Pointer  51bucketloop:  52 for {  53 // 遍历桶中的8个cell  54 for i := uintptr(0); i &amp;lt; bucketCnt; i&#43;&#43; {  55 // 这里分两种情况，第一种情况是cell位的tophash值和当前tophash值不相等  56 // 在 b.tophash[i] != top 的情况下  57 // 理论上有可能会是一个空槽位  58 // 一般情况下 map 的槽位分布是这样的，e 表示 empty:  59 // [h0][h1][h2][h3][h4][e][e][e]  60 // 但在执行过 delete 操作时，可能会变成这样:  61 // [h0][h1][e][e][h5][e][e][e]  62 // 所以如果再插入的话，会尽量往前面的位置插  63 // [h0][h1][e][e][h5][e][e][e]  64 // ^  65 // ^  66 // 这个位置  67 // 所以在循环的时候还要顺便把前面的空位置先记下来  68 // 因为有可能在后面会找到相等的key，也可能找不到相等的key  69 if b.tophash[i] != top {  70 // 如果cell位为空，那么就可以在对应位置进行插入  71 if isEmpty(b.tophash[i]) &amp;amp;&amp;amp; inserti == nil {  72 inserti = &amp;amp;b.tophash[i]  73 insertk = add(unsafe.Pointer(b), dataOffset&#43;i*uintptr(t.keysize))  74 elem = add(unsafe.Pointer(b), dataOffset&#43;bucketCnt*uintptr(t.keysize)&#43;i*uintptr(t.elemsize))  75 }  76 if b.tophash[i] == emptyRest {  77 break bucketloop  78 }  79 continue  80 }  81 // 第二种情况是cell位的tophash值和当前的tophash值相等  82 k := add(unsafe.Pointer(b), dataOffset&#43;i*uintptr(t.keysize))  83 if t.indirectkey() {  84 k = *((*unsafe.Pointer)(k))  85 }  86 // 注意，即使当前cell位的tophash值相等，不一定它对应的key也是相等的，所以还要做一个key值判断  87 if !t.key.equal(key, k) {  88 continue  89 }  90 // 如果已经有该key了，就更新它  91 if t.needkeyupdate() {  92 typedmemmove(t.key, k, key)  93 }  94 // 这里获取到了要插入key对应的value的内存地址  95 // pos = start &#43; dataOffset &#43; 8*keysize &#43; i*elemsize  96 elem = add(unsafe.Pointer(b), dataOffset&#43;bucketCnt*uintptr(t.keysize)&#43;i*uintptr(t.elemsize))  97 // 如果顺利到这，就直接跳到done的结束逻辑中去  98 goto done  99 } 100 // 如果桶中的8个cell遍历完，还未找到对应的空cell或覆盖cell，那么就进入它的溢出桶中去遍历 101 ovf := b.overflow(t) 102 // 如果连溢出桶中都没有找到合适的cell，跳出循环。 103 if ovf == nil { 104 break 105 } 106 b = ovf 107 } 108 109 // 在已有的桶和溢出桶中都未找到合适的cell供key写入，那么有可能会触发以下两种情况 110 // 情况一： 111 // 判断当前map的装载因子是否达到设定的6.5阈值，或者当前map的溢出桶数量是否过多。如果存在这两种情况之一，则进行扩容操作。 112 // hashGrow()实际并未完成扩容，对哈希表数据的搬迁（复制）操作是通过growWork()来完成的。 113 // 重新跳入again逻辑，在进行完growWork()操作后，再次遍历新的桶。 114 if !h.growing() &amp;amp;&amp;amp; (overLoadFactor(h.count&#43;1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { 115 hashGrow(t, h) 116 goto again // Growing the table invalidates everything, so try again 117 } 118 119 // 情况二： 120// 在不满足情况一的条件下，会为当前桶再新建溢出桶，并将tophash，key插入到新建溢出桶的对应内存的0号位置 121 if inserti == nil { 122 // all current buckets are full, allocate a new one. 123 newb := h.newoverflow(t, b) 124 inserti = &amp;amp;newb.tophash[0] 125 insertk = add(unsafe.Pointer(newb), dataOffset) 126 elem = add(insertk, bucketCnt*uintptr(t.keysize)) 127 } 128 129 // 在插入位置存入新的key和value 130 if t.indirectkey() { 131 kmem := newobject(t.key) 132 *(*unsafe.Pointer)(insertk) = kmem 133 insertk = kmem 134 } 135 if t.indirectelem() { 136 vmem := newobject(t.elem) 137 *(*unsafe.Pointer)(elem) = vmem 138 } 139 typedmemmove(t.key, insertk, key) 140 *inserti = top 141 // map中的key数量&#43;1 142 h.count&#43;&#43; 143 144done: 145 if h.flags&amp;amp;hashWriting == 0 { 146 throw(&amp;#34;concurrent map writes&amp;#34;) 147 } 148 h.flags &amp;amp;^= hashWriting 149 if t.indirectelem() { 150 elem = *((*unsafe.Pointer)(elem)) 151 } 152 return elem 153} 通过对mapassign的代码分析之后，发现该函数并没有将插入key对应的value写入对应的内存，而是返回了value应该插入的内存地址。为了弄清楚value写入内存的操作是发生在什么时候，分析如下map.go代码。
1package main 2 3func main() { 4 m := make(map[int]int) 5 for i := 0; i &amp;lt; 100; i&#43;&#43; { 6 m[i] = 666 7 } 8} m[i] = 666对应的汇编代码
 1$ go tool compile -S map.go  2...  3 0x0098 00152 (map.go:6) LEAQ type.map[int]int(SB), CX  4 0x009f 00159 (map.go:6) MOVQ CX, (SP)  5 0x00a3 00163 (map.go:6) LEAQ &amp;#34;&amp;#34;..autotmp_2&#43;184(SP), DX  6 0x00ab 00171 (map.go:6) MOVQ DX, 8(SP)  7 0x00b0 00176 (map.go:6) MOVQ AX, 16(SP)  8 0x00b5 00181 (map.go:6) CALL runtime.mapassign_fast64(SB) // 调用函数runtime.mapassign_fast64，该函数实质就是mapassign（上文示例源代码是该mapassign系列的通用逻辑）  9 0x00ba 00186 (map.go:6) MOVQ 24(SP), AX 24(SP), AX // 返回值，即 value 应该存放的内存地址 10 0x00bf 00191 (map.go:6) MOVQ $666, (AX) // 把 666 放入该地址中 11... 赋值的最后一步实际上是编译器额外生成的汇编指令来完成的，可见靠 runtime 有些工作是没有做完的。所以，在go中，编译器和 runtime 配合，才能完成一些复杂的工作。同时说明，在平时学习go的源代码实现时，必要时还需要看一些汇编代码。
C
删除Key
 理解了赋值key的逻辑，删除key的逻辑就比较简单了。本文就不再讨论该部分内容了，读者感兴趣可以自行查看src/runtime/map.go的mapdelete方法逻辑。
D
遍历map
结论：迭代 map 的结果是无序的
1 m := make(map[int]int) 2 for i := 0; i &amp;lt; 10; i&#43;&#43; { 3 m[i] = i 4 } 5 for k, v := range m { 6 fmt.Println(k, v) 7 } 运行以上代码，我们会发现每次输出顺序都是不同的。
map遍历的过程，是按序遍历bucket，同时按需遍历bucket中和其overflow bucket中的cell。但是map在扩容后，会发生key的搬迁，这造成原来落在一个bucket中的key，搬迁后，有可能会落到其他bucket中了，从这个角度看，遍历map的结果就不可能是按照原来的顺序了（详见下文的map扩容内容）。
但其实，go为了保证遍历map的结果是无序的，做了以下事情：map在遍历时，并不是从固定的0号bucket开始遍历的，每次遍历，都会从一个随机值序号的bucket，再从其中随机的cell开始遍历。然后再按照桶序遍历下去，直到回到起始桶结束。
上图的例子，是遍历一个处于未扩容状态的map。如果map正处于扩容状态时，需要先判断当前遍历bucket是否已经完成搬迁，如果数据还在老的bucket，那么就去老bucket中拿数据。
注意：在下文中会讲解到增量扩容和等量扩容。当发生了增量扩容时，一个老的bucket数据可能会分裂到两个不同的bucket中去，那么此时，如果需要从老的bucket中遍历数据，例如1号，则不能将老1号bucket中的数据全部取出，仅仅只能取出老 1 号 bucket 中那些在裂变之后，分配到新 1 号 bucket 中的那些 key（这个内容，请读者看完下文map扩容的讲解之后再回头理解）。
鉴于篇幅原因，本文不再对map遍历的详细源码进行注释贴出。读者可自行查看源码src/runtime/map.go的mapiterinit()和mapiternext()方法逻辑。
这里注释一下mapiterinit()中随机保证的关键代码
1// 生成随机数 2r := uintptr(fastrand()) 3if h.B &amp;gt; 31-bucketCntBits { 4 r &#43;= uintptr(fastrand()) &amp;lt;&amp;lt; 31 5} 6// 决定了从哪个随机的bucket开始 7it.startBucket = r &amp;amp; bucketMask(h.B) 8// 决定了每个bucket中随机的cell的位置 9it.offset = uint8(r &amp;gt;&amp;gt; h.B &amp;amp; (bucketCnt - 1)) 05
map扩容
在文中讲解装载因子时，我们提到装载因子是决定哈希表是否进行扩容的关键指标。在go的map扩容中，除了装载因子会决定是否需要扩容，溢出桶的数量也是扩容的另一关键指标。
为了保证访问效率，当map将要添加、修改或删除key时，都会检查是否需要扩容，扩容实际上是以空间换时间的手段。在之前源码mapassign中，其实已经注释map扩容条件，主要是两点:
 判断已经达到装载因子的临界点，即元素个数 &amp;gt;= 桶（bucket）总数 * 6.5，这时候说明大部分的桶可能都快满了（即平均每个桶存储的键值对达到6.5个），如果插入新元素，有大概率需要挂在溢出桶（overflow bucket）上。  1func overLoadFactor(count int, B uint8) bool { 2 return count &amp;gt; bucketCnt &amp;amp;&amp;amp; uintptr(count) &amp;gt; loadFactorNum*(bucketShift(B)/loadFactorDen) 3}  判断溢出桶是否太多，当桶总数 &amp;lt; 2 ^ 15 时，如果溢出桶总数 &amp;gt;= 桶总数，则认为溢出桶过多。当桶总数 &amp;gt;= 2 ^ 15 时，直接与 2 ^ 15 比较，当溢出桶总数 &amp;gt;= 2 ^ 15 时，即认为溢出桶太多了。  1func tooManyOverflowBuckets(noverflow uint16, B uint8) bool { 2 if B &amp;gt; 15 { 3 B = 15 4 } 5 return noverflow &amp;gt;= uint16(1)&amp;lt;&amp;lt;(B&amp;amp;15) 6} 对于第2点，其实算是对第 1 点的补充。因为在装载因子比较小的情况下，有可能 map 的查找和插入效率也很低，而第 1 点识别不出来这种情况。表面现象就是计算装载因子的分子比较小，即 map 里元素总数少，但是桶数量多（真实分配的桶数量多，包括大量的溢出桶）。
在某些场景下，比如不断的增删，这样会造成overflow的bucket数量增多，但负载因子又不高，未达不到第 1 点的临界值，就不能触发扩容来缓解这种情况。这样会造成桶的使用率不高，值存储得比较稀疏，查找插入效率会变得非常低，因此有了第 2 点判断指标。这就像是一座空城，房子很多，但是住户很少，都分散了，找起人来很困难。
如上图所示，由于对map的不断增删，以0号bucket为例，该桶链中就造成了大量的稀疏桶。
两种情况官方采用了不同的解决方案
 针对 1，将 B &#43; 1，新建一个buckets数组，新的buckets大小是原来的2倍，然后旧buckets数据搬迁到新的buckets。该方法我们称之为增量扩容。 针对 2，并不扩大容量，buckets数量维持不变，重新做一遍类似增量扩容的搬迁动作，把松散的键值对重新排列一次，以使bucket的使用率更高，进而保证更快的存取。该方法我们称之为等量扩容。  对于 2 的解决方案，其实存在一个极端的情况：如果插入 map 的 key 哈希都一样，那么它们就会落到同一个 bucket 里，超过 8 个就会产生 overflow bucket，结果也会造成 overflow bucket 数过多。移动元素其实解决不了问题，因为这时整个哈希表已经退化成了一个链表，操作效率变成了 O(n)。但 Go 的每一个 map 都会在初始化阶段的 makemap时定一个随机的哈希种子，所以要构造这种冲突是没那么容易的。
在源码中，和扩容相关的主要是hashGrow()函数与growWork()函数。hashGrow() 函数实际上并没有真正地“搬迁”，它只是分配好了新的 buckets，并将老的 buckets 挂到了 oldbuckets 字段上。真正搬迁 buckets 的动作在 growWork() 函数中，而调用 growWork() 函数的动作是在mapassign() 和 mapdelete() 函数中。也就是插入（包括修改）、删除 key 的时候，都会尝试进行搬迁 buckets 的工作。它们会先检查 oldbuckets 是否搬迁完毕（检查 oldbuckets 是否为 nil），再决定是否进行搬迁工作。
hashGrow()函数
 1func hashGrow(t *maptype, h *hmap) {  2 // 如果达到条件 1，那么将B值加1，相当于是原来的2倍  3 // 否则对应条件 2，进行等量扩容，所以 B 不变  4 bigger := uint8(1)  5 if !overLoadFactor(h.count&#43;1, h.B) {  6 bigger = 0  7 h.flags |= sameSizeGrow  8 }  9 // 记录老的buckets 10 oldbuckets := h.buckets 11 // 申请新的buckets空间 12 newbuckets, nextOverflow := makeBucketArray(t, h.B&#43;bigger, nil) 13 // 注意&amp;amp;^ 运算符，这块代码的逻辑是转移标志位 14 flags := h.flags &amp;amp;^ (iterator | oldIterator) 15 if h.flags&amp;amp;iterator != 0 { 16 flags |= oldIterator 17 } 18 // 提交grow (atomic wrt gc) 19 h.B &#43;= bigger 20 h.flags = flags 21 h.oldbuckets = oldbuckets 22 h.buckets = newbuckets 23 // 搬迁进度为0 24 h.nevacuate = 0 25 // overflow buckets 数为0 26 h.noverflow = 0 27 28 // 如果发现hmap是通过extra字段 来存储 overflow buckets时 29 if h.extra != nil &amp;amp;&amp;amp; h.extra.overflow != nil { 30 if h.extra.oldoverflow != nil { 31 throw(&amp;#34;oldoverflow is not nil&amp;#34;) 32 } 33 h.extra.oldoverflow = h.extra.overflow 34 h.extra.overflow = nil 35 } 36 if nextOverflow != nil { 37 if h.extra == nil { 38 h.extra = new(mapextra) 39 } 40 h.extra.nextOverflow = nextOverflow 41 } 42} growWork()函数
 1func growWork(t *maptype, h *hmap, bucket uintptr) {  2 // 为了确认搬迁的 bucket 是我们正在使用的 bucket  3 // 即如果当前key映射到老的bucket1，那么就搬迁该bucket1。  4 evacuate(t, h, bucket&amp;amp;h.oldbucketmask())  5  6 // 如果还未完成扩容工作，则再搬迁一个bucket。  7 if h.growing() {  8 evacuate(t, h, h.nevacuate)  9 } 10} 从growWork()函数可以知道，搬迁的核心逻辑是evacuate()函数。这里读者可以思考一个问题：为什么每次至多搬迁2个bucket？这其实是一种性能考量，如果map存储了数以亿计的key-value，一次性搬迁将会造成比较大的延时，因此才采用逐步搬迁策略。
在讲解该逻辑之前，需要读者先理解以下两个知识点。
 知识点1：bucket序号的变化  前面讲到，增量扩容（条件1）和等量扩容（条件2）都需要进行bucket的搬迁工作。对于等量扩容而言，由于buckets的数量不变，因此可以按照序号来搬迁。例如老的的0号bucket，仍然搬至新的0号bucket中。
但是，对于增量扩容而言，就会有所不同。例如原来的B=5，那么增量扩容时，B就会变成6。那么决定key值落入哪个bucket的低位哈希值就会发生变化（从取5位变为取6位），取新的低位hash值得过程称为rehash。
因此，在增量扩容中，某个 key 在搬迁前后 bucket 序号可能和原来相等，也可能是相比原来加上 2^B（原来的 B 值），取决于低 hash 值第倒数第B&#43;1位是 0 还是 1。
如上图所示，当原始的B = 3时，旧buckets数组长度为8，在编号为2的bucket中，其2号cell和5号cell，它们的低3位哈希值相同（不相同的话，也就不会落在同一个桶中了），但是它们的低4位分别是0010、1010。当发生了增量扩容，2号就会被搬迁到新buckets数组的2号bucket中去，5号被搬迁到新buckets数组的10号bucket中去，它们的桶号差距是2的3次方。
 知识点2：确定搬迁区间  在源码中，有bucket x 和bucket y的概念，其实就是增量扩容到原来的 2 倍，桶的数量是原来的 2 倍，前一半桶被称为bucket x，后一半桶被称为bucket y。一个 bucket 中的 key 可能会分裂到两个桶中去，分别位于bucket x的桶，或bucket y中的桶。所以在搬迁一个 cell 之前，需要知道这个 cell 中的 key 是落到哪个区间（而对于同一个桶而言，搬迁到bucket x和bucket y桶序号的差别是老的buckets大小，即2^old_B）。
思考：为什么确定key落在哪个区间很重要？
确定了要搬迁到的目标 bucket 后，搬迁操作就比较好进行了。将源 key/value 值 copy 到目的地相应的位置。设置 key 在原始 buckets 的 tophash 为 evacuatedX 或是 evacuatedY，表示已经搬迁到了新 map 的bucket x或是bucket y，新 map 的 tophash 则正常取 key 哈希值的高 8 位。
下面正式解读搬迁核心代码evacuate()函数。
evacuate()函数
 1func evacuate(t *maptype, h *hmap, oldbucket uintptr) {  2 // 首先定位老的bucket的地址  3 b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize)))  4 // newbit代表扩容之前老的bucket个数  5 newbit := h.noldbuckets()  6 // 判断该bucket是否已经被搬迁  7 if !evacuated(b) {  8 // 官方TODO，后续版本也许会实现  9 // TODO: reuse overflow buckets instead of using new ones, if there  10 // is no iterator using the old buckets. (If !oldIterator.)  11  12 // xy 包含了高低区间的搬迁目的地内存信息  13 // x.b 是对应的搬迁目的桶  14 // x.k 是指向对应目的桶中存储当前key的内存地址  15 // x.e 是指向对应目的桶中存储当前value的内存地址  16 var xy [2]evacDst  17 x := &amp;amp;xy[0]  18 x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize)))  19 x.k = add(unsafe.Pointer(x.b), dataOffset)  20 x.e = add(x.k, bucketCnt*uintptr(t.keysize))  21  22 // 只有当增量扩容时才计算bucket y的相关信息（和后续计算useY相呼应）  23 if !h.sameSizeGrow() {  24 y := &amp;amp;xy[1]  25 y.b = (*bmap)(add(h.buckets, (oldbucket&#43;newbit)*uintptr(t.bucketsize)))  26 y.k = add(unsafe.Pointer(y.b), dataOffset)  27 y.e = add(y.k, bucketCnt*uintptr(t.keysize))  28 }  29  30 // evacuate 函数每次只完成一个 bucket 的搬迁工作，因此要遍历完此 bucket 的所有的 cell，将有值的 cell copy 到新的地方。  31 // bucket 还会链接 overflow bucket，它们同样需要搬迁。  32 // 因此同样会有 2 层循环，外层遍历 bucket 和 overflow bucket，内层遍历 bucket 的所有 cell。  33  34 // 遍历当前桶bucket和其之后的溢出桶overflow bucket  35 // 注意：初始的b是待搬迁的老bucket  36 for ; b != nil; b = b.overflow(t) {  37 k := add(unsafe.Pointer(b), dataOffset)  38 e := add(k, bucketCnt*uintptr(t.keysize))  39 // 遍历桶中的cell，i，k，e分别用于对应tophash，key和value  40 for i := 0; i &amp;lt; bucketCnt; i, k, e = i&#43;1, add(k, uintptr(t.keysize)), add(e, uintptr(t.elemsize)) {  41 top := b.tophash[i]  42 // 如果当前cell的tophash值是emptyOne或者emptyRest，则代表此cell没有key。并将其标记为evacuatedEmpty，表示它“已经被搬迁”。  43 if isEmpty(top) {  44 b.tophash[i] = evacuatedEmpty  45 continue  46 }  47 // 正常不会出现这种情况  48 // 未被搬迁的 cell 只可能是emptyOne、emptyRest或是正常的 top hash（大于等于 minTopHash）  49 if top &amp;lt; minTopHash {  50 throw(&amp;#34;bad map state&amp;#34;)  51 }  52 k2 := k  53 // 如果 key 是指针，则解引用  54 if t.indirectkey() {  55 k2 = *((*unsafe.Pointer)(k2))  56 }  57 var useY uint8  58 // 如果是增量扩容  59 if !h.sameSizeGrow() {  60 // 计算哈希值，判断当前key和vale是要被搬迁到bucket x还是bucket y  61 hash := t.hasher(k2, uintptr(h.hash0))  62 if h.flags&amp;amp;iterator != 0 &amp;amp;&amp;amp; !t.reflexivekey() &amp;amp;&amp;amp; !t.key.equal(k2, k2) {  63 // 有一个特殊情况：有一种 key，每次对它计算 hash，得到的结果都不一样。  64 // 这个 key 就是 math.NaN() 的结果，它的含义是 not a number，类型是 float64。  65 // 当它作为 map 的 key时，会遇到一个问题：再次计算它的哈希值和它当初插入 map 时的计算出来的哈希值不一样！  66 // 这个 key 是永远不会被 Get 操作获取的！当使用 m[math.NaN()] 语句的时候，是查不出来结果的。  67 // 这个 key 只有在遍历整个 map 的时候，才能被找到。  68 // 并且，可以向一个 map 插入多个数量的 math.NaN() 作为 key，它们并不会被互相覆盖。  69 // 当搬迁碰到 math.NaN() 的 key 时，只通过 tophash 的最低位决定分配到 X part 还是 Y part（如果扩容后是原来 buckets 数量的 2 倍）。如果 tophash 的最低位是 0 ，分配到 X part；如果是 1 ，则分配到 Y part。  70 useY = top &amp;amp; 1  71 top = tophash(hash)  72 // 对于正常key，进入以下else逻辑  73 } else {  74 if hash&amp;amp;newbit != 0 {  75 useY = 1  76 }  77 }  78 }  79  80 if evacuatedX&#43;1 != evacuatedY || evacuatedX^1 != evacuatedY {  81 throw(&amp;#34;bad evacuatedN&amp;#34;)  82 }  83  84 // evacuatedX &#43; 1 == evacuatedY  85 b.tophash[i] = evacuatedX &#43; useY  86 // useY要么为0，要么为1。这里就是选取在bucket x的起始内存位置，或者选择在bucket y的起始内存位置（只有增量同步才会有这个选择可能）。  87 dst := &amp;amp;xy[useY]  88  89 // 如果目的地的桶已经装满了（8个cell），那么需要新建一个溢出桶，继续搬迁到溢出桶上去。  90 if dst.i == bucketCnt {  91 dst.b = h.newoverflow(t, dst.b)  92 dst.i = 0  93 dst.k = add(unsafe.Pointer(dst.b), dataOffset)  94 dst.e = add(dst.k, bucketCnt*uintptr(t.keysize))  95 }  96 dst.b.tophash[dst.i&amp;amp;(bucketCnt-1)] = top  97 // 如果待搬迁的key是指针，则复制指针过去  98 if t.indirectkey() {  99 *(*unsafe.Pointer)(dst.k) = k2 // copy pointer 100 // 如果待搬迁的key是值，则复制值过去 101 } else { 102 typedmemmove(t.key, dst.k, k) // copy elem 103 } 104 // value和key同理 105 if t.indirectelem() { 106 *(*unsafe.Pointer)(dst.e) = *(*unsafe.Pointer)(e) 107 } else { 108 typedmemmove(t.elem, dst.e, e) 109 } 110 // 将当前搬迁目的桶的记录key/value的索引值（也可以理解为cell的索引值）加一 111 dst.i&#43;&#43; 112 // 由于桶的内存布局中在最后还有overflow的指针，多以这里不用担心更新有可能会超出key和value数组的指针地址。 113 dst.k = add(dst.k, uintptr(t.keysize)) 114 dst.e = add(dst.e, uintptr(t.elemsize)) 115 } 116 } 117 // 如果没有协程在使用老的桶，就对老的桶进行清理，用于帮助gc 118 if h.flags&amp;amp;oldIterator == 0 &amp;amp;&amp;amp; t.bucket.ptrdata != 0 { 119 b := add(h.oldbuckets, oldbucket*uintptr(t.bucketsize)) 120 // 只清除bucket 的 key,value 部分，保留 top hash 部分，指示搬迁状态 121 ptr := add(b, dataOffset) 122 n := uintptr(t.bucketsize) - dataOffset 123 memclrHasPointers(ptr, n) 124 } 125 } 126 127 // 用于更新搬迁进度 128 if oldbucket == h.nevacuate { 129 advanceEvacuationMark(h, t, newbit) 130 } 131} 132 133func advanceEvacuationMark(h *hmap, t *maptype, newbit uintptr) { 134 // 搬迁桶的进度加一 135 h.nevacuate&#43;&#43; 136 // 实验表明，1024至少会比newbit高出一个数量级（newbit代表扩容之前老的bucket个数）。所以，用当前进度加上1024用于确保O(1)行为。 137 stop := h.nevacuate &#43; 1024 138 if stop &amp;gt; newbit { 139 stop = newbit 140 } 141 // 计算已经搬迁完的桶数 142 for h.nevacuate != stop &amp;amp;&amp;amp; bucketEvacuated(t, h, h.nevacuate) { 143 h.nevacuate&#43;&#43; 144 } 145 // 如果h.nevacuate == newbit，则代表所有的桶都已经搬迁完毕 146 if h.nevacuate == newbit { 147 // 搬迁完毕，所以指向老的buckets的指针置为nil 148 h.oldbuckets = nil 149 // 在讲解hmap的结构中，有过说明。如果key和value均不包含指针，则都可以inline。 150 // 那么保存它们的buckets数组其实是挂在hmap.extra中的。所以，这种情况下，其实我们是搬迁的extra的buckets数组。 151 // 因此，在这种情况下，需要在搬迁完毕后，将hmap.extra.oldoverflow指针置为nil。 152 if h.extra != nil { 153 h.extra.oldoverflow = nil 154 } 155 // 最后，清除正在扩容的标志位，扩容完毕。 156 h.flags &amp;amp;^= sameSizeGrow 157 } 158} 代码比较长，但是文中注释已经比较清晰了，如果对map的扩容还不清楚，可以参见以下图解。
针对上图的map，其B为3，所以原始buckets数组为8。当map元素数变多，加载因子超过6.5，所以引起了增量扩容。
以3号bucket为例，可以看到，由于B值加1，所以在新选取桶时，需要取低4位哈希值，这样就会造成cell会被搬迁到新buckets数组中不同的桶（3号或11号桶）中去。注意，在一个桶中，搬迁cell的工作是有序的：它们是依序填进对应新桶的cell中去的。
当然，实际情况中3号桶很可能还有溢出桶，在这里为了简化绘图，假设3号桶没有溢出桶，如果有溢出桶，则相应地添加到新的3号桶和11号桶中即可，如果对应的3号和11号桶均装满，则给新的桶添加溢出桶来装载。
对于上图的map，其B也为3。假设整个map中的overflow过多，触发了等量扩容。注意，等量扩容时，新的buckets数组大小和旧buckets数组是一样的。
以6号桶为例，它有一个bucket和3个overflow buckets，但是我们能够发现桶里的数据非常稀疏，等量扩容的目的就是为了把松散的键值对重新排列一次，以使bucket的使用率更高，进而保证更快的存取。搬迁完毕后，新的6号桶中只有一个基础bucket，暂时并不需要溢出桶。这样，和原6号桶相比，数据变得紧密，使后续的数据存取变快。
最后回答一下上文中留下的问题：为什么确定key落在哪个区间很重要？因为对于增量扩容而言，原本一个bucket中的key会被分裂到两个bucket中去，它们分别处于bucket x和bucket y中，但是它们之间存在关系 bucket x &#43; 2^B = bucket y （其中，B是老bucket对应的B值）。假设key所在的老bucket序号为n，那么如果key落在新的bucket x，则它应该置入 bucket x起始位置 &#43; nbucket 的内存中去；如果key落在新的bucket y，则它应该置入 bucket y起始位置 &#43; nbucket的内存中去。因此，确定key落在哪个区间，这样就很方便进行内存地址计算，快速找到key应该插入的内存地址。
map 总结和使用建议
01
总结
 Go语言的map，底层是哈希表实现的，通过链地址法解决哈希冲突，它依赖的核心数据结构是数组加链表。
map中定义了2的B次方个桶，每个桶中能够容纳8个key。根据key的不同哈希值，将其散落到不同的桶中。哈希值的低位（哈希值的后B个bit位）决定桶序号，高位（哈希值的前8个bit位）标识同一个桶中的不同 key。
当向桶中添加了很多 key，造成元素过多，超过了装载因子所设定的程度，或者多次增删操作，造成溢出桶过多，均会触发扩容。
扩容分为增量扩容和等量扩容。增量扩容，会增加桶的个数（增加一倍），把原来一个桶中的 keys 被重新分配到两个桶中。等量扩容，不会更改桶的个数，只是会将桶中的数据变得紧凑。不管是增量扩容还是等量扩容，都需要创建新的桶数组，并不是原地操作的。
扩容过程是渐进性的，主要是防止一次扩容需要搬迁的 key 数量过多，引发性能问题。触发扩容的时机是增加了新元素， 桶搬迁的时机则发生在赋值、删除期间，每次最多搬迁两个 桶。查找、赋值、删除的一个很核心的内容是如何定位到 key 所在的位置，需要重点理解。一旦理解，关于 map 的源码就可以看懂了。
02
使用建议
从map设计可以知道，它并不是一个并发安全的数据结构。同时对map进行读写时，程序很容易出错。因此，要想在并发情况下使用map，请加上锁（sync.Mutex或者sync.RwMutex）。其实，Go标准库中已经为我们实现了并发安全的map——sync.Map，我之前写过文章对它的实现进行讲解，详情可以查看本公众号《深入理解sync.Map》一文。
遍历map的结果是无序的，在使用中，应该注意到该点。
通过map的结构体可以知道，它其实是通过指针指向底层buckets数组。所以和slice一样，尽管go函数都是值传递，但是，当map作为参数被函数调用时，在函数内部对map的操作同样会影响到外部的map。
另外，有个特殊的key值math.NaN，它每次生成的哈希值是不一样的，这会造成m[math.NaN]是拿不到值的，而且多次对它赋值，会让map中存在多个math.NaN的key。不过这个基本用不到，知道有这个特殊情况就可以了。
  参考链接   https://en.wikipedia.org/wiki/Associative_array
https://blog.golang.org/maps
景禹 《图解：什么是哈希》
https://mp.weixin.qq.com/s/OHROn0ya_nWR6qkaSFmacw
https://www.cse.cuhk.edu.hk/irwin.king/_media/teaching/csc2100b/tu6.pdf
https://github.com/cch123/golang-notes/blob/master/map.md
https://zhuanlan.zhihu.com/p/66676224
https://draveness.me/golang/docs/part2-foundation/ch03-datastructure/golang-hashmap/
https://github.com/talkgo/night/issues/332
https://my.oschina.net/renhc/blog/2208417
以上内容转载自机器铃砍菜刀的blog
</content>
    </entry>
    
     <entry>
        <title>详解内联优化</title>
        <url>http://shanks.link/blog/2021/04/30/%E8%AF%A6%E8%A7%A3%E5%86%85%E8%81%94%E4%BC%98%E5%8C%96/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 详解内联优化 为了保证程序的执行高效与安全，现代编译器并不会将程序员的代码直接翻译成相应地机器码，它需要做一系列的检查与优化。Go编译器默认做了很多相关工作，例如未使用的引用包检查、未使用的声明变量检查、有效的括号检查、逃逸分析、内联优化、删除无用代码等。本文重点讨论内联优化相关内容。
内联
在《详解逃逸分析》一文中，我们分析了栈分配内存会比堆分配高效地多，那么，我们就会希望对象能尽可能被分配在栈上。在Go中，一个goroutine会有一个单独的栈，栈又会包含多个栈帧，栈帧是函数调用时在栈上为函数所分配的区域。但其实，函数调用是存在一些固定开销的，例如维护帧指针寄存器BP、栈溢出检测等。因此，对于一些代码行比较少的函数，编译器倾向于将它们在编译期展开从而消除函数调用，这种行为就是内联。
 性能对比 首先，看一下函数内联与非内联的性能差异。
 1//go:noinline  2func maxNoinline(a, b int) int {  3 if a &amp;lt; b {  4 return b  5 }  6 return a  7}  8  9func maxInline(a, b int) int { 10 if a &amp;lt; b { 11 return b 12 } 13 return a 14} 15 16func BenchmarkNoInline(b *testing.B) { 17 x, y := 1, 2 18 b.ResetTimer() 19 for i := 0; i &amp;lt; b.N; i&#43;&#43; { 20 maxNoinline(x, y) 21 } 22} 23 24func BenchmarkInline(b *testing.B) { 25 x, y := 1, 2 26 b.ResetTimer() 27 for i := 0; i &amp;lt; b.N; i&#43;&#43; { 28 maxInline(x, y) 29 } 30} 在程序代码中，想要禁止编译器内联优化很简单，在函数定义前一行添加//go:noinline即可。以下是性能对比结果
1BenchmarkNoInline-8 824031799 1.47 ns/op 2BenchmarkInline-8 1000000000 0.255 ns/op 因为函数体内部的执行逻辑非常简单，此时内联与否的性能差异主要体现在函数调用的固定开销上。显而易见，该差异是非常大的。
** ** 内联场景 此时，爱思考的读者可能就会产生疑问：既然内联优化效果这么显著，是不是所有的函数调用都可以内联呢？答案是不可以。因为内联，其实就是将一个函数调用原地展开，替换成这个函数的实现。当该函数被多次调用，就会被多次展开，这会增加编译后二进制文件的大小。而非内联函数，只需要保存一份函数体的代码，然后进行调用。所以，在空间上，一般来说使用内联函数会导致生成的可执行文件变大（但需要考虑内联的代码量、调用次数、维护内联关系的开销）。
问题来了，编译器内联优化的选择策略是什么？
 1package main  2  3func add(a, b int) int {  4 return a &#43; b  5}  6  7func iter(num int) int {  8 res := 1  9 for i := 1; i &amp;lt;= num; i&#43;&#43; { 10 res = add(res, i) 11 } 12 return res 13} 14 15func main() { 16 n := 100 17 _ = iter(n) 18} 假设源码文件为main.go，可通过执行go build -gcflags=&amp;quot;-m -m&amp;quot; main.go命令查看编译器的优化策略。
1$ go build -gcflags=&amp;#34;-m -m&amp;#34; main.go 2# command-line-arguments 3./main.go:3:6: can inline add with cost 4 as: func(int, int) int { return a &#43; b } 4./main.go:7:6: cannot inline iter: unhandled op FOR 5./main.go:10:12: inlining call to add func(int, int) int { return a &#43; b } 6./main.go:15:6: can inline main with cost 67 as: func() { n := 100; _ = iter(n) } 通过以上信息，可知编译器判断add函数与main函数都可以被内联优化，并将add函数内联。同时可以注意到的是，iter函数由于存在循环语句并不能被内联：cannot inline iter: unhandled op FOR。实际上，除了for循环，还有一些情况不会被内联，例如闭包，select，for，defer，go关键字所开启的新goroutine等，详细可见src/cmd/compile/internal/gc/inl.go相关内容。
 1 case OCLOSURE,  2 OCALLPART,  3 ORANGE,  4 OFOR,  5 OFORUNTIL,  6 OSELECT,  7 OTYPESW,  8 OGO,  9 ODEFER, 10 ODCLTYPE, // can&amp;#39;t print yet 11 OBREAK, 12 ORETJMP: 13 v.reason = &amp;#34;unhandled op &amp;#34; &#43; n.Op.String() 14 return true 在上文提到过，内联只针对小代码量的函数而言，那么到底是小于多少才算是小代码量呢？
此时，我将上面的add函数，更改为如下内容
1func add(a, b int) int { 2 a = a &#43; 1 3 return a &#43; b 4} 执行go build -gcflags=&amp;quot;-m -m&amp;quot; main.go命令，得到信息
1./main.go:3:6: can inline add with cost 9 as: func(int, int) int { a = a &#43; 1; return a &#43; b } 对比之前的信息
1./main.go:3:6: can inline add with cost 4 as: func(int, int) int { return a &#43; b } 可以发现，存在cost 4与cost 9的区别。这里的数值代表的是抽象语法树AST的节点，a = a &#43; 1包含的是5个节点。Go函数中超过80个节点的代码量就不再内联。例如，如果在add中写入16个a = a &#43; 1，则不再内联。
1./main.go:3:6: cannot inline add: function too complex: cost 84 exceeds budget 80  内联表 内联会将函数调用的过程抹掉，这会引入一个新的问题：代码的堆栈信息还能否保证。举个例子，如果程序发生panic，内联之后的程序，还能否准确的打印出堆栈信息？看以下例子。
 1package main  2  3func sub(a, b int) {  4 a = a - b  5 panic(&amp;#34;i am a panic information&amp;#34;)  6}  7  8func max(a, b int) int {  9 if a &amp;lt; b { 10 sub(a, b) 11 } 12 return a 13} 14 15func main() { 16 x, y := 1, 2 17 _ = max(x, y) 18} 在该代码样例中，max函数将被内联。执行程序，输出结果如下
1panic: i am a panic information 2 3goroutine 1 [running]: 4main.sub(...) 5 /Users/slp/go/src/workspace/example/main.go:5 6main.max(...) 7 /Users/slp/go/src/workspace/example/main.go:10 8main.main() 9 /Users/slp/go/src/workspace/example/main.go:17 &#43;0x3a 可以发现，panic依然输出了正确的程序堆栈信息，包括源文件位置和行号信息。那，Go是如何做到的呢？
这是由于Go内部会为每个存在内联优化的goroutine维持一个内联树（inlining tree），该树可通过 go build -gcflags=&amp;quot;-d pctab=pctoinline&amp;quot; main.go 命令查看
 1funcpctab &amp;#34;&amp;#34;.sub [valfunc=pctoinline]  2...  3wrote 3 bytes to 0xc000082668  4 00 42 00  5funcpctab &amp;#34;&amp;#34;.max [valfunc=pctoinline]  6...  7wrote 7 bytes to 0xc000082f68  8 00 3c 02 1d 01 09 00  9-- inlining tree for &amp;#34;&amp;#34;.max: 100 | -1 | &amp;#34;&amp;#34;.sub (/Users/slp/go/src/workspace/example/main.go:10:6) pc=59 11-- 12funcpctab &amp;#34;&amp;#34;.main [valfunc=pctoinline] 13... 14wrote 11 bytes to 0xc0004807e8 15 00 1d 02 01 01 07 04 16 03 0c 00 16-- inlining tree for &amp;#34;&amp;#34;.main: 170 | -1 | &amp;#34;&amp;#34;.max (/Users/slp/go/src/workspace/example/main.go:17:9) pc=30 181 | 0 | &amp;#34;&amp;#34;.sub (/Users/slp/go/src/workspace/example/main.go:10:6) pc=29 19--  内联控制 Go程序编译时，默认将进行内联优化。我们可通过-gcflags=&amp;quot;-l&amp;quot;选项全局禁用内联，与一个-l禁用内联相反，如果传递两个或两个以上的-l则会打开内联，并启用更激进的内联策略。如果不想全局范围内禁止优化，则可以在函数定义时添加 //go:noinline 编译指令来阻止编译器内联函数。
以上内容转载自机器铃砍菜刀
</content>
    </entry>
    
     <entry>
        <title>Go精妙的互斥锁设计</title>
        <url>http://shanks.link/blog/2021/04/30/go%E7%B2%BE%E5%A6%99%E7%9A%84%E4%BA%92%E6%96%A5%E9%94%81%E8%AE%BE%E8%AE%A1/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> *Some people, when confronted with a problem, think, “I know, I’ll use threads,” and then two they hav erpoblesms.*
1. 竞争条件
多线程程序在多核CPU机器上访问共享资源时，难免会遇到问题。我们可以来看一个例子
 1var Cnt int  2  3func Add(iter int) {  4 for i := 0; i &amp;lt; iter; i&#43;&#43; {  5 Cnt&#43;&#43;  6 }  7}  8  9func main() { 10 wg := &amp;amp;sync.WaitGroup{} 11 for i := 0; i &amp;lt; 2; i&#43;&#43; { 12 wg.Add(1) 13 go func() { 14 Add(100000) 15 wg.Done() 16 }() 17 } 18 wg.Wait() 19 fmt.Println(Cnt) 20} 很明显，程序的预期结果是200000，但实际的输出却是不可确定的，可能为100910、101364或者其他数值，这就是典型的多线程访问冲突问题。
利用go tool trace分析工具（需要在代码中加入runtime/trace包获取程序运行信息，此处省略），查看该程序运行期间goroutine的执行情况如上图所示。其中G20和G19就是执行Add()函数的两个goroutine，它们在执行期间并行地访问了共享变量Cnt。
类似这种情况，即两个或者多个线程读写某些共享数据，而最后的结果取决于程序运行的精确时序，这就是竞争条件（race condition）。
2. 临界区与互斥
怎样避免竞争条件？实际上凡涉及共享内存、共享文件以及共享任何资源的情况都会引发上文例子中类似的错误，要避免这种错误，关键是要找出某种途径来阻止多线程同时读写共享的数据。换言之，我们需要的是互斥（mutual exclusion），即以某种手段确保当一个线程在使用一个共享变量或文件时，其他线程不能做同样的操作。
我们把对共享内存进行访问的程序片段称作临界区（critical section），例如上例中的Cnt&#43;&#43;片段。从抽象的角度看，我们希望的多线程行为如下图所示。线程A在t1时刻进入临界区，执行一段时间后，在t2时刻线程B试图进入临界区，但是这是不能被允许的，因为同一时刻只能运行一个线程在临界区内，而此时已经有一个线程在临界区内。我们通过某种互斥手段，将B暂时挂起直到线程A离开临界区，即t3时刻B进入临界区。最后，B执行完临界区代码后，离开临界区。
如果我们能够合理地安排，使得两个线程不可能同时处于临界区中，就能够避免竞争条件。因此，我们将代码稍作调整如下：
 1var (  2 Cnt int  3 mu sync.Mutex  4)  5  6func Add(iter int) {  7 mu.Lock()  8 for i := 0; i &amp;lt; iter; i&#43;&#43; {  9 Cnt&#43;&#43; 10 } 11 mu.Unlock() 12} 此时，程序执行得到了预期结果200000。
程序运行期间的执行情况如上图所示。其中G8和G7是执行Add()函数的两个goroutine，通过加入sync.Mutex互斥锁，G8和G7就不再存在竞争条件。
需要明确的是，只有在多核机器上才会发生竞争条件，只有多线程对共享资源做了写操作时才有可能发生竞态问题，只要资源没有发生变化，多个线程读取相同的资源就是安全的。
3. Go互斥锁设计
互斥锁是实现互斥功能的常见实现，Go中的互斥锁即sync.Mutex。本文将基于Go 1.15.2版本，对互斥锁的实现深入研究。
 1type Mutex struct {  2 state int32  3 sema uint32  4}  5  6const (  7 mutexLocked = 1 &amp;lt;&amp;lt; iota  8 mutexWoken  9 mutexStarving 10 mutexWaiterShift = iota // mutexWaiterShift值为3，通过右移3位的位运算，可计算waiter个数 11 starvationThresholdNs = 1e6 // 1ms，进入饥饿状态的等待时间 12) state字段表示当前互斥锁的状态信息，它是int32类型，其低三位的二进制位均有相应的状态含义。
 mutexLocked是state中的低1位，用二进制表示为0001（为了方便，这里只描述后4位），它代表该互斥锁是否被加锁。 mutexWoken是低2位，用二进制表示为0010，它代表互斥锁上是否有被唤醒的goroutine。 mutexStarving是低3位，用二进制表示为0100，它代表当前互斥锁是否处于饥饿模式。 state剩下的29位用于统计在互斥锁上的等待队列中goroutine数目（waiter）。  默认的state字段（无锁状态）如下图所示。
sema字段是信号量，用于控制goroutine的阻塞与唤醒，下文中会有介绍到。
3.1 两种模式 Go实现的互斥锁有两种模式，分别是正常模式和饥饿模式。
在正常模式下，waiter按照先进先出（FIFO）的方式获取锁，但是一个刚被唤醒的waiter与新到达的goroutine竞争锁时，大概率是干不过的。新来的goroutine有一个优势：它已经在CPU上运行，并且有可能不止一个新来的，因此waiter极有可能失败。在这种情况下，waiter还需要在等待队列中排队。为了避免waiter长时间抢不到锁，当waiter超过 1ms 没有获取到锁，它就会将当前互斥锁切换到饥饿模式，防止等待队列中的waiter被饿死。
在饥饿模式下，锁的所有权直接从解锁（unlocking）的goroutine转移到等待队列中的队头waiter。新来的goroutine不会尝试去获取锁，也不会自旋。它们将在等待队列的队尾排队。
如果某waiter获取到了锁，并且满足以下两个条件之一，它就会将锁从饥饿模式切换回正常模式。
 它是等待队列的最后一个goroutine 它等待获取锁的时间小于1ms  饥饿模式是在 Go 1.9版本引入的，它防止了队列尾部waiter一直无法获取锁的问题。与饥饿模式相比，正常模式下的互斥锁性能更好。因为相较于将锁的所有权明确赋予给唤醒的waiter，直接竞争锁能降低整体goroutine获取锁的延时开销。
3.2 加锁 既然被称作锁，那就存在加锁和解锁的操作。sync.Mutex的加锁Lock()代码如下
1func (m *Mutex) Lock() { 2 if atomic.CompareAndSwapInt32(&amp;amp;m.state, 0, mutexLocked) { 3 if race.Enabled { 4 race.Acquire(unsafe.Pointer(m)) 5 } 6 return 7 } 8 m.lockSlow() 9} 代码非常简洁，首先通过CAS判断当前锁的状态（CAS的原理和实现可以参照小菜刀写的《同步原语的基石》一文）。如果锁是完全空闲的，即m.state为0，则对其加锁，将m.state的值赋为1，此时加锁后的state如下
如果，当前锁已经被其他goroutine加锁，则进入m.lockSlow()逻辑。lockSlow函数比较长，这里我们分段阐述。
3.2.1 初始化
** **
1func (m *Mutex) lockSlow() { 2 var waitStartTime int64 // 用于计算waiter的等待时间 3 starving := false // 饥饿模式标志 4 awoke := false // 唤醒标志 5 iter := 0 // 统计当前goroutine的自旋次数 6 old := m.state // 保存当前锁的状态 7 ... 8} 第一段程序是做一些初始化状态、标志的动作。
3.2.2 自旋
lockSlow函数余下的代码，就是一个大的for循环，首先看自旋部分。
 1for {  2 // 判断是否能进入自旋  3 if old&amp;amp;(mutexLocked|mutexStarving) == mutexLocked &amp;amp;&amp;amp; runtime_canSpin(iter) {  4 // !awoke 判断当前goroutine是不是在唤醒状态  5 // old&amp;amp;mutexWoken == 0 表示没有其他正在唤醒的goroutine  6 // old&amp;gt;&amp;gt;mutexWaiterShift != 0 表示等待队列中有正在等待的goroutine  7 if !awoke &amp;amp;&amp;amp; old&amp;amp;mutexWoken == 0 &amp;amp;&amp;amp; old&amp;gt;&amp;gt;mutexWaiterShift != 0 &amp;amp;&amp;amp;  8 // 尝试将当前锁的低2位的Woken状态位设置为1，表示已被唤醒  9 // 这是为了通知在解锁Unlock()中不要再唤醒其他的waiter了 10 atomic.CompareAndSwapInt32(&amp;amp;m.state, old, old|mutexWoken) { 11 awoke = true 12 } 13 // 自旋 14 runtime_doSpin() 15 iter&#43;&#43; 16 old = m.state 17 continue 18 } 19 ... 20} 关于自旋，这里需要简单阐述一下。自旋是自旋锁的行为，它通过忙等待，让线程在某段时间内一直保持执行，从而避免线程上下文的调度开销。自旋锁对于线程只会阻塞很短时间的场景是非常合适的。很显然，单核CPU是不适合使用自旋锁的，因为，在同一时间只有一个线程是处于运行状态，假设运行线程A发现无法获取锁，只能等待解锁，但因为A自身不挂起，所以那个持有锁的线程B没有办法进入运行状态，只能等到操作系统分给A的时间片用完，才能有机会被调度。这种情况下使用自旋锁的代价很高。
在本场景中，之所以想让当前goroutine进入自旋行为的依据是，我们乐观地认为：当前正在持有锁的goroutine能在较短的时间内归还锁。
runtime_canSpin()函数的实现如下
 1//go:linkname sync_runtime_canSpin sync.runtime_canSpin  2func sync_runtime_canSpin(i int) bool {  3 // active_spin = 4  4 if i &amp;gt;= active_spin || ncpu &amp;lt;= 1 || gomaxprocs &amp;lt;= int32(sched.npidle&#43;sched.nmspinning)&#43;1 {  5 return false  6 }  7 if p := getg().m.p.ptr(); !runqempty(p) {  8 return false  9 } 10 return true 11} 由于自旋本身是空转CPU的，所以如果使用不当，反倒会降低程序运行性能。结合函数中的判断逻辑，这里总结出来goroutine能进入自旋的条件如下
 当前互斥锁处于正常模式 当前运行的机器是多核CPU，且GOMAXPROCS&amp;gt;1 至少存在一个其他正在运行的处理器P，并且它的本地运行队列（local runq）为空 当前goroutine进行自旋的次数小于4  前面说到，自旋行为就是让当前goroutine并不挂起，占用cpu资源。我们看一下runtime_doSpin()的实现。
1//go:linkname sync_runtime_doSpin sync.runtime_doSpin 2func sync_runtime_doSpin() { 3 procyield(active_spin_cnt) // active_spin_cnt = 30 4} runtime_doSpin调用了procyield，其实现如下（以amd64为例）
1TEXT runtime·procyield(SB),NOSPLIT,$0-0 2 MOVL cycles&#43;0(FP), AX 3again: 4 PAUSE 5 SUBL $1, AX 6 JNZ again 7 RET 很明显，所谓的忙等待就是执行 30 次 PAUSE 指令，通过该指令占用 CPU 并消耗 CPU 时间。
3.2.3 计算期望状态
前面说过，当前goroutine进入自旋是需要满足相应条件的。如果不满足自旋条件，则进入以下逻辑。
 1 // old是锁当前的状态，new是期望的状态，以期于在后面的CAS操作中更改锁的状态  2 new := old  3 if old&amp;amp;mutexStarving == 0 {  4 // 如果当前锁不是饥饿模式，则将new的低1位的Locked状态位设置为1，表示加锁  5 new |= mutexLocked  6 }  7 if old&amp;amp;(mutexLocked|mutexStarving) != 0 {  8 // 如果当前锁已被加锁或者处于饥饿模式，则将waiter数加1，表示当前goroutine将被作为waiter置于等待队列队尾  9 new &#43;= 1 &amp;lt;&amp;lt; mutexWaiterShift 10 } 11 if starving &amp;amp;&amp;amp; old&amp;amp;mutexLocked != 0 { 12 // 如果当前锁处于饥饿模式，并且已被加锁，则将低3位的Starving状态位设置为1，表示饥饿 13 new |= mutexStarving 14 } 15 // 当awoke为true，则表明当前goroutine在自旋逻辑中，成功修改锁的Woken状态位为1 16 if awoke { 17 if new&amp;amp;mutexWoken == 0 { 18 throw(&amp;#34;sync: inconsistent mutex state&amp;#34;) 19 } 20 // 将唤醒标志位Woken置回为0 21 // 因为在后续的逻辑中，当前goroutine要么是拿到锁了，要么是被挂起。 22 // 如果是挂起状态，那就需要等待其他释放锁的goroutine来唤醒。 23 // 假如其他goroutine在unlock的时候发现Woken的位置不是0，则就不会去唤醒，那该goroutine就无法再醒来加锁。 24 new &amp;amp;^= mutexWoken 25 } 这里需要重点理解一下位操作A |= B，它的含义就是在B的二进制位为1的位，将A对应的二进制位设为1，如下图所示。因此，new |= mutexLocked的作用就是将new的最低一位设置为1。
** **
3.2.4 更新期望状态
在上一步，我们得到了锁的期望状态，接下来通过CAS将锁的状态进行更新。
 1 // 尝试将锁的状态更新为期望状态  2 if atomic.CompareAndSwapInt32(&amp;amp;m.state, old, new) {  3 // 如果锁的原状态既不是被获取状态，也不是处于饥饿模式  4 // 那就直接返回，表示当前goroutine已获取到锁  5 if old&amp;amp;(mutexLocked|mutexStarving) == 0 {  6 break // locked the mutex with CAS  7 }  8 // 如果走到这里，那就证明当前goroutine没有获取到锁  9 // 这里判断waitStartTime != 0就证明当前goroutine之前已经等待过了，则需要将其放置在等待队列队头 10 queueLifo := waitStartTime != 0 11 if waitStartTime == 0 { 12 // 如果之前没有等待过，就以现在的时间来初始化设置 13 waitStartTime = runtime_nanotime() 14 } 15 // 阻塞等待 16 runtime_SemacquireMutex(&amp;amp;m.sema, queueLifo, 1) 17 // 被信号量唤醒之后检查当前goroutine是否应该表示为饥饿 18 // （这里表示为饥饿之后，会在下一轮循环中尝试将锁的状态更改为饥饿模式） 19 // 1. 如果当前goroutine已经饥饿（在上一次循环中更改了starving为true） 20 // 2. 如果当前goroutine已经等待了1ms以上 21 starving = starving || runtime_nanotime()-waitStartTime &amp;gt; starvationThresholdNs 22 // 再次获取锁状态 23 old = m.state 24 // 走到这里，如果此时锁仍然是饥饿模式 25 // 因为在饥饿模式下，锁是直接交给唤醒的goroutine 26 // 所以，即把锁交给当前goroutine 27 if old&amp;amp;mutexStarving != 0 { 28 // 如果当前锁既不是被获取也不是被唤醒状态，或者等待队列为空 29 // 这代表锁状态产生了不一致的问题 30 if old&amp;amp;(mutexLocked|mutexWoken) != 0 || old&amp;gt;&amp;gt;mutexWaiterShift == 0 { 31 throw(&amp;#34;sync: inconsistent mutex state&amp;#34;) 32 } 33 // 因为当前goroutine已经获取了锁，delta用于将等待队列-1 34 delta := int32(mutexLocked - 1&amp;lt;&amp;lt;mutexWaiterShift) 35 // 如果当前goroutine中的starving标志不是饥饿 36 // 或者当前goroutine已经是等待队列中的最后一个了 37 // 就通过delta -= mutexStarving和atomic.AddInt32操作将锁的饥饿状态位设置为0，表示为正常模式 38 if !starving || old&amp;gt;&amp;gt;mutexWaiterShift == 1 { 39 delta -= mutexStarving 40 } 41 atomic.AddInt32(&amp;amp;m.state, delta) 42 // 拿到锁退出，业务逻辑处理完之后，需要调用Mutex.Unlock()方法释放锁 43 break 44 } 45 // 如果锁不是饥饿状态 46 // 因为当前goroutine已经被信号量唤醒了 47 // 那就将表示当前goroutine状态的awoke设置为true 48 // 并且将自旋次数的计数iter重置为0，如果能满足自旋条件，重新自旋等待 49 awoke = true 50 iter = 0 51 } else { 52 // 如果CAS未成功,更新锁状态，重新一个大循环 53 old = m.state 54 } 这里需要理解一下runtime_SemacquireMutex(s *uint32, lifo bool, skipframes int) 函数，它是用于同步库的sleep原语，它的实现是位于src/runtime/sema.go中的semacquire1函数，与它类似的还有runtime_Semacquire(s *uint32) 函数。两个睡眠原语需要等到 *s&amp;gt;0 （本场景中 m.sema&amp;gt;0 ），然后原子递减 *s。SemacquireMutex用于分析竞争的互斥对象，如果lifo（本场景中queueLifo）为true，则将等待者排在等待队列的队头。skipframes是从SemacquireMutex的调用方开始计数，表示在跟踪期间要忽略的帧数。
所以，运行到 SemacquireMutex 就证明当前goroutine在前面的过程中获取锁失败了，就需要sleep原语来阻塞当前goroutine，并通过信号量来排队获取锁：如果是新来的goroutine，就需要放在队尾；如果是被唤醒的等待锁的goroutine，就放在队头。
3.3 解锁 前面说过，有加锁就必然有解锁。我们来看解锁的过程：
 1func (m *Mutex) Unlock() {  2 if race.Enabled {  3 _ = m.state  4 race.Release(unsafe.Pointer(m))  5 }  6  7 // new是解锁的期望状态  8 new := atomic.AddInt32(&amp;amp;m.state, -mutexLocked)  9 if new != 0 { 10 m.unlockSlow(new) 11 } 12} 通过原子操作AddInt32想将锁的低1位Locked状态位置为0。然后判断新的m.state值，如果值为0，则代表当前锁已经完全空闲了，结束解锁，否则进入unlockSlow()逻辑。
这里需要注意的是，锁空闲有两种情况，第一种是完全空闲，它的状态就是锁的初始状态。
第二种空闲，是指的当前锁没被占有，但是会有等待拿锁的goroutine，只是还未被唤醒，例如以下状态的锁也是空闲的，它有两个等待拿锁的goroutine（未唤醒状态）。
以下是unlockSlow函数实现。
 1func (m *Mutex) unlockSlow(new int32) {  2 // 1. 如果Unlock了一个没有上锁的锁，则会发生panic。  3 if (new&#43;mutexLocked)&amp;amp;mutexLocked == 0 {  4 throw(&amp;#34;sync: unlock of unlocked mutex&amp;#34;)  5 }  6 // 2. 正常模式  7 if new&amp;amp;mutexStarving == 0 {  8 old := new  9 for { 10 // 如果锁没有waiter,或者锁有其他以下已发生的情况之一，则后面的工作就不用做了，直接返回 11 // 1. 锁处于锁定状态，表示锁已经被其他goroutine获取了 12 // 2. 锁处于被唤醒状态，这表明有等待goroutine被唤醒，不用再尝试唤醒其他goroutine 13 // 3. 锁处于饥饿模式，那么锁之后会被直接交给等待队列队头goroutine 14 if old&amp;gt;&amp;gt;mutexWaiterShift == 0 || old&amp;amp;(mutexLocked|mutexWoken|mutexStarving) != 0 { 15 return 16 } 17 // 如果能走到这，那就是上面的if判断没通过 18 // 说明当前锁是空闲状态，但是等待队列中有waiter，且没有goroutine被唤醒 19 // 所以，这里我们想要把锁的状态设置为被唤醒，等待队列waiter数-1 20 new = (old - 1&amp;lt;&amp;lt;mutexWaiterShift) | mutexWoken 21 // 通过CAS操作尝试更改锁状态 22 if atomic.CompareAndSwapInt32(&amp;amp;m.state, old, new) { 23 // 通过信号量唤醒goroutine，然后退出 24 runtime_Semrelease(&amp;amp;m.sema, false, 1) 25 return 26 } 27 // 这里是CAS失败的逻辑 28 // 因为在for循环中，锁的状态有可能已经被改变了，所以这里需要及时更新一下状态信息 29 // 以便下个循环里作判断处理 30 old = m.state 31 } 32 // 3. 饥饿模式 33 } else { 34 // 因为是饥饿模式，所以非常简单 35 // 直接唤醒等待队列队头goroutine即可 36 runtime_Semrelease(&amp;amp;m.sema, true, 1) 37 } 38} 在这里，需要理解一下runtime_Semrelease(s *uint32, handoff bool, skipframes int)函数。它是用于同步库的wakeup原语，Semrelease原子增加*s值（本场景中m.sema），并通知阻塞在Semacquire中正在等待的goroutine。如果handoff为真，则将计数直接传递给队头waiter。skipframes是从Semrelease的调用方开始计数，表示在跟踪期间要忽略的帧数。
总结
从代码量而言，go中互斥锁的代码非常轻量简洁，通过巧妙的位运算，仅仅采用state一个字段就实现了四个字段的效果，非常之精彩。
但是，代码量少并不代表逻辑简单，相反，它很复杂。互斥锁的设计中包含了大量的位运算，并包括了两种不同锁模式、信号量、自旋以及调度等内容，读者要真正理解加解锁的过程并不容易，这里再做一个简单回顾总结。
在正常模式下，waiter按照先进先出的方式获取锁；在饥饿模式下，锁的所有权直接从解锁的goroutine转移到等待队列中的队头waiter。
模式切换
如果当前 goroutine 等待锁的时间超过了 1ms，互斥锁就会切换到饥饿模式。
如果当前 goroutine 是互斥锁最后一个waiter，或者等待的时间小于 1ms，互斥锁切换回正常模式。
加锁
 如果锁是完全空闲状态，则通过CAS直接加锁。 如果锁处于正常模式，则会尝试自旋，通过持有CPU等待锁的释放。 如果当前goroutine不再满足自旋条件，则会计算锁的期望状态，并尝试更新锁状态。 在更新锁状态成功后，会判断当前goroutine是否能获取到锁，能获取锁则直接退出。 当前goroutine不能获取到锁时，则会由sleep原语SemacquireMutex陷入睡眠，等待解锁的goroutine发出信号进行唤醒。 唤醒之后的goroutine发现锁处于饥饿模式，则能直接拿到锁，否则重置自旋迭代次数并标记唤醒位，重新进入步骤2中。  解锁
 如果通过原子操作AddInt32后，锁变为完全空闲状态，则直接解锁。 如果解锁一个没有上锁的锁，则直接抛出异常。 如果锁处于正常模式，且没有goroutine等待锁释放，或者锁被其他goroutine设置为了锁定状态、唤醒状态、饥饿模式中的任一种（非空闲状态），则会直接退出；否则，会通过wakeup原语Semrelease唤醒waiter。 如果锁处于饥饿模式，会直接将锁的所有权交给等待队列队头waiter，唤醒的waiter会负责设置Locked标志位。  另外，从Go的互斥锁带有自旋的设计而言，如果我们通过sync.Mutex只锁定执行耗时很低的关键代码，例如锁定某个变量的赋值，性能是非常不错的（因为等待锁的goroutine不用被挂起，持有锁的goroutine会很快释放锁）。所以，我们在使用互斥锁时，应该只锁定真正的临界区。
1mu.Lock() 2defer mu.Unlock() 写如上的代码，是很爽。但是，你有想过这会带来没必要的性能损耗吗？
以上内容转载自机器铃砍菜刀
</content>
    </entry>
    
     <entry>
        <title>Go中看似简单的WaitGroup源码设计，竟然暗含这么多知识？</title>
        <url>http://shanks.link/blog/2021/04/30/go%E4%B8%AD%E7%9C%8B%E4%BC%BC%E7%AE%80%E5%8D%95%E7%9A%84waitgroup%E6%BA%90%E7%A0%81%E8%AE%BE%E8%AE%A1%E7%AB%9F%E7%84%B6%E6%9A%97%E5%90%AB%E8%BF%99%E4%B9%88%E5%A4%9A%E7%9F%A5%E8%AF%86/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Go中看似简单的WaitGroup源码设计，竟然暗含这么多知识？ Go语言提供的协程goroutine可以让我们很容易地写出多线程程序，但是，如何让这些并发执行的goroutine得到有效地控制，这是我们需要探讨的问题。正如小菜刀在《Golang并发控制简述》中所述，Go标准库为我们提供的同步原语中，锁与原子操作注重控制goroutine之间的数据安全，WaitGroup、channel与Context控制的是它们的并发行为。关于锁、原子操作、channel 的实现原理小菜刀均有详细地解析过。因此本文，我们将重点放在WaitGroup上。
初识WaitGroup
WaitGroup是sync包下的内容，用于控制协程间的同步。WaitGroup使用场景同名字的含义一样，当我们需要等待一组协程都执行完成以后，才能做后续的处理时，就可以考虑使用。
 1func main() {  2 var wg sync.WaitGroup  3  4 wg.Add(2) //worker number 2  5  6 go func() {  7 // worker 1 do something  8 fmt.Println(&amp;#34;goroutine 1 done！&amp;#34;)  9 wg.Done() 10 }() 11 12 go func() { 13 // worker 2 do something 14 fmt.Println(&amp;#34;goroutine 2 done！&amp;#34;) 15 wg.Done() 16 }() 17 18 wg.Wait() // wait all waiter done 19 fmt.Println(&amp;#34;all work done！&amp;#34;) 20} 21 22// output 23goroutine 2 done！ 24goroutine 1 done！ 25all work done！ 可以看到WaitGroup的使用非常简单，它提供了三个方法。虽然goroutine之间并不存在类似于父子关系，但是为了方便理解，本文会将调用Wait函数的goroutine称为主goroutine，调用Done函数的goroutine称呼为子goroutine。
1func (wg *WaitGroup) Add(delta int) // 增加WaitGroup中的子goroutine计数值 2func (wg *WaitGroup) Done() // 当子goroutine任务完成，将计数值减1 3func (wg *WaitGroup) Wait() // 阻塞调用此方法的goroutine，直到计数值为0 4 那么它是如何实现的呢？在源码src/sync/waitgroup.go中，我们可以看到它的核心源码只有100行不到，十分地精练，非常值得学习。
前置知识
代码少，不代表就实现简单，易于理解。相反，如果读者没有下述中的前置知识，想要真正理解WaitGroup的实现是会比较费力的。在解析源码之前，我们先过一遍这些知识（如果你都已经掌握，那就可以直接跳到后文的源码解析部分）。
信号量 在学习操作系统时，我们知道信号量是一种保护共享资源的机制，用于解决多线程同步问题。信号量s是具有非负整数值的全局变量，只能由两种特殊的操作来处理，这两种操作称为P和V。
 P(s)：如果s是非零的，那么P将s减1，并且立即返回。如果s为零，那么就挂起这个线程，直到s变为非零，等到另一个执行V(s)操作的线程唤醒该线程。在唤醒之后，P操作将s减1，并将控制返回给调用者。 V(s)：V操作将s加1。如果有任何线程阻塞在P操作等待s变为非零，那么V操作会唤醒这些线程中的一个，然后该线程将s减1，完成它的P操作。  在Go的底层信号量函数中
 runtime_Semacquire(s *uint32) 函数会阻塞goroutine直到信号量s的值大于0，然后原子性地减这个值，即P操作。 runtime_Semrelease(s *uint32, lifo bool, skipframes int) 函数原子性增加信号量的值，然后通知被runtime_Semacquire阻塞的goroutine，即V操作。  这两个信号量函数不止在WaitGroup中会用上，在《Go精妙的互斥锁设计》一文中，我们发现Go在设计互斥锁的时候也少不了信号量的参与。
内存对齐 对于以下的结构体，你能回答出它占用的内存是多少吗
 1type Ins struct {  2 x bool // 1个字节  3 y int32 // 4个字节  4 z byte // 1个字节  5}  6  7func main() {  8 ins := Ins{}  9 fmt.Printf(&amp;#34;ins size: %d, align: %d\n&amp;#34;, unsafe.Sizeof(ins), unsafe.Alignof(ins)) 10} 11 12//output 13ins size: 12, align: 4 按照结构体中字段的大小而言，ins对象占用内存应该是 1&#43;4&#43;1=6 个字节，但是实际上确实12个字节，这就是内存对齐所致。从《CPU缓存体系对Go程序的影响》一文中，我们知道CPU的内存读取并不是一个字节一个字节地读取的，而是一块一块的。因此，在类型的值在内存中对齐的情况下，计算机的加载或者写入会很高效。
在聚合类型（结构体或数组）的内存所占长度或许会比它元素所占内存之和更大。编译器会添加未使用的内存地址用于填充内存空隙，以确保连续的成员或元素相当于结构体或数组的起始地址是对齐的。
因此，在我们设计结构体时，当结构体成员的类型不同时，将相同类型的成员定义在相邻位置可以更节省内存空间。
原子操作CAS CAS是原子操作的一种，可用于在多线程编程中实现不被打断的数据交换操作，从而避免多线程同时改写某一数据时由于执行顺序不确定性以及中断的不可预知性产生的数据不一致问题。该操作通过将内存中的值与指定数据进行比较，当数值一样时将内存中的数据替换为新的值。关于Go中原子操作的底层实现，小菜刀在《同步原语的基石》一文中有详细介绍。
移位运算 &amp;raquo; 与 &amp;laquo; 在之前关于锁的文章《Go精妙的互斥锁设计》与《Go更细粒度的读写锁设计中》，我们能看到大量的位运算操作。灵活的位运算，能让一个普通的数字变化出丰富的含义，这里仅介绍下文中会用到的移位运算。
对于左移位运算 &amp;laquo;，按二进制形式将所有的数字向左移动对应的位数，高位舍弃，低位的空位补零。在数字没有溢出的前提下，左移一位相当于乘以2的1次方，左移n位就相当于乘以2的n次方。
对于右移位运算 &amp;raquo;，按二进制形式把所有的数字向右移动对应位数，低位移出，高位的空位补符号位。右移一位相当于除2，右移n位相当于除以2的n次方。这里是取商，余数就不要了。
移位运算也可以有很巧妙的操作，后文中我们会看到移位运算的高级运用。
unsafa.Pointer指针与uintptr Go中的指针可以分为三类：1.普通类型指针T，例如int；2. unsafe.Pointer指针；3. uintptr。
 *T：普通的指针类型，用于传递对象地址，不能进行指针计算。 unsafe.Pointer指针：通用型指针，任何一个普通类型的指针T都可以转换为unsafe.Pointer指针，而且unsafe.Pointer类型的指针还可以转换回普通指针，并且它可以不用和原来的指针类型T相同。但是它不能进行指针计算，不能读取内存中的值（必须通过转换为某一具体类型的普通指针才行）。 uintptr：准确来讲，uintptr并不是指针，它是一个大小并不明确的无符号整型。unsafe.Pointer类型可以与uinptr相互转换，由于uinptr类型保存了指针所指向地址的数值，因此可以通过该数值进行指针运算。GC时，不会将uintptr当做指针，uintptr类型目标会被回收。  unsafe.Pointer 是桥梁，可以让任意类型的普通指针实现相互转换，也可以将任意类型的指针转换为 uintptr 进行指针运算。但是，unsafe.Pointer和任意类型指针的转换可以让我们将任意值写入内存中，这会破坏Go原有的类型系统，同时由于不是所有的数值都是合法的内存地址，从uintptr到unsafe.Pointer的转换同样会破坏类型系统。因此，既然Go将该包定义为unsafe，那就不应该随意使用。
源码解析
本文基于Go源码1.15.7版本
结构体 sync.WaitGroup的结构体定义如下，它包括了一个 noCopy 的辅助字段，和一个具有复合意义的state1字段。
 1type WaitGroup struct {  2 noCopy noCopy  3  4 // 64-bit value: high 32 bits are counter, low 32 bits are waiter count.  5 // 64-bit atomic operations require 64-bit alignment, but 32-bit  6 // compilers do not ensure it. So we allocate 12 bytes and then use  7 // the aligned 8 bytes in them as state, and the other 4 as storage  8 // for the sema.  9 state1 [3]uint32 10} 11 12// state returns pointers to the state and sema fields stored within wg.state1. 13func (wg *WaitGroup) state() (statep *uint64, semap *uint32) { 14 // 64位编译器地址能被8整除，由此可判断是否为64位对齐 15 if uintptr(unsafe.Pointer(&amp;amp;wg.state1))%8 == 0 { 16 return (*uint64)(unsafe.Pointer(&amp;amp;wg.state1)), &amp;amp;wg.state1[2] 17 } else { 18 return (*uint64)(unsafe.Pointer(&amp;amp;wg.state1[1])), &amp;amp;wg.state1[0] 19 } 20} 其中，noCopy字段是空结构体，它并不会占用内存，编译器也不会对其进行字节填充。它主要是为了通过go vet工具来做静态编译检查，防止开发者在使用WaitGroup过程中对其进行了复制，从而导致的安全隐患。关于这部分内容，可以阅读《no copy机制》详细了解。
state1字段是一个长度为3的uint32数组。它用于表示三部分内容：1. 通过Add()设置的子goroutine的计数值counter；2. 通过Wait()陷入阻塞的waiter数；3. 信号量semap。
由于后续是对 uint64 类型的statep进行操作，而64位整数的原子操作需要64位对齐，32位的编译器并不能保证这一点。因此，在64位与32位的环境下，state1字段的组成含义是不相同的。
需要注意的是，当我们初始化一个WaitGroup对象时，其counter值、waiter值、semap值均为0。
Add函数 Add()函数的入参是一个整型，它可正可负，是对counter数值的更改。如果counter数值变为0，那么所有阻塞在Wait()函数的waiter将会被唤醒；如果counter数值为负值，将引起panic。
我们将竞态检测部分的代码去掉，Add()函数的实现源码如下
 1func (wg *WaitGroup) Add(delta int) {  2 // 获取包含counter与waiter的复合状态statep，表示信号量值的semap  3 statep, semap := wg.state()  4 state := atomic.AddUint64(statep, uint64(delta)&amp;lt;&amp;lt;32)  5 v := int32(state &amp;gt;&amp;gt; 32)  6 w := uint32(state)  7  8 if v &amp;lt; 0 {  9 panic(&amp;#34;sync: negative WaitGroup counter&amp;#34;) 10 } 11 12 if w != 0 &amp;amp;&amp;amp; delta &amp;gt; 0 &amp;amp;&amp;amp; v == int32(delta) { 13 panic(&amp;#34;sync: WaitGroup misuse: Add called concurrently with Wait&amp;#34;) 14 } 15 16 if v &amp;gt; 0 || w == 0 { 17 return 18 } 19 20 if *statep != state { 21 panic(&amp;#34;sync: WaitGroup misuse: Add called concurrently with Wait&amp;#34;) 22 } 23 24 // 如果执行到这，一定是 counter=0，waiter&amp;gt;0 25 // 能执行到这，一定是执行了Add(-x)的goroutine 26 // 它的执行，代表所有子goroutine已经完成了任务 27 // 因此，我们需要将复合状态全部归0，并释放掉waiter个数的信号量 28 *statep = 0 29 for ; w != 0; w-- { 30 // 释放信号量，执行一次就将唤醒一个阻塞的waiter 31 runtime_Semrelease(semap, false, 0) 32 } 33} 代码非常精简，我们接下来对关键部分进行剖析。
1 state := atomic.AddUint64(statep, uint64(delta)&amp;lt;&amp;lt;32) // 新增counter数值delta 2 v := int32(state &amp;gt;&amp;gt; 32) // 获取counter值 3 w := uint32(state) // 获取waiter值 此时的statep是一个uint64数值，如果此时statep中包含的counter数为2，waiter为1，输入delta为1，那么这三行代码的逻辑过程如下图所示。
在得到当前counter数v与waiter数w后，会对它们的值进行判断，分几种情况。
 1 // 情况1：这是很低级的错误，counter值不能为负  2 if v &amp;lt; 0 {  3 panic(&amp;#34;sync: negative WaitGroup counter&amp;#34;)  4 }  5  6 // 情况2：misuse引起panic  7 // 因为wg其实是可以用复用的，但是下一次复用的基础是需要将所有的状态重置为0才可以  8 if w != 0 &amp;amp;&amp;amp; delta &amp;gt; 0 &amp;amp;&amp;amp; v == int32(delta) {  9 panic(&amp;#34;sync: WaitGroup misuse: Add called concurrently with Wait&amp;#34;) 10 } 11 12 // 情况3：本次Add操作只负责增加counter值，直接返回即可。 13 // 如果此时counter值大于0，唤醒的操作留给之后的Add调用者（执行Add(negative int)） 14 // 如果waiter值为0，代表此时还没有阻塞的waiter 15 if v &amp;gt; 0 || w == 0 { 16 return 17 } 18 19 // 情况4: misuse引起的panic 20 if *statep != state { 21 panic(&amp;#34;sync: WaitGroup misuse: Add called concurrently with Wait&amp;#34;) 22 } 关于 misuse 和 reused 引发 panic 的情况，如果没有示例错误代码，其实是比较难解释的。值得高兴的是，在Go源码中给出了错误使用示范，这些例子位于src/sync/waitgroup_test.go文件下，想深入了解的读者可以去看以下三个测试函数中的示例。
1func TestWaitGroupMisuse(t *testing.T) 2func TestWaitGroupMisuse2(t *testing.T) 3func TestWaitGroupMisuse3(t *testing.T) 4 Done函数 Done()函数比较简单，就是调用Add(-1)。在实际使用时，当子goroutine任务完成之后，就应该调用Done()函数。
1func (wg *WaitGroup) Done() { 2 wg.Add(-1) 3} Wait函数 如果WaitGroup中的counter值大于0，那么执行Wait()函数的主goroutine会将waiter值加1，并阻塞等待该值为0，才能继续执行后续代码。
我们将竞态检测部分的代码去掉，Wait()函数的实现源码如下
 1func (wg *WaitGroup) Wait() {  2 statep, semap := wg.state()  3 for {  4 state := atomic.LoadUint64(statep) // 原子读取复合状态statep  5 v := int32(state &amp;gt;&amp;gt; 32) // 获取counter值  6 w := uint32(state) // 获取waiter值  7 // 如果此时v==0,证明已经没有待执行任务的子goroutine，直接退出即可。  8 if v == 0 {  9 return 10 } 11 // 如果在执行CAS原子操作和读取复合状态之间，没有其他goroutine更改了复合状态 12 // 那么就将waiter值&#43;1，否则：进入下一轮循环，重新读取复合状态 13 if atomic.CompareAndSwapUint64(statep, state, state&#43;1) { 14 // 对waiter值累加成功后 15 // 等待Add函数中调用 runtime_Semrelease 唤醒自己 16 runtime_Semacquire(semap) 17 // reused 引发panic 18 // 在当前goroutine被唤醒时，由于唤醒自己的goroutine通过调用Add方法时 19 // 已经通过 *statep = 0 语句做了重置操作 20 // 此时的复合状态位不为0，就是因为还未等Waiter执行完Wait，WaitGroup就已经发生了复用 21 if *statep != 0 { 22 panic(&amp;#34;sync: WaitGroup is reused before previous Wait has returned&amp;#34;) 23 } 24 return 25 } 26 } 27} 总结
要看懂WaitGroup的源码实现，我们需要有一些前置知识，例如信号量、内存对齐、原子操作、移位运算和指针转换等。
但其实WaitGroup的实现思路还是蛮简单的，通过结构体字段state1维护了两个计数器和一个信号量，计数器分别是通过Add()添加的子goroutine的计数值counter，通过Wait()陷入阻塞的waiter数，信号量用于阻塞与唤醒Waiter。当执行Add(positive n)时，counter &#43;=n，表明新增n个子goroutine执行任务。每个子goroutine完成任务之后，需要调用Done()函数将counter值减1，当最后一个子goroutine完成时，counter值会是0，此时就需要唤醒阻塞在Wait()调用中的Waiter。
但是，在使用WaitGroup时，有几点需要注意
  通过Add()函数添加的counter数一定要与后续通过Done()减去的数值一致。如果前者大，那么阻塞在Wait()调用处的goroutine将永远得不到唤醒；如果后者大，将会引发panic。
  Add()的增量函数应该最先得到执行。
  不要对WaitGroup对象进行复制使用。
  如果要复用WaitGroup，则必须在所有先前的Wait()调用返回之后再进行新的Add()调用。
  以上内容转载自机器铃砍柴刀
</content>
    </entry>
    
     <entry>
        <title>如何有效地测试Go代码</title>
        <url>http://shanks.link/blog/2021/04/30/%E5%A6%82%E4%BD%95%E6%9C%89%E6%95%88%E5%9C%B0%E6%B5%8B%E8%AF%95go%E4%BB%A3%E7%A0%81/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 如何有效地测试Go代码 单元测试
如果把开发程序比作盖房子，那么我们必须确保所有的用料都是合格的，否则盖起来的房子就会存在问题。对于程序而言，我们可以将盖房子的砖头、钢筋、水泥等当做一个个功能单元，如果每个单元是合格的，我们将有信心认为程序是健壮的。单元测试（Unit Test,UT）就是检验功能单元是否合格的工具。
一个没有UT的项目，它的代码质量与工程保证是堪忧的。但在实际开发工作中，很多程序员往往并不写测试代码，他们的开发周期可能如下图所示。
而做了充分UT的程序员，他们的项目开发周期更大概率如下。
项目开发中，不写UT也许能使代码交付更快，但是我们无法保证写出来的代码真的能够正确地执行。写UT可以减少后期解决bug的时间，也能让我们放心地使用自己写出来的代码。从长远来看，后者更能有效地节省开发时间。
既然UT这么重要，是什么原因在阻止开发人员写UT呢？这是因为除了开发人员的惰性习惯之外，编写UT代码同样存在难点。
 代码耦合度高，缺少必要的抽象与拆分，以至于不知道如何写UT。 存在第三方依赖，例如依赖数据库连接、HTTP请求、数据缓存等。  可见，编写可测试代码的难点就在于解耦与依赖。
接口与Mock
对于难点1，我们需要面向接口编程。在《接口Interface——塑造健壮与可扩展的Go应用程序》一文中，我们讨论了使用接口给代码带来的灵活解耦与高扩展特性。接口是对一类对象的抽象性描述，表明该类对象能提供什么样的服务，它最主要的作用就是解耦调用者和实现者，这成为了可测试代码的关键。
对于难点2，我们可以通过Mock测试来解决。Mock测试就是在测试过程中，对于某些不容易构造或者不容易获取的对象，用一个虚拟的对象来创建以便测试的测试方法。
如果我们的代码都是面向接口编程，调用方与服务方将是松耦合的依赖关系。在测试代码中，我们就可以Mock 出另一种接口的实现，从而很容易地替换掉第三方的依赖。
测试工具
** **
1. 自带测试库：testing
在介绍Mock测试之前，先看一下Go中最简单的测试单元应该如何写。假设我们在math.go文件下有以下两个函数，现在我们需要对它们写测试案例。
1package math 2 3func Add(x, y int) int { 4 return x &#43; y 5} 6 7func Multi(x, y int) int { 8 return x * y 9} 如果我们的IDE是Goland，它有一个非常好用的一键测试代码生成功能。
如上图所示，光标置于函数名之上，右键选择 Generate，我们可以选择生成整个package、当前file或者当前选中函数的测试代码。以 Tests for selection 为例，Goland 会自动在当前 math.go 同级目录新建测试文件math_test.go，内容如下。
 1package math  2  3import &amp;#34;testing&amp;#34;  4  5func TestAdd(t *testing.T) {  6 type args struct {  7 x int  8 y int  9 } 10 tests := []struct { 11 name string 12 args args 13 want int 14 }{ 15 // TODO: Add test cases. 16 } 17 for _, tt := range tests { 18 t.Run(tt.name, func(t *testing.T) { 19 if got := Add(tt.args.x, tt.args.y); got != tt.want { 20 t.Errorf(&amp;#34;Add() = %v, want %v&amp;#34;, got, tt.want) 21 } 22 }) 23 } 24} 可以看到，在Go测试惯例中，单元测试的默认组织方式就是写在以 _test.go 结尾的文件中，所有的测试方法也都是以 Test 开头并且只接受一个 testing.T 类型的参数。同时，如果我们要给函数名为 Add 的方法写单元测试，那么对应的测试方法一般会被写成 TestAdd 。
当测试模板生成之后，我们只需将测试案例添加至 TODO 即可。
 1 {  2 &amp;#34;negative &#43; negative&amp;#34;,  3 args{-1, -1},  4 -2,  5 },  6 {  7 &amp;#34;negative &#43; positive&amp;#34;,  8 args{-1, 1},  9 0, 10 }, 11 { 12 &amp;#34;positive &#43; positive&amp;#34;, 13 args{1, 1}, 14 2, 15 }, 此时，运行测试文件，可以发现所有测试案例，均成功通过。
1=== RUN TestAdd 2--- PASS: TestAdd (0.00s) 3=== RUN TestAdd/negative_&#43;_negative 4 --- PASS: TestAdd/negative_&#43;_negative (0.00s) 5=== RUN TestAdd/negative_&#43;_positive 6 --- PASS: TestAdd/negative_&#43;_positive (0.00s) 7=== RUN TestAdd/positive_&#43;_positive 8 --- PASS: TestAdd/positive_&#43;_positive (0.00s) 9PASS 2. 断言库：testify 简单了解了Go内置 testing 库的测试写法后，推荐一个好用的断言测试库：testify。testify具有常见断言和mock的工具链，最重要的是，它能够与内置库 testing 很好地配合使用，其项目地址位于https://github.com/stretchr/testify。
如果采用testify库，需要引入&amp;quot;github.com/stretchr/testify/assert&amp;quot;。之外，上述测试代码中以下部分
1 if got := Add(tt.args.x, tt.args.y); got != tt.want { 2 t.Errorf(&amp;#34;Add() = %v, want %v&amp;#34;, got, tt.want) 3 } 更改为如下断言形式
1 assert.Equal(t, Add(tt.args.x, tt.args.y), tt.want, tt.name) testify 提供的断言方法帮助我们快速地对函数的返回值进行测试，从而减少测试代码工作量。它可断言的类型非常丰富，例如断言Equal、断言NIl、断言Type、断言两个指针是否指向同一对象、断言包含、断言子集等。
不要小瞧这一行代码，如果我们在测试案例中，将&amp;quot;positive &#43; positive&amp;quot;的期望值改为3，那么测试结果中会自动提供报错信息。
 1...  2=== RUN TestAdd/positive_&#43;_positive  3 math_test.go:36:  4 Error Trace: math_test.go:36  5 Error: Not equal:  6 expected: 2  7 actual : 3  8 Test: TestAdd/positive_&#43;_positive  9 Messages: positive &#43; positive 10 --- FAIL: TestAdd/positive_&#43;_positive (0.00s) 11 12 13Expected :2 14Actual :3 15... 3. 接口mock框架：gomock 介绍完基本的测试方法的写法后，我们需要讨论基于接口的 Mock 方法。在Go语言中，最通用的 Mock 手段是通过Go官方的 gomock 框架来自动生成其 Mock 方法。该项目地址位于https://github.com/golang/mock。
为了方便读者理解，本文举一个小明玩手机的例子。小明喜欢玩手机，他每天都需要通过手机聊微信、玩王者、逛知乎，如果某天没有干这些事情，小明就没办法睡觉。在该情景中，我们可以将手机抽象成接口如下。
1// mockDemo/equipment/phone.go 2type Phone interface { 3 WeiXin() bool 4 WangZhe() bool 5 ZhiHu() bool 6} 小明手上有一部非常老的IPhone6s，我们为该手机对象实现Phone接口。
 1// mockDemo/equipment/phone6s.go  2type Iphone6s struct {  3}  4  5func NewIphone6s() *Iphone6s {  6 return &amp;amp;Iphone6s{}  7}  8  9func (p *Iphone6s) WeiXin() bool { 10 fmt.Println(&amp;#34;Iphone6s chat wei xin!&amp;#34;) 11 return true 12} 13 14func (p *Iphone6s) WangZhe() bool { 15 fmt.Println(&amp;#34;Iphone6s play wang zhe!&amp;#34;) 16 return true 17} 18 19func (p *Iphone6s) ZhiHu() bool { 20 fmt.Println(&amp;#34;Iphone6s read zhi hu!&amp;#34;) 21 return true 22} 接着，我们定义Person对象用来表示小明，并定义Person对象的生活函数dayLife和入睡函数goSleep。
 1// mockDemo/person.go  2type Person struct {  3 name string  4 phone equipment.Phone  5}  6  7func NewPerson(name string, phone equipment.Phone) *Person {  8 return &amp;amp;Person{  9 name: name, 10 phone: phone, 11 } 12} 13 14func (x *Person) goSleep() { 15 fmt.Printf(&amp;#34;%s go to sleep!&amp;#34;, x.name) 16} 17 18func (x *Person) dayLife() bool { 19 fmt.Printf(&amp;#34;%s&amp;#39;s daily life:\n&amp;#34;, x.name) 20 if x.phone.WeiXin() &amp;amp;&amp;amp; x.phone.WangZhe() &amp;amp;&amp;amp; x.phone.ZhiHu() { 21 x.goSleep() 22 return true 23 } 24 return false 25} 最后，我们把小明和iphone6s对象实例化出来，并开启他一天的生活。
 1//mockDemo/main.go  2func main() {  3 phone := equipment.NewIphone6s()  4 xiaoMing := NewPerson(&amp;#34;xiaoMing&amp;#34;, phone)  5 xiaoMing.dayLife()  6}  7  8// output  9xiaoMing&amp;#39;s daily life: 10Iphone6s chat wei xin! 11Iphone6s play wang zhe! 12Iphone6s read zhi hu! 13xiaoMing go to sleep! 14 由于小明每天必须刷完手机才能睡觉，即Person.goSleep，那么小明能否睡觉依赖于手机。
按照当前代码，如果小明的手机坏了，或者小明换了一个手机，那他就没办法睡觉了，这肯定是万万不行的。因此我们需要把小明对某特定手机的依赖Mock掉，这个时候 gomock 框架排上了用场。
如果没有下载gomock库，则执行以下命令获取
1GO111MODULE=on go get github.com/golang/mock/mockgen 通过执行以下命令对phone.go中的Phone接口Mock
1mockgen -destination equipment/mock_iphone.go -package equipment -source equipment/phone.go 在执行该命令前，当前项目的组织结构如下
1. 2├── equipment 3│ ├── iphone6s.go 4│ └── phone.go 5├── go.mod 6├── go.sum 7├── main.go 8└── person.go 执行mockgen命令之后，在equipment/phone.go的同级目录，新生成了测试文件 mock_iphone.go（它的代码自动生成功能，是通过Go自带generate工具完成的，感兴趣的读者可以阅读《Go工具之generate》一文），其部分内容如下
 1...  2// MockPhone is a mock of Phone interface  3type MockPhone struct {  4 ctrl *gomock.Controller  5 recorder *MockPhoneMockRecorder  6}  7  8// MockPhoneMockRecorder is the mock recorder for MockPhone  9type MockPhoneMockRecorder struct { 10 mock *MockPhone 11} 12 13// NewMockPhone creates a new mock instance 14func NewMockPhone(ctrl *gomock.Controller) *MockPhone { 15 mock := &amp;amp;MockPhone{ctrl: ctrl} 16 mock.recorder = &amp;amp;MockPhoneMockRecorder{mock} 17 return mock 18} 19 20// EXPECT returns an object that allows the caller to indicate expected use 21func (m *MockPhone) EXPECT() *MockPhoneMockRecorder { 22 return m.recorder 23} 24 25// WeiXin mocks base method 26func (m *MockPhone) WeiXin() bool { 27 m.ctrl.T.Helper() 28 ret := m.ctrl.Call(m, &amp;#34;WeiXin&amp;#34;) 29 ret0, _ := ret[0].(bool) 30 return ret0 31} 32 33// WeiXin indicates an expected call of WeiXin 34func (mr *MockPhoneMockRecorder) WeiXin() *gomock.Call { 35 mr.mock.ctrl.T.Helper() 36 return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, &amp;#34;WeiXin&amp;#34;, reflect.TypeOf((*MockPhone)(nil).WeiXin)) 37} 38... 此时，我们的person.go中的 Person.dayLife 方法就可以测试了。
 1func TestPerson_dayLife(t *testing.T) {  2 type fields struct {  3 name string  4 phone equipment.Phone  5 }  6  7 // 生成mockPhone对象  8 mockCtl := gomock.NewController(t)  9 mockPhone := equipment.NewMockPhone(mockCtl) 10 // 设置mockPhone对象的接口方法返回值 11 mockPhone.EXPECT().ZhiHu().Return(true) 12 mockPhone.EXPECT().WeiXin().Return(true) 13 mockPhone.EXPECT().WangZhe().Return(true) 14 15 tests := []struct { 16 name string 17 fields fields 18 want bool 19 }{ 20 {&amp;#34;case1&amp;#34;, fields{&amp;#34;iphone6s&amp;#34;, equipment.NewIphone6s()}, true}, 21 {&amp;#34;case2&amp;#34;, fields{&amp;#34;mocked phone&amp;#34;, mockPhone}, true}, 22 } 23 for _, tt := range tests { 24 t.Run(tt.name, func(t *testing.T) { 25 x := &amp;amp;Person{ 26 name: tt.fields.name, 27 phone: tt.fields.phone, 28 } 29 assert.Equal(t, tt.want, x.dayLife()) 30 }) 31 } 32} 对接口进行Mock，可以让我们在未实现具体对象的接口功能前，或者该接口调用代价非常高时，也能对业务代码进行测试。而且在开发过程中，我们同样可以利用Mock对象，不用因为等待接口实现方实现相关功能，从而停滞后续的开发。
在这里我们能够体会到在Go程序中接口对于测试的重要性。没有接口的Go代码，单元测试会非常难写。所以，如果一个稍大型的项目中，没有任何接口，那么该项目的质量一定是堪忧的。
4. 常见三方mock依赖库 在上文中提到，因为存在某些存在第三方依赖，会让我们的代码难以测试。但其实已经有一些比较成熟的mock依赖库可供我们使用。由于篇幅原因，以下列出的一些mock库将不再贴出示例代码，详细信息可通过对应的项目地址进行了解。
 go-sqlmock  这是Go语言中用以测试数据库交互的SQL模拟驱动库，其项目地址为 https://github.com/DATA-DOG/go-sqlmock。它而无需真正地数据库连接，就能够在测试中模拟sql驱动程序行为，非常有助于维护测试驱动开发（TDD）的工作流程。
 httpmock  用于模拟外部资源的http响应，它使用模式匹配的方式匹配 HTTP 请求的 URL，在匹配到特定的请求时就会返回预先设置好的响应。其项目地址为 https://github.com/jarcoal/httpmock 。
 gripmock  它用于模拟gRPC服务的服务器，通过使用.proto文件生成对gRPC服务的实现，其项目地址为 https://github.com/tokopedia/gripmock。
 redismock  用于测试与Redis服务器的交互，其项目地址位于 https://github.com/elliotchance/redismock。
5. 猴子补丁：monkey patch 如果上述的方案都不能很好的写出测试代码，这时可以考虑使用猴子补丁。猴子补丁简单而言就是属性在运行时的动态替换，它在理论上可以替换运行时中的一切函数。这种测试方式在动态语言例如Python中比较合适。在Go中，monkey库通过在运行时重写正在运行的可执行文件并插入跳转到您要调用的函数来实现Monkey patching。项目作者写道：这个操作很不安全，不建议任何人在测试环境之外进行使用。其项目地址为https://github.com/bouk/monkey。
monkey库的API比较简单，例如可以通过调用 monkey.Patch(&amp;lt;target function&amp;gt;, &amp;lt;replacement function&amp;gt;)来实现对函数的替换，以下是操作示例。
 1package main  2  3import (  4 &amp;#34;fmt&amp;#34;  5 &amp;#34;os&amp;#34;  6 &amp;#34;strings&amp;#34;  7  8 &amp;#34;bou.ke/monkey&amp;#34;  9) 10 11func main() { 12 monkey.Patch(fmt.Println, func(a ...interface{}) (n int, err error) { 13 s := make([]interface{}, len(a)) 14 for i, v := range a { 15 s[i] = strings.Replace(fmt.Sprint(v), &amp;#34;hell&amp;#34;, &amp;#34;*bleep*&amp;#34;, -1) 16 } 17 return fmt.Fprintln(os.Stdout, s...) 18 }) 19 fmt.Println(&amp;#34;what the hell?&amp;#34;) // what the *bleep*? 20} 需要注意的是，如果启用了内联，则monkey有时无法进行patching，因此，我们需要尝试在禁用内联的情况下运行测试。例如以上例子，我们需要通过以下命令执行。
1$ go build -o main -gcflags=-l main.go;./main 2what the *bleep*? 总结
在项目开发中，单元测试是重要且必须的。对于单元测试的两大难点：解耦与依赖，我们的代码可以采用 面向接口&#43;mock依赖 的方式进行组织，将依赖都做成可插拔的，那在单元测试里面隔离依赖就是一件水到渠成的事情。
另外，本文讨论了一些实用的测试工具，包括自带测试库testing的快速生成测试代码，断言库testify的断言使用，接口mock框架gomock如何mock接口方法和一些常见的三方依赖mock库推荐，最后再介绍了测试大杀器猴子补丁，当然，不到万不得已，不要使用猴子补丁。
最后，在这些测试工具的使用上，本文的内容也只是一些浅尝辄止的介绍，希望读者能够在实际项目中多写写单元测试，深入体会TDD的开发思想。
以上内容转载自机器铃砍柴刀
</content>
    </entry>
    
     <entry>
        <title>同步原理的基石</title>
        <url>http://shanks.link/blog/2021/04/30/%E5%90%8C%E6%AD%A5%E5%8E%9F%E7%90%86%E7%9A%84%E5%9F%BA%E7%9F%B3/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 同步原语的基石 Go是一门以并发编程见长的语言，它提供了一系列的同步原语方便开发者使用，例如sync包下的Mutex、RWMutex、WaitGroup、Once、Cond，以及抽象层级更高的Channel。但是，它们的实现基石是原子操作。需要记住的是：软件原子操作离不开硬件指令的支持。本文拟通过探讨原子操作——**比较并交换(compare and swap, CAS)**的实现，来理解Go是如何借助硬件指令来实现这一过程的。
什么是CAS
看源码实现之前，我们先理解一下CAS。
维基百科定义：CAS是原子操作的一种，可用于在多线程编程中实现不被打断的数据交换操作，从而避免多线程同时改写某一数据时由于执行顺序不确定性以及中断的不可预知性产生的数据不一致问题。该操作通过将内存中的值与指定数据进行比较，当数值一样时将内存中的数据替换为新的值。
CAS的实现思想可以用以下伪代码表示
1bool Cas(int *val, int old, int new) 2 Atomically: 3 if(*val == old){ 4 *val = new; 5 return 1; 6 } else { 7 return 0; 8 } 在sync/atomic/doc.go中，定义了一系列原子操作函数原型。以CompareAndSwapInt32为例，有以下代码
 1package main  2  3import (  4 &amp;#34;fmt&amp;#34;  5 &amp;#34;sync/atomic&amp;#34;  6)  7  8func main() {  9 a := int32(10) 10 ok := atomic.CompareAndSwapInt32(&amp;amp;a, 10, 100) 11 fmt.Println(a, ok) 12 ok = atomic.CompareAndSwapInt32(&amp;amp;a, 10, 50) 13 fmt.Println(a, ok) 14} 它的执行结果如下
1 $ go run main.go 2100 true 3100 false CAS能做什么
CAS从线程层面来说，它是非阻塞的，其乐观地认为在数据更新期间没有其他线程影响，因此也常常被称为是一种轻量级的乐观锁。它关注的是并发安全，而并非并发同步。
在文章开头时，我们就已经提到原子操作是实现上层同步原语的基石。以互斥锁为例，为了方便理解，我们在这里将它的状态定义为0和1，0代表目前该锁空闲，1代表已被加锁。那么，这个时候，CAS就是管理状态的最佳选择。以下是sync.Mutex中Lock方法的部分实现代码。
 1func (m *Mutex) Lock() {  2 // Fast path: grab unlocked mutex.  3 if atomic.CompareAndSwapInt32(&amp;amp;m.state, 0, mutexLocked) {  4 if race.Enabled {  5 race.Acquire(unsafe.Pointer(m))  6 }  7 return  8 }  9 // Slow path (outlined so that the fast path can be inlined) 10 m.lockSlow() 11} 在atomic.CompareAndSwapInt32(&amp;amp;m.state, 0, mutexLocked)中，m.state代表锁的状态，通过CAS函数，判断锁此时的状态是否空闲（m.state==0），是，则对其加锁（这里mutexLocked的值为1）。
源码解读
同样还是以CompareAndSwapInt32为例，它在sync/atomic/doc.go中定义的函数原型如下
1func CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool) 2 对应的汇编代码位于sync/atomic/asm.s中
1TEXT ·CompareAndSwapInt32(SB),NOSPLIT,$0 2 JMP runtime∕internal∕atomic·Cas(SB) 通过指令JMP，跳转到它的实际实现runtime∕internal∕atomic·Cas(SB)。这里需要注意的是，由于架构体系差异，其汇编实现也会存在差别。在本文，我们就以常见的amd64为例，因此进入runtime/internal/atomic/asm_amd64.s，汇编代码如下
1TEXT runtime∕internal∕atomic·Cas(SB),NOSPLIT,$0-17 2 MOVQ ptr&#43;0(FP), BX 3 MOVL old&#43;8(FP), AX 4 MOVL new&#43;12(FP), CX 5 LOCK 6 CMPXCHGL CX, 0(BX) 7 SETEQ ret&#43;16(FP) 8 RET Go的汇编是基于 Plan9 的，我想是因为Ken Thompson（他是Plan 9操作系统的核心成员）吧。如果你不熟悉Plan 9，看到这段汇编可能比较懵。小菜刀觉得没必要花过多时间去学懂，因为它很复杂且另类，同时涉及到很多硬件知识。不过如果只是要求看懂简单的汇编代码，稍微研究下还是能够做到的。
由于本文的重点并不是plan 9，所以这里就只解释上述汇编代码的含义。
atomic.Cas(SB)的函数原型为func CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool)，其入参addr为8个字节（64位系统），old和new分别为4个字节，返回参数swapped为1个字节，所以17=8&#43;4&#43;4&#43;1。
FP（Frame pointer: arguments and locals），它是伪寄存器，用来表示函数参数与局部变量。其通过symbol&#43;offset(FP)的方式进行使用。在本函数中，我们可以把FP指向的内容表示为如下所示。
ptr&#43;0(FP)代表的意思就是ptr从FP偏移0byte处取内容。AX，BX，CX在这里，知道它们是存放数据的寄存器即可。MOV X Y所做的操作是将X上的内容复制到Y上去，MOV后缀L表示“长字”（32位，4个字节），Q表示“四字”（64位，8个字节）。
1 MOVQ ptr&#43;0(FP), BX // 第一个参数addr命名为ptr，放入BP(MOVQ，完成8个字节的复制) 2 MOVL old&#43;8(FP), AX // 第二个参数old，放入AX（MOVL，完成4个字节的复制） 3 MOVL new&#43;12(FP), CX // 第三个参数new，放入CX（MOVL，完成4个字节的复制） 重点来了，LOCK指令。这里参考 Intel 的64位和IA-32架构开发手册
1Causes the processor’s LOCK# signal to be asserted during execution of the accompanying instruction (turns the instruction into an atomic instruction). In a multiprocessor environment, the LOCK# signal ensures that the processor has exclusive use of any shared memory while the signal is asserted. 在多处理器环境中，指令前缀LOCK能够确保，在执行LOCK随后的指令时，处理器拥有对任何共享内存的独占使用。
LOCK：是一个指令前缀，其后必须跟一条“读-改-写”性质的指令，它们可以是ADD, ADC, AND, BTC, BTR, BTS, CMPXCHG, CMPXCH8B, CMPXCHG16B, DEC, INC, NEG, NOT, OR, SBB, SUB, XOR, XADD, XCHG。该指令是一种锁定协议，用于封锁总线，禁止其他 CPU 对内存的操作来保证原子性。
在汇编代码里给指令加上 LOCK 前缀，这是CPU 在硬件层面支持的原子操作。但这样的锁粒度太粗，其他无关的内存操作也会被阻塞，大幅降低系统性能，核数越多愈发显著。
为了提高性能，Intel 从 Pentium 486 开始引入了粒度较细的缓存锁：MESI协议（关于该协议，小菜刀在之前的文章《CPU缓存体系对Go程序的影响》有详细介绍过）。此时，尽管有LOCK前缀，但如果对应数据已经在 cache line里，也就不用锁定总线，仅锁住缓存行即可。
1 LOCK 2 CMPXCHGL CX, 0(BX) CMPXCHGL，L代表4个字节。该指令会把AX（累加器寄存器）中的内容（old）和第二个操作数（0(BX)）中的内容（ptr所指向的数据）比较。如果相等，则把第一个操作数（CX）中的内容（new）赋值给第二个操作数。
1 SETEQ ret&#43;16(FP) 2 RET SETEQ 与CMPXCHGL是配合使用的，如果CMPXCHGL中比较结果是相等的，则设置ret（即函数原型中的swapped）为1，不等则设置为0。RET代表函数返回。
总结
本文探讨了atomic.CompareAndSwapInt32是如何通过硬件指令LOCK实现原子性操作的封装。但要记住，在不同的架构平台，依赖的机器指令是不同的，本文仅研究的是amd64下的汇编实现。
在Go提供的原子操作库atomic中，除了CAS还有许多有用的原子方法，它们共同筑起了Go同步原语体系的基石。
1func SwapIntX(addr *intX, new intX) (old intX) 2func CompareAndSwapIntX(addr *intX, old, new intX) (swapped bool) 3func AddIntX(addr *intX, delta intX) (new intX) 4func LoadIntX(addr *uintX) (val uintX) 5func StoreIntX(addr *intX, val intX) 6func XPointer(addr *unsafe.Pointer, val unsafe.Pointer) 7 那么它们是如何实现的？小菜刀将它们实现的关键指令总结如下。
 Swap : XCHGQ CAS : LOCK&#43; CMPXCHGQ Add : LOCK &#43; XADDQ Load : MOVQ Store : XCHGQ Pointer : 以上指令结合GC 调度  这里大家可能会好奇，Swap和Store会对共享数据做修改，但是为啥它们没有加LOCK，小菜刀对此也同样疑惑。好在 Intel 的64位和IA-32架构开发手册中给出了答案：
1If a memory operand is referenced, the processor’s locking protocol is automatically implemented for the duration of the exchange operation, regardless of the presence or absence of the LOCK prefix or of the value of the IOPL 在实现Swap和Store方法时，其实不管是否存在LOCK前缀，在交换操作期间（XCHGQ）将自动实现CPU的锁定协议。
除此之外，在Load和Store/Swap的实现中，前者没有使用锁定协议，而后者需要。两者结合，那这不就是一种读共享，写独占的思想吗？
以上内容转载自机器铃砍柴刀
</content>
    </entry>
    
     <entry>
        <title>Golang append扩容机制</title>
        <url>http://shanks.link/blog/2021/04/30/golang-append%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> append扩容机制 在《切片传递的隐藏危机》一文，小菜刀有简单地提及到切片扩容的问题。在读者讨论群，有人举了以下例子，并想得到一个合理的回答。
1package main 2 3func main() { 4 s := []int{1,2} 5 s = append(s, 3,4,5) 6 println(cap(s)) 7} 8 9// output: 6 为什么结果不是5，不是8，而是6呢？由于小菜刀在该文中关于扩容的描述不够准确，让读者产生了疑惑。因此本文想借此机会细致分析一下append函数及其背后的扩容机制。
我们知道，append是一种用户在使用时，并不需要引入相关包而可直接调用的函数。它是内置函数，其定义位于源码包 builtin 的builtin.go。
 1// The append built-in function appends elements to the end of a slice. If  2// it has sufficient capacity, the destination is resliced to accommodate the  3// new elements. If it does not, a new underlying array will be allocated.  4// Append returns the updated slice. It is therefore necessary to store the  5// result of append, often in the variable holding the slice itself:  6// slice = append(slice, elem1, elem2)  7// slice = append(slice, anotherSlice...)  8// As a special case, it is legal to append a string to a byte slice, like this:  9// slice = append([]byte(&amp;#34;hello &amp;#34;), &amp;#34;world&amp;#34;...) 10func append(slice []Type, elems ...Type) []Type 11 append 会追加一个或多个数据至 slice 中，这些数据会存储至 slice 的底层数组。其中，底层数组长度是固定的，如果数组的剩余空间足以容纳追加的数据，则可以正常地将数据存入该数组。一旦追加数据后总长度超过原数组长度，原数组就无法满足存储追加数据的要求。此时会怎么处理呢？
同时我们发现，该文件中仅仅定义了函数签名，并没有包含函数实现的任何代码。这里我们不免好奇，append究竟是如何实现的呢？
编译过程
为了回答上述问题，我们不妨从编译入手。Go编译可分为四个阶段：词法与语法分析、类型检查与抽象语法树（AST）转换、中间代码生成和生成最后的机器码。
我们主要需要关注的是第二和第三阶段的代码，分别是位于src/cmd/compile/internal/gc/typecheck.go下的类型检查逻辑
1func typecheck1(n *Node, top int) (res *Node) { 2 ... 3 switch n.Op { 4 case OAPPEND: 5 ... 6} 位于src/cmd/compile/internal/gc/walk.go下的抽象语法树转换逻辑
 1func walkexpr(n *Node, init *Nodes) *Node {  2 ...  3 case OAPPEND:  4 // x = append(...)  5 r := n.Right  6 if r.Type.Elem().NotInHeap() {  7 yyerror(&amp;#34;%v can&amp;#39;t be allocated in Go; it is incomplete (or unallocatable)&amp;#34;, r.Type.Elem())  8 }  9 switch { 10 case isAppendOfMake(r): 11 // x = append(y, make([]T, y)...) 12 r = extendslice(r, init) 13 case r.IsDDD(): 14 r = appendslice(r, init) // also works for append(slice, string). 15 default: 16 r = walkappend(r, init, n) 17 } 18 ... 19} 和位于src/cmd/compile/internal/gc/ssa.go下的中间代码生成逻辑
1// append converts an OAPPEND node to SSA. 2// If inplace is false, it converts the OAPPEND expression n to an ssa.Value, 3// adds it to s, and returns the Value. 4// If inplace is true, it writes the result of the OAPPEND expression n 5// back to the slice being appended to, and returns nil. 6// inplace MUST be set to false if the slice can be SSA&amp;#39;d. 7func (s *state) append(n *Node, inplace bool) *ssa.Value { 8 ... 9} 其中，中间代码生成阶段的state.append方法，是我们重点关注的地方。入参 inplace 代表返回值是否覆盖原变量。如果为false，展开逻辑如下（注意：以下代码只是为了方便理解的伪代码，并不是 state.append 中实际的代码）。同时，小菜刀注意到如果写成 append(s, e1, e2, e3) 不带接收者的形式，并不能通过编译，所以暂未明白它的场景在哪。
 1 // If inplace is false, process as expression &amp;#34;append(s, e1, e2, e3)&amp;#34;:  2 ptr, len, cap := s  3 newlen := len &#43; 3  4 if newlen &amp;gt; cap {  5 ptr, len, cap = growslice(s, newlen)  6 newlen = len &#43; 3 // recalculate to avoid a spill  7 }  8 // with write barriers, if needed:  9 *(ptr&#43;len) = e1 10 *(ptr&#43;len&#43;1) = e2 11 *(ptr&#43;len&#43;2) = e3 12 return makeslice(ptr, newlen, cap) 如果是true，例如 slice = append(slice, 1, 2, 3) 语句，那么返回值会覆盖原变量。展开方式逻辑如下
 1 // If inplace is true, process as statement &amp;#34;s = append(s, e1, e2, e3)&amp;#34;:  2  3 a := &amp;amp;s  4 ptr, len, cap := s  5 newlen := len &#43; 3  6 if uint(newlen) &amp;gt; uint(cap) {  7 newptr, len, newcap = growslice(ptr, len, cap, newlen)  8 vardef(a) // if necessary, advise liveness we are writing a new a  9 *a.cap = newcap // write before ptr to avoid a spill 10 *a.ptr = newptr // with write barrier 11 } 12 newlen = len &#43; 3 // recalculate to avoid a spill 13 *a.len = newlen 14 // with write barriers, if needed: 15 *(ptr&#43;len) = e1 16 *(ptr&#43;len&#43;1) = e2 17 *(ptr&#43;len&#43;2) = e3 不管 inpalce 是否为true，我们均会获取切片的数组指针、大小和容量，如果在追加元素后，切片新的大小大于原始容量，就会调用 runtime.growslice 对切片进行扩容，并将新的元素依次加入切片。
因此，通过append向元素类型为 int 的切片（已包含元素 1，2，3）追加元素 1， slice=append(slice,1)可分为两种情况。
情况1，切片的底层数组还有可容纳追加元素的空间。
情况2，切片的底层数组已无可容纳追加元素的空间，需调用扩容函数，进行扩容。
扩容函数
前面我们提到，追加操作时，当切片底层数组的剩余空间不足以容纳追加的元素，就会调用 growslice，其调用的入参 cap 为追加元素后切片的总长度。
growslice 的代码较长，我们可以根据逻辑分为三个部分。
 初步确定切片容量   1func growslice(et *_type, old slice, cap int) slice {  2 ...  3 newcap := old.cap  4 doublecap := newcap &#43; newcap  5 if cap &amp;gt; doublecap {  6 newcap = cap  7 } else {  8 if old.len &amp;lt; 1024 {  9 newcap = doublecap 10 } else { 11 // Check 0 &amp;lt; newcap to detect overflow 12 // and prevent an infinite loop. 13 for 0 &amp;lt; newcap &amp;amp;&amp;amp; newcap &amp;lt; cap { 14 newcap &#43;= newcap / 4 15 } 16 // Set newcap to the requested cap when 17 // the newcap calculation overflowed. 18 if newcap &amp;lt;= 0 { 19 newcap = cap 20 } 21 } 22 } 23 ... 24} 在该环节中，如果需要的容量 cap 超过原切片容量的两倍 doublecap，会直接使用需要的容量作为新容量newcap。否则，当原切片长度小于1024时，新切片的容量会直接翻倍。而当原切片的容量大于等于1024时，会反复地增加25%，直到新容量超过所需要的容量。
 计算容量所需内存大小   1 var overflow bool  2 var lenmem, newlenmem, capmem uintptr  3  4 switch {  5 case et.size == 1:  6 lenmem = uintptr(old.len)  7 newlenmem = uintptr(cap)  8 capmem = roundupsize(uintptr(newcap))  9 overflow = uintptr(newcap) &amp;gt; maxAlloc 10 newcap = int(capmem) 11 case et.size == sys.PtrSize: 12 lenmem = uintptr(old.len) * sys.PtrSize 13 newlenmem = uintptr(cap) * sys.PtrSize 14 capmem = roundupsize(uintptr(newcap) * sys.PtrSize) 15 overflow = uintptr(newcap) &amp;gt; maxAlloc/sys.PtrSize 16 newcap = int(capmem / sys.PtrSize) 17 case isPowerOfTwo(et.size): 18 var shift uintptr 19 if sys.PtrSize == 8 { 20 // Mask shift for better code generation. 21 shift = uintptr(sys.Ctz64(uint64(et.size))) &amp;amp; 63 22 } else { 23 shift = uintptr(sys.Ctz32(uint32(et.size))) &amp;amp; 31 24 } 25 lenmem = uintptr(old.len) &amp;lt;&amp;lt; shift 26 newlenmem = uintptr(cap) &amp;lt;&amp;lt; shift 27 capmem = roundupsize(uintptr(newcap) &amp;lt;&amp;lt; shift) 28 overflow = uintptr(newcap) &amp;gt; (maxAlloc &amp;gt;&amp;gt; shift) 29 newcap = int(capmem &amp;gt;&amp;gt; shift) 30 default: 31 lenmem = uintptr(old.len) * et.size 32 newlenmem = uintptr(cap) * et.size 33 capmem, overflow = math.MulUintptr(et.size, uintptr(newcap)) 34 capmem = roundupsize(capmem) 35 newcap = int(capmem / et.size) 36 } 在该环节，通过判断切片元素的字节大小是否为1，系统指针大小（32位为4，64位为8）或2的倍数，进入相应所需内存大小的计算逻辑。
这里需要注意的是 roundupsize 函数，它根据输入期望大小 size ，返回 mallocgc 实际将分配的内存块的大小。
 1func roundupsize(size uintptr) uintptr {  2 if size &amp;lt; _MaxSmallSize {  3 if size &amp;lt;= smallSizeMax-8 {  4 return uintptr(class_to_size[size_to_class8[divRoundUp(size, smallSizeDiv)]])  5 } else {  6 return uintptr(class_to_size[size_to_class128[divRoundUp(size-smallSizeMax, largeSizeDiv)]])  7 }  8 }  9 10 // Go的内存管理虚拟地址页大小为 8k（_PageSize） 11 // 当size的大小即将溢出时，就不采用向上取整的做法，直接用当前期望size值。 12 if size&#43;_PageSize &amp;lt; size { 13 return size 14 } 15 return alignUp(size, _PageSize) 16} 根据内存分配中的大小对象原则，如果期望分配内存非大对象 ( &amp;lt;_MaxSmallSize )，即小于32k，则需要根据 divRoundUp 函数将待申请的内存向上取整，取整时会使用 class_to_size 以及 size_to_class8 和 size_to_class128 数组。这些数组方便于内存分配器进行分配，以提高分配效率并减少内存碎片。
1// _NumSizeClasses = 67 代表67种特定大小的对象类型 2var class_to_size = [_NumSizeClasses]uint16{0, 8, 16, 32, 48, 64, 80, 96, 112,...} 当期望分配内存为大对象时，会通过 alignUp 将该 size 的大小向上取值为虚拟页大小（_PageSize）的倍数。
 内存分配   1 if overflow || capmem &amp;gt; maxAlloc {  2 panic(errorString(&amp;#34;growslice: cap out of range&amp;#34;))  3 }  4  5 var p unsafe.Pointer  6 if et.ptrdata == 0 {  7 p = mallocgc(capmem, nil, false)  8 memclrNoHeapPointers(add(p, newlenmem), capmem-newlenmem)  9 } else { 10 p = mallocgc(capmem, et, true) 11 if lenmem &amp;gt; 0 &amp;amp;&amp;amp; writeBarrier.enabled { 12 bulkBarrierPreWriteSrcOnly(uintptr(p), uintptr(old.array), lenmem-et.size&#43;et.ptrdata) 13 } 14 } 15 memmove(p, old.array, lenmem) 16 17 return slice{p, old.len, newcap} 如果在第二个环节中，造成了溢出或者期望分配的内存超过最大分配限制，会引起 panic。
mallocgc 分配一个大小为前面计算得到的 capmem 对象。如果是小对象，则直接从当前G所在P的缓存空闲列表中分配；如果是大对象，则从堆上进行分配。同时，如果切片中的元素不是指针类型，那么会调用 memclrNoHeapPointers将超出切片当前长度的位置清空；如果是元素是指针类型，且原有切片元素个数不为0 并可以打开写屏障时，需要调用 bulkBarrierPreWriteSrcOnly 将旧切片指针标记隐藏，在新切片中保存为nil指针。
在最后使用memmove将原数组内存中的内容拷贝到新申请的内存中，并将新的内存指向指针p 和旧的长度值，新的容量值赋值给新的 slice 并返回。
注意，在 growslice 完成后，只是把旧有数据拷贝到了新的内存中去，且计算得到新的 slice 容量大小，并没有完成最终追加数据的操作。如果 slice 当前 len =3，cap=3，slice=append(slice,1)，那它完成的工作如下图所示。
growslice之后，此时新的slice已经拷贝了旧的slice数据，并且其底层数组有充足的剩余空间追加数据。后续只需拷贝追加数据至剩余空间，并修改 len 值即可，这一部分就不再深究了。
总结
这里回到文章开头中的例子
1package main 2 3func main() { 4 s := []int{1,2} 5 s = append(s, 3,4,5) 6 println(cap(s)) 7} 由于初始 s 的容量是2，现需要追加3个元素，所以通过 append 一定会触发扩容，并调用 growslice 函数，此时他的入参 cap 大小为2&#43;3=5。通过翻倍原有容量得到 doublecap = 2&#43;2，doublecap 小于 cap 值，所以在第一阶段计算出的期望容量值 newcap=5。在第二阶段中，元素类型大小 int 和 sys.PtrSize 相等，通过 roundupsize 向上取整内存的大小到 capmem = 48 字节，所以新切片的容量newcap 为 48 / 8 = 6 ，成功解释！
在切片 append 操作时，如果底层数组已无可容纳追加元素的空间，则需扩容。扩容并不是在原有底层数组的基础上增加内存空间，而是新分配一块内存空间作为切片的底层数组，并将原有数据和追加数据拷贝至新的内存空间中。
在扩容的容量确定上，相对比较复杂，它与CPU位数、元素大小、是否包含指针、追加个数等都有关系。当我们看完扩容源码逻辑后，发现去纠结它的扩容确切值并没什么必要。
在实际使用中，如果能够确定切片的容量范围，比较合适的做法是：切片初始化时就分配足够的容量空间，在append追加操作时，就不用再考虑扩容带来的性能损耗问题。
 1func BenchmarkAppendFixCap(b *testing.B) {  2 for i := 0; i &amp;lt; b.N; i&#43;&#43; {  3 a := make([]int, 0, 1000)  4 for i := 0; i &amp;lt; 1000; i&#43;&#43; {  5 a = append(a, i)  6 }  7 }  8}  9 10func BenchmarkAppend(b *testing.B) { 11 for i := 0; i &amp;lt; b.N; i&#43;&#43; { 12 a := make([]int, 0) 13 for i := 0; i &amp;lt; 1000; i&#43;&#43; { 14 a = append(a, i) 15 } 16 } 17} 它们的压测结果如下，孰优孰劣，一目了然。
1 $ go test -bench=. -benchmem 2 3BenchmarkAppendFixCap-8 1953373 617 ns/op 0 B/op 0 allocs/op 4BenchmarkAppend-8 426882 2832 ns/op 16376 B/op 11 allocs/op 以上内容转载自机器铃砍柴刀
</content>
    </entry>
    
     <entry>
        <title>浅谈逃逸分析</title>
        <url>http://shanks.link/blog/2021/04/30/%E6%B5%85%E8%B0%88%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 详解逃逸分析 Go是一门带有垃圾回收的现代语言，它抛弃了传统C/C&#43;&#43;的开发者需要手动管理内存的方式，实现了内存的主动申请和释放的管理。Go的垃圾回收，让堆和栈的概念对程序员保持透明，它增加的逃逸分析与GC，使得程序员的双手真正地得到了解放，给了开发者更多的精力去关注软件设计本身。
就像《CPU缓存体系对Go程序的影响》文章中说过的一样，“你不一定需要成为一名硬件工程师，但是你确实需要了解硬件的工作原理”。Go虽然帮我们实现了内存的自动管理，我们仍然需要知道其内在原理。内存管理主要包括两个动作：分配与释放。逃逸分析就是服务于内存分配，为了更好理解逃逸分析，我们先谈一下堆栈。
堆和栈
应用程序的内存载体，我们可以简单地将其分为堆和栈。
在Go中，栈的内存是由编译器自动进行分配和释放，栈区往往存储着函数参数、局部变量和调用函数帧，它们随着函数的创建而分配，函数的退出而销毁。一个goroutine对应一个栈，栈是调用栈（call stack）的简称。一个栈通常又包含了许多栈帧（stack frame），它描述的是函数之间的调用关系，每一帧对应一次尚未返回的函数调用，它本身也是以栈形式存放数据。
举例：在一个goroutine里，函数A()正在调用函数B()，那么这个调用栈的内存布局示意图如下。
与栈不同的是，应用程序在运行时只会存在一个堆。狭隘地说，内存管理只是针对堆内存而言的。程序在运行期间可以主动从堆上申请内存，这些内存通过Go的内存分配器分配，并由垃圾收集器回收。
栈是每个goroutine独有的，这就意味着栈上的内存操作是不需要加锁的。而堆上的内存，有时需要加锁防止多线程冲突（为什么要说有时呢，因为Go的内存分配策略学习了TCMalloc的线程缓存思想，他为每个处理器P分配了一个mcache，从mcache分配内存也是无锁的）。
而且，对于程序堆上的内存回收，还需要通过标记清除阶段，例如Go采用的三色标记法。但是，在栈上的内存而言，它的分配与释放非常廉价。简单地说，它只需要两个CPU指令：一个是分配入栈，另外一个是栈内释放。而这，只需要借助于栈相关寄存器即可完成。
另外还有一点，栈内存能更好地利用CPU的缓存策略。因为它们相较于堆而言是更连续的。
逃逸分析
我们如何知道一个对象是应该放在堆内存，还是栈内存之上呢？可以官网的FAQ（地址：https://golang.org/doc/faq）中找到答案。
如果可以，Go编译器会尽可能将变量分配到到栈上。但是，当编译器无法证明函数返回后，该变量没有被引用，那么编译器就必须在堆上分配该变量，以此避免悬挂指针（dangling pointer）。另外，如果局部变量非常大，也会将其分配在堆上。
那么，Go是如何确定的呢？答案就是：逃逸分析。编译器通过逃逸分析技术去选择堆或者栈，逃逸分析的基本思想如下：检查变量的生命周期是否是完全可知的，如果通过检查，则可以在栈上分配。否则，就是所谓的逃逸，必须在堆上进行分配。
Go语言虽然没有明确说明逃逸分析规则，但是有以下几点准则，是可以参考的。
 逃逸分析是在编译器完成的，这是不同于jvm的运行时逃逸分析; 如果变量在函数外部没有引用，则优先放到栈中； 如果变量在函数外部存在引用，则必定放在堆中；  我们可通过go build -gcflags &#39;-m -l&#39;命令来查看逃逸分析结果，其中-m 打印逃逸分析信息，-l禁止内联优化。下面，我们通过一些案例，来熟悉一些常见的逃逸情况。
情况一：变量类型不确定
1package main 2 3import &amp;#34;fmt&amp;#34; 4 5func main() { 6 a := 666 7 fmt.Println(a) 8} 逃逸分析结果如下
1 $ go build -gcflags &amp;#39;-m -l&amp;#39; main.go 2# command-line-arguments 3./main.go:7:13: ... argument does not escape 4./main.go:7:13: a escapes to heap 分析结果告诉我们变量a逃逸到了堆上。但是我们并没有外部引用，为什么也会有逃逸呢？为了看到更多细节，可以在语句中再添加一个-m参数。得到信息如下
 1 $ go build -gcflags &amp;#39;-m -m -l&amp;#39; main.go  2# command-line-arguments  3./main.go:7:13: a escapes to heap:  4./main.go:7:13: flow: {storage for ... argument} = &amp;amp;{storage for a}:  5./main.go:7:13: from a (spill) at ./main.go:7:13  6./main.go:7:13: from ... argument (slice-literal-element) at ./main.go:7:13  7./main.go:7:13: flow: {heap} = {storage for ... argument}:  8./main.go:7:13: from ... argument (spill) at ./main.go:7:13  9./main.go:7:13: from fmt.Println(... argument...) (call parameter) at ./main.go:7:13 10./main.go:7:13: ... argument does not escape 11./main.go:7:13: a escapes to heap a逃逸是因为它被传入了fmt.Println的参数中，这个方法参数自己发生了逃逸。
1func Println(a ...interface{}) (n int, err error) 2 因为fmt.Println的函数参数为interface类型，编译期不能确定其参数的具体类型，所以将其分配于堆上。
情况二：暴露给外部指针
 1package main  2  3func foo() *int {  4 a := 666  5 return &amp;amp;a  6}  7  8func main() {  9 _ = foo() 10} 逃逸分析如下，变量a发生了逃逸。
1 $ go build -gcflags &amp;#39;-m -m -l&amp;#39; main.go 2# command-line-arguments 3./main.go:4:2: a escapes to heap: 4./main.go:4:2: flow: ~r0 = &amp;amp;a: 5./main.go:4:2: from &amp;amp;a (address-of) at ./main.go:5:9 6./main.go:4:2: from return &amp;amp;a (return) at ./main.go:5:2 7./main.go:4:2: moved to heap: a 这种情况直接满足我们上述中的原则：变量在函数外部存在引用。这个很好理解，因为当函数执行完毕，对应的栈帧就被销毁，但是引用已经被返回到函数之外。如果这时外部从引用地址取值，虽然地址还在，但是这块内存已经被释放回收了，这就是非法内存，问题可就大了。所以，很明显，这种情况必须分配到堆上。
情况三：变量所占内存较大
 1func foo() {  2 s := make([]int, 10000, 10000)  3 for i := 0; i &amp;lt; len(s); i&#43;&#43; {  4 s[i] = i  5 }  6}  7  8func main() {  9 foo() 10} 逃逸分析结果
1$ go build -gcflags &amp;#39;-m -m -l&amp;#39; main.go 2# command-line-arguments 3./main.go:4:11: make([]int, 10000, 10000) escapes to heap: 4./main.go:4:11: flow: {heap} = &amp;amp;{storage for make([]int, 10000, 10000)}: 5./main.go:4:11: from make([]int, 10000, 10000) (too large for stack) at ./main.go:4:11 6./main.go:4:11: make([]int, 10000, 10000) escapes to heap 当我们创建了一个容量为10000的int类型的底层数组对象时，由于对象过大，它也会被分配到堆上。这里我们不禁要想一个问题，为啥大对象需要分配到堆上。
这里需要注意，在上文中没有说明的是：在Go中，执行用户代码的goroutine是一种用户态线程，其调用栈内存被称为用户栈，它其实也是从堆区分配的，但是我们仍然可以将其看作和系统栈一样的内存空间，它的分配和释放是通过编译器完成的。与其相对应的是系统栈，它的分配和释放是操作系统完成的。在GMP模型中，一个M对应一个系统栈（也称为M的g0栈），M上的多个goroutine会共享该系统栈。
不同平台上的系统栈最大限制不同。
1$ ulimit -s 28192 以x86_64架构为例，它的系统栈大小最大可为8Mb。我们常说的goroutine初始大小为2kb，其实说的是用户栈，它的最小和最大可以在runtime/stack.go中找到，分别是2KB和1GB。
1// The minimum size of stack used by Go code 2_StackMin = 2048 3... 4var maxstacksize uintptr = 1 &amp;lt;&amp;lt; 20 // enough until runtime.main sets it for real 而堆则会大很多，从1.11之后，Go采用了稀疏的内存布局，在Linux的x86-64架构上运行时，整个堆区最大可以管理到256TB的内存。所以，为了不造成栈溢出和频繁的扩缩容，大的对象分配在堆上更加合理。那么，多大的对象会被分配到堆上呢。
通过测试，小菜刀发现该大小为64KB（这在Go内存分配中是属于大对象的范围：&amp;gt;32kb），即s :=make([]int, n, n)中，一旦n达到8192，就一定会逃逸。注意，网上有人通过fmt.Println(unsafe.Sizeof(s))得到s的大小为24字节，就误以为只需分配24个字节的内存，这是错误的，因为实际还有底层数组的内存需要分配。
情况四：变量大小不确定
我们将情况三种的示例，简单更改一下。
 1package main  2  3func foo() {  4 n := 1  5 s := make([]int, n)  6 for i := 0; i &amp;lt; len(s); i&#43;&#43; {  7 s[i] = i  8 }  9} 10 11func main() { 12 foo() 13} 得到逃逸分析结果如下
1$ go build -gcflags &amp;#39;-m -m -l&amp;#39; main.go 2# command-line-arguments 3./main.go:5:11: make([]int, n) escapes to heap: 4./main.go:5:11: flow: {heap} = &amp;amp;{storage for make([]int, n)}: 5./main.go:5:11: from make([]int, n) (non-constant size) at ./main.go:5:11 6./main.go:5:11: make([]int, n) escapes to heap 这次，我们在make方法中，没有直接指定大小，而是填入了变量n，这时Go逃逸分析也会将其分配到堆区去。可见，为了保证内存的绝对安全，Go的编译器可能会将一些变量不合时宜地分配到堆上，但是因为这些对象最终也会被垃圾收集器处理，所以也能接受。
总结
本文只列举了逃逸分析的部分例子，实际的情况还有很多，理解思想最重要。这里就不过多列举了。
既然Go的堆栈分配对于开发者来说是透明的，编译器已经通过逃逸分析为对象选择好了分配方式。那么我们还可以从中获益什么？
答案是肯定的，理解逃逸分析一定能帮助我们写出更好的程序。知道变量分配在栈堆之上的差别，那么我们就要尽量写出分配在栈上的代码，堆上的变量变少了，可以减轻内存分配的开销，减小gc的压力，提高程序的运行速度。
所以，你会发现有些Go上线项目，它们在函数传参的时候，并没有传递结构体指针，而是直接传递的结构体。这个做法，虽然它需要值拷贝，但是这是在栈上完成的操作，开销远比变量逃逸后动态地在堆上分配内存少的多。当然该做法不是绝对的，如果结构体较大，传递指针将更合适。
因此，从GC的角度来看，指针传递是个双刃剑，需要谨慎使用，否则线上调优解决GC延时可能会让你崩溃。
以上内容转载自机器铃砍柴刀
</content>
    </entry>
    
     <entry>
        <title>Once函数单次调用</title>
        <url>http://shanks.link/blog/2021/04/29/once%E5%87%BD%E6%95%B0%E5%8D%95%E6%AC%A1%E8%B0%83%E7%94%A8/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 认识单例
超超：您好，面试官~
面试官：你好，你平时开发是用 windows 还是 linux 居多？
超超：￣□￣｜｜我平时都是用windows开发的。
面试官：那你知道 windows 的资源管理器只能单开，但是cmd命令行可以开很多个，有想过这是为什么吗？
考点：单例的使用场景优缺点
超超：资源管理器在整个系统运行过程中不会因为不同的任务管理器内容改变而改变，因此为了节省资源全局只需要有一份，这是单例。
单例怎么用
 面试官：你刚才说到了单例，你知道go里面怎么使用单例吗？
考点：go如何使用单例
超超：(￣▽￣)／ 这个简单，举个例子，婷婷在购物时，android端和web端只有一个指向用户婷婷的对象
 1package main  2  3import (  4 &amp;#34;fmt&amp;#34;  5 &amp;#34;sync&amp;#34;  6)  7  8//婷婷的淘宝客户端和web端都会指向婷婷这一个人  9type Woman struct { 10 name string 11} 12 13var ( 14 once sync.Once 15 ting *Woman 16) 17 18func getTing() *Woman { 19 once.Do(func() { 20 ting = new(Woman) 21 ting.name = &amp;#34;tingting&amp;#34; 22 fmt.Println(&amp;#34;newtingting&amp;#34;) 23 }) 24 fmt.Println(&amp;#34;gettingting&amp;#34;) 25 return ting 26} 27 28func main() { 29 for i := 0; i &amp;lt; 3; i&#43;&#43; { 30 _ = getTing() 31 } 32} 结果
1newtingting 2gettingting 3gettingting 4gettingting 源码实现
面试官：那你能说说sync.Once是怎么实现的吗（：举个例子还秀起来了
考点：深入源码，进一步了解**Once**
超超：sync.Once是由Once结构体和其Do，doSlow俩个方法实现的
1type Once struct { 2 // done indicates whether the action has been performed. 3 // It is first in the struct because it is used in the hot path. 4 // The hot path is inlined at every call site. 5 // Placing done first allows more compact instructions on some architectures (amd64/x86), 6 // and fewer instructions (to calculate offset) on other architectures. 7 done uint32 8 m Mutex 9} done是标识位，用来判断方法f是否被执行完，其初始值为0，当f执行结束时，done被设为1。
m做竞态控制，当f第一次执行还未结束时，通过m加锁的方式阻塞其他once.Do执行f。
这里有个地方需要特别注意下，once.Do是不可以嵌套使用的，嵌套使用将导致死锁。
 1func (o *Once) Do(f func()) {  2 // Note: Here is an incorrect implementation of Do:  3 //  4 // if atomic.CompareAndSwapUint32(&amp;amp;o.done, 0, 1) {  5 // f()  6 // }  7 //  8 // Do guarantees that when it returns, f has finished.  9 // This implementation would not implement that guarantee: 10 // given two simultaneous calls, the winner of the cas would 11 // call f, and the second would return immediately, without 12 // waiting for the first&amp;#39;s call to f to complete. 13 // This is why the slow path falls back to a mutex, and why 14 // the atomic.StoreUint32 must be delayed until after f returns. 15 16 if atomic.LoadUint32(&amp;amp;o.done) == 0 { 17 // Outlined slow-path to allow inlining of the fast-path. 18 o.doSlow(f) 19 } 20} 21 22func (o *Once) doSlow(f func()) { 23 o.m.Lock() 24 defer o.m.Unlock() 25 if o.done == 0 { 26 defer atomic.StoreUint32(&amp;amp;o.done, 1) 27 f() 28 } 29}  Do()方法  作用：通过原子操作判断o.done，如果o.done==0则f未被执行完，进入doSlow(f func())，如果f执行完则退出Do()。
入参：无
出参：无
 doSlow(f func())方法  作用：通过加锁的方式，执行f，并在f执行结束时，将o.done置为1
入参：执行体f，通常为对象的创建或者模块数据加载
出参：无
面试官：你知道atomic.CompareAndSwapUint32(&amp;amp;o.done, 0, 1)的作用是什么吗？
考点：对sync包了解的广度
超超：CompareAndSwapUint32简称CAS，通过原子操作判断当o.done值等于0时，使o.done等于1并返回true，当o.done值不等于0，直接返回false
面试官：很好，那你能说说Do()方法中可以把atomic.LoadUint32直接替换为atomic.CompareAndSwapUint32吗？
考点：多线程思维
超超：这个是不可以的，因为f的执行是需要时间的，如果用CAS可能会导致f创建的对象尚未完成，其他地方就开始调用了。如图所示，A,B俩个协程都调用Once.Do方法，A协程先完成CAS将done值置为了1，导致B协程误以为对象创建完成，继而调用对象方法而出错。
这里doSlow中的o.done == 0判断，也需要注意一下，因为可能会出现A,B俩个协程都进行了LoadUint32判断，并且都是true，如果不进行第二次校验的话，对象会被new俩次
扩展
面试官：看来你对源码sync.Once的实现还比较熟悉，那你知道懒汉模式和饿汉模式吗？
考点：单例创建的延伸
超超：
饿汉模式：是指在程序启动时就进行数据加载，这样避免了数据冲突，也是线程安全的，但是这可能会造成内存浪费。比如在程序启动时就new一个 woman对象加载婷婷相关数据，当需要调用婷婷相关方法时，不用再创建对象。
懒汉模式：是指需要执行对象相关方法时，才主动去加载数据，这样做可以避免内存的浪费，比如当需要调用婷婷相关的方法时，才去new一个 woman对象加载婷婷相关数据，然后调用方法。
面试官：不错，倒是会一点花拳绣腿，那我们开始真正的面试吧。
超超：啊！？
未完待续 ~
以上内容转载自机器铃砍柴刀
</content>
    </entry>
    
     <entry>
        <title>面试题型系列:滑动窗口技巧</title>
        <url>http://shanks.link/blog/2021/04/29/%E9%9D%A2%E8%AF%95%E9%A2%98%E5%9E%8B%E7%B3%BB%E5%88%97%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E6%8A%80%E5%B7%A7/</url>
        <categories>
          <category>algorithm</category>
        </categories>
        <tags>
          <tag>algorithm</tag>
        </tags>
        <content type="html"> 面试题型系列：滑动窗口技巧 本文是公众号读者上山打老虎的第二篇原创投稿，主要内容是讲解算法技巧之滑动窗口。上山兄一直保持着刷题的习惯，并形成了自己的一套做题心得，当然他也是无情的offer收割机。同时上山兄会持续给本号投稿算法类文章，代码示例均采用Go语言，希望该算法系列文章有助读者更好地备战面试。
在数组中查找一个数，可以使用二分法查找，但是算法问题中还有一些是在数组（或字符串）中查找一个子区间，这时滑动窗口就是一种很好的解决思路。
很多同学学过滑动窗口算法，但是一做题就错，这是因为有很多细节问题会在解答时出错，本文将依次介绍该算法的模板，易错点，分类题型，希望读者看完之后能极大的提高做题速度以及准确度。
什么是滑动窗口
概念 滑动窗口是双指针算法的一种，利用双指针在数组单一方向滑动，形成一个子区间，对子区间进行剪枝，最终得出满足条件的解。
过程 window中元素未完全包含target时，right向右滑动
此时window包含target中所有元素，将left向右滑动
Go代码模板  1func checkInclusion(nums []int, target []int) bool {  2 window := make(map[byte]int, len(nums))  3 left, right := 0, 0  4  5 for right &amp;lt; len(nums) {  6 c := nums[right]  7 window[c]&#43;&#43;  8 //right右滑变量变化  9 right&#43;&#43; 10 11 for 满足left右滑条件 { 12 //判断区间是否满足条件（可能在left右滑的前中后） 13 14 d := nums[left] 15 //left右滑变量的改动 16 17 left&#43;&#43; 18 } 19 } 20 return false 21} 易错点  left和right滑动时，容易漏掉某个变量的值变化，这里教大家一个技巧，每次写完复查前面声明的变量，在滑动时是否改变 left右滑动时，先判断是否满足条件，再做变量值的变化，颠倒会导致第一次满足条件的解漏掉  例题解析
值匹配 这道题是求最长子串，这里我们需要敏锐地捕捉到“子串”关键词。该题中，我们把字符串当做数组，“子串”就是子区间，这赤裸裸的就是滑动窗口的题型呀。
废话不多说，直接先上模板！
 1func lengthOfLongestSubstring(s string) int {  2 lens := len(s)  3 window := make(map[byte]int, lens)  4 left, right := 0, 0  5  6 for right &amp;lt; lens{  7 c := nums[right]  8 window[c]&#43;&#43;  9 //right右滑变量变化 10 right&#43;&#43; 11 12 for 满足left右滑条件 { 13 //判断区间是否满足条件（可能在left右滑的前中后） 14 15 d := nums[left] 16 //left右滑变量的改动 17 18 left&#43;&#43; 19 } 20 } 21 return false 22} 分析
 满足left右滑动的条件：无重复字符，即右滑时window容器中每个元素值&amp;lt;=1 是否更新结果值条件：在window中无重复的元素后，即for循环之后，判断res-left与之前无重复字符串最大长度（res）之间关系 right右滑动变量变化：参照声明的四个变量，这题只有winow和right变化 left右滑动变量变化：参照声明的四个变量，这题只有winow和left变化   1func lengthOfLongestSubstring(s string) int {  2 lens := len(s)  3 window := make(map[byte]int, lens)  4 left, right, res := 0, 0, 0  5  6 //right右滑动  7 for right &amp;lt; lens {  8 b := s[right]  9 window[b]&#43;&#43; 10 right&#43;&#43; 11 //left右滑动 12 for window[b] &amp;gt; 1 { 13 c := s[left] 14 window[c]-- 15 left&#43;&#43; 16 } 17 //判断区间是否满足条件 18 if right-left &amp;gt; res { 19 res = right - left 20 } 21 } 22 return res 23} 区间匹配 很明显这又是一个求子串的问题，分析如下
 满足left右滑动的条件：这题和前言中题类似，设一个target切片记录目标区间每个元素的个数[A:1,B:1,C:1]，当window中所有目标元素个数（vaild）都达到target要求时，left右滑缩小区间 是否更新结果值条件：在left右滑时，即for循环中判断当前right-left与之前最小覆盖子串之间关系 right右滑动变量变化：参照声明的变量有当前区间window，达标元素个数vaild，窗口右边界right left右滑动变量变化：参照声明的变量有起始位置start，结果字符串长度res，达标元素个数vaild，当前区间window，窗口左边界left   1func minWindow(s string, t string) string {  2 //变量初始化  3 lens := len(s)  4 lent := len(t)  5 window := make(map[byte]int, lens)  6 target := make(map[byte]int, lent)  7 left, right, vaild := 0, 0, 0  8 res := lens  9 start := -1 10 11 for i := 0; i &amp;lt; lent; i&#43;&#43; { 12 target[t[i]]&#43;&#43; 13 } 14 15 //right右滑动 16 for right &amp;lt; lens { 17 b := s[right] 18 window[b]&#43;&#43; 19 if target[b] == window[b] { 20 vaild&#43;&#43; 21 } 22 right&#43;&#43; 23 24 //left右滑动 25 for vaild == len(target) { 26 c := s[left] 27 //是否更新结果值 28 if res &amp;gt;= right-left { 29 start = left 30 res = right - left 31 } 32 33 if window[c] == target[c] { 34 vaild-- 35 } 36 window[c]-- 37 left&#43;&#43; 38 } 39 } 40 if start == -1 { 41 return &amp;#34;&amp;#34; 42 } 43 return s[start : start&#43;res] 44} 总结
  题型：求子串、求子数组，在这样的题目关键字中，我们可以考虑通过双指针单向滑动剪枝出满足条件的区间
  记住模板：一容（window），二变（left，right），三扩（right右移），四缩（left右移）
  思路：俩个条件（left右滑条件，是否更新结果值条件），俩个变化（right右滑动变量变化，left右滑动变量变化）
  易错点：例如第二题每次滑动需要更新的变量很多，稍有不慎就会少更新某个量，每次对照开始声明的变量可以万无一失
  转转自机器铃砍柴刀
</content>
    </entry>
    
     <entry>
        <title>切片传递的隐藏危机</title>
        <url>http://shanks.link/blog/2021/04/29/%E5%88%87%E7%89%87%E4%BC%A0%E9%80%92%E7%9A%84%E9%9A%90%E8%97%8F%E5%8D%B1%E6%9C%BA/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 切片传递的隐藏危机 在Go的源码库或者其他开源项目中，会发现有些函数在需要用到切片入参时，它采用是指向切片类型的指针，而非切片类型。这里未免会产生疑问：切片底层不就是指针指向底层数组数据吗，为何不直接传递切片，两者有什么区别？
例如，在源码log包中，Logger对象上绑定了formatHeader方法，它的入参对象buf，其类型是*[]byte，而非[]byte。
1func (l *Logger) formatHeader(buf *[]byte, t time.Time, file string, line int) {} 有以下例子
 1func modifySlice(innerSlice []string) {  2 innerSlice[0] = &amp;#34;b&amp;#34;  3 innerSlice[1] = &amp;#34;b&amp;#34;  4 fmt.Println(innerSlice)  5}  6  7func main() {  8 outerSlice := []string{&amp;#34;a&amp;#34;, &amp;#34;a&amp;#34;}  9 modifySlice(outerSlice) 10 fmt.Print(outerSlice) 11} 12 13// 输出如下 14[b b] 15[b b] 我们将modifySlice函数的入参类型改为指向切片的指针
 1func modifySlice(innerSlice *[]string) {  2 (*innerSlice)[0] = &amp;#34;b&amp;#34;  3 (*innerSlice)[1] = &amp;#34;b&amp;#34;  4 fmt.Println(*innerSlice)  5}  6  7func main() {  8 outerSlice := []string{&amp;#34;a&amp;#34;, &amp;#34;a&amp;#34;}  9 modifySlice(&amp;amp;outerSlice) 10 fmt.Print(outerSlice) 11} 12 13// 输出如下 14[b b] 15[b b] 在上面的例子中，两种函数传参类型得到的结果都一样，似乎没发现有什么区别。通过指针传递它看起来毫无用处，而且无论如何切片都是通过引用传递的，在两种情况下切片内容都得到了修改。
这印证了我们一贯的认知：函数内对切片的修改，将会影响到函数外的切片。但，真的是如此吗？
考证与解释
在《[你真的懂string与]byte的转换了吗》一文中，我们讲过切片的底层结构如下所示。
1type slice struct { 2 array unsafe.Pointer 3 len int 4 cap int 5} array是底层数组的指针，len表示长度，cap表示容量。
我们对上文中的例子，做以下细微的改动。
 1func modifySlice(innerSlice []string) {  2 innerSlice = append(innerSlice, &amp;#34;a&amp;#34;)  3 innerSlice[0] = &amp;#34;b&amp;#34;  4 innerSlice[1] = &amp;#34;b&amp;#34;  5 fmt.Println(innerSlice)  6}  7  8func main() {  9 outerSlice := []string{&amp;#34;a&amp;#34;, &amp;#34;a&amp;#34;} 10 modifySlice(outerSlice) 11 fmt.Print(outerSlice) 12} 13 14// 输出如下 15[b b a] 16[a a] 神奇的事情发生了，函数内对切片的修改竟然没能对外部切片造成影响？
为了清晰地明白发生了什么，将打印添加更多细节。
 1func modifySlice(innerSlice []string) {  2 fmt.Printf(&amp;#34;%p %v %p\n&amp;#34;, &amp;amp;innerSlice, innerSlice, &amp;amp;innerSlice[0])  3 innerSlice = append(innerSlice, &amp;#34;a&amp;#34;)  4 innerSlice[0] = &amp;#34;b&amp;#34;  5 innerSlice[1] = &amp;#34;b&amp;#34;  6 fmt.Printf(&amp;#34;%p %v %p\n&amp;#34;, &amp;amp;innerSlice, innerSlice, &amp;amp;innerSlice[0])  7}  8  9func main() { 10 outerSlice := []string{&amp;#34;a&amp;#34;, &amp;#34;a&amp;#34;} 11 fmt.Printf(&amp;#34;%p %v %p\n&amp;#34;, &amp;amp;outerSlice, outerSlice, &amp;amp;outerSlice[0]) 12 modifySlice(outerSlice) 13 fmt.Printf(&amp;#34;%p %v %p\n&amp;#34;, &amp;amp;outerSlice, outerSlice, &amp;amp;outerSlice[0]) 14} 15 16// 输出如下 170xc00000c060 [a a] 0xc00000c080 180xc00000c0c0 [a a] 0xc00000c080 190xc00000c0c0 [b b a] 0xc000022080 200xc00000c060 [a a] 0xc00000c080 在Go函数中，函数的参数传递均是值传递。那么，将切片通过参数传递给函数，其实质是复制了slice结构体对象，两个slice结构体的字段值均相等。正常情况下，由于函数内slice结构体的array和函数外slice结构体的array指向的是同一底层数组，所以当对底层数组中的数据做修改时，两者均会受到影响。
但是存在这样的问题：如果指向底层数组的指针被覆盖或者修改（copy、重分配、append触发扩容），此时函数内部对数据的修改将不再影响到外部的切片，代表长度的len和容量cap也均不会被修改。
为了让读者更清晰的认识到这一点，将上述过程可视化如下。
可以看到，当切片的长度和容量相等时，发生append，就会触发切片的扩容。扩容时，会新建一个底层数组，将原有数组中的数据拷贝至新数组，追加的数据也会被置于新数组中。切片的array指针指向新底层数组。所以，函数内切片与函数外切片的关联已经彻底斩断，它的改变对函数外切片已经没有任何影响了。
注意，切片扩容并不总是等倍扩容。为了避免读者产生误解，这里对切片扩容原则简单说明一下（源码位于src/runtime/slice.go 中的 growslice 函数）：
切片扩容时，当需要的容量超过原切片容量的两倍时，会直接使用需要的容量作为新容量。否则，当原切片长度小于1024时，新切片的容量会直接翻倍。而当原切片的容量大于等于1024时，会反复地增加25%，直到新容量超过所需要的容量。
到此，我们终于知道为什么有些函数在用到切片入参时，它需要采用指向切片类型的指针，而非切片类型。
 1func modifySlice(innerSlice *[]string) {  2 *innerSlice = append(*innerSlice, &amp;#34;a&amp;#34;)  3 (*innerSlice)[0] = &amp;#34;b&amp;#34;  4 (*innerSlice)[1] = &amp;#34;b&amp;#34;  5 fmt.Println(*innerSlice)  6}  7  8func main() {  9 outerSlice := []string{&amp;#34;a&amp;#34;, &amp;#34;a&amp;#34;} 10 modifySlice(&amp;amp;outerSlice) 11 fmt.Print(outerSlice) 12} 13 14// 输出如下 15[b b a] 16[b b a] 请记住，如果你只想修改切片中元素的值，而不会更改切片的容量与指向，则可以按值传递切片，否则你应该考虑按指针传递。
** **
例题巩固
为了判断读者是否已经真正理解上述问题，我将上面的例子做了两个变体，读者朋友们可以自测。
测试一
 1func modifySlice(innerSlice []string) {  2 innerSlice[0] = &amp;#34;b&amp;#34;  3 innerSlice = append(innerSlice, &amp;#34;a&amp;#34;)  4 innerSlice[1] = &amp;#34;b&amp;#34;  5 fmt.Println(innerSlice)  6}  7  8func main() {  9 outerSlice := []string{&amp;#34;a&amp;#34;, &amp;#34;a&amp;#34;} 10 modifySlice(outerSlice) 11 fmt.Println(outerSlice) 12} 测试二
 1func modifySlice(innerSlice []string) {  2 innerSlice = append(innerSlice, &amp;#34;a&amp;#34;)  3 innerSlice[0] = &amp;#34;b&amp;#34;  4 innerSlice[1] = &amp;#34;b&amp;#34;  5 fmt.Println(innerSlice)  6}  7  8func main() {  9 outerSlice:= make([]string, 0, 3) 10 outerSlice = append(outerSlice, &amp;#34;a&amp;#34;, &amp;#34;a&amp;#34;) 11 modifySlice(outerSlice) 12 fmt.Println(outerSlice) 13} 测试一答案
1[b b a] 2[b a] 测试二答案
1[b b a] 2[b b] 你做对了吗？
以上内容转载自机器铃砍柴刀
</content>
    </entry>
    
     <entry>
        <title>一文读懂channel设计</title>
        <url>http://shanks.link/blog/2021/04/29/%E4%B8%80%E6%96%87%E8%AF%BB%E6%87%82channel%E8%AE%BE%E8%AE%A1/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 在Go中，要理解channel，首先需要认识goroutine。
为什么会有goroutine
现代操作系统中为我们提供了三种基本的构造并发程序的方法：多进程、I/O多路复用和多线程。其中最简单的构造方式当属多进程，但是多进程的并发程序，由于对进程控制和进程间通信开销巨大，这样的并发方式往往会很慢。
因此，操作系统提供了更小粒度的运行单元：线程（确切叫法是内核线程）。它是一种运行在进程上下文中的逻辑流，线程之间通过操作系统来调度，其调度模型如下图所示。
多线程的并发方式，相较于多进程而言要快得多。但是由于线程上下文切换总是不可避免的陷入内核态，它的开销依然较大。那么有没有不必陷入内核态的运行载体呢？有，用户级线程。用户级线程的切换由用户程序自己控制，不需要内核干涉，因此少了进出内核态的消耗。
这里的用户级线程就是协程（coroutine），它们的切换由运行时系统来统一调度管理，内核态并不知道它的存在。协程是抽象于内核线程之上的对象，一个内核线程可以对应多个协程。但最终的系统调用仍然需要内核线程来完成。注意，线程的调度是操作系统来管理，是一种抢占式调度。而协程不同，协程之间需要合作，会主动交出执行权，是一种协作式调度，这也是为何被称为协程的原因。
Go天生在语言层面支持了协程，即我们常说的goroutine。Go的runtime系统实现的是一种M:N调度模型，通过GMP对象来描述，其中G代表的就是协程，M是线程，P是调度上下文。在Go程序中，一个goroutine就代表着一个最小用户代码执行流，它们也是并发流的最小单元。
channel的存在定位
从内存的角度而言，并发模型只分两种：基于共享内存和基于消息通信（内存拷贝）。在Go中，两种并发模型的同步原语均有提供：sync.*和atomic.*代表的就是基于共享内存；channel代表的就是基于消息通信。而Go提倡后者，它包括三大元素：goroutine（执行体），channel（通信），select（协调）。
Do not communicate by sharing memory; instead, share memory by communicating.
在Go中通过goroutine&#43;channel的方式，可以简单、高效地解决并发问题，channel就是goroutine之间的数据桥梁。
Concurrency is the key to designing high performance network services. Go&amp;rsquo;s concurrency primitives (goroutines and channels) provide a simple and efficient means of expressing concurrent execution.
以下是一个简单的channel使用示例代码。
 1func goroutineA(ch &amp;lt;-chan int) {  2 fmt.Println(&amp;#34;[goroutineA] want a data&amp;#34;)  3 val := &amp;lt;- ch  4 fmt.Println(&amp;#34;[goroutineA] received the data&amp;#34;, val)  5}  6  7func goroutineB(ch chan&amp;lt;- int) {  8 time.Sleep(time.Second*1)  9 ch &amp;lt;- 1 10 fmt.Println(&amp;#34;[goroutineB] send the data 1&amp;#34;) 11} 12 13func main() { 14 ch := make(chan int, 1) 15 go goroutineA(ch) 16 go goroutineB(ch) 17 time.Sleep(2*time.Second) 18} 上述过程趣解图如下
channel源码解析
channel源码位于src/go/runtime/chan.go。本章内容分为两部分：channel内部结构和channel操作。
1. channel内部结构
** **
1ch := make(chan int,2) 对于以上channel的申明语句，我们可以在程序中加入断点，得到ch的信息如下。
很好，看起来非常的清晰。但是，这些信息代表的是什么含义呢？接下来，我们先看几个重要的结构体。
 hchan  当我们通过make(chan Type, size)生成channel时，在runtime系统中，生成的是一个hchan结构体对象。源码位于src/runtime/chan.go
 1type hchan struct {  2 qcount uint // 循环队列中数据数  3 dataqsiz uint // 循环队列的大小  4 buf unsafe.Pointer // 指向大小为dataqsize的包含数据元素的数组指针  5 elemsize uint16 // 数据元素的大小  6 closed uint32 // 代表channel是否关闭  7 elemtype *_type // _type代表Go的类型系统，elemtype代表channel中的元素类型  8 sendx uint // 发送索引号，初始值为0  9 recvx uint // 接收索引号，初始值为0 10 recvq waitq // 接收等待队列，存储试图从channel接收数据(&amp;lt;-ch)的阻塞goroutines 11 sendq waitq // 发送等待队列，存储试图发送数据(ch&amp;lt;-)到channel的阻塞goroutines 12 13 lock mutex // 加锁能保护hchan的所有字段，包括waitq中sudoq对象 14}  waitq  waitq用于表达处于阻塞状态的goroutines链表信息，first指向链头goroutine，last指向链尾goroutine。
1type waitq struct { 2 first *sudog 3 last *sudog 4}  sudug  sudog代表的就是一个处于等待列表中的goroutine对象，源码位于src/runtime/runtime2.go
1type sudog struct { 2 g *g 3 next *sudog 4 prev *sudog 5 elem unsafe.Pointer // data element (may point to stack) 6 c *hchan // channel 7 ... 8} 为了更好理解hchan结构体，我们将通过以下代码来理解hchan中的字段含义。
 1package main  2  3import &amp;#34;time&amp;#34;  4  5func goroutineA(ch chan int) {  6 ch &amp;lt;- 100  7}  8  9func goroutineB(ch chan int) { 10 ch &amp;lt;- 200 11} 12 13func goroutineC(ch chan int) { 14 ch &amp;lt;- 300 15} 16 17func goroutineD(ch chan int) { 18 ch &amp;lt;- 300 19} 20 21func main() { 22 ch := make(chan int, 4) 23 for i := 0; i &amp;lt; 4; i&#43;&#43; { 24 ch &amp;lt;- i * 10 25 } 26 go goroutineA(ch) 27 go goroutineB(ch) 28 go goroutineC(ch) 29 go goroutineD(ch) 30 // 第一个sleep是为了给上足够的时间让所有goroutine都已启动 31 time.Sleep(time.Millisecond * 500) 32 time.Sleep(time.Second) 33} 打开代码调试功能，将程序运行至断点time.Sleep(time.Second)处，此时得到的chan信息如下。
在该channel中，通过make(chan int, 4)定义的channel大小为4，即dataqsiz的值为4。同时由于循环队列中已经添加了4个元素，所以qcount值也为4。此时，有4个goroutine（A-D）想发送数据给channel，但是由于存放数据的循环队列已满，所以只能进入发送等待列表，即sendq。同时要注意到，此时的发送和接收索引值均为0，即下一次接收数据的goroutine会从循环队列的第一个元素拿，发送数据的goroutine会发送到循环队列的第一个位置。
上述hchan结构可视化图解如下
 ** ** 2. channel操作 将channel操作分为四部分：创建、发送、接收和关闭。
  创建   本文的参考Go版本为1.15.2。其channel的创建实现代码位于src/go/runtime/chan.go的makechan方法。
 1func makechan(t *chantype, size int) *hchan {  2 elem := t.elem  3  4 // 发送元素大小限制  5 if elem.size &amp;gt;= 1&amp;lt;&amp;lt;16 {  6 throw(&amp;#34;makechan: invalid channel element type&amp;#34;)  7 }  8 // 对齐检查  9 if hchanSize%maxAlign != 0 || elem.align &amp;gt; maxAlign { 10 throw(&amp;#34;makechan: bad alignment&amp;#34;) 11 } 12 13 // 判断是否会内存溢出 14 mem, overflow := math.MulUintptr(elem.size, uintptr(size)) 15 if overflow || mem &amp;gt; maxAlloc-hchanSize || size &amp;lt; 0 { 16 panic(plainError(&amp;#34;makechan: size out of range&amp;#34;)) 17 } 18 19 // 为构造的hchan对象分配内存 20 var c *hchan 21 switch { 22 // 无缓冲的channel或者元素大小为0的情况 23 case mem == 0: 24 c = (*hchan)(mallocgc(hchanSize, nil, true)) 25 c.buf = c.raceaddr() 26 // 元素不包含指针的情况 27 case elem.ptrdata == 0: 28 c = (*hchan)(mallocgc(hchanSize&#43;mem, nil, true)) 29 c.buf = add(unsafe.Pointer(c), hchanSize) 30 // 元素包含指针 31 default: 32 c = new(hchan) 33 c.buf = mallocgc(mem, elem, true) 34 } 35 36 // 初始化相关参数 37 c.elemsize = uint16(elem.size) 38 c.elemtype = elem 39 c.dataqsiz = uint(size) 40 lockInit(&amp;amp;c.lock, lockRankHchan) 41 42 if debugChan { 43 print(&amp;#34;makechan: chan=&amp;#34;, c, &amp;#34;; elemsize=&amp;#34;, elem.size, &amp;#34;; dataqsiz=&amp;#34;, size, &amp;#34;\n&amp;#34;) 44 } 45 return c 46} 可以看到，makechan方法主要就是检查传送元素的合法性，并为hchan分配内存，初始化相关参数，包括对锁的初始化。
  发送   channel的发送实现代码位于src/go/runtime/chan.go的chansend方法。发送过程，存在以下几种情况。
a. 当发送的channel为nil
1if c == nil { 2 if !block { 3 return false 4 } 5 gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2) 6 throw(&amp;#34;unreachable&amp;#34;) 7} 往一个nil的channel中发送数据时，调用gopark函数将当前执行的goroutine从running态转入waiting态。
b. 往已关闭的channel中发送数据
1 if c.closed != 0 { 2 unlock(&amp;amp;c.lock) 3 panic(plainError(&amp;#34;send on closed channel&amp;#34;)) 4 } 如果向已关闭的channel中发送数据，会引发panic。
c. 如果已经有阻塞的接收goroutines（即recvq中指向非空），那么数据将被直接发送给接收goroutine
1if sg := c.recvq.dequeue(); sg != nil { 2 // Found a waiting receiver. We pass the value we want to send 3 // directly to the receiver, bypassing the channel buffer (if any). 4 send(c, sg, ep, func() { unlock(&amp;amp;c.lock) }, 3) 5 return true 6} 该逻辑的实现代码在send方法和sendDirect中。
 1func send(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) {  2 ... // 省略了竞态代码  3 if sg.elem != nil {  4 sendDirect(c.elemtype, sg, ep)  5 sg.elem = nil  6 }  7 gp := sg.g  8 unlockf()  9 gp.param = unsafe.Pointer(sg) 10 if sg.releasetime != 0 { 11 sg.releasetime = cputicks() 12 } 13 goready(gp, skip&#43;1) 14} 15 16func sendDirect(t *_type, sg *sudog, src unsafe.Pointer) { 17 dst := sg.elem 18 typeBitsBulkBarrier(t, uintptr(dst), uintptr(src), t.size) 19 memmove(dst, src, t.size) 20} 其中，memmove我们已经在源码系列中遇到多次了，它的目的是将内存中src的内容拷贝至dst中去。另外，注意到goready(gp, skip&#43;1)这句代码，它会使得之前在接收等待队列中的第一个goroutine的状态变为runnable，这样go的调度器就可以重新让该goroutine得到执行。
d. 对于有缓冲的channel来说，如果当前缓冲区hchan.buf有可用空间，那么会将数据拷贝至缓冲区
 1if c.qcount &amp;lt; c.dataqsiz {  2 qp := chanbuf(c, c.sendx)  3 if raceenabled {  4 raceacquire(qp)  5 racerelease(qp)  6 }  7 typedmemmove(c.elemtype, qp, ep)  8 // 发送索引号&#43;1  9 c.sendx&#43;&#43; 10 // 因为存储数据元素的结构是循环队列，所以当当前索引号已经到队末时，将索引号调整到队头 11 if c.sendx == c.dataqsiz { 12 c.sendx = 0 13 } 14 // 当前循环队列中存储元素数&#43;1 15 c.qcount&#43;&#43; 16 unlock(&amp;amp;c.lock) 17 return true 18} 其中，chanbuf(c, c.sendx)是获取指向对应内存区域的指针。typememmove会调用memmove方法，完成数据的拷贝工作。另外注意到，当对hchan进行实际操作时，是需要调用lock(&amp;amp;c.lock)加锁，因此，在完成数据拷贝后，通过unlock(&amp;amp;c.lock)将锁释放。
e. 有缓冲的channel，当hchan.buf已满；或者无缓冲的channel，当前没有接收的goroutine
 1gp := getg()  2mysg := acquireSudog()  3mysg.releasetime = 0  4if t0 != 0 {  5 mysg.releasetime = -1  6}  7// No stack splits between assigning elem and enqueuing mysg  8// on gp.waiting where copystack can find it.  9mysg.elem = ep 10mysg.waitlink = nil 11mysg.g = gp 12mysg.isSelect = false 13mysg.c = c 14gp.waiting = mysg 15gp.param = nil 16c.sendq.enqueue(mysg) 17gopark(chanparkcommit, unsafe.Pointer(&amp;amp;c.lock), waitReasonChanSend, traceEvGoBlockSend, 2) 通过getg获取当前执行的goroutine。acquireSudog是先获得当前执行goroutine的线程M，再获取M对应的P，最后将P的sudugo缓存队列中的队头sudog取出（详见源码src/runtime/proc.go）。通过c.sendq.enqueue将sudug加入到channel的发送等待列表中，并调用gopark将当前goroutine转为waiting态。
 发送操作会对hchan加锁。 当recvq中存在等待接收的goroutine时，数据元素将会被直接拷贝给接收goroutine。 当recvq等待队列为空时，会判断hchan.buf是否可用。如果可用，则会将发送的数据拷贝至hchan.buf中。 如果hchan.buf已满，那么将当前发送goroutine置于sendq中排队，并在运行时中挂起。 向已经关闭的channel发送数据，会引发panic。  对于无缓冲的channel来说，它天然就是hchan.buf已满的情况，因为它的hchan.buf的容量为0。
 1package main  2  3import &amp;#34;time&amp;#34;  4  5func main() {  6 ch := make(chan int)  7 go func(ch chan int) {  8 ch &amp;lt;- 100  9 }(ch) 10 time.Sleep(time.Millisecond * 500) 11 time.Sleep(time.Second) 12} 在上述示例中，发送goroutine向无缓冲的channel发送数据，但是没有接收goroutine。将断点置于time.Sleep(time.Second)，得到此时ch结构如下。
可以看到，在无缓冲的channel中，其hchan的buf长度为0，当没有接收groutine时，发送的goroutine将被置于sendq的发送队列中。
  接收   channel的接收实现分两种，v :=&amp;lt;-ch对应于chanrecv1，v, ok := &amp;lt;- ch对应于chanrecv2，但它们都依赖于位于src/go/runtime/chan.go的chanrecv方法。
1func chanrecv1(c *hchan, elem unsafe.Pointer) { 2 chanrecv(c, elem, true) 3} 4 5func chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) { 6 _, received = chanrecv(c, elem, true) 7 return 8} chanrecv的详细代码此处就不再展示，和chansend逻辑对应，具体处理准则如下。
 接收操作会对hchan加锁。 当sendq中存在等待发送的goroutine时，意味着此时的hchan.buf已满（无缓存的天然已满），分两种情况（见代码src/go/runtime/chan.go的recv方法）：1. 如果是有缓存的hchan，那么先将缓冲区的数据拷贝给接收goroutine，再将sendq的队头sudog出队，将出队的sudog上的元素拷贝至hchan的缓存区。2. 如果是无缓存的hchan，那么直接将出队的sudog上的元素拷贝给接收goroutine。两种情况的最后都会唤醒出队的sudog上的发送goroutine。 当sendq发送队列为空时，会判断hchan.buf是否可用。如果可用，则会将hchan.buf的数据拷贝给接收goroutine。 如果hchan.buf不可用，那么将当前接收goroutine置于recvq中排队，并在运行时中挂起。 与发送不同的是，当channel关闭时，goroutine还能从channel中获取数据。如果recvq等待列表中有goroutines，那么它们都会被唤醒接收数据。如果hchan.buf中还有未接收的数据，那么goroutine会接收缓冲区中的数据，否则goroutine会获取到元素的零值。  以下是channel关闭之后，接收goroutine的读取示例代码。
 1func main() {  2 ch := make(chan int, 1)  3 ch &amp;lt;- 10  4 close(ch)  5 a, ok := &amp;lt;-ch  6 fmt.Println(a, ok)  7 b, ok := &amp;lt;-ch  8 fmt.Println(b, ok)  9 c := &amp;lt;-ch 10 fmt.Println(c) 11} 12 13//输出如下 1410 true 150 false 160 注意：在channel中进行的所有元素转移都伴随着内存的拷贝。
 1func main() {  2 type Instance struct {  3 ID int  4 name string  5 }  6  7 var ins = Instance{ID: 1, name: &amp;#34;Golang&amp;#34;}  8  9 ch := make(chan Instance, 3) 10 ch &amp;lt;- ins 11 12 fmt.Println(&amp;#34;ins的原始值：&amp;#34;, ins) 13 14 ins.name = &amp;#34;Python&amp;#34; 15 go func(ch chan Instance) { 16 fmt.Println(&amp;#34;channel接收值：&amp;#34;, &amp;lt;-ch) 17 }(ch) 18 19 time.Sleep(time.Second) 20 fmt.Println(&amp;#34;ins的最终值：&amp;#34;, ins) 21} 22 23// 输出结果 24ins的原始值： {1 Golang} 25channel接收值： {1 Golang} 26ins的最终值： {1 Python} 前半段图解如下
后半段图解如下
注意: 如果把channel传递类型替换为Instance指针时，那么尽管channel存入到buf中的元素已经是拷贝对象了，从channel中取出又被拷贝了一次。但是由于它们的类型是Instance指针，拷贝对象与原始对象均会指向同一个内存地址，修改原有元素对象的数据时，会影响到取出数据。
 1func main() {  2 type Instance struct {  3 ID int  4 name string  5 }  6  7 var ins = &amp;amp;Instance{ID: 1, name: &amp;#34;Golang&amp;#34;}  8  9 ch := make(chan *Instance, 3) 10 ch &amp;lt;- ins 11 12 fmt.Println(&amp;#34;ins的原始值：&amp;#34;, ins) 13 14 ins.name = &amp;#34;Python&amp;#34; 15 go func(ch chan *Instance) { 16 fmt.Println(&amp;#34;channel接收值：&amp;#34;, &amp;lt;-ch) 17 }(ch) 18 19 time.Sleep(time.Second) 20 fmt.Println(&amp;#34;ins的最终值：&amp;#34;, ins) 21} 22 23// 输出结果 24ins的原始值： &amp;amp;{1 Golang} 25channel接收值： &amp;amp;{1 Python} 26ins的最终值： &amp;amp;{1 Python} 因此，在使用channel时，尽量避免传递指针，如果传递指针，则需谨慎。
  关闭   channel的关闭实现代码位于src/go/runtime/chan.go的chansend方法，详细执行逻辑已通过注释写明。
 1func closechan(c *hchan) {  2 // 如果hchan对象为nil，则会引发painc  3 if c == nil {  4 panic(plainError(&amp;#34;close of nil channel&amp;#34;))  5 }  6  7 // 对hchan加锁  8 lock(&amp;amp;c.lock)  9 // 不同多次调用close(c chan&amp;lt;- Type)方法，否则会引发painc 10 if c.closed != 0 { 11 unlock(&amp;amp;c.lock) 12 panic(plainError(&amp;#34;close of closed channel&amp;#34;)) 13 } 14 15 if raceenabled { 16 callerpc := getcallerpc() 17 racewritepc(c.raceaddr(), callerpc, funcPC(closechan)) 18 racerelease(c.raceaddr()) 19 } 20 21 // close标志 22 c.closed = 1 23 24 // gList代表Go的GMP调度的G集合 25 var glist gList 26 27 // 该for循环是为了释放recvq上的所有等待接收sudog 28 for { 29 sg := c.recvq.dequeue() 30 if sg == nil { 31 break 32 } 33 if sg.elem != nil { 34 typedmemclr(c.elemtype, sg.elem) 35 sg.elem = nil 36 } 37 if sg.releasetime != 0 { 38 sg.releasetime = cputicks() 39 } 40 gp := sg.g 41 gp.param = nil 42 if raceenabled { 43 raceacquireg(gp, c.raceaddr()) 44 } 45 glist.push(gp) 46 } 47 48 // 该for循环会释放sendq上的所有等待发送sudog 49 for { 50 sg := c.sendq.dequeue() 51 if sg == nil { 52 break 53 } 54 sg.elem = nil 55 if sg.releasetime != 0 { 56 sg.releasetime = cputicks() 57 } 58 gp := sg.g 59 gp.param = nil 60 if raceenabled { 61 raceacquireg(gp, c.raceaddr()) 62 } 63 glist.push(gp) 64 } 65 // 释放sendq和recvq之后，hchan释放锁 66 unlock(&amp;amp;c.lock) 67 68 // 将上文中glist中的加入的goroutine取出，让它们均变为runnable（可执行）状态，等待调度器执行 69 // 注意：我们上文中分析过，试图向一个已关闭的channel发送数据，会引发painc。 70 // 所以，如果是释放sendq中的goroutine，它们一旦得到执行将会引发panic。 71 for !glist.empty() { 72 gp := glist.pop() 73 gp.schedlink = 0 74 goready(gp, 3) 75 } 76} 关于关闭操作，有几个点需要注意一下。
 如果关闭已关闭的channel会引发painc。 对channel关闭后，如果有阻塞的读取或发送goroutines将会被唤醒。读取goroutines会获取到hchan的已接收元素，如果没有，则获取到元素零值；发送goroutine的执行则会引发painc。  对于第二点，我们可以很好利用这一特性来实现对程序执行流的控制（类似于sync.WaitGroup的作用），以下是示例程序代码。
 1func main() {  2 ch := make(chan struct{})  3 //  4 go func() {  5 // do something work...  6 // when work has done, call close()  7 close(ch)  8 }()  9 // waiting work done 10 &amp;lt;- ch 11 // other work continue... 12} 总结
channel是Go中非常强大有用的机制，为了更有效地使用它，我们必须了解它的实现原理，这也是写作本文的目的。
 hchan结构体有锁的保证，对于并发goroutine而言是安全的 channel接收、发送数据遵循FIFO（First In First Out）原语 channel的数据传递依赖于内存拷贝 channel能阻塞（gopark）、唤醒（goready）goroutine 所谓无缓存的channel，它的工作方式就是直接发送goroutine拷贝数据给接收goroutine，而不通过hchan.buf  另外，可以看到Go在channel的设计上权衡了简单与性能。为了简单性，hchan是有锁的结构，因为有锁的队列会更易理解和实现，但是这样会损失一些性能。考虑到整个 channel 操作带锁的成本较高，其实官方也曾考虑过使用无锁 channel 的设计，但是由于目前已有提案中（https://github.com/golang/go/issues/8899），无锁实现的channel可维护性差、且实际性能测试不具有说服力，而且也不符合Go的简单哲学，因此官方目前为止并没有采纳无锁设计。
在性能上，有一点，我们需要认识到：所谓channel中阻塞goroutine，只是在runtime系统中被blocked，它是用户层的阻塞。而实际的底层内核线程不受影响，它仍然是unblocked的。
 参考链接 https://speakerdeck.com/kavya719/understanding-channels
https://codeburst.io/diving-deep-into-the-golang-channels-549fd4ed21a8
https://github.com/talkgo/night/issues/450
以上内容转载自机器铃砍柴刀
</content>
    </entry>
    
     <entry>
        <title>Go函数调用惯例</title>
        <url>http://shanks.link/blog/2021/04/28/go%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E6%83%AF%E4%BE%8B/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Go函数调用惯例 本文旨在探讨Go函数中的一个问题：**为什么Go函数能支持多参数返回，而C/C&#43;&#43;、java不行？**这其实牵涉到了一个叫做函数调用惯例的问题。
调用惯例
在程序代码中，函数提供了最小功能单元，程序执行实际上就是函数间相互调用的过程。在调用时，函数调用方和被调用方必须遵守某种约定，它们的理解要一致，该约定就被称为函数调用惯例。
函数调用惯例往往由编译器来规定，本文主要关心两个点：
  函数的参数（入参与出参）是通过栈还是寄存器传递？
  如果通过栈传递，是从左至右，还是从右至左入栈？
  栈   栈是现代计算机程序里最为重要的概念之一，没有栈就没有函数，也没有局部变量。栈保存了一个函数调用所需要的维护信息，这常常被称为堆栈帧(Stack Frame)或活动记录 (Activate Record)。堆栈帧一般包括如下几方面内容：
 函数的返回地址和参数。 临时变量:包括函数的非静态局部变量以及编译器自动生成的其他临时变量。 保存的上下文信息:包括在函数调用前后需要保持不变的寄存器。  一个堆栈帧可以用指向栈顶的栈指针寄存器SP与维护当前栈帧的基准地址的基准指针寄存器BP来表示。因此，一个典型的函数活动记录可以表示为如下
在参数及其之后的数据即当前函数的活动记录。BP固定在图中所示的位置（通过它便于索引参数与变量等），它不会随着函数的执行而变化。而SP始终指向栈顶，随着函数的执行，SP会不断变化。在BP之前是该函数的返回地址，在32位机器表示为BP&#43;4，64位机器表示为BP&#43;8，再往前就是压入栈中的参数。BP所直接指向的数据是调用该函数前BP的值，这样在函数返回的时候，BP可以通过读取这个值恢复到调用前的值。
  汇编代码解析   下面，我们来对比分析C和Go调用惯例差异。
 C调用惯例  假设有main.c的C程序源文件，其中main函数调用add函数，详细代码如下。
1// main.c 2int add(int arg1, int arg2, int arg3, int arg4,int arg5, int arg6,int arg7, int arg8) { 3 return arg1 &#43; arg2 &#43; arg3 &#43; arg4 &#43; arg5 &#43; arg6 &#43; arg7 &#43; arg8; 4} 5 6int main() { 7 int i = add(10, 20, 30, 40, 50, 60, 70, 80); 8} 我们通过clang编译器在x86_64平台上进行编译。
1$ clang -v 2Apple clang version 12.0.0 (clang-1200.0.32.29) 3Target: x86_64-apple-darwin19.5.0 main.c 编译后得到的汇编代码如下
 1 $ clang -S main.c  2 ...  3_main:  4 ...  5 subq $32, %rsp  6 movl $10, %edi // 将参数1数据置于edi寄存器  7 movl $20, %esi // 将参数2数据置于esi寄存器  8 movl $30, %edx // 将参数3数据置于edx寄存器  9 movl $40, %ecx // 将参数4数据置于ecx寄存器 10 movl $50, %r8d // 将参数5数据置于r8d寄存器 11 movl $60, %r9d // 将参数6数据置于r9d寄存器 12 movl $70, (%rsp) // 将参数7数据置于栈上 13 movl $80, 8(%rsp) // 将参数8数据置于栈上 14 callq _add // 调用add函数 15 xorl %ecx, %ecx 16 movl %eax, -4(%rbp) 17 movl %ecx, %eax // 最终通过eax寄存器承载着返回值返回 18 addq $32, %rsp 19 popq %rbp 20 retq 21 ... 22_add: 23 ... 24 movl 24(%rbp), %eax 25 movl 16(%rbp), %r10d 26 movl %edi, -4(%rbp) // 将edi寄存器上的数据放置于栈上 27 movl %esi, -8(%rbp) // 将esi寄存器上的数据放置于栈上 28 movl %edx, -12(%rbp) // 将edx寄存器上的数据放置于栈上 29 movl %ecx, -16(%rbp) // 将ecx寄存器上的数据放置于栈上 30 movl %r8d, -20(%rbp) // 将r8d寄存器上的数据放置于栈上 31 movl %r9d, -24(%rbp) // 将edi寄存器上的数据放置于栈上 32 movl -4(%rbp), %ecx // 将栈上的数据 10 放置于ecx寄存器 33 addl -8(%rbp), %ecx // 实际为：ecx = ecx &#43; 20 34 addl -12(%rbp), %ecx // ecx = ecx &#43; 30 35 addl -16(%rbp), %ecx // ecx = ecx &#43; 40 36 addl -20(%rbp), %ecx // ecx = ecx &#43; 50 37 addl -24(%rbp), %ecx // ecx = ecx &#43; 60 38 addl 16(%rbp), %ecx // ecx = ecx &#43; 70 39 addl 24(%rbp), %ecx // ecx = ecx &#43; 80 40 movl %eax, -28(%rbp) 41 movl %ecx, %eax // 最终通过eax寄存器承载着返回值返回 42 popq %rbp 43 retq 44 ... 因此，在main函数调用add函数之前，其参数存放如下图所示
调用add函数后的数据存放如下图所示
因此，对于默认的C语言调用惯例（cdecl调用惯例），我们可以得出以下结论
 当函数参数不超过六个时，其参数会按照顺序分别使用 edi、esi、edx、ecx、r8d 和 r9d 六个寄存器进行传递； 当参数超过六个，那么超过的参数会使用栈传递，函数的参数会以从右到左的顺序依次入栈  C语言函数的返回值是通过寄存器传递完成的，不过根据返回值的大小，有以下三种情况。
 小于4字节，返回值存入eax寄存器，由函数调用方读取eax的值 返回值5到8字节，采用eax和edx寄存器联合返回 大于8个字节，首先在栈上额外开辟一部分空间temp，将temp对象的地址做为隐藏参数入栈。函数返回时将数据拷贝给temp对象，并将temp对象的地址用寄存器eax传出。调用方从eax指向的temp对象拷贝内容。  可以看到，由于采用了寄存器传递返回值的设计，C语言的返回值只能有一个，这里回答了C为什么不能实现函数多值返回。
 Go函数调用惯例  假设有main.go的Go程序源文件，和C中例子一样，其中main函数调用add函数，详细代码如下。
1package main 2 3func add(arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8 int) int { 4 return arg1 &#43; arg2 &#43; arg3 &#43; arg4 &#43; arg5 &#43; arg6 &#43; arg7 &#43; arg8 5} 6 7func main() { 8 _ = add(10, 20, 30, 40, 50, 60, 70, 80) 9} 使用go tool compile -S -N -l main.go 命令编译得到如下汇编代码
 1&amp;#34;&amp;#34;.main STEXT size=122 args=0x0 locals=0x50  2 // 80代表栈帧大小为80个字节，0是入参和出参大小之和  3 0x0000 00000 (main.go:7) TEXT &amp;#34;&amp;#34;.main(SB), ABIInternal, $80-0  4 ...  5 0x000f 00015 (main.go:7) SUBQ $80, SP  6 0x0013 00019 (main.go:7) MOVQ BP, 72(SP)  7 0x0018 00024 (main.go:7) LEAQ 72(SP), BP  8 ...  9 0x001d 00029 (main.go:8) MOVQ $10, (SP) // 将数据填置栈上 10 0x0025 00037 (main.go:8) MOVQ $20, 8(SP) 11 0x002e 00046 (main.go:8) MOVQ $30, 16(SP) 12 0x0037 00055 (main.go:8) MOVQ $40, 24(SP) 13 0x0040 00064 (main.go:8) MOVQ $50, 32(SP) 14 0x0049 00073 (main.go:8) MOVQ $60, 40(SP) 15 0x0052 00082 (main.go:8) MOVQ $70, 48(SP) 16 0x005b 00091 (main.go:8) MOVQ $80, 56(SP) 17 0x0064 00100 (main.go:8) PCDATA $1, $0 18 0x0064 00100 (main.go:8) CALL &amp;#34;&amp;#34;.add(SB) // 调用add函数 19 0x0069 00105 (main.go:9) MOVQ 72(SP), BP 20 0x006e 00110 (main.go:9) ADDQ $80, SP 21 0x0072 00114 (main.go:9) RET 22 ... 23 24&amp;#34;&amp;#34;.add STEXT nosplit size=55 args=0x48 locals=0x0 25 // add栈帧大小为0字节，72是 8个入参 &#43; 1个出参 的字节大小之和 26 0x0000 00000 (main.go:3) TEXT &amp;#34;&amp;#34;.add(SB), NOSPLIT|ABIInternal, $0-72 27 ... 28 0x0000 00000 (main.go:3) MOVQ $0, &amp;#34;&amp;#34;.~r8&#43;72(SP) // 初始化返回值，将其置为0 29 0x0009 00009 (main.go:4) MOVQ &amp;#34;&amp;#34;.arg1&#43;8(SP), AX // 开始将栈上的值放置在AX寄存器上 30 0x000e 00014 (main.go:4) ADDQ &amp;#34;&amp;#34;.arg2&#43;16(SP), AX // AX = AX &#43; 20 31 0x0013 00019 (main.go:4) ADDQ &amp;#34;&amp;#34;.arg3&#43;24(SP), AX 32 0x0018 00024 (main.go:4) ADDQ &amp;#34;&amp;#34;.arg4&#43;32(SP), AX 33 0x001d 00029 (main.go:4) ADDQ &amp;#34;&amp;#34;.arg5&#43;40(SP), AX 34 0x0022 00034 (main.go:4) ADDQ &amp;#34;&amp;#34;.arg6&#43;48(SP), AX 35 0x0027 00039 (main.go:4) ADDQ &amp;#34;&amp;#34;.arg7&#43;56(SP), AX 36 0x002c 00044 (main.go:4) ADDQ &amp;#34;&amp;#34;.arg8&#43;64(SP), AX 37 0x0031 00049 (main.go:4) MOVQ AX, &amp;#34;&amp;#34;.~r8&#43;72(SP) // 将结果AX填置到对应栈上位置 38 0x0036 00054 (main.go:4) RET 39 ... 同样的，我们将main函数调用add函数时，其参数存放可视化出来如下所示
这里我们可以看到，add函数的入参压栈顺序和C一样，都是从右至左，即最后一个参数在靠近栈底方向的SP&#43;56~SP&#43;64，而第一个参数是在栈顶SP~SP&#43;8。
调用add函数后的数据存放如下图所示
注意，这里与C中调用不同的是，由于通过栈传递参数，所以并不需要将寄存器中保存的参数再拷贝至栈上。在本例中，add帧直接调用main帧栈上的数据进行计算即可。通过将结果累加到AX寄存器上，最后再将最终的返回值置回栈中即可，返回值的位置是在最后一个入参之上。
因此我们知道，Go函数的出入参均是通过栈来传递的。所以，如果想返回多值，那么仅需要在栈上多分配一些内存即可。到这里也就回答了文章开头的问题。
总结
在函数调用惯例中，C语言和Go语言选择了不同的实现方式。C语言同时使用了寄存器与栈传递参数，而Go语言除了在函数计算过程中会临时使用例如AX这种累加寄存器之外，全部是通过栈完成参数的传递。
任何选择都会有它的优劣所在，总体来讲，C语言实现方式更多地是考虑性能，Go语言实现方式更多地是考虑复杂度。下面，我们详细比较一下两种调用惯例。
C语言方式 CPU访问寄存器的效率会明显高于栈；
不同平台的寄存器存在差异，需要为每种架构设定对应的寄存器传递规则；
参数过多时，需要同时使用寄存器与栈传递，增加了实现复杂度，且此时函数调用性能和Go语言方式差别不再大；
只能支持一个返回值。
Go语言方式 遵循Go语言的跨平台编译理念：都是通过栈传递，因此不用担心架构不同带来的寄存器差异；
参数较少的情况下，函数调用性能会比C语言方式低；
编译器易于维护；
可以支持多返回值。
以上内容转载自机器铃砍柴刀
</content>
    </entry>
    
     <entry>
        <title>CPU缓存体系对程序的影响</title>
        <url>http://shanks.link/blog/2021/04/28/cpu%E7%BC%93%E5%AD%98%E4%BD%93%E7%B3%BB%E5%AF%B9%E7%A8%8B%E5%BA%8F%E7%9A%84%E5%BD%B1%E5%93%8D/</url>
        <categories>
          <category>algorithm</category>
        </categories>
        <tags>
          <tag>cpu</tag><tag>cache</tag>
        </tags>
        <content type="html"> CPU缓存体系对Go程序的影响 小菜刀最近在medium上阅读了一篇高赞文章《Go and CPU Caches》，其地址为https://teivah.medium.com/go-and-cpu-caches-af5d32cc5592，感觉收获颇多。小菜刀在该文章的基础上做了些修改和扩展，整理出来分享给读者朋友们。
CPU缓存体系
现代计算机处理器架构多数采用对称多处理系统（Symmetric multiprocessing system，SMS）。在这个系统中，每一个核心都当成是独立的处理器，多处理器被连接到同一个共享的主存上，并由单一操作系统来控制。
为了加速内存访问，处理器有着不同级别的缓存，分别是 L1、L2 和 L3。确切的体系结构可能因供应商、处理器模型等而异。目前最常见的架构是把 L1 和 L2 缓存内嵌在 CPU 核心本地，而把 L3 缓存设计成跨核心共享。
一个CPU通常包含多个核心，每个CPU核心拥有L1 Cache和 L2 Cache，在L1 Cache中又分为dCache（数据缓存）和iCache（指令缓存），同时多核心共享L3 Cache。
越靠近CPU核心的缓存，其容量越小，但是访问延迟越低。
当然，这些具体的数字会因处理器模型而异。不过，可以得出明显的结论就是，处理器访问L1缓存的速度远远快过直接访问主存，它们至少相差数十倍。
CPU从主存中读取数据至Cache时，并非单个字节形式进行读取，而是以连续内存块的方式进行拷贝，拷贝块内存的单元被称为缓存行（Cache Line）。这样做的理论依据是著名的局部性原理。
 时间局部性（temporal locality）：如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。 空间局部性（spatial locality）：在最近的将来将用到的信息很可能与现在正在使用的信息在空间地址上是临近的。  L1的缓存行大小一般是64字节， L2和L3高速缓存行的大小大于或等于L1高速缓存行大小，通常不超过L1高速缓存行大小的两倍。同时，L2和L3高速缓存的高速缓存行需要小于内存页（一般是4kb）。
以小菜刀的电脑为例，以下是系统报告
但是，这里没有展示出L1 Cache及其缓存行的大小，我们可通过以下命令方式获取，得知本机的缓存行大小为64字节。
1$ sysctl -a | egrep &amp;#39;cachesize|cachelinesize&amp;#39; 2hw.cachesize: 8589934592 32768 262144 6291456 0 0 0 0 0 0 3hw.cachelinesize: 64 4hw.l1icachesize: 32768 5hw.l1dcachesize: 32768 6hw.l2cachesize: 262144 7hw.l3cachesize: 6291456 这意味着，如果处理器需要拷贝一个int64类型组成的Go切片到缓存中时，它会单次一起拷贝8个元素，而不是单个拷贝。如果我们的程序能让数据是以连续内存的方式存储（例如数组），这样当处理器访问数据元素时，缓存命中率就会很高。通过减少从内存中读取数据的频率，从而提高程序的性能。
缓存行在Go程序中的具体应用
来看一个具体的例子，该例为我们展示了利用CPU缓存带来的好处。
 1func createMatrix(size int) [][]int64 {  2 matrix := make([][]int64, size)  3 for i := 0; i &amp;lt; size; i&#43;&#43; {  4 matrix[i] = make([]int64, size)  5 }  6 return matrix  7}  8  9const matrixLength = 6400 10 11func BenchmarkMatrixCombination(b *testing.B) { 12 matrixA := createMatrix(matrixLength) 13 matrixB := createMatrix(matrixLength) 14 15 for n := 0; n &amp;lt; b.N; n&#43;&#43; { 16 for i := 0; i &amp;lt; matrixLength; i&#43;&#43; { 17 for j := 0; j &amp;lt; matrixLength; j&#43;&#43; { 18 matrixA[i][j] = matrixA[i][j] &#43; matrixB[i][j] 19 } 20 } 21 } 22} 23 24func BenchmarkMatrixReversedCombination(b *testing.B) { 25 matrixA := createMatrix(matrixLength) 26 matrixB := createMatrix(matrixLength) 27 28 for n := 0; n &amp;lt; b.N; n&#43;&#43; { 29 for i := 0; i &amp;lt; matrixLength; i&#43;&#43; { 30 for j := 0; j &amp;lt; matrixLength; j&#43;&#43; { 31 matrixA[i][j] = matrixA[i][j] &#43; matrixB[j][i] 32 } 33 } 34 } 35} 在上述的代码中，有两个6400*6400的初始化数组矩阵A和B，将A和B的元素进行相加，第一种方式是对应行列坐标相加，即matrixA[i][j] = matrixA[i][j] &#43; matrixB[i][j]，第二种方式是对称行列坐标相加，即matrixA[i][j] = matrixA[i][j] &#43; matrixB[j][i]。那这两种不同的相加方式，会有什么样的结果呢？
1BenchmarkMatrixCombination-8 16 67211689 ns/op 2BenchmarkMatrixReversedCombination-8 3 480798925 ns/op 可以看到，两种相加方式，性能差异竟然接近十倍，这是为什么呢？
接下来，我们通过几幅图来更直观地理解中间发生了什么。蓝色圆圈代表矩阵A的当前元素坐标，粉红色圆圈代表了矩阵B的当前元素坐标。在第二种相加方式中，由于程序的操作是 matrixA[i][j] = matrixA[i][j] &#43; matrixB[j][i] ，所以当矩阵A的元素坐标为 (4,0) 时，矩阵B对应的元素坐标就是 (0,4)。
**注：**在此图中，我们用横坐标和纵坐标表示矩阵，并且（0,0）代表是矩阵的左上角坐标。在实际的计算机存储中，一个矩阵所有的行将会被分配到一片连续的内存上。不过为了更直观地表示，我们这里还是按照数学的表示方法。
此外，在此后的示例中，我们将矩阵大小设定为缓存行大小的倍数。因此，缓存行不会在下一行“超载”。
我们如何在两个矩阵中遍历的？
蓝色圆圈向右移动，直到到达最后一列，然后移动到位置（5,0）的下一行，依此类推。相反地，红色圆圈向下移动，然后转到下一列。
当粉红色圆圈在坐标 (0,4) 之时，处理器会缓存指针所在那一行 (在这个示意图里，我们假设缓存行的大小是 4 个元素)。因此，当粉红色圆圈到达坐标 (0,.5) 时，我们可以认为该坐标上的变量已经存在与L1 cache中了吗？这实际上取决于矩阵的大小。
如果矩阵的大小与L1 Cache的大小相比足够小，那么答案是肯定的，坐标 (0,5)处的元素已经在L1 Cache中。否则，该缓存行就会在访问坐标 (0,5) 之前就被清出 L1。此时，将会产生一个缓存缺失，然后处理器就不得不通过别的方式访问该变量 (比如从 L2 里去取)。此时，程序的状态将会是这样的：
那么，矩阵的大小应该是多大才能从充分利用L1 Cache呢？让我们做一些数学运算。
1$ sysctl hw.l1dcachesize 2hw.l1dcachesize: 32768 以小菜刀的机器为例，L1 的数据缓存大小为32kb。但L1缓存行的大小为64字节。因此，我可以在L1 数据缓存中存储多达512条缓存行。那么，我们如果将上例中的矩阵大小matrixLength改为512会怎样？以下是基准测试结果。
1BenchmarkMatrixCombination-8 3379 360017 ns/op 2BenchmarkMatrixReversedCombination-8 1801 585807 ns/op 尽管我们已经将两中测试用例的性能差距缩小了很多 (用 6400 大小的矩阵测的时候，第二个要慢了大约 700%)，但我们还是可以看到会有明显的差距。那是哪里有问题呢？
在基准测试中，我们处理的是两个矩阵，因此CPU必须为两者均存储缓存行。在完全理想的环境下（在压测时没有其他任何程序在运行，但这是肯定不可能的），L1缓存将用一半的容量来存储第一个矩阵，另外一半的容量存储第二个矩阵。那我们再对两个矩阵大小进行4倍压缩，即matrixLength为128（原文中是256时接近相等，但在小菜刀机器上实测是128个元素才接近相等），看看此时的基准测试情况。
1BenchmarkMatrixCombination-8 64750 17665 ns/op 2BenchmarkMatrixReversedCombination-8 57712 20404 ns/op 此时，我们终于到达了两个结果（接近）相等的地步。
通过上面的尝试，我们应该知道在处理大容量矩阵时，应该如何减少CPU缓存带来的影响。这里介绍一种循环嵌套优化的技术（loop nest optimization）：在遍历矩阵时，每次都以一个固定大小的矩阵块为单位来遍历，以此最大化利用CPU缓存。
在以下示例中，我们将一个矩阵块定义为4*4元素大小。在第一个矩阵中，我们从 (4,0) 遍历至 (4,3)，然后再切换到下一行。在第二个矩阵中从 (0,4) 遍历至 (3,4) ，然后切换到下一列。
当粉红色圆圈遍历完第一列时，处理器将相应的所有存储行都存储到L1中去了。因此，对矩形块其他元素的遍历就是直接从L1里访问了，这能明显提高访问速度。
我们将上述技术通过Go实现。首先，我们必须谨慎选择块的大小。在前面的示例中，我们矩阵一行元素的内存大小等于缓存行的容量。它不应该比这再小了，否则的话我们的缓存行中会存储一些不会被访问的元素数据，这浪费缓存行的空间。在Go基准测试中，我们存储的元素类型为int64（8个字节）。因为缓存行的大小是64字节，即8个元素大小。那么，矩形块的大小应该至少为8。
 1func BenchmarkMatrixReversedCombinationPerBlock(b *testing.B) {  2 matrixA := createMatrix(matrixLength)  3 matrixB := createMatrix(matrixLength)  4 blockSize := 8  5  6 for n := 0; n &amp;lt; b.N; n&#43;&#43; {  7 for i := 0; i &amp;lt; matrixLength; i &#43;= blockSize {  8 for j := 0; j &amp;lt; matrixLength; j &#43;= blockSize {  9 for ii := i; ii &amp;lt; i&#43;blockSize; ii&#43;&#43; { 10 for jj := j; jj &amp;lt; j&#43;blockSize; jj&#43;&#43; { 11 matrixA[ii][jj] = matrixA[ii][jj] &#43; matrixB[jj][ii] 12 } 13 } 14 } 15 } 16 } 17} 此时matrixLength为6400，它与最初直接遍历的方式相比结果如下。
1BenchmarkMatrixReversedCombinationPerBlock-8 6 184520538 ns/op 2BenchmarkMatrixReversedCombination-8 3 480904016 ns/op 可以看到，通过加入小的遍历矩形块后，我们的整体遍历速度已经是最初版本的3倍了，充分利用CPU缓存特性能够潜在帮助我们设计更高效的算法。
​ 缓存一致性与伪共享问题
*Cache Coherency* &amp;amp; *False Sharing*
注意，第一个例子呈现的是一个单线程程序，当使用多线程时，我们会遇到缓存伪共享的问题。首先，理解伪共享，需要先理解缓存一致性。
假设有一个双核CPU，两个核心上并行运行着不同的线程，它们同时从内存中读取两个不同的数据A和B，如果这两个数据在物理内存上是连续的（或者非常接近），那么就会出现在两个核心的L1 Cache中均存在var1和var2的情况。
通过前文我们知道，为了提高数据访问效率，每个CPU核心上都内嵌了一个容量小，但速度快的缓存体系，用于保存最常访问的那些数据。因为CPU直接访问内存的速度实在太慢，因此当数据被修改时，处理器也会首先只更改缓存中的内容，并不会马上将更改写回到内存中去，那么这样就会产生问题。
以上图为例，如果此时两个处于不同核心的线程1和线程2都试图去修改数据，例如线程1修改数据A，线程2修改数据B，这样就造成了在各缓存之间，缓存与内存之间数据均不一致。此时在线程1中看到的数据B和线程2中看到的数据A不再一样（或者如果有更多核上搭载的线程，它们从内存中取的还是老数据），即存在脏数据，这给程序带来了巨大隐患。因此有必要维护多核的缓存一致性。
缓存一致性的朴素解决思想也比较简单：只要在多核共享缓存行上有数据修改操作，就通知所有的CPU核更新缓存，或者放弃缓存，等待下次访问的时候再重新从内存中读取。
但很明显，这样的约束条件会对程序性能有所影响，目前有很多维护缓存一致性的协议，其中，最著名的是Intel CPU中使用的MESI缓存一致性协议。
MESI协议 理解MESI协议前，我们需要知道的是：所有cache与内存，cache与cache之间的数据传输都发生在一条共享的数据总线上，所有的cpu核都能看到这条总线。
MESI协议是一种监听协议，cahce不但与内存通信时和总线打交道，同时它会不停地监听总线上发生的数据交换，跟踪其他cache在做什么。所以当一个cache代表它所属的cpu核去读写内存，或者对数据进行修改，其它cpu核都会得到通知，它们以此来使自己的cache保持同步。
MESI的四个独立字母是代表Cache line的四个状态，每个缓存行只可能是四种状态之一。在缓存行中占用两比特位，其含义如下。
 Modified（被修改的）：处于这一状态的数据只在本核处理器中有缓存，且其数据已被修改，但还没有更新到内存中。 Exclusive（独占的）：处于这一状态的数据只在本核处理器中有缓存，且其数据没有被修改，与内存一致。 Shared（共享的）：处于这一状态的数据在多核处理器中都有缓存。 Invalid（无效的）：本CPU中的这份缓存已经无效了。  还是通过上述例子，一起来看处理器是如何通过MESI保证缓存一致性的。
 假设线程1首先读取数据A，因为按缓存行读取，且A和B在物理内存上是相邻的，所以数据B也会被加载到Core 1的缓存行中，此时将此缓存行标记为Exclusive状态。   接着线程2读取数据B，它从内存中取出了数据A和数据B到缓存行中。由于在Core 1中已经存在当前数据的缓存行，那么此时处理器会将这两个缓存行标记为Shared状态。   Core1 上的线程1要修改数据A，它发现当前缓存行的状态是Shared，所以它会先通过数据总线发送消息给Core 2，通知Core 2将对应的缓存行标记为Invalid，然后再修改数据A，同时将Core 1上当前缓存行标记为Modified。   此后，线程2想要修改数据B，但此时Core2 中的当前缓存行已经处于Invalid状态，且由于Core 1当中对应的缓存行也有数据B，且缓存行处于Modified状态。因此，Core2 通过内存总线通知Core1 将当前缓存行数据写回到内存，然后Core 2再从内存读取缓存行大小的数据到Cache中，接着修改数据B，当前缓存行标记为Modified。最后，通知Core1将对应缓存行标记为Invalid。  所以，可以发现，如果Core 1和 Core2 上的线程持续交替的对数据A和数据B作修改，就会重复 3 和 4 这两个步骤。这样，Cache 并没有起到缓存的效果。
虽然变量 A 和 B 之间其实并没有任何的关系，但是因为归属于一个缓存行 ，这个缓存行中的任意数据被修改后，它们都会相互影响。因此，这种因为多核线程同时读写同一个 Cache Line 的不同变量，而导致 CPU 缓存失效的现象就是伪共享。
内存填充 那有没有什么办法规避这种伪共享呢？答案是有的：内存填充（Memory Padding）。它的做法是在两个变量之间填充足够多的空间，以保证它们属于不同的缓存行。下面，我们看一个具体的例子。
 1// 这里M需要足够大，否则会存在goroutine 1已经执行完成，而goroutine 2还未启动的情况  2const M = 1000000  3  4type SimpleStruct struct {  5 n int  6}  7  8func BenchmarkStructureFalseSharing(b *testing.B) {  9 structA := SimpleStruct{} 10 structB := SimpleStruct{} 11 wg := sync.WaitGroup{} 12 13 b.ResetTimer() 14 for i := 0; i &amp;lt; b.N; i&#43;&#43; { 15 wg.Add(2) 16 go func() { 17 for j := 0; j &amp;lt; M; j&#43;&#43; { 18 structA.n &#43;= 1 19 } 20 wg.Done() 21 }() 22 go func() { 23 for j := 0; j &amp;lt; M; j&#43;&#43; { 24 structB.n &#43;= 1 25 } 26 wg.Done() 27 }() 28 wg.Wait() 29 } 30} 在该例中，我们相继实例化了两个结构体对象structA和structB，因此，这两个结构体应该会在内存中被连续分配。之后，我们创建两个goroutine，分别去访问这两个结构体对象。
structA上的变量n被goroutine 1访问，structB上的变量n被goroutine 2访问。然后，由于这两个结构体在内存上的地址是连续的，所以两个n会存在于两个CPU缓存行中（假设两个goroutine会被调度分配到不同CPU核上的线程，当然，这不是一定保证的），压测结果如下。
1BenchmarkStructureFalseSharing-8 538 2245798 ns/op 下面我们使用内存填充：在结构体中填充一个为缓存行大小的占位对象CacheLinePad。
 1type PaddedStruct struct {  2 n int  3 _ CacheLinePad  4}  5  6type CacheLinePad struct {  7 _ [CacheLinePadSize]byte  8}  9 10const CacheLinePadSize = 64 然后，我们实例化这两个结构体，并继续在单独的goroutine中访问两个变量。
 1// 这里M需要足够大，否则会存在goroutine 1已经执行完成，而goroutine 2还未启动的情况  2const M = 1000000  3  4func BenchmarkStructurePadding(b *testing.B) {  5 structA := PaddedStruct{}  6 structB := SimpleStruct{}  7 wg := sync.WaitGroup{}  8  9 b.ResetTimer() 10 for i := 0; i &amp;lt; b.N; i&#43;&#43; { 11 wg.Add(2) 12 go func() { 13 for j := 0; j &amp;lt; M; j&#43;&#43; { 14 structA.n &#43;= 1 15 } 16 wg.Done() 17 }() 18 go func() { 19 for j := 0; j &amp;lt; M; j&#43;&#43; { 20 structB.n &#43;= 1 21 } 22 wg.Done() 23 }() 24 wg.Wait() 25 } 26} 在CPU Cache中，内存分布应该如下图所示，因为两个变量之间有足够多的内存填充，所以它们只会存在于不同CPU核心的缓存行。
下面是两种方式的压测结果对比
1BenchmarkStructureFalseSharing-8 538 2245798 ns/op 2BenchmarkStructurePadding-8 793 1506534 ns/op 可以看到，在该例中使用填充的比最初的实现会快30%左右，这是一种以空间换时间的做法。需要注意的是，内存填充的确能提升执行速度，但是同时会导致更多的内存分配与浪费。
结语
机械同理心（Mechanical sympathy）是软件开发领域的一个重要概念，其源自三届世界冠军 F1赛车手 Jackie Stewart 的一句名言：
You don’t have to be an engineer to be a racing driver, but you do have to have Mechanical Sympathy. （若想成为一名赛车手，你不必成为一名工程师，但必须要有机械同理心。）
了解赛车的运作方式能让你成为更好的赛车手，同样，理解计算机硬件的工作原理能让程序员写出更优秀的代码。你不一定需要成为一名硬件工程师，但是你确实需要了解硬件的工作原理，并在设计软件时考虑这一点。
现代计算机为了弥补CPU处理器与主存之间的性能差距，引入了多级缓存体系。有了缓存的存在，CPU就不必直接与主存打交道，而是与响应更快的L1 Cache进行交互。根据局部性原理，缓存与内存的交换数据单元为一个缓存行，缓存行的大小一般是64个字节。
因为缓存行的存在，我们需要写出缓存命中率更高的程序，减少从主存中交换数据的频率，从而提高程序执行效率。同时，在多核多线程当中，为了保证缓存一致性，处理器引入了MESI协议，这样就可能会存在CPU 缓存失效的伪共享问题。最后，我们介绍了一种以空间换时间的内存填充做法，它虽然提高了程序执行效率，但也造成了更多的内存浪费。
以上内容转载自机器铃砍柴刀
</content>
    </entry>
    
     <entry>
        <title>Go的string与[]byte转换原理</title>
        <url>http://shanks.link/blog/2021/04/27/go%E7%9A%84string%E4%B8%8Ebyte%E8%BD%AC%E6%8D%A2%E5%8E%9F%E7%90%86/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> string类型和[]byte类型是我们编程时最常使用到的数据结构。本文将探讨两者之间的转换方式，通过分析它们之间的内在联系来拨开迷雾。
两种转换方式
 标准转换  go中string与[]byte的互换，相信每一位gopher都能立刻想到以下的转换方式，我们将之称为标准转换。
// string to []byte s1 := &amp;#34;hello&amp;#34; b := []byte(s1)  // []byte to string s2 := string(b)  强转换  通过unsafe和reflect包，可以实现另外一种转换方式，我们将之称为强转换（也常常被人称作黑魔法）。
 func String2Bytes(s string) []byte {  sh := (*reflect.StringHeader)(unsafe.Pointer(&amp;amp;s))  bh := reflect.SliceHeader{  Data: sh.Data,  Len: sh.Len,  Cap: sh.Len,  }  return *(*[]byte)(unsafe.Pointer(&amp;amp;bh))  }  func Bytes2String(b []byte) string {  return *(*string)(unsafe.Pointer(&amp;amp;b)) }   性能对比   既然有两种转换方式，那么我们有必要对它们做性能对比。
 1// 测试强转换功能  2func TestBytes2String(t *testing.T) {  3 x := []byte(&amp;#34;Hello Gopher!&amp;#34;)  4 y := Bytes2String(x)  5 z := string(x)  6  7 if y != z {  8 t.Fail()  9 } 10} 11 12// 测试强转换功能 13func TestString2Bytes(t *testing.T) { 14 x := &amp;#34;Hello Gopher!&amp;#34; 15 y := String2Bytes(x) 16 z := []byte(x) 17 18 if !bytes.Equal(y, z) { 19 t.Fail() 20 } 21} 22 23// 测试标准转换string()性能 24func Benchmark_NormalBytes2String(b *testing.B) { 25 x := []byte(&amp;#34;Hello Gopher! Hello Gopher! Hello Gopher!&amp;#34;) 26 for i := 0; i &amp;lt; b.N; i&#43;&#43; { 27 _ = string(x) 28 } 29} 30 31// 测试强转换[]byte到string性能 32func Benchmark_Byte2String(b *testing.B) { 33 x := []byte(&amp;#34;Hello Gopher! Hello Gopher! Hello Gopher!&amp;#34;) 34 for i := 0; i &amp;lt; b.N; i&#43;&#43; { 35 _ = Bytes2String(x) 36 } 37} 38 39// 测试标准转换[]byte性能 40func Benchmark_NormalString2Bytes(b *testing.B) { 41 x := &amp;#34;Hello Gopher! Hello Gopher! Hello Gopher!&amp;#34; 42 for i := 0; i &amp;lt; b.N; i&#43;&#43; { 43 _ = []byte(x) 44 } 45} 46 47// 测试强转换string到[]byte性能 48func Benchmark_String2Bytes(b *testing.B) { 49 x := &amp;#34;Hello Gopher! Hello Gopher! Hello Gopher!&amp;#34; 50 for i := 0; i &amp;lt; b.N; i&#43;&#43; { 51 _ = String2Bytes(x) 52 } 53} 测试结果如下
 1$ go test -bench=&amp;#34;.&amp;#34; -benchmem  2goos: darwin  3goarch: amd64  4pkg: workspace/example/stringBytes  5Benchmark_NormalBytes2String-8 38363413 27.9 ns/op 48 B/op 1 allocs/op  6Benchmark_Byte2String-8 1000000000 0.265 ns/op 0 B/op 0 allocs/op  7Benchmark_NormalString2Bytes-8 32577080 34.8 ns/op 48 B/op 1 allocs/op  8Benchmark_String2Bytes-8 1000000000 0.532 ns/op 0 B/op 0 allocs/op  9PASS 10ok workspace/example/stringBytes 3.170s 注意，-benchmem可以提供每次操作分配内存的次数，以及每次操作分配的字节数。
当x的数据均为&amp;quot;Hello Gopher!&amp;ldquo;时，测试结果如下
 1$ go test -bench=&amp;#34;.&amp;#34; -benchmem  2goos: darwin  3goarch: amd64  4pkg: workspace/example/stringBytes  5Benchmark_NormalBytes2String-8 245907674 4.86 ns/op 0 B/op 0 allocs/op  6Benchmark_Byte2String-8 1000000000 0.266 ns/op 0 B/op 0 allocs/op  7Benchmark_NormalString2Bytes-8 202329386 5.92 ns/op 0 B/op 0 allocs/op  8Benchmark_String2Bytes-8 1000000000 0.532 ns/op 0 B/op 0 allocs/op  9PASS 10ok workspace/example/stringBytes 4.383s 强转换方式的性能会明显优于标准转换。
** **
读者可以思考以下问题
1.为什么强转换性能会比标准转换好？
2.为什么在上述测试中，当x的数据较大时，标准转换方式会有一次分配内存的操作，从而导致其性能更差，而强转换方式却不受影响？
3.既然强转换方式性能这么好，为什么go语言提供给我们使用的是标准转换方式？
原理分析
要回答以上三个问题，首先要明白是string和[]byte在go中到底是什么。
  []byte   在go中，byte是uint8的别名，在go标准库builtin中有如下说明：
1// byte is an alias for uint8 and is equivalent to uint8 in all ways. It is 2// used, by convention, to distinguish byte values from 8-bit unsigned 3// integer values. 4type byte = uint8 在go的源码中src/runtime/slice.go，slice的定义如下：
1type slice struct { 2 array unsafe.Pointer 3 len int 4 cap int 5} array是底层数组的指针，len表示长度，cap表示容量。对于[]byte来说，array指向的就是byte数组。
  string   关于string类型，在go标准库builtin中有如下说明：
// string is the set of all strings of 8-bit bytes, conventionally but not // necessarily representing UTF-8-encoded text. A string may be empty, but // not nil. Values of string type are immutable. type string string 翻译过来就是：string是8位字节的集合，通常但不一定代表UTF-8编码的文本。string可以为空，但是不能为nil。string的值是不能改变的。
在go的源码中src/runtime/string.go，string的定义如下：
1type stringStruct struct { 2 str unsafe.Pointer 3 len int 4} stringStruct代表的就是一个string对象，str指针指向的是某个数组的首地址，len代表的数组长度。那么这个数组是什么呢？我们可以在实例化stringStruct对象时找到答案。
1//go:nosplit 2func gostringnocopy(str *byte) string { 3 ss := stringStruct{str: unsafe.Pointer(str), len: findnull(str)} 4 s := *(*string)(unsafe.Pointer(&amp;amp;ss)) 5 return s 6} 可以看到，入参str指针就是指向byte的指针，那么我们可以确定string的底层数据结构就是byte数组。
综上，string与[]byte在底层结构上是非常的相近（后者的底层表达仅多了一个cap属性，因此它们在内存布局上是可对齐的），这也就是为何builtin中内置函数copy会有一种特殊情况copy(dst []byte, src string) int的原因了。
1// The copy built-in function copies elements from a source slice into a 2// destination slice. (As a special case, it also will copy bytes from a 3// string to a slice of bytes.) The source and destination may overlap. Copy 4// returns the number of elements copied, which will be the minimum of 5// len(src) and len(dst). 6func copy(dst, src []Type) int 7   区别   对于[]byte与string而言，两者之间最大的区别就是string的值不能改变。这该如何理解呢？下面通过两个例子来说明。
对于[]byte来说，以下操作是可行的：
1b := []byte(&amp;#34;Hello Gopher!&amp;#34;) 2b [1] = &amp;#39;T&amp;#39; string，修改操作是被禁止的：
1s := &amp;#34;Hello Gopher!&amp;#34; 2s[1] = &amp;#39;T&amp;#39; 而string能支持这样的操作：
1s := &amp;#34;Hello Gopher!&amp;#34; 2s = &amp;#34;Tello Gopher!&amp;#34; 字符串的值不能被更改，但可以被替换。string在底层都是结构体stringStruct{str: str_point, len: str_len}，string结构体的str指针指向的是一个字符常量的地址， 这个地址里面的内容是不可以被改变的，因为它是只读的，但是这个指针可以指向不同的地址。
那么，以下操作的含义是不同的：
1s := &amp;#34;S1&amp;#34; // 分配存储&amp;#34;S1&amp;#34;的内存空间，s结构体里的str指针指向这块内存 2s = &amp;#34;S2&amp;#34; // 分配存储&amp;#34;S2&amp;#34;的内存空间，s结构体里的str指针转为指向这块内存 3 4b := []byte{1} // 分配存储&amp;#39;1&amp;#39;数组的内存空间，b结构体的array指针指向这个数组。 5b = []byte{2} // 将array的内容改为&amp;#39;2&amp;#39; 图解如下
因为string的指针指向的内容是不可以更改的，所以每更改一次字符串，就得重新分配一次内存，之前分配的空间还需要gc回收，这是导致string相较于[]byte操作低效的根本原因。
  标准转换的实现细节   []byte(string)的实现（源码在src/runtime/string.go中）
 1// The constant is known to the compiler.  2// There is no fundamental theory behind this number.  3const tmpStringBufSize = 32  4  5type tmpBuf [tmpStringBufSize]byte  6  7func stringtoslicebyte(buf *tmpBuf, s string) []byte {  8 var b []byte  9 if buf != nil &amp;amp;&amp;amp; len(s) &amp;lt;= len(buf) { 10 *buf = tmpBuf{} 11 b = buf[:len(s)] 12 } else { 13 b = rawbyteslice(len(s)) 14 } 15 copy(b, s) 16 return b 17} 18 19// rawbyteslice allocates a new byte slice. The byte slice is not zeroed. 20func rawbyteslice(size int) (b []byte) { 21 cap := roundupsize(uintptr(size)) 22 p := mallocgc(cap, nil, false) 23 if cap != uintptr(size) { 24 memclrNoHeapPointers(add(p, uintptr(size)), cap-uintptr(size)) 25 } 26 27 *(*slice)(unsafe.Pointer(&amp;amp;b)) = slice{p, size, int(cap)} 28 return 29} 这里有两种情况：s的长度是否大于32。当大于32时，go需要调用mallocgc分配一块新的内存（大小由s决定），这也就回答了上文中的问题2：当x的数据较大时，标准转换方式会有一次分配内存的操作。
最后通过copy函数实现string到[]byte的拷贝，具体实现在src/runtime/slice.go中的slicestringcopy方法。
 1func slicestringcopy(to []byte, fm string) int {  2 if len(fm) == 0 || len(to) == 0 {  3 return 0  4 }  5  6 // copy的长度取决与string和[]byte的长度最小值  7 n := len(fm)  8 if len(to) &amp;lt; n {  9 n = len(to) 10 } 11 12 // 如果开启了竞态检测 -race 13 if raceenabled { 14 callerpc := getcallerpc() 15 pc := funcPC(slicestringcopy) 16 racewriterangepc(unsafe.Pointer(&amp;amp;to[0]), uintptr(n), callerpc, pc) 17 } 18 // 如果开启了memory sanitizer -msan 19 if msanenabled { 20 msanwrite(unsafe.Pointer(&amp;amp;to[0]), uintptr(n)) 21 } 22 23 // 该方法将string的底层数组从头部复制n个到[]byte对应的底层数组中去（这里就是copy实现的核心方法，在汇编层面实现 源文件为memmove_*.s） 24 memmove(unsafe.Pointer(&amp;amp;to[0]), stringStructOf(&amp;amp;fm).str, uintptr(n)) 25 return n 26} copy实现过程图解如下
string([]byte)的实现（源码也在src/runtime/string.go中）
 1// Buf is a fixed-size buffer for the result,  2// it is not nil if the result does not escape.  3func slicebytetostring(buf *tmpBuf, b []byte) (str string) {  4 l := len(b)  5 if l == 0 {  6 // Turns out to be a relatively common case.  7 // Consider that you want to parse out data between parens in &amp;#34;foo()bar&amp;#34;,  8 // you find the indices and convert the subslice to string.  9 return &amp;#34;&amp;#34; 10 } 11 // 如果开启了竞态检测 -race 12 if raceenabled { 13 racereadrangepc(unsafe.Pointer(&amp;amp;b[0]), 14 uintptr(l), 15 getcallerpc(), 16 funcPC(slicebytetostring)) 17 } 18 // 如果开启了memory sanitizer -msan 19 if msanenabled { 20 msanread(unsafe.Pointer(&amp;amp;b[0]), uintptr(l)) 21 } 22 if l == 1 { 23 stringStructOf(&amp;amp;str).str = unsafe.Pointer(&amp;amp;staticbytes[b[0]]) 24 stringStructOf(&amp;amp;str).len = 1 25 return 26 } 27 28 var p unsafe.Pointer 29 if buf != nil &amp;amp;&amp;amp; len(b) &amp;lt;= len(buf) { 30 p = unsafe.Pointer(buf) 31 } else { 32 p = mallocgc(uintptr(len(b)), nil, false) 33 } 34 stringStructOf(&amp;amp;str).str = p 35 stringStructOf(&amp;amp;str).len = len(b) 36 // 拷贝字节数组至字符串 37 memmove(p, (*(*slice)(unsafe.Pointer(&amp;amp;b))).array, uintptr(len(b))) 38 return 39} 40 41// 实例stringStruct对象 42func stringStructOf(sp *string) *stringStruct { 43 return (*stringStruct)(unsafe.Pointer(sp)) 44} 可见，当数组长度超过32时，同样需要调用mallocgc分配一块新内存。最后通过memmove完成拷贝。
  强转换的实现细节   \1. 万能的unsafe.Pointer指针
在go中，任何类型的指针T都可以转换为unsafe.Pointer类型的指针，它可以存储任何变量的地址。同时，unsafe.Pointer类型的指针也可以转换回普通指针，而且可以不必和之前的类型T相同。另外，unsafe.Pointer类型还可以转换为uintptr类型，该类型保存了指针所指向地址的数值，从而可以使我们对地址进行数值计算。以上就是强转换方式的实现依据。
而string和slice在reflect包中，对应的结构体是reflect.StringHeader和reflect.SliceHeader，它们是string和slice的运行时表达。
 1type StringHeader struct {  2 Data uintptr  3 Len int  4}  5  6type SliceHeader struct {  7 Data uintptr  8 Len int  9 Cap int 10} \2. 内存布局
从string和slice的运行时表达可以看出，除了SilceHeader多了一个int类型的Cap字段，Date和Len字段是一致的。所以，它们的内存布局是可对齐的，这说明我们就可以直接通过unsafe.Pointer进行转换。
[]byte转string图解
string转[]byte图解
   Q&amp;amp;A   Q1.为什么强转换性能会比标准转换好？
对于标准转换，无论是从[]byte转string还是string转[]byte都会涉及底层数组的拷贝。而强转换是直接替换指针的指向，从而使得string和[]byte指向同一个底层数组。这样，当然后者的性能会更好。
Q2.为什么在上述测试中，当x的数据较大时，标准转换方式会有一次分配内存的操作，从而导致其性能更差，而强转换方式却不受影响？
标准转换时，当数据长度大于32个字节时，需要通过mallocgc申请新的内存，之后再进行数据拷贝工作。而强转换只是更改指针指向。所以，当转换数据较大时，两者性能差距会愈加明显。
Q3.既然强转换方式性能这么好，为什么go语言提供给我们使用的是标准转换方式？
首先，我们需要知道Go是一门类型安全的语言，而安全的代价就是性能的妥协。但是，性能的对比是相对的，这点性能的妥协对于现在的机器而言微乎其微。另外强转换的方式，会给我们的程序带来极大的安全隐患。
如下示例
1a := &amp;#34;hello&amp;#34; 2b := String2Bytes(a) 3b[0] = &amp;#39;H&amp;#39; a是string类型，前面我们讲到它的值是不可修改的。通过强转换将a的底层数组赋给b，而b是一个[]byte类型，它的值是可以修改的，所以这时对底层数组的值进行修改，将会造成严重的错误（通过defer&#43;recover也不能捕获）。
1unexpected fault address 0x10b6139 2fatal error: fault 3[signal SIGBUS: bus error code=0x2 addr=0x10b6139 pc=0x1088f2c] Q4. 为什么string要设计为不可修改？
我认为有必要思考一下该问题。string不可修改，意味它是只读属性，这样的好处就是：在并发场景下，我们可以在不加锁的控制下，多次使用同一字符串，在保证高效共享的情况下而不用担心安全问题。
  取舍场景    在你不确定安全隐患的条件下，尽量采用标准方式进行数据转换。 当程序对运行性能有高要求，同时满足对数据仅仅只有读操作的条件，且存在频繁转换（例如消息转发场景），可以使用强转换。  以上内容转载自机器铃砍菜刀
</content>
    </entry>
    
     <entry>
        <title>Go工具之vet静态诊断器</title>
        <url>http://shanks.link/blog/2021/04/27/go%E5%B7%A5%E5%85%B7%E4%B9%8Bvet%E9%9D%99%E6%80%81%E8%AF%8A%E6%96%AD%E5%99%A8/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Go工具之vet——静态诊断器 go的vet工具是go代码静态诊断器，可以用以检查go项目中可通过编译但仍可能存在错误的代码，例如无法访问的代码、错误的锁使用、不必要的赋值、布尔运算错误等。
使用示例
vet是go工具套件的其中之一，它是和go编译器一起发布的，因此当我们安装好go之后，就已经带有vet工具。
vet调用方式非常简单，参数1的位置可以指定目录、源码文件或包（packages）。
go vet &amp;lt;directory|files|packages&amp;gt; 例如当前目录定义了main.go文件，在fmt.Printf()中使用了错误的格式符%d，而编译器并不会检查到该错误（这里笔者觉得有点奇怪，go既然是强类型语言，编译阶段为何要允许通过？），这会导致程序运行时的输出和预期不符。
1package main 2 3import &amp;#34;fmt&amp;#34; 4 5func main() { 6 s := &amp;#34;this is a string&amp;#34; 7 fmt.Printf(&amp;#34;inappropriate formate %d\n&amp;#34;, s) 8} 使用vet命令进行静态检查，会报告此错误。
1$ go vet main.go 2# command-line-arguments 3./main.go:7:2: Printf format %d has arg s of wrong type string 诊断器与flag
vet的代码分析是由多个子诊断器组成的，目前包含22个（基于go 1.14.1，在最新版1.15 Release Notes中发现vet增加了一些内容，新增对string(int)转换的诊断和对interface-interface类型断言的诊断），这些诊断器单元代表着vet的检测范围。
 1asmdecl report mismatches between assembly files and Go declarations  2assign check for useless assignments  3atomic check for common mistakes using the sync/atomic package  4bools check for common mistakes involving boolean operators  5buildtag check that &#43;build tags are well-formed and correctly located  6cgocall detect some violations of the cgo pointer passing rules  7composites check for unkeyed composite literals  8copylocks check for locks erroneously passed by value  9errorsas report passing non-pointer or non-error values to errors.As 10httpresponse check for mistakes using HTTP responses 11loopclosure check references to loop variables from within nested functions 12lostcancel check cancel func returned by context.WithCancel is called 13nilfunc check for useless comparisons between functions and nil 14printf check consistency of Printf format strings and arguments 15shift check for shifts that equal or exceed the width of the integer 16stdmethods check signature of methods of well-known interfaces 17structtag check that struct field tags conform to reflect.StructTag.Get 18tests check for common mistaken usages of tests and examples 19unmarshal report passing non-pointer or non-interface values to unmarshal 20unreachable check for unreachable code 21unsafeptr check for invalid conversions of uintptr to unsafe.Pointer 22unusedresult check for unused results of calls to some functions 例如上文示例中的格式化符的错误，就是检查子诊断器printf中报出的错误。对于特定的诊断器，如果想了解更多细节，可通过命令go tool vet help 查看，例如
go tool vet help printf 使用vet时，其默认是打开了所有的诊断器。如果想禁用某个诊断器analyzer，则可以加上-=false，代表不检查analyzer包含的内容。
1go vet -printf=false main.go 相应的，如果只想使用某个特定的analyzer，那么可加上-=true，代表只检查analyzer所包含的内容。
1go vet -printf=true main.go vet命令除了可以设置诊断器之外，还提供了很多flag，这里就不详细列出。可通过go tool vet help命令查看完整内容。
这里介绍两个相对有用的flag
 -c=N  设置此flag可以输出错误代码行的上下相邻N行源代码。
$ go vet -c=2 main.go # command-line-arguments ./main.go:7:2: Printf format %d has arg s of wrong type string 5 func main() { 6 s := &amp;#34;this is a string&amp;#34; 7 fmt.Printf(&amp;#34;inappropriate formate %d\n&amp;#34;, s) 8 } 9  -json  设置此flag可以将错误报告以json形式输出。
 $ go vet -json main.go # command-line-arguments {  &amp;#34;command-line-arguments&amp;#34;: {  &amp;#34;printf&amp;#34;: [  {  &amp;#34;posn&amp;#34;: &amp;#34;/Users/slp/go/src/example/vet/main.go:7:2&amp;#34;,  &amp;#34;message&amp;#34;: &amp;#34;Printf format %d has arg s of wrong type string&amp;#34;  }  ]  } } 通过查看vet的源码（位于$GOROOT/src/cmd/vet/main.go），可以发现其诊断器全是通过引入库golang.org/x/tools/go/analysis中的内容，这是Go官方所维护的库。详细代码可以在github地址：https://github.com/golang/tools/tree/master/go/analysis中获取。
package main  import (  &amp;#34;cmd/internal/objabi&amp;#34;   &amp;#34;golang.org/x/tools/go/analysis/unitchecker&amp;#34;   &amp;#34;golang.org/x/tools/go/analysis/passes/asmdecl&amp;#34;  &amp;#34;golang.org/x/tools/go/analysis/passes/assign&amp;#34;  &amp;#34;golang.org/x/tools/go/analysis/passes/atomic&amp;#34;  ... )  func main() {  objabi.AddVersionFlag()   unitchecker.Main(  asmdecl.Analyzer,  assign.Analyzer,  atomic.Analyzer,  ...  ) } 常见错误示例与vet诊断
** **
 printf错误  package main  import &amp;#34;fmt&amp;#34;  func main() {  s := &amp;#34;this is a string&amp;#34;  fmt.Printf(&amp;#34;inappropriate formate %s\n&amp;#34;, &amp;amp;s) }  $ go vet main.go # command-line-arguments ./main.go:7:2: Printf format %s has arg &amp;amp;s of wrong type *string  布尔错误  package main  import &amp;#34;fmt&amp;#34;  func main() {  i := 1   fmt.Println(i != 0 || i != 1)  fmt.Println(i == 1 &amp;amp;&amp;amp; i == 0)  fmt.Println(i == 1 &amp;amp;&amp;amp; i == 1) }  $ go vet main.go # command-line-arguments ./main.go:8:14: suspect or: i != 0 || i != 1 ./main.go:9:14: suspect and: i == 1 &amp;amp;&amp;amp; i == 0 ./main.go:10:14: redundant and: i == 1 &amp;amp;&amp;amp; i == 1  range与go协程引起的错误  package main  import (  &amp;#34;fmt&amp;#34;  &amp;#34;time&amp;#34; )  func main() {  arr := []int{1,2,3}  for _, i := range arr{  go func() {  fmt.Println(i)  }()  }  time.Sleep(time.Second) }   $ go run main.go 3 3 3   $ go vet main.go # command-line-arguments ./main.go:12:16: loop variable i captured by func literal 这个错误小菜刀在《不要忽略goroutine的启动时间》介绍过，感兴趣的可以看下。顺便纠正下那篇文章的结论：goroutine的启动延迟是诱因，本质原因还是由于迭代获取的临时变量是同一个地址变量。
 错误使用锁  package main  import (  &amp;#34;fmt&amp;#34;  &amp;#34;sync&amp;#34; )  func valueMutex(msg string, mutex sync.Mutex) {  mutex.Lock()  defer mutex.Unlock()  fmt.Println(msg) }  func main() {  mu := sync.Mutex{}  msg := &amp;#34;this is a message&amp;#34;  valueMutex(msg, mu) }  $ go run main.go this is a message   $ go vet main.go # command-line-arguments ./main.go:8:35: valueMutex passes lock by value: sync.Mutex ./main.go:17:18: call of valueMutex copies lock value: sync.Mutex 这种用法是非常危险的，函数参数中不能值传递锁（锁不能被复制，在《no copy机制》文中有介绍），应该使用指针（将参数类型sync.Mutex改为*sync.Mutex），否则极容易导致死锁。
 不能到达的代码  package main  import &amp;#34;fmt&amp;#34;  func unreachable(str string) string {  return str  // something work  return &amp;#34;result&amp;#34; }  func main() {  s := unreachable(&amp;#34;init string&amp;#34;)  fmt.Println(s) }  $ go run main.go init string  $ go vet main.go # command-line-arguments ./main.go:8:2: unreachable code  定义context，忽略了cancel  package main  import (  &amp;#34;context&amp;#34;  &amp;#34;time&amp;#34; )  func child(ctx context.Context) {  // do something }  func main() {  ctx, _ := context.WithTimeout(context.Background(), time.Second*5)  child(ctx) }   $ go run main.go no problem  $ go vet main.go # command-line-arguments ./main.go:15:7: the cancel function returned by context.WithTimeout should be called, not discarded, to avoid a context leak 总结
go vet是检测go项目中静态错误的有效工具，清除go vet扫描出的错误，有利于提高代码质量和养成良好的编程习惯。但是，go vet也并不是万能的，它仅仅是帮助程序员排除可能的错误，代码的质量高低更取决于程序员的水平、代码规范和编码态度。
最后，vet作为一个有效的代码质量诊断工具，笔者希望每位gopher都能够充分利用。
以上内容转载自机器铃砍菜刀
</content>
    </entry>
    
     <entry>
        <title>不能忽略GoRoutinue的启动时间</title>
        <url>http://shanks.link/blog/2021/04/27/%E4%B8%8D%E8%83%BD%E5%BF%BD%E7%95%A5goroutinue%E7%9A%84%E5%90%AF%E5%8A%A8%E6%97%B6%E9%97%B4/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 不要忽略goroutine的启动时间 项目中需要将数据推给多个服务器，大致如下
 package main   import (  &amp;#34;fmt&amp;#34;  &amp;#34;sync&amp;#34;  )   func mockSendToServer(url string) {  fmt.Printf(&amp;#34;server url: %s\n&amp;#34;, url) }  func main() {  urls := []string{&amp;#34;0.0.0.0:5000&amp;#34;, &amp;#34;0.0.0.0:6000&amp;#34;, &amp;#34;0.0.0.0:7000&amp;#34;}  wg := sync.WaitGroup{}  for _, url := range urls {  wg.Add(1)  go func() {  defer wg.Done()  mockSendToServer(url)  }()  }  wg.Wait() } 请读者停来下思考一下，以上代码会得到什么样的输出。
1$ go run main.go 2server url: 0.0.0.0:7000 3server url: 0.0.0.0:7000 4server url: 0.0.0.0:7000 这个结果，是不是和你想的一样呢。那么，问题出在了哪里？为什么从for循环中传递的url变得相同了，且为数组中的最后一项url。
原因分析
在Go中提供了非常好的程序分析工具，trace和pprof。trace侧重于分析goroutine的调度，pprof则侧重于程序的运行性能。为了更好地排查上述bug产生的原因，代码中新增了trace代码段。
 package main   import (  &amp;#34;fmt&amp;#34;  &amp;#34;os&amp;#34;  &amp;#34;runtime/trace&amp;#34;  &amp;#34;sync&amp;#34;  )  func mockSendToServer(url string) {  fmt.Printf(&amp;#34;server url: %s\n&amp;#34;, url) }  func main() {  f, err := os.Create(&amp;#34;trace.out&amp;#34;)  if err != nil {  panic(err)  }  defer f.Close()   err = trace.Start(f)  if err != nil {  panic(err)  }  defer trace.Stop()  urls := []string{&amp;#34;0.0.0.0:5000&amp;#34;, &amp;#34;0.0.0.0:6000&amp;#34;, &amp;#34;0.0.0.0:7000&amp;#34;}  wg := sync.WaitGroup{}  for _, url := range urls {  wg.Add(1)  go func() {  defer wg.Done()  mockSendToServer(url)  }()  }  wg.Wait() } 运行命令go run main.go ，将在同级目录生成trace.out文件。此时，执行go tool命令。
1go tool trace trace.out 22020/08/15 16:35:58 Parsing trace... 32020/08/15 16:35:58 Splitting trace... 42020/08/15 16:35:58 Opening browser. Trace viewer is listening on http://127.0.0.1:61272 在web浏览器（推荐使用Chrome）打开http://127.0.0.1:61272
    在这里，我们只关心两项指标。第一行View trace（可视化整个程序的调度流程）和第二行Groutine analysis。相信读者对trace和pprof的基本玩法都有了解，这里就不做过多介绍。后续小菜刀也会尽力出一些关于它们使用的详细文章。
进入Goroutine analysis项。
可以看到，程序一共有5个goroutine，分别是三个for循环里启动的匿名go func()、一个trace.Start.func1和runtime.main。
进入main.main.func1
这三个代表的就是for循环结构体里面启动的三个goroutine。这里，请记住它们的编号19、20、21。
此时，退回到http://127.0.0.1:61272页面，进入View trace项。
点击G1（G1代表的是runtime.main）所在的绿色方框，得到如下信息
上图是重点！我们可以看到G18、G19、G20、G21都是通过G1衍生出来的。同时可以看到，G1运行阻塞于第35行代码处，即wg.Wait()。
但是，通过上图中goroutine的运行时序，此时for循环中的3个goroutine均还未成功启动运行（虽然已经在主goroutine即main中通过go关键字进行了goroutine调用声明）。
那么，到这里读者应该清楚上文中bug产生的原因了吧。
1for _, url := range urls { 2 wg.Add(1) 3 go func() { 4 defer wg.Done() 5 mockSendToServer(url) 6 }() 7} 8wg.Wait() 原因
当主goroutine中的for循环逻辑已经走完并阻塞于wg.Wait（）一段时间后，go func的goroutine才启动准备（准备资源，挂载M线程等）完毕。那么，此时三个goroutine中获取的url都是指向的最后一次for循环的url，因此就造成了上文中的bug。
**goroutine的启动时间是多少 **
通过在小菜刀电脑上的多次运行观察，一次goroutine的启动准备时间在数十微秒左右。当然该值在不同的操作系统和硬件设备上肯定会存在一些差异。为此，小菜刀在程序以下部分做了些小改动，以做测试
 1for i, url := range urls {  2 wg.Add(1)  3 go func() {  4 defer wg.Done()  5 mockSendToServer(url)  6 }()  7 if i == 1 {  8 //在读取url为&amp;#34;0.0.0.0:6000&amp;#34;时，睡50微秒  9 time.Sleep(time.Microsecond * 50) 10 } 11} 12wg.Wait() 程序多次运行会产生不同的结果
 1 $ go run main.go  2server url: 0.0.0.0:6000  3server url: 0.0.0.0:7000  4server url: 0.0.0.0:6000  5  6 $ go run main.go  7server url: 0.0.0.0:6000  8server url: 0.0.0.0:6000  9server url: 0.0.0.0:7000 10 11 $ go run main.go 12server url: 0.0.0.0:6000 13server url: 0.0.0.0:7000 14server url: 0.0.0.0:7000 那么，我们就选取6000、7000、7000的结果来分析下当时goroutine的启动和调度情况。
如上，可以得知：由于在第二次for循环中让主goroutine睡了50微秒，使得首次被主goroutine调起的go func（上图表现为G20）已经得到了充足的时间来准备启动。但是首次调起的go func，其获取url的时间片是在第二次循环的睡眠阶段，因此它得到的url是&amp;quot;0.0.0.0:6000&amp;quot;，而其他两个go func（G21和G19）最终运行时获取的值还是&amp;quot;0.0.0.0:7000&amp;quot;的url。
之所以睡眠50微秒会造成不同的结果，是由于goroutine的启动时间并不固定，会存在一定范围的波动。
因此，解决上文的bug的方案应为如下
1for _, url := range urls { 2 wg.Add(1) 3 go func(url string) { 4 defer wg.Done() 5 mockSendToServer(url) 6 }(url) 7} 8wg.Wait() 将每次遍历的url所指向值，通过函数入参，作为数据资源赋予给go func,这样不管goroutine启动会有多耗时，其url已经作为goroutine的私有数据保存，后续运行就用上了正确的url，那么，上文bug也相应解除。
后记
小菜刀在线上遇到该bug时，虽然已经知道通过url入参的方式进行修改，但当时没有过多思考，以为问题是出在了for&amp;hellip;range的值拷贝上面。通过后续和同事的讨论与自己多次不同尝试之后，才意识到原来是goroutine的启动时间在捣鬼。
最后，希望读者们看完此文，不会再写出此bug。
以上内容转载自机器铃kan
</content>
    </entry>
    
     <entry>
        <title>深入理解sync.Once</title>
        <url>http://shanks.link/blog/2021/04/27/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3sync.once/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 深入理解sync.Once sync.Once是让函数方法只被调用执行一次的实现，其最常应用于单例模式之下，例如初始化系统配置、保持数据库唯一连接等。
sync.Once的单例模式示例
** **
 1package main  2  3import (  4 &amp;#34;fmt&amp;#34;  5 &amp;#34;sync&amp;#34;  6)  7  8type Instance struct{}  9 10var ( 11 once sync.Once 12 instance *Instance 13) 14 15func NewInstance() *Instance { 16 once.Do(func() { 17 instance = &amp;amp;Instance{} 18 fmt.Println(&amp;#34;Inside&amp;#34;) 19 }) 20 fmt.Println(&amp;#34;Outside&amp;#34;) 21 return instance 22} 23 24func main() { 25 for i := 0; i &amp;lt; 3; i&#43;&#43; { 26 _ = NewInstance() 27 } 28} 输出
1$ go run main.go 2Inside 3Outside 4Outside 5Outside 从上述例子可以看到，虽然多次调用NewInstance()函数，但是Once.Do()中的方法有且仅被执行了一次。那么sync.Once是如何做到这一点的呢？
sync.Once的源码解析
1type Once struct { 2 // done indicates whether the action has been performed. 3 // It is first in the struct because it is used in the hot path. 4 // The hot path is inlined at every call site. 5 // Placing done first allows more compact instructions on some architectures (amd64/x86), 6 // and fewer instructions (to calculate offset) on other architectures. 7 done uint32 8 m Mutex 9} Once结构体非常简单，其中done是调用标识符，Once对象初始化时，其done值默认为0，Once仅有一个Do()方法，当Once首次调用Do()方法后，done值变为1。m作用于初始化竞态控制，在第一次调用Once.Do()方法时，会通过m加锁，以保证在第一个Do()方法中的参数f()函数还未执行完毕时，其他此时调用Do()方法会被阻塞（不返回也不执行）。
Once.Do()方法的实现细节如下
 1func (o *Once) Do(f func()) {  2 // Note: Here is an incorrect implementation of Do:  3 //  4 // if atomic.CompareAndSwapUint32(&amp;amp;o.done, 0, 1) {  5 // f()  6 // }  7 //  8 // Do guarantees that when it returns, f has finished.  9 // This implementation would not implement that guarantee: 10 // given two simultaneous calls, the winner of the cas would 11 // call f, and the second would return immediately, without 12 // waiting for the first&amp;#39;s call to f to complete. 13 // This is why the slow path falls back to a mutex, and why 14 // the atomic.StoreUint32 must be delayed until after f returns. 15 16 if atomic.LoadUint32(&amp;amp;o.done) == 0 { 17 // Outlined slow-path to allow inlining of the fast-path. 18 o.doSlow(f) 19 } 20} 21 22func (o *Once) doSlow(f func()) { 23 o.m.Lock() 24 defer o.m.Unlock() 25 if o.done == 0 { 26 defer atomic.StoreUint32(&amp;amp;o.done, 1) 27 f() 28 } 29} Do()方法的入参是一个无参数输入与返回的函数，当o.done值为0时，执行doSlow()方法，为1则退出Do()方法。doSlow()方法很简单：加锁，再次检查o.done值，执行f()，原子操作将o.done值置为1，最后释放锁。
注意事项
1. 在官方示例代码中，提到了一种错误实现Do()方法的方式。
1func (o *Once) Do(f func()) { 2 if atomic.CompareAndSwapUint32(&amp;amp;o.done, 0, 1) { 3 f() 4 } 5} 当并发多次调用Do()方法时，第一个被执行的Do()方法会将o.done值从0置为1，并执行f()，其他的调用Do()方法会立即被返回。这种处理方式和加锁的方式会有所不同：它不能保证在第一个调用执行Do()方法中的f()函数被执行完毕之前，其他的f()函数会阻塞等待。
 1package main  2  3import (  4 &amp;#34;fmt&amp;#34;  5 &amp;#34;sync&amp;#34;  6 &amp;#34;time&amp;#34;  7)  8  9type Config struct {} 10 11func (c *Config) init(filename string) { 12 fmt.Printf(&amp;#34;mock [%s] config initial done!\n&amp;#34;, filename) 13} 14 15var ( 16 once sync.Once 17 cfg *Config 18) 19 20func main() { 21 cfg = &amp;amp;Config{} 22 23 go once.Do(func() { 24 time.Sleep(3 * time.Second) 25 cfg.init(&amp;#34;first file path&amp;#34;) 26 }) 27 28 time.Sleep(time.Second) 29 once.Do(func() { 30 time.Sleep(time.Second) 31 cfg.init(&amp;#34;second file path&amp;#34;) 32 }) 33 fmt.Println(&amp;#34;运行到这里！&amp;#34;) 34 time.Sleep(5 * time.Second) 35} 输出
1$ go run main.go 2mock [first file path] config initial done! 3运行到这里！ 可以看到第二次调用once.Do()时候，其输入参数f()函数虽然没有被执行，但是整个Do()是被阻塞的（被阻塞于o.m.Lock()处），它需要等待首次调用once.Do()执行完毕，才会退出阻塞状态。而错误实现Do()方法的方式，就无法保证此规则的实现。
2. 避免死锁
 1package main  2  3import (  4 &amp;#34;fmt&amp;#34;  5 &amp;#34;sync&amp;#34;  6)  7  8func main() {  9 once := sync.Once{} 10 once.Do(func() { 11 fmt.Println(&amp;#34;outside call&amp;#34;) 12 once.Do(func() { 13 fmt.Println(&amp;#34;inside call&amp;#34;) 14 }) 15 }) 16} 输出
1$ go run main.go 2outside call 3fatal error: all goroutines are asleep - deadlock! 注意，同样由于o.m.Lock()处的代码限定，once.Do()内部调用Do()方法时，会造成死锁的发生。
以上内容转载自机器铃砍柴刀
</content>
    </entry>
    
     <entry>
        <title>数据库连接池</title>
        <url>http://shanks.link/blog/2021/04/27/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0/</url>
        <categories>
          <category>algorithm</category>
        </categories>
        <tags>
          <tag>algorithm</tag>
        </tags>
        <content type="html"> 数据库连接池 池（Pool）是指某类资源的容器，它是一种用于提高程序效率和降低系统开销的技术，比如线程池、连接池、内存池、对象池。但它们的核心理念一致：资源复用。
本文主要探究数据库连接池的相关问题，并实现一个简单的Go版本连接池Demo，希望能对读者理解池技术有些帮助。
数据库连接池的基本思想就是为数据库连接建立一个缓冲池，预先在缓冲池中放入一定数量的数据库连接，当用户需要访问数据库时，从池中取出一条空闲连接，使用完毕后，将该连接返回到池中，以供其他的请求访问使用。
为什么需要数据库连接池？
首先，需要明确的是，数据库连接是一种有限的、昂贵的资源。如果按照单个连接来进行数据库操作，在高并发的情况下会导致数据库连接数耗尽的问题，并且单个连接的频繁创建和关闭，会极大地增加数据库的开销。例如，mysql数据库可通过以下mysql命令查看其设置的最大连接数。
   show variables like &amp;#39;%max_connections%&amp;#39;; 而数据库连接池负责分配、管理和释放数据库连接，它允许客户端请求复用现有的数据库连接，而不是重新建立一个。
核心概念
1. 连接数
连接池中应该放置多少连接，才能使系统的性能最佳？系统可通过设置最小连接数和最大连接数等参数来调整。
最小连接数
最小连接数是连接池空闲状态下维持的数据库连接数，也是系统启动时连接池所创建的连接数。创建过多，则系统启动就会较慢，且如果应用程序对数据库连接的使用量不大，会造成数据库连接资源的浪费。如果创建过少，则系统启动较快，但后续对请求的响应就会较慢。
最大连接数
最大连接数，是连接池能申请的最大连接数。超过最大连接数的请求，将加入等待队列中，当池中有可用连接时，再处理这些请求。
最小连接数的设置，可根据系统正常访问量的大小来确定一个合适的数值；而最大连接数，则可根据高峰场景下的系统访问量来设置。
2. 空闲时间
当连接请求超过最小连接数时，在超过后的连接请求需要连接池为它们建立新的连接，但是总的连接数不能超过最大连接数限制。对于这些大于最小连接数的数据库连接在使用完后不会被马上释放，它将被放在连接池中等待重复使用或者超过设定的空闲时间后被释放。
Demo实现
定义数据库连接池对象Pool
type Pool struct {  mu sync.Mutex  minConn int // 最小连接数  maxConn int // 最大连接数  numConn int // 池已申请的连接数  conns chan *DBConn //当前池中空闲连接实例  close bool }  // 初始化池实例 func NewPool(min, max int) *Pool {  p := &amp;amp;Pool{  minConn: min,  maxConn: max,  numConn: min,  conns: make(chan *DBConn, max),  close: false,  }  for i := 0; i &amp;lt; min; i&#43;&#43; {  p.conns &amp;lt;- NewDBConn()  }  return p } 模拟数据库连接对象DBConn
type DBConn struct {  idleTime int // 标记该数据库连接空闲时间 }  // 新建数据库连接 func NewDBConn() *DBConn {  return &amp;amp;DBConn{idleTime: 0} }  // 关闭数据库连接 func (d *DBConn) Close() {} 池对象方法定义
// 从池中取出连接 func (p *Pool) Get() *DBConn {  if p.close {  return nil  }  p.mu.Lock()  defer p.mu.Unlock()   if p.numConn &amp;gt;= p.maxConn || len(p.conns) &amp;gt; 0 { // 保证了池申请连接数量不超过最大连接数  d := &amp;lt;-p.conns // 若池中没有可取的连接，则等待其他请求返回连接至池中再取  return d  }  p.numConn&#43;&#43;  return NewDBConn() //申请新的连接 }  // 将连接返回池中 func (p *Pool) Put(d *DBConn) {  if p.close {  return  }  p.mu.Lock()  defer p.mu.Unlock()  p.conns &amp;lt;- d }  // 关闭池 func (p *Pool) Close() {  p.mu.Lock()  defer p.mu.Unlock()  for d := range p.conns {  d.Close()  }  p.close = true } （左右滑动查看完整代码图片）
考虑代码篇幅原因，本Demo并没有实现释放空闲超时的数据库连接功能，即没有对p.numConn做&amp;ndash;计数和Pool的RemoveConn方法。实际情况中，设计连接池，还有很多因素需要考虑，例如：
  超时移除：当池中空闲的连接数大于最小连接数时，应当对数据库连接进行空闲超时检查，当满足要求时，释放该条连接，并从池中移除。但最终在池中维持的数据库连接条数应该等于最小连接数。
  连接可用：对池中的数据库连接建立保活机制，保证每条连接是可用的。
  事务处理：由于事务的原子性，一组sql语句要么全做，要么全不做。如果简单采用连接复用的策略，就会发生问题，因为没有办法控制属于同一个事务的多个数据库操作方法的动作，可能这些数据库操作是在多个连接上进行的，并且这些连接可能被其他非事务方法复用。为此可以使用每一个事务独占一个连接来实现，虽然这种方法有点浪费连接池资源，但可以大大降低事务管理的复杂性。
  以上内容转载自机器铃砍柴刀
</content>
    </entry>
    
     <entry>
        <title>Go no copy 机制</title>
        <url>http://shanks.link/blog/2021/04/27/go-no-copy-%E6%9C%BA%E5%88%B6/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> no copy机制 小菜刀读Go源码时，发现一个高频注释语句“XXX must not be copied after first use“。例如sync包下的Pool、Cond、WaitGroup、Mutex、Map和atomoic.Vaule、strings.Builder等，都有该句注释。
为什么注释文档中要强调no copy？ 安全！
如果结构体对象包含指针字段，当该对象被拷贝时，会使得两个对象中的指针字段变得不再安全。
type S struct {  f1 int  f2 *s }  type s struct {  name string }  func main() {  mOld := S{  f1: 0,  f2: &amp;amp;s{name: &amp;#34;mike&amp;#34;},  }  mNew := mOld //拷贝  mNew.f1 = 1  mNew.f2.name = &amp;#34;jane&amp;#34;   fmt.Println(mOld.f1, mOld.f2) //输出：0 &amp;amp;{jane} } 如上，结构体对象S中存在两个field，分别是f1和f2，其中f2是指向s类型的指针。当mNew复制了mOld之后，mNew对两个字段进行了改变，可以看到f1字段的更改，不会对mOld造成影响。但是，nNew中f2字段的修改也会把mOld中的f2字段修改掉，这引发了安全问题。
Go是如何保证no copy的？ 1. runtime checking  strings.Builder中copy检查  func main() {  var a strings.Builder  a.Write([]byte(&amp;#34;a&amp;#34;))  b := a  b.Write([]byte(&amp;#34;b&amp;#34;)) } // 运行报错：panic: strings: illegal use of non-zero Builder copied by value 报错信息，来源于strings.Builder的copyCheck。
type Builder struct {  addr *Builder // of receiver, to detect copies by value  buf []byte }  func (b *Builder) Write(p []byte) (int, error) {  b.copyCheck()  b.buf = append(b.buf, p...)  return len(p), nil }  func (b *Builder) copyCheck() {  if b.addr == nil {  b.addr = (*Builder)(noescape(unsafe.Pointer(b)))  } else if b.addr != b {  panic(&amp;#34;strings: illegal use of non-zero Builder copied by value&amp;#34;)  } } 在Builder中，addr是一个指向自身的指针。当对上文中的a复制给b时，a和b本身是不同的对象。因此，b.addr实际还是指向a的指针，这就会触发条件b.addr!=b，造成panic。
 sync.Cond中copy检查  在源码中，拥有copy检查机制的还有sync.Cond。
type Cond struct {  noCopy noCopy  L Locker  notify notifyList  checker copyChecker }  func (c *Cond) Wait() {  c.checker.check()  ... }  type copyChecker uintptr  func (c *copyChecker) check() {  if uintptr(*c) != uintptr(unsafe.Pointer(c)) &amp;amp;&amp;amp;  !atomic.CompareAndSwapUintptr((*uintptr)(c), 0, uintptr(unsafe.Pointer(c))) &amp;amp;&amp;amp;  uintptr(*c) != uintptr(unsafe.Pointer(c)) {  panic(&amp;#34;sync.Cond is copied&amp;#34;)  } } 这里的check函数初看不易明白。因此，定义一个相似的结构体对象，来探究这里的check函数究竟是如何做copy检查的。
type cond struct {  checker copyChecker }  type copyChecker uintptr  func (c *copyChecker) check() {  fmt.Printf(&amp;#34;Before: c: %12v, *c: %12v, uintptr(*c): %12v, uintptr(unsafe.Pointer(c)): %12v\n&amp;#34;, c, *c, uintptr(*c), uintptr(unsafe.Pointer(c)))  swapped := atomic.CompareAndSwapUintptr((*uintptr)(c), 0, uintptr(unsafe.Pointer(c)))  fmt.Printf(&amp;#34;After : c: %12v, *c: %12v, uintptr(*c): %12v, uintptr(unsafe.Pointer(c)): %12v, swapped: %12v\n&amp;#34;, c, *c, uintptr(*c), uintptr(unsafe.Pointer(c)), swapped) }  func main() {  var a cond  a.checker.check()  b := a  b.checker.check() }  // 输出 Before: c: 0xc0000b4008, *c: 0, uintptr(*c): 0, uintptr(unsafe.Pointer(c)): 824634458120 After : c: 0xc0000b4008, *c: 824634458120, uintptr(*c): 824634458120, uintptr(unsafe.Pointer(c)): 824634458120, swapped: true Before: c: 0xc0000b4040, *c: 824634458120, uintptr(*c): 824634458120, uintptr(unsafe.Pointer(c)): 824634458176 After : c: 0xc0000b4040, *c: 824634458120, uintptr(*c): 824634458120, uintptr(unsafe.Pointer(c)): 824634458176, swapped: false 这下，sync.Cond的copy检查就很清晰了。当a被b copy之后，uintptr(*c)和uintptr(unsafe.Pointer(c))的值是不同的，通过uint对象的原子比较方法CompareAndSwapUintptr将返回false，它证明了对象a被copy过，从而调用panic保护sync.Cond不被复制。
2. go vet checking
上述两个例子都是在程序编译后，runtime检查的。但是，正如文中开篇所述，sync包下的其他的对象如Pool、WaitGroup、Mutex、Map等，它们其实也需要copy检查机制，但是在源码中，却没有提供运行时检查。那该如何保证我们的代码中这些对象在使用中未被copy，从而避免潜在的安全问题呢？
Go在源代码src/sync/cond.go中的一段注释给了我们答案。
// noCopy may be embedded into structs which must not be copied // after the first use. // // See https://golang.org/issues/8005#issuecomment-190753527 // for details. type noCopy struct{}  // Lock is a no-op used by -copylocks checker from `go vet`. func (*noCopy) Lock() {} func (*noCopy) Unlock() {} 很明显，runtime时的copy检查虽然很重要，但是，该操作会影响程序的执行性能。Go官方目前只提供了strings.Builder和sync.Cond的runtime拷贝检查机制，对于其他需要nocopy对象类型来说，使用go vet工具来做静态编译检查。
具体实施来说，就是该对象，或对象中存在filed，它拥有Lock()和Unlock()方法，即实现sync.Locker接口。之后，可以通过go vet功能，来检查代码中该对象是否有被copy。
例如sync.Pool和sync.WaitGroup就内嵌了noCopy属性，sync.Mutex实现了sync.Locker接口，sync.Map内嵌了sync.Mutex。
 静态检查  // wg.go package main  import &amp;#34;sync&amp;#34;  func main() { 	var sm sync.Mutex 	sm.Lock() 	sm.Unlock() 	sm2 := sm 	sm2.Lock() } 如上，sm在first use后，被copy给sm2。注意：该代码运行时，不会报错，但是却存在安全隐患。
 $ go vet wg.go  # command-line-arguments ./wg.go:9:9: assignment copies lock value to sm2: sync.Mutex 通过以上命令，即可检查出sync.Mutex有被copy。因此，举一反三，如果在我们自己的项目开发中，定义某对象不能被copy，那么就可以参考Go源码中，嵌入noCopy结构体，最终通过go vet进行copy检查。
type noCopy struct{} func (*noCopy) Lock() {} func (*noCopy) Unlock() {} type MyType struct {  noCopy noCopy  ... } 更多关于Go关于no copy的讨论请参考官方Github issue，地址：https://github.com/golang/go/issues/8005
以上内容转载自机器铃砍菜刀
</content>
    </entry>
    
     <entry>
        <title>万能钥匙中间层</title>
        <url>http://shanks.link/blog/2021/04/26/%E4%B8%87%E8%83%BD%E9%92%A5%E5%8C%99%E4%B8%AD%E9%97%B4%E5%B1%82/</url>
        <categories>
          <category>algorithm</category>
        </categories>
        <tags>
          <tag>algorithm</tag>
        </tags>
        <content type="html"> 万能钥匙-中间层 最近小菜刀重读《程序员的自我修养》，里面提到过一句名言：计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决。
上述名言概括了计算机系统软件体系结构的设计要点，整个体系结构从上到下都是按照严格的层次结构设计的。不仅是计算机系统软件整个体系是这样的，体系里面的每个组件比如操作系统本身，应用程序、软件系统甚至很多硬件结构都是按照这种层次的结构组织和设计的。
下面，本文举例带领大家体会这种中间层理念。
01
计算机软件体系结构
![](/如图所示，每层之间都通过接口进行交互。除了硬件和应用程序，其他都是所谓的中间层，每个中间层都是对它下面层的包装和扩展。正是因为这些中间层的存在，才使得应用程序和硬件之间保持相对的独立。
例如虚拟机技术，其就是在硬件和操作系统之间增加了一层虚拟层，使得一个计算机可以同时运行多个操作系统；又如当前大火的Docker容器技术，是在操作系统和应用之间增加的一层虚拟层，为应用提供一致的运行环境。
这就是层次结构带来的好处，在尽可能少改变甚至不改变其他层的情况下，新增加一个层次就可以提供前所未有的功能。
02
计算机存储体系结构
![](/** **
一个典型的寄存器文件只能储存几百字节的信息，而主存里可存放几十亿字节，但是，计算机处理器从寄存器文件中读取数据比从主存中读取几乎要快100倍，而且随着半导体技术的进步，这种差距还在持续增大。
于是，系统设计者在主存和寄存器之间增加了中间层：高速缓存。其利用局部性原理，即程序具有访问局部区域里的数据和代码的趋势。让高速缓存里存放可能经常访问的数据，大部分的内存操作都能在快速的高速缓存中完成。这样就很好的解决了主存和寄存器之间的性能差距问题。
其实，不止在主存和寄存器之间，在整个存储器结构中，我们都可以把上一层的存储器作为低一层存储器的高速缓存。如上图所示，寄存器文件就是L1的高速缓存，L1是L2的高速缓存，L2是L3的高速缓存，L3是主存的高速缓存，而主存又是磁盘的高速缓存，在分布式文件系统中，本地存储就是存储在其他远程系统中磁盘上的高速缓存。
通过这种高速缓存中间层的设计思想，把整个存储体系作为了一个大的存储器池。结果是，其成本与层次结构底层最便宜的存储设备相当，但是却以接近于层次结构顶部存储设备的高速率向程序提供数据。
03
缓存数据库
![](/网站访问数据的特点一般会呈现“二八定律”，即80%的业务访问集中在%20的数据上。例如：百度搜索热词，新浪微博热门事件等，往往这些都是一小部分数据（热数据），大多数数据比较少被访问（冷数据）。
如果网站对冷热数据都通过传统RDS数据库处理，例如MySQL，那么在当该网站的访问量达到一定规模时，数据库的IO操作很容易进入性能瓶颈。因此，引入了中间层即内存数据库，作为热数据的缓存。因为内存数据库，例如Redis，它们的数据运行在内存当中，IO响应会非常的快，所以可以很好地解决上述问题。
04
中间件技术
中间件可能是诠释中间层理念的最佳实践，以下是维基百科给出的中间件示意图。
![](/但中间件其实是一个很宽泛的概念，我国学术界一般认可的定义是：中间件是指网络环境下处于操作系统、数据库等系统软件和应用软件之间的一种其连接作用的分布式软件，主要解决异构网络环境下分布式应用软件的互连与互操作问题，提供标准接口、协议、屏蔽实现细节，以提高应用系统易移植性（北京大学梅宏）。
常见的有消息中间件、数据库中间件、web中间件，容器等。以目前很火的MQ消息中间件为例，它的出现能够帮助系统对用户请求异步处理、应用解耦和流量削峰等。
05
总结
“计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决”。中间层思想的实践在计算机科学领域中无处不在。除上述之外，代理服务、池技术、网络协议、以及现在热炒的数据中台等，无一不在践行着中间层理念。如果你现在的项目中，交互的两者存在某些不可避免的障碍，不妨考虑是否可通过引入新的中间层解决该问题。
** **
参考：
 《程序员的自我修养》 《深入理解计算机系统》 https://en.wikipedia.org/wiki/Middleware https://blog.csdn.net/singit/article/details/71156863 https://blog.csdn.net/xlgen157387/article/details/53230138 https://www.jianshu.com/p/2820561158c4  以上内容转载自 机器铃砍菜刀
</content>
    </entry>
    
     <entry>
        <title>信号处理与Go程序的优雅退出</title>
        <url>http://shanks.link/blog/2021/04/26/%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86%E4%B8%8Ego%E7%A8%8B%E5%BA%8F%E7%9A%84%E4%BC%98%E9%9B%85%E9%80%80%E5%87%BA/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 信号处理与Go程序的优雅退出 学过计算机系统的人，应该知道异常控制流（ECF）。异常控制流发生在计算机系统的各个层次。比如，在硬件层，硬件检测到的事件会触发控制突然转移到异常处理程序。在操作系统层，内核通过上下文切换将控制从一个用户进程转移到另一个用户进程。在应用层，一个进程可以发送信号到另一个进程，而接收者会将控制突然转移到它的一个信号处理程序。
什么是信号
本文讨论的就是在应用层次的异常，也被称为信号。我们知道，在正常情况下，低层次的硬件异常是由内核异常处理程序处理的，对用户进程而来是不可见的。而信号提供了一种机制，通知用户进程发生了这些异常。
简单来说，一个信号就是一条事件消息，它通知进程系统中发生了一个某种类型的事件。
举几个常见的例子（以linux为例）。SIGINT，它就是通过我们在终端输入的Ctrl&#43;C进行触发；SIGKILL，即终端输入kill -9；SIGUSR1和SIGUSR2，用户自定义信号。
可以通过kill -l查看本机操作系统提供了哪些信号，以下是小菜刀mac上支持的信号列表。
$ kill -l  1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL  5) SIGTRAP 6) SIGABRT 7) SIGEMT 8) SIGFPE  9) SIGKILL 10) SIGBUS 11) SIGSEGV 12) SIGSYS 13) SIGPIPE 14) SIGALRM 15) SIGTERM 16) SIGURG 17) SIGSTOP 18) SIGTSTP 19) SIGCONT 20) SIGCHLD 21) SIGTTIN 22) SIGTTOU 23) SIGIO 24) SIGXCPU 25) SIGXFSZ 26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGINFO 30) SIGUSR1 31) SIGUSR2 如果你想知道每种信号，代表什么含义，可通过man signal命令查看信号注释。
$ man signal  No Name Default Action Description  1 SIGHUP terminate process terminal line hangup  2 SIGINT terminate process interrupt program  3 SIGQUIT create core image quit program  4 SIGILL create core image illegal instruction  5 SIGTRAP create core image trace trap  6 SIGABRT create core image abort program (formerly SIGIOT)  7 SIGEMT create core image emulate instruction executed  8 SIGFPE create core image floating-point exception  9 SIGKILL terminate process kill program  10 SIGBUS create core image bus error  11 SIGSEGV create core image segmentation violation  12 SIGSYS create core image non-existent system call invoked  13 SIGPIPE terminate process write on a pipe with no reader  14 SIGALRM terminate process real-time timer expired  15 SIGTERM terminate process software termination signal  16 SIGURG discard signal urgent condition present on socket  17 SIGSTOP stop process stop (cannot be caught or ignored)  18 SIGTSTP stop process stop signal generated from keyboard  19 SIGCONT discard signal continue after stop  20 SIGCHLD discard signal child status has changed  21 SIGTTIN stop process background read attempted from control terminal  22 SIGTTOU stop process background write attempted to control terminal  23 SIGIO discard signal I/O is possible on a descriptor (see fcntl(2))  24 SIGXCPU terminate process cpu time limit exceeded (see setrlimit(2))  25 SIGXFSZ terminate process file size limit exceeded (see setrlimit(2))  26 SIGVTALRM terminate process virtual time alarm (see setitimer(2))  27 SIGPROF terminate process profiling timer alarm (see setitimer(2))  28 SIGWINCH discard signal Window size change  29 SIGINFO discard signal status request from keyboard  30 SIGUSR1 terminate process User defined signal 1  31 SIGUSR2 terminate process User defined signal 2 注意：SIGKILL和SIGSTOP这两个信号既不能被应用程序捕获，也不能被操作系统阻塞或忽略，这意味着当你在使用kill -9的时候一定要十分的慎重！
信号监听
Go中对信号的监听主要通过os/sgnal包下的四个方法
  Notify：监听信号
  Stop：取消监听
  Reset：重置监听
  Ignore/Ignored：忽略信号
  监听示例代码
func signalHandler() {  signalChan := make(chan os.Signal, 1)  signal.Notify(signalChan) // 监听所有信号。注意，Notify接收可变参数，可以指定监听信号。   go func() {  for {  sig := &amp;lt;-signalChan // 监听到信号  log.Printf(&amp;#34;got signal to exit [signal = %v]&amp;#34;, sig)  }  }() }  func main() {  signalHandler()  select {} } 在goland中执行代码输入示例
2020/05/31 11:28:31 got signal to exit [signal = window size changes] 2020/05/31 11:28:31 got signal to exit [signal = urgent I/O condition] 2020/05/31 11:28:31 got signal to exit [signal = window size changes] 2020/05/31 11:28:32 got signal to exit [signal = interrupt]  Process finished with exit code 9 注意：在该代码中，你再也不能通过Ctrl&#43;C关闭程序了（上述输出第四行代表的就是接收到SIGINT信号），你只能采用kill -9的方式关闭（上述最后一行代表的就是接收到SIGKILL信号）。
当然，你也可以指定监听特定信号。
signal.Notify(c, syscall.SIGHUP, syscall.SIGINT, syscall.SIGTERM) 需要注意的是，不同系统平台的信号定义会有所差别，可在syscall包下zerrors_xxx_yyy.go中找到对应信号（其中，xxx代表操作系统，yyy代表硬件体系。例如小菜刀的机器上对应的就是zerrors_darwin_amd64.go文件中的信号定义）。
Go程序优雅退出
我们都知道，应用程序在部署上线后，都会遇到升级维护的问题，一般需要停掉应用程序，再更新代码，启动程序。但是，我们在停掉线上运行着的应用程序时，通常不能简单粗暴的直接kill，需要做一些退出前处理（例如关掉数据库连接，持久化日志，清理应用垃圾等），而退出处理的触发就是通过信号接收处理。
因此，程序的优雅退出即是，在程序退出之前，相关资源得到妥善地处理。以下为优雅退出示例代码
func SetupSignalHandler(shutdownFunc func(bool)) {  closeSignalChan := make(chan os.Signal, 1)  // 监听四种关闭信号  signal.Notify(closeSignalChan,  syscall.SIGHUP,  syscall.SIGINT,  syscall.SIGTERM,  syscall.SIGQUIT)   go func() {  sig := &amp;lt;-closeSignalChan  log.Printf(&amp;#34;got signal to exit [signal = %v]&amp;#34;, sig)  //判断关闭信号是否为SIGQUIT(用户发送Ctrl&#43;/即可触发)  shutdownFunc(sig == syscall.SIGQUIT)  }() }  func shutdown(isgraceful bool) {  if isgraceful {  //当满足 sig == syscall.SIGQUIT,做相应退出处理  }  // 不是syscall.SIGQUIT的退出信号时，做相应退出处理 }  func main() {  SetupSignalHandler(shutdown) // 注册监听信号，绑定信号处理机制  select {} // 模拟应用程序一直保持在线运行 } 参考文章
  《深入理解计算机系统 第三版》
  https://golang.google.cn/pkg/os/signal/
  以上内容转载自机器铃砍菜刀
</content>
    </entry>
    
     <entry>
        <title>深入理解syncMap</title>
        <url>http://shanks.link/blog/2021/04/26/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3syncmap/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 深入理解sync.Map golang中内置了map关键字，但是它是非线程安全的。从go 1.9开始，标准库加入了sync.Map，提供用于并发安全的map。
普通map的并发问题
map的并发读写代码
** **
func main() {  m := make(map[int]int)   go func() {  for {  _ = m[1] // 读  }  }()   go func() {  for {  m[2] = 2 // 写  }  }()   select {} // 维持主goroutine } 以上是一段并发读写map的代码, 其中一个goroutine一直读，另外一个goroutine一直写。即使读写的map键不相同，且不存在&amp;quot;扩容&amp;quot;等操作，代码还是会报错。
fatal error: concurrent map read and map write 锁&#43;map
那普通map有没有能力实现并发安全呢？答案是肯定的。通过给map额外绑定一个锁（sync.Mutex或sync.RWMutex），封装成一个新的struct，实现并发安全。
定义带有锁的对象M
type M struct {  sync.RWMutex  Map map[int]int } 执行并发读写
func main() {  m := M{Map: make(map[int]int)}   go func() {  for {  m.RLock()  v := m.Map[2] // 读  fmt.Println(v)  m.RUnlock()  }  }()   go func() {  for i := 1; i &amp;gt; 0; i&#43;&#43; {  m.Lock()  m.Map[2] = i // 写  m.Unlock()  }  }()   select {} } 在读goroutine读数据时，通过读锁锁定，在写goroutine写数据时，写锁锁定，程序就能并发安全的运行，运行结果示意如下。
... 1123 1124 1125 ... sync.Map
既然通过加锁的方式就能解决map的并发问题，实现方式简洁，并且利用读写锁而不是Mutex可以进一步减少读写的时候因为锁而带来的性能损耗。那么为什么还会有sync.Map的出现？
当map的数据量非常大时，会引发并发的大量goroutine争夺同一把锁，这种现象将直接导致性能的急剧下降。在java中有类似于map的hashMap，它同样是并发不安全，但是JDK提供了线程安全的ConcurrentHashMap，它在面对上述场景时，其核心解决方案是锁分段技术，即内部使用多个锁，每个区间共享一把锁，当多线程访问map中的不同数据段的数据时，线程间就不会存在锁竞争，从而提高了并发访问效率。那sync.Map采取的是什么策略来提升并发性能的呢？
sync.Map的源码结构（基于1.14.1）
type Map struct {  // 此锁是为了保护Map中的dirty数据  mu Mutex  // 用来存读的数据，只读类型，不会造成读写冲突  read atomic.Value // readOnly  // dirty包含最新的写入数据（entry），在写的同时，将read中未删除的数据拷贝到dirty中  // 因为是go中内置的普通map类型，且涉及写操作，所以需要通过mu加锁  dirty map[interface{}]*entry  // 当读数据时,该字段不在read中，尝试从dirty中读取，不管是否在dirty中读取到数据，misses&#43;1  // 当累计到len（dirty）时，会将dirty拷贝到read中，并将dirty清空，以此提升读性能。  misses int } 在sync.Map中用到了两个冗余数据结构read、dirty。其中read的类型为atomic.Value，它会通过atomic.Value的Load方法将其断言为readOnly对象。
read, _ := m.read.Load().(readOnly) // m为sync.Map 因此，read的真实类型即是readOnly，其数据类型如下。
type readOnly struct {  // read 中的go内置map类型，但是它不需要锁。  m map[interface{}]*entry  // 当sync.Map.diry中的包含了某些不在m中的key时，amended的值为true.  amended bool } amended属性的作用是指明dirty中是否有readOnly.m中未包含的数据，因此当对sync.Map的读操作在read中找不到数据时，将进一步到dirty中查找。
readOnly.m和Map.dirty中map存储的值类型是*entry,它包含一个指针p，指向用户存储的value值。
type entry struct { 	p unsafe.Pointer // *interface{} } entry.p的值有三种类型：
  nil：entry已经被删除，且m.dirty为nil
  expunged：entry被删除，m.dirty不为nil，但entry不存在m.dirty中
  其他：entry有效，记录在m.read中，若dirty不为空，也会记录在dirty中。
  虽然read和dirty存在冗余数据，但是这些数据entry是通过指针指向的，因此，尽管Map的value可能会很大，但是空间存储还是足够的。
以上是sync.Map的数据结构，下面着重看看它的四个方法实现：Load、Store、Delete和Range。
Load
加载方法，通过提供的键key，查找对应的值value。
func (m *Map) Load(key interface{}) (value interface{}, ok bool) {  // 首先从m.read中通过Load方法得到readOnly  read, _ := m.read.Load().(readOnly)  // 从read中的map中查找key  e, ok := read.m[key]  // 如果在read中没有找到，且表明有新数据在diry中（read.amended为true）  // 那么，就需要在dirty中查找，这时需要加锁。  if !ok &amp;amp;&amp;amp; read.amended {  m.mu.Lock()  // 双重检查:避免在本次加锁的时候，有其他goroutine正好将Map中的dirty数据复制到了read中。  // 能发生上述可能的原因是以下两行代码语句，并不是原子操作。  // if !ok &amp;amp;&amp;amp; read.amended {  // m.mu.Lock()  // }  // 而Map.read其并发安全性的保障就在于它的修改是通过原子操作进行的。  // 因此需要再检查一次read.  read, _ = m.read.Load().(readOnly)  e, ok = read.m[key]  // 如果m.read中key还是不存在，且dirty中有新数据，则检查dirty中的数据。  if !ok &amp;amp;&amp;amp; read.amended {  e, ok = m.dirty[key]  // 不管是否从dirty中得到了数据，都会将misses的计数&#43;1  m.missLocked()  }  m.mu.Unlock()  }  if !ok {  return nil, false  }   // 通过Map的load方法，将entry.p加载为对应指针，再返回指针指向的值  return e.load() } Map.missLocked函数是保证sync.Map性能的重要函数，它的目的是将存在有锁的dirty中的数据，转移到只读线程安全的read中去。
func (m *Map) missLocked() {  m.misses&#43;&#43; // 计数&#43;1  if m.misses &amp;lt; len(m.dirty) {  return  }  m.read.Store(readOnly{m: m.dirty}) // 将dirty数据复制到read中去  m.dirty = nil // dirty清空  m.misses = 0 // misses重置为0 } Store
该方法更新或新增键值对key-value。
func (m *Map) Store(key, value interface{}) {  // 如果m.read中存在该键，且该键没有被标记删除（expunged）  // 则尝试直接存储（见entry的tryStore方法）  // 注意： 如果m.dirty中也有该键（key对应的entry），由于都是通过指针指向，所有m.dirty中也会保持最新entry值。  read, _ := m.read.Load().(readOnly)  if e, ok := read.m[key]; ok &amp;amp;&amp;amp; e.tryStore(&amp;amp;value) {  return  }  // 如果不满足上述条件，即m.read不存在或者已经被标记删除  m.mu.Lock()  read, _ = m.read.Load().(readOnly)  if e, ok := read.m[key]; ok { // 如果read中有该键  if e.unexpungeLocked() { // 判断entry是否被标记删除  // 如果entry被标记删除，则将entry添加进m.dirty中  m.dirty[key] = e  }  // 更新entry指向value地址  e.storeLocked(&amp;amp;value)  } else if e, ok := m.dirty[key]; ok { //dirty中有该键：更新  e.storeLocked(&amp;amp;value)  } else { // dirty和read中均无该键：新增  if !read.amended { // 表明dirty中没有新数据，在dirty中增加第一个新键  m.dirtyLocked() // 从m.read中复制未删除的数据到dirty中  m.read.Store(readOnly{m: read.m, amended: true})  }  m.dirty[key] = newEntry(value) // 将entry增加到dirty中  }  m.mu.Unlock() } Store的每次操作都是先从read开始，当不满足条件时，才加锁操作dirty。但是由于存在从read中复制数据的情况（例如dirty刚复制完数据给m.read，又来了一个新键），当m.read中数据量很大时，可能对性能造成影响。
Delete
删除某键值。
func (m *Map) Delete(key interface{}) {  read, _ := m.read.Load().(readOnly)  e, ok := read.m[key]  if !ok &amp;amp;&amp;amp; read.amended {  m.mu.Lock()  read, _ = m.read.Load().(readOnly)  e, ok = read.m[key]  if !ok &amp;amp;&amp;amp; read.amended {  delete(m.dirty, key)  }  m.mu.Unlock()  }  if ok {  e.delete()  } }  // 如果read中有该键，则从read中删除，其删除方式是通过原子操作 func (e *entry) delete() (hadValue bool) {  for {  p := atomic.LoadPointer(&amp;amp;e.p)  // 如果p指针为空，或者被标记清除  if p == nil || p == expunged {  return false  }  // 通过原子操作，将e.p标记为nil.  if atomic.CompareAndSwapPointer(&amp;amp;e.p, p, nil) {  return true  }  } } Delete中的逻辑和Store逻辑相似，都是从read开始，如果这个key（也即是entry）不在read中，且dirty中有新数据，则加锁从dirty中删除。注意，和Load与Store方法一样，也是需要双检查。
Range
想要遍历sync.Map，不能通过for range的形式，因此，它自身提供了Range方法，通过回调的方式遍历。
func (m *Map) Range(f func(key, value interface{}) bool) {  read, _ := m.read.Load().(readOnly)  // 判断dirty中是否有新的数据  if read.amended {  m.mu.Lock()  // 双检查  read, _ = m.read.Load().(readOnly)  if read.amended {  // 将dirty中的数据复制到read中  read = readOnly{m: m.dirty}  m.read.Store(read)  m.dirty = nil  m.misses = 0  }  m.mu.Unlock()  }   // 遍历已经整合过dirty的read  for k, e := range read.m {  v, ok := e.load()  if !ok {  continue  }  if !f(k, v) {  break  }  } } sync.Map的优化总结
  空间换时间：通过两个冗余的数据结构（read、write），减小锁对性能的影响。
  读操作使用read，避免读写冲突。
  动态调整：通过misses值，避免dirty数据过多。
  双检查机制：避免在非原子操作时产生数据错误。
  延迟删除机制：删除一个键值只是先打标记，只有等提升dirty（复制到read中，并清空自身）时才清理删除的数据。
  优先从read中读、改和删除，因为对read的操作不用加锁，大大提升性能。
  ** **
sync.Map的使用例子
func main() {  var sm sync.Map  // 注意：同一个sync.Map，和map不一样，每个item的key或value可以和其他的数据类型不一样  // 只要满足key能hash即可  sm.Store(1, &amp;#34;a&amp;#34;)  sm.Store(&amp;#34;b&amp;#34;, 2)  sm.Store(&amp;#34;c&amp;#34;, 3)  // 和map获取key值类似  if v, ok := sm.Load(&amp;#34;b&amp;#34;); ok {  fmt.Println(v)  }   // 删除某个key的键值对  sm.Delete(1)   // 参数fun中的参数是遍历获得的key和value，返回一个bool值  // 返回true时，继续遍历  // 返回false，遍历结束  sm.Range(func(key, value interface{}) bool {  fmt.Println(key,value)  return true  }) } 输出
2b 2c 3 sync.Map的性能
在Go源码$GOROOT/src/sync中，提供了测试代码。
  map_reference_test.go: 定义了测试用的mapInterface接口，sync.Map、RwMutexMap和DeepCopyMap对象实现该接口方法。
  map_test.go: 三个对象的方法测试代码。
  map_bench_test.go: 三个对象的benchmark性能对比测试代码。
  在小菜刀的机器上，运行性能测试结果如下。
$ go test -bench=LoadMostlyHits -benchmem BenchmarkLoadMostlyHits/*sync_test.DeepCopyMap-8 80252629 13.5 ns/op 7 B/op 0 allocs/op BenchmarkLoadMostlyHits/*sync_test.RWMutexMap-8 23025050 51.8 ns/op 7 B/op 0 allocs/op BenchmarkLoadMostlyHits/*sync.Map-8 67718686 14.9 ns/op 7 B/op 0 allocs/op  $ go test -bench=LoadMostlyMisses -benchmem BenchmarkLoadMostlyMisses/*sync_test.DeepCopyMap-8 128480215 11.2 ns/op 7 B/op 0 allocs/op BenchmarkLoadMostlyMisses/*sync_test.RWMutexMap-8 23989224 47.4 ns/op 7 B/op 0 allocs/op BenchmarkLoadMostlyMisses/*sync.Map-8 132403878 9.30 ns/op 7 B/op 0 allocs/op  $ go test -bench=LoadOrStoreBalanced -benchmem BenchmarkLoadOrStoreBalanced/*sync_test.RWMutexMap-8 3909409 553 ns/op 99 B/op 2 allocs/op BenchmarkLoadOrStoreBalanced/*sync.Map-8 3574923 368 ns/op 97 B/op 3 allocs/op  $ go test -bench=LoadOrStoreUnique -benchmem BenchmarkLoadOrStoreUnique/*sync_test.RWMutexMap-8 2053806 647 ns/op 174 B/op 2 allocs/op BenchmarkLoadOrStoreUnique/*sync.Map-8 2456720 577 ns/op 140 B/op 4 allocs/op  $ go test -bench=LoadOrStoreCollision -benchmem BenchmarkLoadOrStoreCollision/*sync_test.DeepCopyMap-8 153679003 8.18 ns/op 0 B/op 0 allocs/op BenchmarkLoadOrStoreCollision/*sync_test.RWMutexMap-8 13718534 87.9 ns/op 0 B/op 0 allocs/op BenchmarkLoadOrStoreCollision/*sync.Map-8 175620835 7.08 ns/op 0 B/op 0 allocs/op  $ go test -bench=Range -benchmem BenchmarkRange/*sync_test.DeepCopyMap-8 416906 2947 ns/op 0 B/op 0 allocs/op BenchmarkRange/*sync_test.RWMutexMap-8 22784 52370 ns/op 16384 B/op 1 allocs/op BenchmarkRange/*sync.Map-8 369955 3194 ns/op 0 B/op 0 allocs/op  $ go test -bench=AdversarialAlloc -benchmem BenchmarkAdversarialAlloc/*sync_test.DeepCopyMap-8 1875109 646 ns/op 539 B/op 1 allocs/op BenchmarkAdversarialAlloc/*sync_test.RWMutexMap-8 19454866 61.6 ns/op 8 B/op 1 allocs/op BenchmarkAdversarialAlloc/*sync.Map-8 3712470 320 ns/op 51 B/op 1 allocs/op  $ go test -bench=AdversarialDelete -benchmem BenchmarkAdversarialDelete/*sync_test.DeepCopyMap-8 6749067 215 ns/op 168 B/op 1 allocs/op BenchmarkAdversarialDelete/*sync_test.RWMutexMap-8 16046545 76.9 ns/op 25 B/op 1 allocs/op BenchmarkAdversarialDelete/*sync.Map-8 18678104 64.2 ns/op 如何选择Map
从性能测试结果可以看出，sync.Map并不是为了代替锁&#43;map的组合。它的设计，是为了在某些并发场景下，相对前者能有较小的性能损耗。
源码文档中（$GOROOT/src/sync/map.go）已经给出了sync.Map的合适场景。
// The Map type is specialized. Most code should use a plain Go map instead, // with separate locking or coordination, for better type safety and to make it // easier to maintain other invariants along with the map content. // // The Map type is optimized for two common use cases: (1) when the entry for a given // key is only ever written once but read many times, as in caches that only grow, // or (2) when multiple goroutines read, write, and overwrite entries for disjoint // sets of keys. In these two cases, use of a Map may significantly reduce lock // contention compared to a Go map paired with a separate Mutex or RWMutex. 两种情况应该选择sync.Map
 key值一次写入，多次读取（即写少读多场景）。 多个goroutine的读取、写入和覆盖在不相交的key集。  以上内容转载自机器铃砍菜刀
</content>
    </entry>
    
     <entry>
        <title>高并发系统之限流技术</title>
        <url>http://shanks.link/blog/2021/04/26/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B9%8B%E9%99%90%E6%B5%81%E6%8A%80%E6%9C%AF/</url>
        <categories>
          <category>algorithm</category>
        </categories>
        <tags>
          <tag>algorithm</tag>
        </tags>
        <content type="html"> 高并发系统之限流技术 在开发高并发系统时，有三把利器用来保护系统：缓存、降级和限流。限流是指通过对并发访问/请求进行限速或者对一个时间内的的请求进行限量来保护系统，一旦达到限制条件则可以拒绝服务。
总体来说，实现限流有三种主流方式：计数器，漏桶算法（leaky-bucket）和令牌桶算法token-bucket）。
计数器
1. 简单计数器
简单计数器是限流算法中最简单也是最容易实现的一种算法。比如我们规定，对于接口A来说，1分钟的请求次数不能超过1000次。那么，设置一个请求计数器，将初始值设为0。当有请求进来时，会把计数器&#43;1，如果在1分钟间隔以内计数器的值大于1000，说明请求数过多，对后续请求拒绝服务；当1分钟间隔后，重置计数器。
实现代码
 限流器定义  type RequestLimitService struct {  Interval time.Duration // 设置时间窗口大小  MaxCount int // 窗口内能支持的最大请求数（阈值）  Lock sync.Mutex // 并发控制锁  ReqCount int // 当前窗口请求数（计数器） }  实现限流器的两个核心方法  // 判断当前窗口请求数是否大于最大请求数 func (reqLimit *RequestLimitService) IsAvailable() bool {  reqLimit.Lock.Lock()  defer reqLimit.Lock.Unlock()   return reqLimit.ReqCount &amp;lt; reqLimit.MaxCount }  // 对当前窗口请求数 &#43;1 func (reqLimit *RequestLimitService) Increase() {  reqLimit.Lock.Lock()  defer reqLimit.Lock.Unlock()   reqLimit.ReqCount &#43;= 1 }  生成限流器  func NewRequestLimitService(interval time.Duration, maxCnt int) *RequestLimitService {  reqLimit := &amp;amp;RequestLimitService{  Interval: interval,  MaxCount: maxCnt,  }   go func() {  ticker := time.NewTicker(interval) // 当达到窗口时间，将计数器清零  for {  &amp;lt;-ticker.C  reqLimit.Lock.Lock()  fmt.Println(&amp;#34;Reset Count...&amp;#34;)  reqLimit.ReqCount = 0  reqLimit.Lock.Unlock()  }  }()   return reqLimit } 简单计数器算法实现起来非常方便，但是简单说明了它能考虑到的问题不够全面。设想，在上面的例子中，如果某用户在00：59到01：00之间发送了500个请求，并且在01：00和01：01之间又发送了500个请求，那么用户其实在这2秒间就已经发送了1000个请求，他的请求应该被拒绝。但是，简单计数器的设计则允许了这样的情况发生。因此，如果恶意用户利用通过在临近时间窗口的重置计数机制而发起大量突发请求，那么我们的系统很容易就被弄瘫痪。
2. 滑动窗口 对于刚才的问题，存在的问题就在于统计的精度太低，因此引入了滑动窗口（rolling window）的概念。
在上图中，整个红色的虚线矩形框表示一个时间窗口，该例中，一个时间窗口就是一分钟。将时间窗口进行划分，划成6格，所以每格代表的是10秒钟。每过10秒钟，窗口就会往右滑动一格。每一个格子都有自己独立的计数器counter，比如当一个请求在0:35秒的时候到达，0:30~0:39对应的counter就会加1。
那么滑动窗口怎么解决刚才的临界问题的？我们可以根据上图延用刚才的例子，0:59至01:00到达的500个请求会落在绿色的格子中，而01:00至01:01到达的请求会落在黄色的格子中。当时间到达1:00时，我们的窗口会往右移动一格，那么此时时间窗口内的总请求数量一共是1000个（假定前面的格子没有发生请求），达到了限定1000的条件，所以此时能够检测出来触发了限流。
总结：简单计数器算法其实就是滑动窗口算法的最简单实现。只是它没有对时间窗口做进一步地划分，只有1格。由此可见，当滑动窗口的格子划分的越多，滑动窗口的滚动就越平滑，限流的统计就会越精确。
漏桶算法
漏桶算法的思想比较好理解。首先，我们有一个固定容量的桶，有水流进来，也有水流出去。我们无法预计一共有多少水会流进来，也无法预计水流入的速度。但是这个桶可以固定水流出的速度。而且，当桶满了之后，多余的水将会溢出。
我们将算法中的水换成实际应用中的请求，可以看到漏桶算法天生就限制了请求的速度。当使用了漏桶算法，我们可以保证接口会以一个常速速率来处理请求。所以漏桶算法不会出现上述的临界问题。
伪代码实现
// 定义漏桶结构 type leakyBucket struct {  timestamp time.Time // 当前注水时间戳 （当前请求时间戳）  capacity float64 // 桶的容量（接受缓存的请求总量）  rate float64// 水流出的速度（处理请求速度）  water float64 // 当前水量（当前累计请求数） }  // 判断是否加水（是否处理请求） func addWater(bucket leakyBucket) bool {  now := time.Now()  // 先执行漏水，计算剩余水量  leftWater := math.Max(0,bucket.water - now.Sub(bucket.timestamp).Seconds()*bucket.rate)  bucket.timestamp = now  if leftWater &#43; 1 &amp;lt; bucket.water {  // 尝试加水，此时水桶未满  bucket.water = leftWater &#43;1  return true  }else {  // 水满了，拒绝加水  return false  } } uber 在 Github 上开源了一套用于服务限流的 go 语言库 ratelimit, 该库即是基于漏桶算法实现。
令牌桶算法
对于很多应用场景来说，除了要求能够限制数据的平均传输速率外，还要求允许某种程度的突发传输。这时候漏桶算法就不合适了，令牌桶算法派上了用场。
从图中我们可以看到，令牌桶算法比漏桶算法稍显复杂。首先，我们有一个固定容量的桶，桶里存放着令牌（token）。桶一开始是空的，token以一个固定的速率r往桶里填充，直到达到桶的容量，多余的令牌将会被丢弃。每当一个请求过来时，就会尝试从桶里移除一个令牌，如果没有令牌的话，请求无法通过。
伪代码实现
// 定义令牌桶结构 type tokenBucket struct {  timestamp time.Time // 当前时间戳  capacity float64 // 桶的容量（存放令牌的最大量）  rate float64// 令牌放入速度  tokens float64 // 当前令牌总量 }  // 判断是否获取令牌（若能获取，则处理请求） func getToken(bucket tokenBucket) bool {  now := time.Now()  // 先添加令牌  leftTokens := math.Max(bucket.capacity, bucket.tokens &#43; now.Sub(bucket.timestamp).Seconds()*bucket.rate)  bucket.timestamp = now  if leftTokens &amp;lt; 1 {  // 若桶中一个令牌都没有了，则拒绝  return false  }else {  // 桶中还有令牌，领取令牌  bucket.tokens -= 1  return true  } } 其实，Go官方团队已实现了基于令牌桶算法的限流库，即 golang.org/x/time/rate。
令牌桶和漏桶算法对比
  令牌桶是按照固定速率往桶中添加令牌，请求是否被处理需要看桶中令牌是否足够，当令牌数减为零时则拒绝新的请求；
  漏桶则是按照常量固定速率流出请求，流入请求速率任意，当流入的请求数累积到漏桶容量时，则新流入的请求被拒绝；
  令牌桶限制的是平均流入速率（允许突发请求，只要有令牌就可以处理，支持一次拿多个令牌），并允许一定程度的突发流量；
  漏桶限制的是常量流出速率（即流出速率是一个固定常量值，比如都是1的速率流出，而不能一次是1，下次又是2），从而平滑突发流入速率；
  令牌桶允许一定程度的突发，而漏桶主要目的是平滑流入速率；
  两个算法实现可以一样，但是方向是相反的，对于相同的参数得到的限流效果是一样的。
  总结，漏桶算法和令牌桶算法的主要区别在于，“漏桶算法”能够强行限制数据的传输速率（或请求频率），而“令牌桶算法”在能够限制数据的平均传输速率外，还允许某种程度的突发传输。
参考资料
https://en.wikipedia.org/wiki/Leaky_bucket
https://en.wikipedia.org/wiki/Token_bucket
https://github.com/uber-go/ratelimit/
https://godoc.org/golang.org/x/time/rate
https://www.cyhone.com/articles/analisys-of-golang-rate/
https://www.iteye.com/blog/jinnianshilongnian-2305117
    以上内容转载自机器铃砍菜刀
</content>
    </entry>
    
     <entry>
        <title>Golang开发者学习图鉴</title>
        <url>http://shanks.link/blog/2021/04/26/golang%E5%BC%80%E5%8F%91%E8%80%85%E5%AD%A6%E4%B9%A0%E5%9B%BE%E9%89%B4/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Golang开发者学习图鉴 想成为一名优秀的Golang开发者，你知道需要掌握哪些技能吗？为了帮助你更好的上🚗，本文为你提供了2020版Go开发者成长路线图。
1. 先决条件
  Go
  SQL
  2. 通用开发技能
  学习GIT，在GitHub上建立一些仓库，与其它人分享你的代码
  了解 HTTP(S) 协议，request 方法（GET, POST, PUT, PATCH, DELETE, OPTIONS）
  使用Google搜索，感受Google 搜索的力量
  看一些和数据结构以及算法有关的书籍
  学习关于认证的基础实现
  面向对象原则
  3. Web框架
  Echo
  Beego
  Gin
  Revel
  Chi
  4. 数据库
关系型
      SQL Server
  PostgreSQL
  MariaDB
  MySQL
  CockroachDB
  TiDB
  云数据库
      CosmosDB
  DynamoDB
  搜索引擎
      ElasticSearch
  Solr
  Sphinx
  NoSQL
      MongoDB
  Redis
  Apache Cassandra
  RavenDB
  CouchDB
  5. 对象关系映射框架
  Gorm
  Xorm
  6. 高速缓存
 GCache  分布式缓存
      Go-Redis
  GoMemcached
  7. 日志
日志框架
      Zap
  ZeroLog
  Logrus
  日志管理系统
      Sentry.io
  Loggly.com
  分布式追踪
     Jaeger  8. 实时通信
 Socket.IO  9. API 客户端
REST
      Gentleman
  GRequests
  heimdall
  GraphQL
      gqlgen
  graphql-go
  10. 最好知道
  Validator
  Glow
  GJson
  Authboss
  Go-Underscore
  11. 测试
单元、行为和集成测试
      GoMock
  Testify
  GinkGo
  GoMega
  GoCheck
  GoDog
  GoConvey
  端对端测试
      Selenium
  Endly
  12. 任务调度
  Gron
  JobRunner
  13. 微服务
消息代理
      RabbitMQ
  Apache Kafka
  ActiveMQ
  Azure Service Bus
  构建事件驱动型服务
      Watermill
  Message-Bus
  框架
      GoKit
  Micro
  rpcx
  RPC
      Protocol Buffers
  gRPC-Go
  gRPC-Gateway
  Twirp
  14. Go-模式
本路线图的目的是让你看到学习Go语言的一个全景图。在你对接下来要学习什么感到困惑的时候，这个路线图会给你一些指导，而不是鼓励你去选择当下流行的东西。你需要逐渐了解为什么一个工具可能会比另一个工具更适合某些场景。但请记住，流行的东西并不意味着一定适合你的工作。
参考链接：
https://github.com/Alikhll/golang-developer-roadmap
https://medium.com/tech-tajawal/modern-backend-developer-in-2018-6b3f7b5f8b9
以上内容转载自其它blog
</content>
    </entry>
    
     <entry>
        <title>Go并发控制</title>
        <url>http://shanks.link/blog/2021/04/26/go%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Golang并发控制简述 引言 Golang中通过go关键字就可开启一个goroutine，因此，在Go中可以轻松写出并发代码。但是，如何对这些并发执行的groutines有效地控制？
提到并发控制，很多人可能最先想到的是锁。Golang中同样提供了锁的相关机制，包括互斥锁sync.Mutex，和读写锁sync.RWMutex。除了锁，还有原子操作sync/atomic等。但是，这些机制关注的重点是goroutines的并发数据安全性。而本文想讨论的是goroutine的并发行为控制。
在goroutine并发行为控制中，有三种常见的方式，分别是WaitGroup、channel和Context。
WaitGroup ** **
WaitGroup位于sync包下，它的使用方法如下。
func main() {  var wg sync.WaitGroup   wg.Add(2) //添加需要完成的工作量2   go func() {  wg.Done() //完成工作量1  fmt.Println(&amp;#34;goroutine 1 完成工作！&amp;#34;)  }()   go func() {  wg.Done() //完成工作量1  fmt.Println(&amp;#34;goroutine 2 完成工作！&amp;#34;)  }()   wg.Wait() //等待工作量2均完成  fmt.Println(&amp;#34;所有的goroutine均已完成工作！&amp;#34;) }  输出: //goroutine 2 完成工作！ //goroutine 1 完成工作！ //所有的goroutine均已完成工作！ WaitGroup这种并发控制方式尤其适用于：某任务需要多 goroutine 协同工作，每个 goroutine 只能做该任务的一部分，只有全部的 goroutine 都完成，任务才算是完成。因此，WaitGroup同名字的含义一样，是一种等待的方式。
但是，在实际的业务中，有这么一种场景：当满足某个要求时，需主动的通知某一个 goroutine 结束。比如我们开启一个后台监控goroutine，当不再需要监控时，就应该通知这个监控 goroutine 结束，不然它会一直空转，造成泄漏。
Channel 对于上述场景，WaitGroup无能为力。那能想到的最简单的方法：定义一个全局变量，在其它地方通过修改这个变量进行通知，后台 goroutine 会不停的检查这个变量，如果发现变量发生了变化，即自行关闭，但是这个方法未免有些笨拙。这种情况，channel&#43;select可派上用场。
func main() {  exit := make(chan bool)   go func() {  for {  select {  case &amp;lt;-exit:  fmt.Println(&amp;#34;退出监控&amp;#34;)  return  default:  fmt.Println(&amp;#34;监控中&amp;#34;)  time.Sleep(2 * time.Second)  }  }  }()   time.Sleep(5 * time.Second)  fmt.Println(&amp;#34;通知监控退出&amp;#34;)  exit &amp;lt;- true   //防止main goroutine过早退出  time.Sleep(5 * time.Second) }  输出： //监控中 //监控中 //监控中 //通知监控退出 //退出监控 这种 channel&#43;select 的组合，是比较优雅的通知goroutine 结束的方式。
但是，该方案同样存在局限性。试想，如果有多个 goroutine 都需要控制结束怎么办？如果这些 goroutine 又衍生了其它更多的goroutine 呢？当然我们可以定义很多 channel 来解决这个问题，但是 goroutine 的关系链导致这种场景的复杂性。
Context 以上场景常见于CS架构模型下。在Go中，常常为每个client开启单独的goroutine（A）来处理它的一系列request，并且往往单个A中也会请求其他服务（启动另一个goroutine B），B也可能会请求另外的goroutine C，C再将request发送给例如Databse的server。设想，当client断开连接，那么与之相关联的A、B、C均需要立即退出，系统才可回收A、B、C所占用的资源。退出A简单，但是，如何通知B、C也退出呢？
这个时候，Context就出场了。
func A(ctx context.Context, name string) {  go B(ctx ,name) //A调用了B  for {  select {  case &amp;lt;-ctx.Done():  fmt.Println(name, &amp;#34;A退出&amp;#34;)  return  default:  fmt.Println(name, &amp;#34;A do something&amp;#34;)  time.Sleep(2 * time.Second)  }  } }  func B(ctx context.Context, name string) {  for {  select {  case &amp;lt;-ctx.Done():  fmt.Println(name, &amp;#34;B退出&amp;#34;)  return  default:  fmt.Println(name, &amp;#34;B do something&amp;#34;)  time.Sleep(2 * time.Second)  }  } }  func main() {  ctx, cancel := context.WithCancel(context.Background())   go A(ctx, &amp;#34;【请求1】&amp;#34;) //模拟client来了1个连接请求   time.Sleep(3 * time.Second)  fmt.Println(&amp;#34;client断开连接，通知对应处理client请求的A,B退出&amp;#34;)  cancel() //假设满足某条件client断开了连接，那么就传播取消信号，ctx.Done()中得到取消信号   time.Sleep(3 * time.Second) }  输出： //【请求1】 A do something //【请求1】 B do something //【请求1】 A do something //【请求1】 B do something //client断开连接，通知对应处理client请求的A,B退出 //【请求1】 B退出 //【请求1】 A退出 示例中模拟了客户端来了连接请求，相应开启Goroutine A进行处理，A同时开启了B处理，A和B都使用了 Context 进行跟踪，当我们使用 cancel 函数通知取消时，这 2个 goroutine 都会被结束。
这就是 Context 的控制能力，它就像一个控制器一样，按下开关后，所有基于这个 Context 或者衍生的子 Context 都会收到通知，这时就可以进行清理操作了，最终释放 goroutine，这就优雅的解决了 goroutine 启动后不可控的问题。
关于Context的详细用法，不在本文讨论范围之内。后续会出专门对Context包的讲解文章，敬请关注。
总结 本文列举了三种Golang中并发行为控制模式。模式之间没有好坏之分，只在于不同的场景用恰当的方案。实际项目中，往往多种方式混合使用。
 WaitGroup：多个goroutine的任务处理存在依赖或拼接关系。 channel&#43;select：可以主动取消goroutine；多groutine中数据传递；channel可以代替WaitGroup的工作，但会增加代码逻辑复杂性；多channel可以满足Context的功能，同样，也会让代码逻辑变得复杂。 Context：多层级groutine之间的信号传播（包括元数据传播，取消信号传播、超时控制等）。  以上内容转载自机器铃砍菜刀
</content>
    </entry>
    
     <entry>
        <title>Go之Sort排序</title>
        <url>http://shanks.link/blog/2021/04/26/go%E4%B9%8Bsort%E6%8E%92%E5%BA%8F/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Golang之sort包 Go语言是一门非常简单优雅的语言，其源码更是其风格标杆。看源码，不仅能学习Go的设计哲学，了解如何调用库函数，同时帮助我们写出更优雅的go代码。
Go源码位于GOROOT目录下的src中。
本文学习1.14.1版本源码库的sort包。该包对外提供的主要功能是排序和搜索。
其核心的函数分别是：sort.Sort()与sort.Search()。
1. sort.Sort()
函数定义如下
func Sort(data Interface) { 	n := data.Len() 	quickSort(data, 0, n, maxDepth(n)) } Sort函数中调用了quickSort方法，该方法下是排序算法的具体实现，核心策略是根据待排序的数据量，相应调整不同的排序算法，这部分内容不在本文分析内容之中。
对包使用者来说，需要注意的是，Sort的入参是Interface接口，这Interface是什么呢？以下是其在sort.go中的定义。
type Interface interface { 	// Len is the number of elements in the collection. 	Len() int // Less reports whether the element with 	// index i should sort before the element with index j. 	Less(i, j int) bool // Swap swaps the elements with indexes i and j. 	Swap(i, j int) } 可见，Interface是一个接口类型（interface），其需要实现的函数方法分别是：Len、Less和Swap。这意味着什么呢？
我们知道，go中的接口实现是隐式实现，只要对象实现了接口定义的方法，即可实现该接口。因此，这种方式是一种非侵入式的实现。
那么，如果需要某对象能调用Sort方法，即实现其参数Interface接口即可。
在Sort包中，已经实现了部分对象类型对Sort函数的调用，包括：[]int,[]float64,[]string。以[]int类型为例，看其代码实现。
type IntSlice []int //使用IntSlice类型对[]int类型进行封装 //IntSlice对象实现Interface接口 func (p IntSlice) Len() int { return len(p) } func (p IntSlice) Less(i, j int) bool { return p[i] &amp;lt; p[j] } func (p IntSlice) Swap(i, j int) { p[i], p[j] = p[j], p[i] } ... //由于Intslice对象实现了Interface接口，即可以作为参数调用Sort方法。 func Ints(a []int) { Sort(IntSlice(a)) } 这就是sort包对外提供的Ints函数：当需要对[]int数组进行排序时，直接调用sort.Ints()。
package main  import (  &amp;#34;fmt&amp;#34;  &amp;#34;sort&amp;#34; )  func main() {  a := []int{12,45,33,78,9,14}  sort.Ints(a)  fmt.Println(a) //[9 12 14 33 45 78] } sort.Float64()和sort.Strings()同理。
2. 自定义对象调用Sort()
思考：假如需要排序的是自定义对象，应该如何实现。
给定对象person，其包括两个属性: name string, age int。那么如何根据姓名或者age给person进行排序。完整示例如下。
package main  import (  &amp;#34;fmt&amp;#34;  &amp;#34;sort&amp;#34; )  type person struct { //定义对象person  name string  age int }  type personSlice []person //给[]person绑定对象  // 实现sort包定义的Interface接口 func (s personSlice) Len() int {  return len(s) }  func (s personSlice) Less(i, j int) bool {  return s[i].age &amp;lt; s[j].age }  func (s personSlice) Swap(i, j int) {  s[i].age, s[j].age = s[j].age, s[i].age }  func main() {  p := personSlice{  person{  name: &amp;#34;mike&amp;#34;,  age: 13,  }, person{  name: &amp;#34;jane&amp;#34;,  age: 12,  }, person{  name: &amp;#34;peter&amp;#34;,  age: 14,  }}  sort.Sort(p)  fmt.Println(p) // [{mike 12} {jane 13} {peter 14}] } 注意：并不是所有对象都能实现排序，前提是排序依赖的属性列是可比较的，如int，string等。
3. sort.Search()
函数原型
func Search(n int, f func(int) bool) int {} Serarch里面的算法细节本文不讨论，只关注如何实现调用。Search函数中n参数是待搜索对象集的长度，注意此对象集必须是已排序过的；f参数是一个匿名函数，实现规则见下文[]int例子。
同样的，sort包已为几个特定对象实现了调用函数，包括[]int,[]float64,[]string。以[]int为例。
// 输入已排序[]int类型a，和某item值x，返回其在[]int中的索引值。 // 注：小于[]int最小值返回0，大于最大值，返回len(a) func SearchInts(a []int, x int) int {  return Search(len(a), func(i int) bool { return a[i] &amp;gt;= x }) } ... // 返回IntSlice([]int)中的x所在索引值 // 注：小于[]int最小值返回0，大于最大值，返回len(a) func (p IntSlice) Search(x int) int { return SearchInts(p, x) } 使用示例：
package main  import (  &amp;#34;fmt&amp;#34;  &amp;#34;sort&amp;#34; )  func main() {  a := []int{3,2,4,5,1}  sort.Ints(a)  fmt.Println(a) // [1 2 3 4 5]  fmt.Println(sort.SearchInts(a,5)) // 4  fmt.Println(sort.SearchInts(a,6)) // 5  fmt.Println(sort.IntSlice(a).Search(5)) // 4 } 4. 自定义对象调用Search
同样是person对象，如果想根据age来查找排序后的person集合（personSlice）中下标，该如何实现。示例代码如下。
// 调用sort.Search函数，构造PersonSlice自己的Search方法 func (s personSlice) Search(age int) int{  return sort.Search(len(s), func(i int) bool {  return s[i].age&amp;gt;=age  }) } func main() {  p := personSlice{  person{  name: &amp;#34;mike&amp;#34;,  age: 13,  }, person{  name: &amp;#34;jane&amp;#34;,  age: 12,  }, person{  name: &amp;#34;peter&amp;#34;,  age: 14,  }}  sort.Sort(p)  fmt.Println(p) // [{mike 12} {jane 13} {peter 14}]  fmt.Println(p.Search(13)) // 1 } 5. 其他函数
当然，在sort包中还有其他的一些函数暴露给用户使用，例如：sort.IsSorted()用于判断对象是否有序；sort.Stable()提供稳定排序，即当元素类型相等时，保留原有相对位置；sort.Reverse()提供对象集合元素反转等。有了sort.Sort()和sort.Search()的理解，这些函数都是相似的调用或实现。
以上内容转载自机器铃砍菜刀
</content>
    </entry>
    
     <entry>
        <title>Go交叉编译</title>
        <url>http://shanks.link/blog/2021/04/26/go%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91/</url>
        <categories>
          
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Go交叉编译 交叉编译是指在一个硬件平台生成另一个硬件平台的可执行文件。而Go提供了非常方便的交叉编译方式。
如何编译
Go交叉编译，涉及到几个环境变量的设置: GOARCH、GOOS和CGO_ENABLED。
 GOARCH：编译目标平台的硬件体系架构（amd64, 386, arm, ppc64等）。 GOOS：编译目标平台上的操作系统（darwin, freebsd, linux, windows）。 CGO_ENABLED：代表是否开启CGO，1表示开启，0表示禁用。由于CGO不能支持交叉编译，所以需要禁用。  GO中env的具体环境变量的注释，可通过输入命令go help environment查看。
 ~ $ go help environment... GOARCH The architecture, or processor, for which to compile code. Examples are amd64, 386, arm, ppc64.... GOOS The operating system for which to compile code. Examples are linux, darwin, windows, netbsd.... CGO_ENABLED Whether the cgo command is supported. Either 0 or 1. Mac 下编译 Linux 和 Windows 64位可执行程序
export CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build main.goexport CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build main.go Linux 下编译 Mac 和 Windows 64位可执行程序
export CGO_ENABLED=0 GOOS=darwin GOARCH=amd64 go build main.goexport CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build main.go Windows 下编译 Mac 和 Linux 64位可执行程序
SET CGO_ENABLED=0 GOOS=darwin GOARCH=amd64 go build main.goSET CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build main.go 其他平台或32位系统类似，这里就不再赘述。
GO是如何做到交叉编译？
Go交叉编译的实现通过在文件顶部增加构建标记，进行选择编译。
// &#43;build 注：Go源码里的编译器源码位于$GOROOT/src/cmd/compile路径下，链接器源码位于$GOROOT/src/link路径下。
我们的切入点从Go编译器的main函数为入口，代码位于$GOROOT/src/cmd/compile/main.go。以环境变量GOARCH为例，看一下Go编译器是如何通过构建标记来选择对应的体系架构目标进行编译。
package main // 引用了Go所能支持的所有架构体系库代码，根据GOARCH选择对应的体系代码import ( &amp;#34;cmd/compile/internal/amd64&amp;#34; &amp;#34;cmd/compile/internal/arm&amp;#34; &amp;#34;cmd/compile/internal/arm64&amp;#34; .... &amp;#34;cmd/compile/internal/x86&amp;#34;...) // 初始化代码var archInits = map[string]func(*gc.Arch){ &amp;#34;386&amp;#34;: x86.Init, &amp;#34;amd64&amp;#34;: amd64.Init, &amp;#34;arm&amp;#34;: arm.Init, &amp;#34;arm64&amp;#34;: arm64.Init,...} func main() { // disable timestamps for reproducible output log.SetFlags(0) log.SetPrefix(&amp;#34;compile: &amp;#34;) // 通过objabi.GOARCH选择对应的架构体系 archInit, ok := archInits[objabi.GOARCH]... gc.Main(archInit)...} objabi.GOARCH是$GOROOT/src/cmd/internal/objabi/util.go中的变量GOARCH。
var ( defaultGOROOT string // set by linker ... GOROOT = envOr(&amp;#34;GOROOT&amp;#34;, defaultGOROOT) GOARCH = envOr(&amp;#34;GOARCH&amp;#34;, defaultGOARCH) GOOS = envOr(&amp;#34;GOOS&amp;#34;, defaultGOOS)...) defaultGOARCH是runtime包里的GOARCH值，如下所示。
// Code generated by go tool dist; DO NOT EDIT. package objabi import &amp;#34;runtime&amp;#34; ...const defaultGOOS = runtime.GOOSconst defaultGOARCH = runtime.GOARCH... 而该值又是通过sys.GOARCH赋值。$GOROOT/src/runtime/extern.go。
// GOARCH is the running program&amp;#39;s architecture target:// one of 386, amd64, arm, s390x, and so on.const GOARCH string = sys.GOARCH 终于来到了重点！$GOROOT/src/runtime/internal/sys/agoarch_amd64.go
// Code generated by gengoos.go using &amp;#39;go generate&amp;#39;. DO NOT EDIT. // 我的机器平台是amd64，且未对GOARCH的值做修改。因此这里的构建标签是amd64.// &#43;build amd64 package sys const GOARCH = `amd64` 通过构建amd64的编译标签，从而控制了Go编译时需要选择对应的架构代码。即：如果不是amd64，例如arm，那对应的编译代码就是$GOROOT/src/runtime/internal/sys/agoarch_arm.go。
如何利用交叉编译？
虽然golang 可以跨平台编译，但却无法解决系统的差异性。在靠近底层逻辑的项目中，我们需要直接调用操作系统函数，例如同样是实现IO多路服用，在darwin系统调用kqueue，而linux系统需调用epoll。
相同功能可以编写类似xxx_windows.go xxx.Linux.go文件，根据操作系统编译对应源文件，而不是在文件中用if else规划执行路径。
交叉编译同样可以理解为条件编译，通过构建的build标签，选择需要编译进最终执行二进制文件的代码。
这里给一个简单的条件编译示例，如下。
代码文件
 go.mod main.go myfunc.go  main.go：程序入口，调用位于myfunc.go中的speak函数。
package main import &amp;#34;fmt&amp;#34; func main() { fmt.Println(&amp;#34;mike&amp;#34;) speak(&amp;#34;hello&amp;#34;)} myfunc.go: 构建了build标签，需要build命令 带上-tag speak，该代码才能被编译。
//&#43;build speak package main func speak(s string) { println(&amp;#34;speak:&amp;#34;, s)} 执行命令
$ go build -o main$ ./main 输出
mike 可以看到，在main函数中的speak()函数并没有被执行，因为myfunc.go没有被编译。如果需要将myfunc.go编译进最终的执行代码，则执行命令
$ go build -tags speak -o main$ ./main 输出
$ mike$ speak: hello 上述条件编译示例对你是否有启发呢？
举例：项目开发中，如果想打印程序中的某些信息以便调试，而又不想打印相关代码生成到最终的可执行文件中，那么条件编译便可派上用场。
参考链接： https: //golang.org/cmd/go
https: /golang.org/pkg/go/build
以上内容转载自机器铃砍菜刀
</content>
    </entry>
    
     <entry>
        <title>Go语言内部包--控制包成员的对外暴露</title>
        <url>http://shanks.link/blog/2021/04/26/go%E8%AF%AD%E8%A8%80%E5%86%85%E9%83%A8%E5%8C%85--%E6%8E%A7%E5%88%B6%E5%8C%85%E6%88%90%E5%91%98%E7%9A%84%E5%AF%B9%E5%A4%96%E6%9A%B4%E9%9C%B2/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Go语言内部包&amp;ndash;控制包成员的对外暴露 Go 语言中的软件包推荐按照：组织名/项目名 的形式安排软件包的文件目录结构，一般「项目名」文件目录下还会按照功能、抽象约定、具体实现等维度再划分一些子目录。在 Go 语言里包的导入路径不同则被判定为不同的包，所以同一个软件包项目下的「功能一」包依赖「功能二」包里的成员时，那么成员必须是导出成员才能被「功能一」包引用。但是这样一来，其他项目或者其他组织的代码也就都可以使用这个导出的成员了，假如包里的一些成员我们只想在指定的包之间共享而不想对外暴露该怎么办呢？ Go 语言内部包这个特性可以让我们实现这个目标。
内部包 Go语言1.4版本后增加了 Internal packages 特征用于控制包的导入，即internal package只能被特定的包导入。
内部包的规范约定：导入路径包含internal关键字的包，只允许internal的父级目录及父级目录的子包导入，其它包无法导入。
示例 . |-- resources | |-- internal | | |-- cpu | | | `-- cup.go | | `-- mem | | `-- mem.go | |-- input | | |-- input.go | `-- mainboard.go |-- prototype | `-- professional.go |-- go.mod |-- go.sum 如上包结构的程序，resources/internal/cpu和resources/internal/mem只能被resources包及其子包resources/input中的代码导入，不能被prototype包里的代码导入。当在prototype包的代码中导入并调用resources/internal/cpu包的函数时，编译器根据文件的目录结构判断出来prototype包相对于被导入的包是外部包，所以整个程序会编译失败，报类似下面的错误：
use of internal package /resources/internal/cpu not allowed 总结 internal/ 是 go 编译器在编译程序时可以识别的特殊目录名，除非两个包都具有相同的祖先，否则它将阻止另一个包导入internal/目录下的包。因此，我们将internal/目录中的软件包称为内部包。
要为项目创建内部包，只需将包文件放在名为internal/的目录中。当 go 编译器在导入路径中看到带有internal/的软件包被导入时，它将验证导入包的程序文件是否位于internal/目录的父级目录，或父级目录的子目录中。
举例来说导入路径为 /a/b/c/internal/d/e/f 的包，只能被位于/a/b/c目录或者其子目录中的代码引入，而不能被位于/a/b/e 目录或其子目录中的代码引用。
以上内容转载自KevinYan11
</content>
    </entry>
    
     <entry>
        <title>Go 面试官：什么是协程，协程和线程的区别和联系？</title>
        <url>http://shanks.link/blog/2021/04/25/go-%E9%9D%A2%E8%AF%95%E5%AE%98%E4%BB%80%E4%B9%88%E6%98%AF%E5%8D%8F%E7%A8%8B%E5%8D%8F%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%8C%BA%E5%88%AB%E5%92%8C%E8%81%94%E7%B3%BB/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 既要理解线程，还要讲解协程，并且诠释两者间的区别，但是由于提到线程，就必然涉及进程，因此本文将会同时梳理介绍 “进程、协程、协程” 三者的随笔知识，希望能引发大家的一些思考。
吸鱼之路开始。
进程 进程是什么 进程是操作系统对一个正在运行的程序的一种抽象，进程是资源分配的最小单位。
进程在操作系统中的抽象表现
为什么有进程 为什么会有 ”进程“ 呢？说白了还是为了合理压榨 CPU 的性能和分配运行的时间片，不能 “闲着“。
在计算机中，其计算核心是 CPU，负责所有计算相关的工作和资源。单个 CPU 一次只能运行一个任务。如果一个进程跑着，就把唯一一个 CPU 给完全占住，那是非常不合理的。
那为什么要压榨 CPU 的性能？因为 CPU 实在是太快，太快，太快了，寄存器仅仅能够追的上他的脚步，RAM 和别的挂在各总线上的设备则更是望尘莫及。
多进程的缘由 如果总是在运行一个进程上的任务，就会出现一个现象。就是任务不一定总是在执行 ”计算型“ 的任务，会有很大可能是在执行网络调用，阻塞了，CPU 岂不就浪费了？
进程的上下文切换
这又出现了多进程，多个 CPU，多个进程。多进程就是指计算机系统可以同时执行多个进程，从一个进程到另外一个进程的转换是由操作系统内核管理的，一般是同时运行多个软件。
线程 有了多进程，想必在操作系统上可以同时运行多个进程。那么为什么有了进程，还要线程呢？
原因如下：
 进程间的信息难以共享数据，父子进程并未共享内存，需要通过进程间通信（IPC），在进程间进行信息交换，性能开销较大。 创建进程（一般是调用 fork 方法）的性能开销较大。  大家又把目光转向了进程内，能不能在进程里做点什么呢？
进程由多个线程组成
一个进程可以由多个称为线程的执行单元组成。每个线程都运行在进程的上下文中，共享着同样的代码和全局数据。
多个进程，就可以有更多的线程。多线程比多进程之间更容易共享数据，在上下文切换中线程一般比进程更高效。
原因如下：
  线程之间能够非常方便、快速地共享数据。
   只需将数据复制到进程中的共享区域就可以了，但需要注意避免多个线程修改同一份内存。    创建线程比创建进程要快 10 倍甚至更多。
   线程都是同一个进程下自家的孩子，像是内存页、页表等就不需要了。    协程是怎么回事 协程是什么 协程（Coroutine）是用户态的线程。通常创建协程时，会从进程的堆中分配一段内存作为协程的栈。
线程的栈有 8 MB，而协程栈的大小通常只有 KB，而 Go 语言的协程更夸张，只有 2-4KB，非常的轻巧。
协程的诞生 根据维基百科的说法，马尔文·康威于 1958 年发明了术语 “coroutine” 并用于构建汇编程序，关于协程最初的出版解说在 1963 年发表。
也就是历史上是先有的 “协程”，再有的 “线程”，线程是在在协程的基础上添加了栈等功能后扩展出来的。
但为什么一开始协程没有火起来呢？这个比较难考证，大概率还是与 60 年前的计算机时代背景有关。
而如今人们把协程调度的逻辑更进一步抽象为 “等 IO，让出，IO 完毕”，在此基础上人们发现协程的方式能解决多线程环境下很多代码逻辑 “混乱”。
协程的优势 既然线程似乎已经很好地填补了进程的遗憾，那怎么又出来了一个 “协程”，难道是重复造轮子吗？
协程的优势（via InfoQ @八两）如下：
 节省 CPU：避免系统内核级的线程频繁切换，造成的 CPU 资源浪费。好钢用在刀刃上。而协程是用户态的线程，用户可以自行控制协程的创建于销毁，极大程度避免了系统级线程上下文切换造成的资源浪费。 节约内存：在 64 位的Linux中，一个线程需要分配 8MB 栈内存和 64MB 堆内存，系统内存的制约导致我们无法开启更多线程实现高并发。而在协程编程模式下，可以轻松有十几万协程，这是线程无法比拟的。 稳定性：前面提到线程之间通过内存来共享数据，这也导致了一个问题，任何一个线程出错时，进程中的所有线程都会跟着一起崩溃。 开发效率：使用协程在开发程序之中，可以很方便的将一些耗时的IO操作异步化，例如写文件、耗时 IO 请求等。  协程本质上就是用户态下的线程，所以也有人说协程是 “轻线程”，但我们一定要区分用户态和内核态的区别，很关键。
总结 归归根到底，在日常或面试中遇到 “什么是协程，协程和线程的区别和联系？” 这类问题时，面试者常规会把进程、线程、协程都介绍一遍。
为了方便记忆和诠释，推荐大家结合故事来讲会比较好，这一块可以参考阮一峰大神翻译的《进程与线程的一个简单解释》，会带来不少好感。
而最关键的部分，在于协程和线程的区别和联系是什么？
我们可以通过文章中的介绍，从协程 -&amp;gt; 线程的历史进程来说明。接着进一步对比协程和线程两者的优势和缺点，就能比较好的诠释区别和联系了。
更优秀的部分，可以诠释完基本概念和区别后，进一步延伸都你所面试的岗位，例如是 Go 语言，就可以介绍 Go 语言的协程的具体应用和实现。
毕竟，Go 语言可以轻轻松松开数十万个协程，毫无波澜。这样能够更好的体现你对协程、线程的知识深度和广度应用，而不是单纯的背概念。
参考  线程和进程的区别是什么？ 有了多线程，为什么还要有协程？ 进程与线程的一个简单解释  以上内容转载自煎鱼的blog
</content>
    </entry>
    
     <entry>
        <title>从底层到应用，想深入Map这篇文章千万不要错过！</title>
        <url>http://shanks.link/blog/2021/04/20/%E4%BB%8E%E5%BA%95%E5%B1%82%E5%88%B0%E5%BA%94%E7%94%A8%E6%83%B3%E6%B7%B1%E5%85%A5map%E8%BF%99%E7%AF%87%E6%96%87%E7%AB%A0%E5%8D%83%E4%B8%87%E4%B8%8D%E8%A6%81%E9%94%99%E8%BF%87/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 转载自上山打老虎的blog
超超经过了一番磨难通过了面试官单例的灵魂拷问，面试官貌似想通过一道场景应用题来考验超超对Golang的容器是否足够熟悉。下面来看看超超是如何解答的吧！
红黑树和哈希表
面试官：那我们来看这样一个问题，你看废纸篓（回收站）里面有图片，文件夹，app等各种文件，把这个抽象成各种不同类型的数据，你会用什么容器去存储他？
考点：Golang容器特点
超超：go语言中可以批量存储的基础数据类型有map、slice、array，以及container包中的容器heap，list，ring。如果是存储的是不同数据类型，那么容器的值类型应该是interface。废纸篓中的文件数量在使用时波动还是挺大的，因此可以排除array，废纸篓中往往有按日期或者修改时间排序的功能，所以用heap比较好。
面试官：那我们先挑一个工作中比较常用的map来说一下吧，我看你还学过C&#43;&#43;，那你能给我说说C&#43;&#43;中的map和go语言中的map有什么区别吗？
考点：哈希表和红黑树
超超：C&#43;&#43;中的map底层用的是红黑树，而Go语言中的map底层用的是哈希表。下面我来分别介绍一下这俩种数据结构吧。
哈希表：哈希表又称散列表，是一种线性结构，可以通过键直接访问到内存中的值，时间复杂度为O(1)。他由计算键值的哈希函数和存储值的线性表俩部分构成。
红黑树：是一种自平衡二叉查找树，利用查找树左子树上所有节点的值均小于它的根节点的值，右子树上所有节点的值均大于它的根节点的值，这样俩个性质可以快速在树中查找到目标值，时间复杂的为O(logn)。
面试官：哈希表和红黑树的优缺点是什么呢？
考点：使用场景
超超：那我从时间复杂度，空间复杂度和有序性三个方面比较一下吧。
时间复杂度：红黑树查询的时间复杂度是O(logn)，哈希表查询的时间复杂度是O(1)。单看复杂度似乎任何场景下哈希表都比红黑树更优，其实不然，哈希表需要用hash函数进行处理才可以用键取到对应的值，而红黑树查询操作是不需要进行额外操作的。当存储的数据量比较小时，用哈希函数的时间损耗就无法忽略了，此时用红黑树更佳。
空间复杂度：哈希表是有额外空间浪费的，因为存储值的线性表空间需要预设，当存储的数据量较少时，表中是存在空闲内存的。而红黑树无论数据量多少都不会存在浪费空间的问题。
有序性：红黑树用for range遍历是有序的，而哈希表遍历结果是无序的，并且在go语言中为了让开发人员注意到这一点，作者在range时特意封装了一层，加入了随机种子，这样遍历顺序更加的混乱。但是红黑树为了维持有序性和红黑节点的平衡性，在增删改节点时，可能都需要进行旋转操作，而哈希表只需要用哈希函数重新计算键值即可。
因此在需要一定量增删改操作的场景下用哈希表时间上表现更好，在元素数据量较少，需要保证元素有序性或者注重内存损耗的场景下用红黑树更佳。
面试官：既然Go语言中的map是用哈希表实现的，那我们就来重点说一下哈希表吧，你知道哈希冲突是什么吗？常用的解决方式又是什么呢？
考点：哈希冲突
超超：哈希冲突是指可能存在两个不同的初始值在经过哈希运算后得到同样的结果，比如现在有1-10十个数字，要将他们存到容量只有9的哈希表中，此时必然会出现哈希冲突。常用的哈希冲突的解决办法有链地址法，开放定址法。
链地址法：将产生哈希冲突的元素用链表串起来，并将表头指针存放在线性表的相应桶中。举个例子，假设哈希函数为H(key)=(Hash(key)±d) MOD m，其中m为散列表长度设为7，现在我们将一组数{21,17,42,57,25}存到哈希表中。
开放地址法：开放地址法又分为线性探查法，平方探查法。他们区别在于哈希函数的不同，线性探查法的哈希函数为H(key)=(Hash(key)±d) MOD m，当发生哈希冲突时，d会以±(d&#43;1)的方式扩散后再用哈希函数去计算值。而平方探查法中哈希函数为H(key)=(Hash(key)±d²) MOD m，当发生哈希冲突时，d会以±(d&#43;1)²方式扩散再用哈希函数去计算值。下面以线性探查法为例。
面试官：那你可以给我说一下链地址法和线性探查法的优缺点？
考点：哈希冲突解决方式
超超：可以的，这个就设计到了哈希表中的一个很重要的概念载荷因子，载荷因子是用来描述线性表中元素的稀疏程度的，他的计算公式为：装载因子=填入表中的元素个数 / 散列表的长度。载装因子越大表示线性表中元素越多，发生哈希冲突的可能性就越大。在go语言中如果载荷因子大于0.65就需要扩容了。
链地址法优点在于当载荷因子较大时，可以将数据链在桶的后面，虽然当桶后链表的长度等于线性表长度时也会扩容，但是与线性探查法相比多了一个存储的地方，避免频繁的扩容。缺点在于载荷因子较小时，线性表中大量空闲的桶空间就发生了内存浪费。
线性探查法优点在于当载荷因子较小时，可以将线性表中更多的桶利用起来，减少内存资源的浪费。缺点在于当载荷因子较大时，线性探查会经历大量的哈希碰撞，性能不高，且需要频繁的扩容。
Map底层
面试官：你刚刚提到了在遍历map时，go用了一个随机种子来使得每次遍历结果都是不一样的，这个可以详细给我说一下吗？
考点：map底层实现
超超：那我先介绍一下map的底层结构吧，map由结构体hmap构成
hmap
type hmap struct {  // Note: the format of the hmap is also encoded in cmd/compile/internal/gc/reflect.go.  // Make sure this stays in sync with the compiler&amp;#39;s definition.  count int // 哈希表中元素个数，即len(map)的返回值  flags uint8  B uint8 // 线性表中桶个数的的对数log_2(哈希表元素数量最大可达到装载因子*2^B)  noverflow uint16 // 溢出桶的大概数字;详情见incrnoverflow  hash0 uint32 // 哈希种子   buckets unsafe.Pointer // 指向线性表的指针，数组大小为2^B，如果元素个数为0，它为nil.  oldbuckets unsafe.Pointer // 指向扩容后的老线性表地址  nevacuate uintptr // 表示扩容进度   extra *mapextra // 垃圾回收用 } bmap结构体
// A bucket for a Go map. type bmap struct {  // tophash包含此桶中每个键的哈希值最高字节（高8位）信息（也就是前面所述的high-order bits）。  // 如果tophash[0] &amp;lt; minTopHash，tophash[0]则代表桶的搬迁（evacuation）状态。  tophash [bucketCnt]uint8 } 为了便于理解，示意图如下所示
在顺序遍历时会用随机种子产生一个随机数，表示开始遍历的桶位置，因为随机数每次产生的数字可能都是不同的，所以每次for range得到的结果也是不同的。以下为初始化哈希迭代器的方法源码:
func mapiterinit(t *maptype, h *hmap, it *hiter) {  if raceenabled &amp;amp;&amp;amp; h != nil {  callerpc := getcallerpc()  racereadpc(unsafe.Pointer(h), callerpc, funcPC(mapiterinit))  }   if h == nil || h.count == 0 {  return  }   if unsafe.Sizeof(hiter{})/sys.PtrSize != 12 {  throw(&amp;#34;hash_iter size incorrect&amp;#34;) // see cmd/compile/internal/gc/reflect.go  }  it.t = t  it.h = h   // grab snapshot of bucket state  it.B = h.B  it.buckets = h.buckets  if t.bucket.ptrdata == 0 {  // Allocate the current slice and remember pointers to both current and old.  // This preserves all relevant overflow buckets alive even if  // the table grows and/or overflow buckets are added to the table  // while we are iterating.  h.createOverflow()  it.overflow = h.extra.overflow  it.oldoverflow = h.extra.oldoverflow  }   // 产生随机数  r := uintptr(fastrand())  if h.B &amp;gt; 31-bucketCntBits {  r &#43;= uintptr(fastrand()) &amp;lt;&amp;lt; 31  }  //决定桶的开始位置  it.startBucket = r &amp;amp; bucketMask(h.B)  //决定桶中bmap的开始位置  it.offset = uint8(r &amp;gt;&amp;gt; h.B &amp;amp; (bucketCnt - 1))   // iterator state  it.bucket = it.startBucket   // Remember we have an iterator.  // Can run concurrently with another mapiterinit().  if old := h.flags; old&amp;amp;(iterator|oldIterator) != iterator|oldIterator {  atomic.Or8(&amp;amp;h.flags, iterator|oldIterator)  }   mapiternext(it) } 面试官：那map在什么时候会扩容呢？
考点：map扩容方式
超超：有俩种方式会导致map的扩容，另一种是由于桶后面跟的链表太长所导致的扩容。
载荷因子引起：当元素个数 &amp;gt;= 桶（bucket）总数 * 6.5，这时说明大部分桶都被占满了如果再来元素，大概率会发生哈希冲突。因此需要扩容，扩容方式为将 B &#43; 1，新建一个buckets数组，新的buckets大小是原来的2倍，然后旧buckets数据搬迁到新的buckets。该方法我们称之为增量扩容。如下图所示，插入25时会经历大量哈希冲突，再插入元素时6/8=0.67就需要扩容了。
链表长度引起：判断溢出桶是否太多，当桶总数 &amp;lt; 2 ^ 15 时，如果溢出桶总数 &amp;gt;= 桶总数，则认为溢出桶过多。当桶总数 &amp;gt;= 2 ^ 15 时，直接与 2 ^ 15 比较，当溢出桶总数 &amp;gt;= 2 ^ 15 时，即认为溢出桶太多了。buckets数量维持不变，将长度过长的溢出桶搬运到[]bmap的其他桶上，该方法我们称之为等量扩容。如下图所示，每一个溢出桶可以存八个元素，为了画图方便这里老虎就只当做只能存一个元素处理了，当插入元素41时，链表长度已经达到了5，如果哈希冲突过多，那么会最终演变为遍历访问链表，时间复杂度为O(n)的算法了！
拓展应用
面试官：如果我想要遍历的结果的是有序的该怎么做呢？
考点：容器组合使用
超超：这里就需要申请一个辅助容器slice用来存储key的次序，然后顺序遍历slice获取到有序的key，再到map中获取value，代码如下
package main  import (  &amp;#34;fmt&amp;#34;  &amp;#34;sort&amp;#34; )  func main() {   //创建class包括超超和婷婷俩个对象  class := map[int]string{1: &amp;#34;chaochao&amp;#34;, 2: &amp;#34;tingting&amp;#34;}   //辅助有序遍历的ids切片  ids := make([]int, 0, 10)  for k, _ := range class {  ids = append(ids, k)  }   //对id进行排序  sort.Ints(ids)  for _, v := range ids {  //根据有序切片取出  fmt.Println(class[v])  } } 这是一个最简单的原型，如果map中元素中是不断变化的，可以将slice和map封装在一起。一个简易的排序map代码如下：
package main  import (  &amp;#34;container/list&amp;#34;  &amp;#34;fmt&amp;#34; )  //Map结构体 type Map struct {  ids *list.List  class map[interface{}]interface{} }  //创建一个Map func NewMap() *Map {  m := &amp;amp;Map{  ids: list.New(),  class: make(map[interface{}]interface{}),  }  return m }  //向Map中添加元素 func (p *Map) push(id int, name string) bool {  if p.class[id] != nil {  return false  }  p.ids.PushBack(id)  p.class[id] = name  return true }  //对ids排序，通过ids的顺序遍历获取names func (p *Map) getNames() []interface{} {  names := make([]interface{}, 0, p.ids.Len())  //sort(p.ids)对list排序，篇幅有限读者可自行实现  for i := p.ids.Front(); i != nil; i = i.Next() {  names = append(names, p.class[i.Value])  }  return names }  func main() {  m := NewMap()  m.push(1, &amp;#34;chaochao&amp;#34;)  m.push(2, &amp;#34;tingting&amp;#34;)  names := m.getNames()  for k, v := range names {  fmt.Println(k, v)  } } 面试官：确实很简陋哈，但是还比较容易理解。那如果我要实现一个set该怎么做呢？
考点：容器组合使用
超超：STL中的set也是有序的，且只有值没有键，因此不需要用list对key排序了，直接获取key排序即可。代码如下
package main  import (  &amp;#34;fmt&amp;#34; )  //定义Set结构体 type Set struct {  class map[interface{}]bool }  //创建一个Set func NewSet() *Set {  s := &amp;amp;Set{  class: make(map[interface{}]bool),  }  return s }  //向Set中添加元素 func (p *Set) push(id int, name string) bool {  if p.class[id] {  return false  }  p.class[name] = true  return true }  //对class中的key排序 func (p *Set) getNames() []interface{} {  names := make([]interface{}, 0, len(p.class))  for k, _ := range p.class {  names = append(names, k)  }  //sort(names)  return names }  func main() {  m := NewSet()  m.push(1, &amp;#34;chaochao&amp;#34;)  m.push(2, &amp;#34;tingting&amp;#34;)  names := m.getNames()  for k, v := range names {  fmt.Println(k, v)  } } 面试官：map的并发问题，我们等下再问吧，先看这样一个问题。你看废纸篓中的文件是可以按名称排序的，假设文件的名称都可以用ASCII码转化成一个具体的数字，比如“plan.txt”将每位字母转化成数字后相加最终结果为825，现在要求你设计一个find方法可以用文件名快速查到对应的位置该怎么做。
参考：
菜刀兄Go是如何设计Map的(强烈推荐阅读)
</content>
    </entry>
    
     <entry>
        <title>嗯，你觉得 Go 在什么时候会抢占 P？</title>
        <url>http://shanks.link/blog/2021/04/19/%E5%97%AF%E4%BD%A0%E8%A7%89%E5%BE%97-go-%E5%9C%A8%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E6%8A%A2%E5%8D%A0-p/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 嗯，你觉得 Go 在什么时候会抢占 P？ 前几天我们有聊到《单核 CPU，开两个 Goroutine，其中一个死循环，会怎么样？》的问题，我们在一个细节部分有提到：
有新的小伙伴会产生更多的疑问，那就是在 Go 语言中，是如何抢占 P 的呢，这里面是怎么做的？
今天这篇文章我们就来解密抢占 P。
调度器的发展史 在 Go 语言中，Goroutine 早期是没有设计成抢占式的，早期 Goroutine 只有读写、主动让出、锁等操作时才会触发调度切换。
这样有一个严重的问题，就是垃圾回收器进行 STW 时，如果有一个 Goroutine 一直都在阻塞调用，垃圾回收器就会一直等待他，不知道等到什么时候&amp;hellip;
这种情况下就需要抢占式调度来解决问题。如果一个 Goroutine 运行时间过久，就需要进行抢占来解决。
这块 Go 语言在 Go1.2 起开始实现抢占式调度器，不断完善直至今日：
 Go0.x：基于单线程的程调度器。 Go1.0：基于多线程的调度器。 Go1.1：基于任务窃取的调度器。 Go1.2 - Go1.13：基于协作的抢占式调度器。 Go1.14：基于信号的抢占式调度器。  调度器的新提案：非均匀存储器访问调度（Non-uniform memory access，NUMA）， 但由于实现过于复杂，优先级也不够高，因此迟迟未提上日程。
有兴趣的小伙伴可以详见 Dmitry Vyukov, dvyukov 所提出的 NUMA-aware scheduler for Go。
为什么要抢占 P 为什么会要想去抢占 P 呢，说白了就是不抢，就没机会运行，会 hang 死。又或是资源分配不均了，
这在调度器设计中显然是不合理的。
跟这个例子一样：
// Main Goroutine func main() {  // 模拟单核 CPU  runtime.GOMAXPROCS(1)   // 模拟 Goroutine 死循环  go func() {  for {  }  }()   time.Sleep(time.Millisecond)  fmt.Println(&amp;#34;脑子进煎鱼了&amp;#34;) } 这个例子在老版本的 Go 语言中，就会一直阻塞，没法重见天日，是一个需要做抢占的场景。
但可能会有小伙伴问，抢占了，会不会有新问题。因为原本正在使用 P 的 M 就凉凉了（M 会与 P 进行绑定），没了 P 也就没法继续执行了。
这其实没有问题，因为该 Goroutine 已经阻塞在了系统调用上，暂时是不会有后续的执行新诉求。
但万一代码是在运行了好一段时间后又能够运行了（业务上也允许长等待），也就是该 Goroutine 从阻塞状态中恢复了，期望继续运行，没了 P 怎么办？
这时候该 Goroutine 可以和其他 Goroutine 一样，先检查自身所在的 M 是否仍然绑定着 P：
 若是有 P，则可以调整状态，继续运行。 若是没有 P，可以重新抢 P，再占有并绑定 P，为自己所用。  也就是抢占 P，本身就是一个双向行为，你抢了我的 P，我也可以去抢别人的 P 来继续运行。
怎么抢占 P 讲解了为什么要抢占 P 的原因后，我们进一步深挖，“他” 是怎么抢占到具体的 P 的呢？
这就涉及到前文所提到的 runtime.retake 方法了，其处理以下两种场景：
 抢占阻塞在系统调用上的 P。 抢占运行时间过长的 G。  在此主要针对抢占 P 的场景，分析如下：
func retake(now int64) uint32 {  n := 0  // 防止发生变更，对所有 P 加锁  lock(&amp;amp;allpLock)  // 走入主逻辑，对所有 P 开始循环处理  for i := 0; i &amp;lt; len(allp); i&#43;&#43; {  _p_ := allp[i]  pd := &amp;amp;_p_.sysmontick  s := _p_.status  sysretake := false  ...  if s == _Psyscall {  // 判断是否超过 1 个 sysmon tick 周期  t := int64(_p_.syscalltick)  if !sysretake &amp;amp;&amp;amp; int64(pd.syscalltick) != t {  pd.syscalltick = uint32(t)  pd.syscallwhen = now  continue  }   ...  }  }  unlock(&amp;amp;allpLock)  return uint32(n) } 该方法会先对 allpLock 上锁，这个变量含义如其名，allpLock 可以防止该数组发生变化。
其会保护 allp、idlepMask 和 timerpMask 属性的无 P 读取和大小变化，以及对 allp 的所有写入操作，可以避免影响后续的操作。
场景一 前置处理完毕后，进入主逻辑，会使用万能的 for 循环对所有的 P（allp）进行一个个处理。
 t := int64(_p_.syscalltick)  if !sysretake &amp;amp;&amp;amp; int64(pd.syscalltick) != t {  pd.syscalltick = uint32(t)  pd.syscallwhen = now  continue  } 第一个场景是：会对 syscalltick 进行判定，如果在系统调用（syscall）中存在超过 1 个 sysmon tick 周期（至少 20us）的任务，则会从系统调用中抢占 P，否则跳过。
场景二 如果未满足会继续往下，走到如下逻辑：
func retake(now int64) uint32 {  for i := 0; i &amp;lt; len(allp); i&#43;&#43; {  ...  if s == _Psyscall {  // 从此处开始分析  if runqempty(_p_) &amp;amp;&amp;amp;  atomic.Load(&amp;amp;sched.nmspinning)&#43;atomic.Load(&amp;amp;sched.npidle) &amp;gt; 0 &amp;amp;&amp;amp;  pd.syscallwhen&#43;10*1000*1000 &amp;gt; now {  continue  }  ...  }  }  unlock(&amp;amp;allpLock)  return uint32(n) } 第二个场景，聚焦到这一长串的判断中：
 runqempty(_p_) == true 方法会判断任务队列 P 是否为空，以此来检测有没有其他任务需要执行。 atomic.Load(&amp;amp;sched.nmspinning)&#43;atomic.Load(&amp;amp;sched.npidle) &amp;gt; 0 会判断是否存在空闲 P 和正在进行调度窃取 G 的 P。 pd.syscallwhen&#43;10*1000*1000 &amp;gt; now 会判断系统调用时间是否超过了 10ms。  这里奇怪的是 runqempty 方法明明已经判断了没有其他任务，这就代表了没有任务需要执行，是不需要抢夺 P 的。
但实际情况是，由于可能会阻止 sysmon 线程的深度睡眠，最终还是希望继续占有 P。
在完成上述判断后，进入到抢夺 P 的阶段：
func retake(now int64) uint32 {  for i := 0; i &amp;lt; len(allp); i&#43;&#43; {  ...  if s == _Psyscall {  // 承接上半部分  unlock(&amp;amp;allpLock)  incidlelocked(-1)  if atomic.Cas(&amp;amp;_p_.status, s, _Pidle) {  if trace.enabled {  traceGoSysBlock(_p_)  traceProcStop(_p_)  }  n&#43;&#43;  _p_.syscalltick&#43;&#43;  handoffp(_p_)  }  incidlelocked(1)  lock(&amp;amp;allpLock)  }  }  unlock(&amp;amp;allpLock)  return uint32(n) }  解锁相关属性：需要调用 unlock 方法解锁 allpLock，从而实现获取 sched.lock，以便继续下一步。 减少闲置 M：需要在原子操作（CAS）之前减少闲置 M 的数量（假设有一个正在运行）。否则在发生抢夺 M 时可能会退出系统调用，递增 nmidle 并报告死锁事件。 修改 P 状态：调用 atomic.Cas 方法将所抢夺的 P 状态设为 idle，以便于交于其他 M 使用。 抢夺 P 和调控 M：调用 handoffp 方法从系统调用或锁定的 M 中抢夺 P，会由新的 M 接管这个 P。  总结 至此完成了抢占 P 的基本流程，我们可得出满足以下条件：
 如果存在系统调用超时：存在超过 1 个 sysmon tick 周期（至少 20us）的任务，则会从系统调用中抢占 P。 如果没有空闲的 P：所有的 P 都已经与 M 绑定。需要抢占当前正处于系统调用之，而实际上系统调用并不需要的这个 P 的情况，会将其分配给其它 M 去调度其它 G。 如果 P 的运行队列里面有等待运行的 G，为了保证 P 的本地队列中的 G 得到及时调度。而自己本身的 P 又忙于系统调用，无暇管理。此时会寻找另外一个 M 来接管 P，从而实现继续调度 G 的目的。  参考  NUMA-aware scheduler for Go go-under-the-hood 深入解析 Go-抢占式调度 Go语言调度器源代码情景分析  以上内容转载自煎鱼的blog
</content>
    </entry>
    
     <entry>
        <title>The Go runtime scheduler&#39;s clever way of dealing with system calls</title>
        <url>http://shanks.link/blog/2021/04/19/the-go-runtime-schedulers-clever-way-of-dealing-with-system-calls/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> The Go runtime scheduler&amp;rsquo;s clever way of dealing with system calls One of Go&amp;rsquo;s signature features is goroutines, which are lightweight threads that are managed by the Go runtime. The Go runtime implements goroutines using a M:N work stealing scheduler to multiplex goroutines on to operating system threads. The scheduler has special terminology for three important entities; a G is a goroutine, an M is an OS thread (a &amp;lsquo;machine&amp;rsquo;), and a P is a &amp;lsquo;processor&amp;rsquo;, which at its core is a limited resource that must be claimed by an M in order to run Go code. Having a limited supply of Ps is how Go limits how many things it will do at once, so as to not overload the overall system; generally there is one P per actual CPU that the OS reports (the number of Ps is GOMAXPROCS).
When a goroutine performs network IO or any system call operation that can definitely be done asynchronously, Go has an entire runtime subsystem, the netpoller, that converts what looks like multiple separate synchronous operations into a single wait (using operating system mechanisms like epoll). Rather than actually making a blocking system call, your goroutine goes to sleep waiting for its network socket, just as if it was waiting for a channel to become ready. This is all conceptually straightforward, if tricky to implement efficiently.
However, network IO and similar things are far from the only system calls that Go programs can make, so Go has to deal with blocking system calls as well. The straightforward way to handle blocking system calls is for your goroutine&amp;rsquo;s M to release its P just before it makes the system call and then try to re-acquire a P after the system call resumes. If there&amp;rsquo;s no free P at that time, your goroutine gets parked in the scheduler along with everything else that&amp;rsquo;s waiting to run.
While all system calls are blocking in theory, not all are expected to be blocking in practice. For example, on modern systems the &amp;lsquo;system call&amp;rsquo; to get the current time may not even enter the kernel (see vdso(7) on Linux). Having goroutines go through the full work of releasing their current P and then re-acquiring one for these system calls has two problems. First, there&amp;rsquo;s a bunch of overhead involved in locking (and releasing) all of the data structures involved. Second, if there&amp;rsquo;s more runnable goroutines than Ps, a goroutine that makes this sort of system call won&amp;rsquo;t be able to re-acquire a P and will have to park itself; the moment it released the P, something else was scheduled onto it. This is extra runtime overhead, is sort of unfair, and kind of defeats the purpose of having fast system calls (especially ones that don&amp;rsquo;t go into the kernel).
So the Go runtime and scheduler actually have two ways of handling blocking system calls, a pessimistic way for system calls that are expected to be slow and an optimistic way for ones that are expected to be fast. The pessimistic system call path implements the straightforward approach where the runtime actively releases the P before the system call, attempts to get it back afterward, and parks itself if it can&amp;rsquo;t. The optimistic system call path doesn&amp;rsquo;t release the P; instead, it sets a special P state flag and just makes the system call. A special internal goroutine, the sysmon goroutine, then comes along periodically and looks for P&amp;rsquo;s that have been sitting in this &amp;lsquo;making a system call&amp;rsquo; state for too long and steals them away from the goroutine making the system call. When the system call returns, the runtime code checks to see if its P has been stolen out from underneath it, and if it hasn&amp;rsquo;t it can just go on (if the P has been stolen, the runtime tries to get another P and then may have to park your goroutine).
If everything works out, the optimistic system call path has very low overhead (mostly it requires a couple of atomic compare and swap operations). If things don&amp;rsquo;t work out and there&amp;rsquo;s more runnable goroutines than there are Ps, then one P will be unnecessarily idle for what is probably generally a few tens of microseconds (the sysmon goroutine runs at most once every 20 microseconds, but can run less frequently if there seems to be no need for it). There are probably worst case scenarios possible, but in general this seems to be a worthwhile tradeoff on the part of the Go runtime.
以上内容转载自
</content>
    </entry>
    
     <entry>
        <title>用 Go struct 不能犯的一个低级错误！</title>
        <url>http://shanks.link/blog/2021/04/18/%E7%94%A8-go-struct-%E4%B8%8D%E8%83%BD%E7%8A%AF%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%8E%E7%BA%A7%E9%94%99%E8%AF%AF/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 转载自煎鱼的blog
用 Go struct 不能犯的一个低级错误！ 原创 陈煎鱼 脑子进煎鱼了 3天前
收录于话题
#Go45
#面试题13
大家好，我是煎鱼。
前段时间我分享了 《手撕 Go 面试官：Go 结构体是否可以比较，为什么？》的文章，把基本 Go struct 的比较依据研究了一番。这不，最近有一位读者，遇到了一个关于 struct 的新问题，踩到了雷区。不得解。
大家一起来看看，建议大家在看到代码例子后先思考一下答案，再往下看。
独立思考很重要。
疑惑的例子 其给出的例子一如下：
type People struct {}  func main() {  a := &amp;amp;People{}  b := &amp;amp;People{}  fmt.Println(a == b) } 你认为输出结果是什么呢？
输出结果是：false。
再稍加改造一下，例子二如下：
type People struct {}  func main() {  a := &amp;amp;People{}  b := &amp;amp;People{}  fmt.Printf(&amp;#34;%p\n&amp;#34;, a)  fmt.Printf(&amp;#34;%p\n&amp;#34;, b)  fmt.Println(a == b) } 输出结果是：true。
他的问题是 &amp;ldquo;为什么第一个返回 false 第二个返回 true，是什么原因导致的？
煎鱼进一步的精简这个例子，得到最小示例：
func main() {  a := new(struct{})  b := new(struct{})  println(a, b, a == b)   c := new(struct{})  d := new(struct{})  fmt.Println(c, d)  println(c, d, c == d) } 输出结果：
// a, b; a == b 0xc00005cf57 0xc00005cf57 false  // c, d &amp;amp;{} &amp;amp;{} // c, d, c == d 0x118c370 0x118c370 true 第一段代码的结果是 false，第二段的结果是 true，且可以看到内存地址指向的完全一样，也就是排除了输出后变量内存指向改变导致的原因。
进一步来看，似乎是 fmt.Print 方法导致的，但一个标准库里的输出方法，会导致这种奇怪的问题？
问题剖析 如果之前有被这个 “坑” 过，或有看过源码的同学。可能能够快速的意识到，导致这个输出是逃逸分析所致的结果。
我们对例子进行逃逸分析：
// 源代码结构 $ cat -n main.go  5 func main() {  6 a := new(struct{})  7 b := new(struct{})  8 println(a, b, a == b)  9  10 c := new(struct{})  11 d := new(struct{})  12 fmt.Println(c, d)  13 println(c, d, c == d)  14 }  // 进行逃逸分析 $ go run -gcflags=&amp;#34;-m -l&amp;#34; main.go # command-line-arguments ./main.go:6:10: a does not escape ./main.go:7:10: b does not escape ./main.go:10:10: c escapes to heap ./main.go:11:10: d escapes to heap ./main.go:12:13: ... argument does not escape 通过分析可得知变量 a, b 均是分配在栈中，而变量 c, d 分配在堆中。
其关键原因是因为调用了 fmt.Println 方法，该方法内部是涉及到大量的反射相关方法的调用，会造成逃逸行为，也就是分配到堆上。
为什么逃逸后相等 关注第一个细节，就是 “为什么逃逸后，两个空 struct 会是相等的？”。
这里主要与 Go runtime 的一个优化细节有关，如下：
// runtime/malloc.go var zerobase uintptr 变量 zerobase 是所有 0 字节分配的基础地址。更进一步来讲，就是空（0字节）的在进行了逃逸分析后，往堆分配的都会指向 zerobase 这一个地址。
所以空 struct 在逃逸后本质上指向了 zerobase，其两者比较就是相等的，返回了 true。
为什么没逃逸不相等 关注第二个细节，就是 “为什么没逃逸前，两个空 struct 比较不相等？”。
Go spec
从 Go spec 来看，这是 Go 团队刻意而为之的设计，不希望大家依赖这一个来做判断依据。如下：
  This is an intentional language choice to give implementations flexibility in how they handle pointers to zero-sized objects. If every pointer to a zero-sized object were required to be different, then each allocation of a zero-sized object would have to allocate at least one byte. If every pointer to a zero-sized object were required to be the same, it would be different to handle taking the address of a zero-sized field within a larger struct.
  还说了一句很经典的，细品：
  Pointers to distinct zero-size variables may or may not be equal.
  另外空 struct 在实际使用中的场景是比较少的，常见的是：
 设置 context，传递时作为 key 时用到。 设置空 struct 业务场景中临时用到。  但业务场景的情况下，也大多数会随着业务发展而不断改变，假设有个远古时代的 Go 代码，依赖了空 struct 的直接判断，岂不是事故上身？
不可直接依赖 因此 Go 团队这番操作，与 Go map 的随机性如出一辙，避免大家对这类逻辑的直接依赖，是值得思考的。
而在没逃逸的场景下，两个空 struct 的比较动作，你以为是真的在比较。实际上已经在代码优化阶段被直接优化掉，转为了 false。
因此，虽然在代码上看上去是 == 在做比较，实际上结果是 a == b 时就直接转为了 false，比都不需要比了。
你说妙不？
没逃逸让他相等 既然我们知道了他是在代码优化阶段被优化的，那么相对的，知道了原理的我们也可以借助在 go 编译运行时的 gcflags 指令，让他不优化。
在运行前面的例子时，执行 -gcflags=&amp;quot;-N -l&amp;quot; 指令：
$ go run -gcflags=&amp;#34;-N -l&amp;#34; main.go 0xc000092f06 0xc000092f06 true &amp;amp;{} &amp;amp;{} 0x118c370 0x118c370 true 你看，两个比较的结果都是 true 了。
总结 在今天这篇文章中，我们针对 Go 语言中的空结构体（struct）的比较场景进行了进一步的补全。经过这两篇文章的洗礼，你会更好的理解 Go 结构体为什么叫既可比较又不可比较了。
而空结构比较的奇妙，主要原因如下：
 若逃逸到堆上，空结构体则默认分配的是 runtime.zerobase 变量，是专门用于分配到堆上的 0 字节基础地址。因此两个空结构体，都是 runtime.zerobase，一比较当然就是 true 了。 若没有发生逃逸，也就分配到栈上。在 Go 编译器的代码优化阶段，会对其进行优化，直接返回 false。并不是传统意义上的，真的去比较了。  不会有人拿来出面试题，不会吧，为什么 Go 结构体说可比较又不可比较？
最后，感谢欧神的指导和曹大的文章。我是煎鱼，咱们下篇文章见 ：）
参考  欧神的微信交流 曹大的一个空 struct 的“坑”  </content>
    </entry>
    
     <entry>
        <title>Goroutine 泄露的 N 种方法，真刺激！</title>
        <url>http://shanks.link/blog/2021/04/18/goroutine-%E6%B3%84%E9%9C%B2%E7%9A%84-n-%E7%A7%8D%E6%96%B9%E6%B3%95%E7%9C%9F%E5%88%BA%E6%BF%80/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 转载自煎鱼的blog
大家好，我是煎鱼。
前几天分享 Go 群友提问的文章时，有读者在朋友圈下提到，希望我能够针对 Goroutine 泄露这块进行讲解，他在面试的时候经常被问到。
另外我也相信很多小伙伴，在做救火队长时排查过 Goroutine 泄露的问题，因为 Goroutine 作为一个载体，基本跑不了干系。
因此今天的男主角，就是 Go 语言的著名品牌标识 Goroutine，一个随随便便就能开几十万个快车进车道的大杀器。
 for {  go func() {}()  } 本文会聚焦于 Goroutine 泄露的 N 种方法，进行详解和说明。
为什么要问 面试官为啥会问 Goroutine（协程）泄露这种奇特的问题呢？
可以猜测是：
 Goroutine 实在是使用门槛实在是太低了，随手就一个就能起，出现了不少滥用的情况。例如：并发 map。 Goroutine 本身在 Go 语言的标准库、复合类型、底层源码中应用广泛。例如：HTTP Server 对每一个请求的处理就是一个协程去运行。  很多 Go 工程在线上出事故时，基本 Goroutine 的关联，大家都会作为救火队长，风风火火的跑去看指标、看日志，通过 PProf 采集 Goroutine 运行情况等。
自然他也就是最受瞩目的那颗 “星” 了，所以在日常面试中，被问几率也就极高了。
Goroutine 泄露 了解清楚大家爱问的原因后，我们开始对 Goroutine 泄露的 N 种方法进行研究，希望通过前人留下的 “坑”，了解其原理和避开这些问题。
泄露的原因大多集中在：
 Goroutine 内正在进行 channel/mutex 等读写操作，但由于逻辑问题，某些情况下会被一直阻塞。 Goroutine 内的业务逻辑进入死循环，资源一直无法释放。 Goroutine 内的业务逻辑进入长时间等待，有不断新增的 Goroutine 进入等待。  接下来我会引用在网上冲浪收集到的一些 Goroutine 泄露例子（会在文末参考注明出处）。
channel 使用不当 Goroutine&#43;Channel 是最经典的组合，因此不少泄露都出现于此。
最经典的就是上面提到的 channel 进行读写操作时的逻辑问题。
发送不接收 第一个例子：
func main() {  for i := 0; i &amp;lt; 4; i&#43;&#43; {  queryAll()  fmt.Printf(&amp;#34;goroutines: %d\n&amp;#34;, runtime.NumGoroutine())  } }  func queryAll() int {  ch := make(chan int)  for i := 0; i &amp;lt; 3; i&#43;&#43; {  go func() { ch &amp;lt;- query() }()  }  return &amp;lt;-ch }  func query() int {  n := rand.Intn(100)  time.Sleep(time.Duration(n) * time.Millisecond)  return n } 输出结果：
goroutines: 3 goroutines: 5 goroutines: 7 goroutines: 9 在这个例子中，我们调用了多次 queryAll 方法，并在 for 循环中利用 Goroutine 调用了 query 方法。其重点在于调用 query 方法后的结果会写入 ch 变量中，接收成功后再返回 ch 变量。
最后可看到输出的 goroutines 数量是在不断增加的，每次多 2 个。也就是每调用一次，都会泄露 Goroutine。
原因在于 channel 均已经发送了（每次发送 3 个），但是在接收端并没有接收完全（只返回 1 个 ch），所诱发的 Goroutine 泄露。
接收不发送 第二个例子：
func main() {  defer func() {  fmt.Println(&amp;#34;goroutines: &amp;#34;, runtime.NumGoroutine())  }()   var ch chan struct{}  go func() {  ch &amp;lt;- struct{}{}  }()   time.Sleep(time.Second) } 输出结果：
goroutines: 2 在这个例子中，与 “发送不接收” 两者是相对的，channel 接收了值，但是不发送的话，同样会造成阻塞。
但在实际业务场景中，一般更复杂。基本是一大堆业务逻辑里，有一个 channel 的读写操作出现了问题，自然就阻塞了。
nil channel 第三个例子：
func main() {  defer func() {  fmt.Println(&amp;#34;goroutines: &amp;#34;, runtime.NumGoroutine())  }()   var ch chan int  go func() {  &amp;lt;-ch  }()   time.Sleep(time.Second) } 输出结果：
goroutines: 2 在这个例子中，可以得知 channel 如果忘记初始化，那么无论你是读，还是写操作，都会造成阻塞。
正常的初始化姿势是：
 ch := make(chan int)  go func() {  &amp;lt;-ch  }()  ch &amp;lt;- 0  time.Sleep(time.Second) 调用 make 函数进行初始化。
奇怪的慢等待 第四个例子：
func main() {  for {  go func() {  _, err := http.Get(&amp;#34;https://www.xxx.com/&amp;#34;)  if err != nil {  fmt.Printf(&amp;#34;http.Get err: %v\n&amp;#34;, err)  }  // do something...  }()   time.Sleep(time.Second * 1)  fmt.Println(&amp;#34;goroutines: &amp;#34;, runtime.NumGoroutine())  } } 输出结果：
goroutines: 5 goroutines: 9 goroutines: 13 goroutines: 17 goroutines: 21 goroutines: 25 ... 在这个例子中，展示了一个 Go 语言中经典的事故场景。也就是一般我们会在应用程序中去调用第三方服务的接口。
但是第三方接口，有时候会很慢，久久不返回响应结果。恰好，Go 语言中默认的 http.Client 是没有设置超时时间的。
因此就会导致一直阻塞，一直阻塞就一直爽，Goroutine 自然也就持续暴涨，不断泄露，最终占满资源，导致事故。
在 Go 工程中，我们一般建议至少对 http.Client 设置超时时间：
 httpClient := http.Client{  Timeout: time.Second * 15,  } 并且要做限流、熔断等措施，以防突发流量造成依赖崩塌，依然吃 P0。
互斥锁忘记解锁 第五个例子：
func main() {  total := 0  defer func() {  time.Sleep(time.Second)  fmt.Println(&amp;#34;total: &amp;#34;, total)  fmt.Println(&amp;#34;goroutines: &amp;#34;, runtime.NumGoroutine())  }()   var mutex sync.Mutex  for i := 0; i &amp;lt; 10; i&#43;&#43; {  go func() {  mutex.Lock()  total &#43;= 1  }()  } } 输出结果：
total: 1 goroutines: 10 在这个例子中，第一个互斥锁 sync.Mutex 加锁了，但是他可能在处理业务逻辑，又或是忘记 Unlock了。
因此导致后面的所有 sync.Mutex 想加锁，却因未释放又都阻塞住了。一般在 Go 工程中，我们建议如下写法：
 var mutex sync.Mutex  for i := 0; i &amp;lt; 10; i&#43;&#43; {  go func() {  mutex.Lock()  defer mutex.Unlock()  total &#43;= 1  }()  } 同步锁使用不当 第六个例子：
func handle(v int) {  var wg sync.WaitGroup  wg.Add(5)  for i := 0; i &amp;lt; v; i&#43;&#43; {  fmt.Println(&amp;#34;脑子进煎鱼了&amp;#34;)  wg.Done()  }  wg.Wait() }  func main() {  defer func() {  fmt.Println(&amp;#34;goroutines: &amp;#34;, runtime.NumGoroutine())  }()   go handle(3)  time.Sleep(time.Second) } 在这个例子中，我们调用了同步编排 sync.WaitGroup，模拟了一遍我们会从外部传入循环遍历的控制变量。
但由于 wg.Add 的数量与 wg.Done 数量并不匹配，因此在调用 wg.Wait 方法后一直阻塞等待。
在 Go 工程中使用，我们会建议如下写法：
 var wg sync.WaitGroup  for i := 0; i &amp;lt; v; i&#43;&#43; {  wg.Add(1)  defer wg.Done()  fmt.Println(&amp;#34;脑子进煎鱼了&amp;#34;)  }  wg.Wait() 排查方法 我们可以调用 runtime.NumGoroutine 方法来获取 Goroutine 的运行数量，进行前后一比较，就能知道有没有泄露了。
但在业务服务的运行场景中，Goroutine 内导致的泄露，大多数处于生产、测试环境，因此更多的是使用 PProf：
import (  &amp;#34;net/http&amp;#34;  _ &amp;#34;net/http/pprof&amp;#34; )  http.ListenAndServe(&amp;#34;localhost:6060&amp;#34;, nil)) 只要我们调用 http://localhost:6060/debug/pprof/goroutine?debug=1，PProf 会返回所有带有堆栈跟踪的 Goroutine 列表。
也可以利用 PProf 的其他特性进行综合查看和分析，这块参考我之前写的《Go 大杀器之性能剖析 PProf》，基本是全村最全的教程了。
总结 在今天这篇文章中，我们针对 Goroutine 泄露的 N 种常见的方式方法进行了一一分析，虽说看起来都是比较基础的场景。
但结合在实际业务代码中，就是一大坨中的某个细节导致全盘皆输了，希望上面几个案例能够给大家带来警惕。
而面试官爱问，怕不是自己踩过许多坑，也希望进来的同僚，也是身经百战了。
靠谱的工程师，而非只是八股工程师。
参考  波罗学大佬的《Go 笔记之如何防止 goroutine 泄露》 二斗斗的《怎么看待Goroutine 泄露》  </content>
    </entry>
    
     <entry>
        <title>你知道 Go 结构体和结构体指针调用有什么区别吗？</title>
        <url>http://shanks.link/blog/2021/04/17/%E4%BD%A0%E7%9F%A5%E9%81%93-go-%E7%BB%93%E6%9E%84%E4%BD%93%E5%92%8C%E7%BB%93%E6%9E%84%E4%BD%93%E6%8C%87%E9%92%88%E8%B0%83%E7%94%A8%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%E5%90%97/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 转载自煎鱼的blog
本期的男主角是《Go 结构体和结构体指针调用有什么区别》，希望对大家有所帮助，带来一些思考。
请在此处默念自己心目中的答案，再和煎鱼一同研讨一波 Go 的技术哲学。
结构体是什么 在 Go 语言中有个基本类型，开发者们称之为结构体（struct）。是 Go 语言中非常常用的，基本定义：
type struct_variable_type struct {  member definition  member definition  ...  member definition } 简单示例：
package main  import &amp;#34;fmt&amp;#34;  type Vertex struct {  Name1 string  Name2 string }  func main() {  v := Vertex{&amp;#34;脑子进了&amp;#34;, &amp;#34;煎鱼&amp;#34;}  v.Name2 = &amp;#34;蒸鱼&amp;#34;  fmt.Println(v.Name2) } 输出结果：
蒸鱼 这部分属于基础知识，因此不再过多解释。如果看不懂，建议重学 Go 语言语法基础。
结构体和指针调用 讲解前置概要后，直接进入本文主题。如下例子：
type MyStruct struct {  Name string }  func (s MyStruct) SetName1(name string) {  s.Name = name }  func (s *MyStruct) SetName2(name string) {  s.Name = name } 该程序声明了一个 User 结构体，其包含两个结构体方法，分别是 SetName1 和 SetName2 方法，两者之间的差异就是引用的方式不同。
进一步延伸，这两者有什么区别，什么情况下用哪种，有没有什么注意事项？
注：很巧，我有一个朋友，当年刚上手 Go 语言时，就纠结过这个问题。
两者区别 从许多小伙伴的反馈来看，这两个例子之间的区别可能会让人感到困惑，经常会有人纠结要不要使用 “指针”，又担心 GC 什么的。
实际上情况没那么复杂，看看下面的例子：
func (s MyStruct) SetName1(name string) func (s *MyStruct) SetName2(name string) 当在一个类型上定义一个方法时，接收器（在上面的例子中是 s）的行为就像它是方法的一个参数一样。其相当于：
 func SetName1(s MyStruct, name string){  u.Name = name  }   func SetName2(s *MyStruct,name string){  u.Name = name  } 因此结构体方法是要将接收器定义成值，还是指针。这本质上与函数参数应该是值还是指针是同一个问题。
如何选择 整体有以下几个考虑因素，按重要程度顺序排列：
 在使用上的考虑：方法是否需要修改接收器？如果需要，接收器必须是一个指针。 在效率上的考虑：如果接收器很大，比如：一个大的结构，使用指针接收器会好很多。 在一致性上的考虑：如果类型的某些方法必须有指针接收器，那么其余的方法也应该有指针接收器，所以无论类型如何使用，方法集都是一致的。  回到上面的例子中，从功能使用角度来看：
 如果 SetName2 方法修改了 s 的字段，调用者是可以看到这些字段值变更的，因为其是指针引用，本质上是同一份。 相对 SetName1 方法来讲，该方法是用调用者参数的副本来调用的，本质上是值传递，它所做的任何字段变更对调用者来说是看不见的。  另外对于基本类型、切片和小结构等类型，值接收器是非常廉价的。
因此除非方法的语义需要指针，那么值接收器是最高效和清晰的。在 GC 方面，也不需要过度关注。出现时再解决就好了。
总结 在本文中，我们针对 Go 结构体和结构体指针调用有什么区别，这个问题进行了深入浅出的分析和说明。
而在本文中所介绍的部分内容，来自于官方 FAQ 的 “Should I define methods on values or pointers?”，可以认为是官方给出的基本解答了（问的人是真的多）。
谁疑惑这个问题，转发这篇文章，吸就完了。
</content>
    </entry>
    
     <entry>
        <title>再见 Go 面试官：单核 CPU，开两个 Goroutine，其中一个死循环，会怎么样</title>
        <url>http://shanks.link/blog/2021/04/17/%E5%86%8D%E8%A7%81-go-%E9%9D%A2%E8%AF%95%E5%AE%98%E5%8D%95%E6%A0%B8-cpu%E5%BC%80%E4%B8%A4%E4%B8%AA-goroutine%E5%85%B6%E4%B8%AD%E4%B8%80%E4%B8%AA%E6%AD%BB%E5%BE%AA%E7%8E%AF%E4%BC%9A%E6%80%8E%E4%B9%88%E6%A0%B7/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 以下转载自煎鱼的blog
最近金三银四，是面试的季节。在我的 Go 读者交流群里出现了许多小伙伴在讨论自己面试过程中所遇到的一些 Go 面试题。若大家有兴趣，欢迎加我的微信进群一同交流。
今天的男主角，是与 Go 工程师有调度相关的知识，那就是 “单核 CPU，开两个 Goroutine，其中一个死循环，会怎么样？”
请在此处默念自己心目中的答案，再往和煎鱼一起研讨一波 Go 的技术哲学。
问题定义 针对这个问题，我们需要把问题剖开来看看，其具有以下几个元素：
 运行 Go 程序的计算机只有一个单核 CPU。 两个 Goroutine 在运行。 一个 Goroutine 死循环。  根据这道题的题意，可大致理解其想要问的是 Go 调度相关的一些知识理解。
单核 CPU 第一个要点，就是要明确 “计算机只有一个单核 CPU” 这一个变量定义，对 Go 程序会产生什么影响，否则很难继续展开。
既然明确涉及 Goroutine，这里就会考察到你对 Go 的调度模型 GMP 的基本理解了。
从单核 CPU 来看，最大的影响就是 GMP 模型中的 P，因为 P 的数量默认是与 CPU 核数（GOMAXPROCS）保持一致的。
 G：Goroutine，实际上我们每次调用 go func 就是生成了一个 G。 P：Processor，处理器，一般 P 的数量就是处理器的核数，可以通过 GOMAXPROCS 进行修改。 M：Machine，系统线程。  这三者交互实际来源于 Go 的 M: N 调度模型。也就是 M 必须与 P 进行绑定，然后不断地在 M 上循环寻找可运行的 G 来执行相应的任务。
Goroutine 受限 第二个要点，就是 Goroutine 的数量和运行模式都是受限的。有两个 Goroutine，一个 Goroutine 在死循环，另外一个在正常运行。
这可以理解为 Main Goroutine &#43; 起了一个新 Goroutine 跑着死循环，因为本身 main 函数就是一个主协程在运行着，没毛病。
需要注意的是，Goroutine 里跑着死循环，也就是时时刻刻在运行着 “业务逻辑”。这块需要与单核 CPU 关联起来，考虑是否会一直阻塞住，把整个 Go 进程运行给 hang 住了？
注：但若是在现场面试，可以先枚举出这种场景，诠释清楚后。再补充提问面试官，是否这类场景？
Go 版本的问题 第三个要点，是一个隐性的拓展点。如果你是一个老 Go 粉，经常关注 Go 版本的更新情况（至少大版本），则应该会知道 Go 的调度是会变动的（会在后面的小节讲解）。
因此本文这个问题，在不同的 Go 语言版本中，结果可能会是不一样的。但是面试官并没有指出，这里就需要考虑到：
 面试官故意不指出，等着你指出。 面试官没留意到这块，没想那么多。 面试官自己都不知道这块的 “新” 知识，他的知识可能还是老的。  如果你注意到了，是一个小亮点，说明你在这块有一定的知识积累。
实战演练 在刚刚过去的 3s 中，你已经把上面的考量都在大脑中过了一遍。接下来我们正式进入实战演练，构造一个例子：
// Main Goroutine func main() {  // 模拟单核 CPU  runtime.GOMAXPROCS(1)   // 模拟 Goroutine 死循环  go func() {  for {  }  }()   time.Sleep(time.Millisecond)  fmt.Println(&amp;#34;脑子进煎鱼了&amp;#34;) } 在上面的例子中，我们通过以下方式达到了面试题所需的目的：
 设置 runtime.GOMAXPROCS 方法模拟了单核 CPU 下只有一个 P 的场景。 运行一个 Goroutine，内部跑一个 for 死循环，达到阻塞运行的目的。 运行一个 Goroutine，主函数（main）本身就是一个 Main Goroutine。  思考一下：这段程序是否会输出 ”脑子进煎鱼了“ 呢，为什么？
答案是：
 在 Go1.14 前，不会输出任何结果。 在 Go1.14 及之后，能够正常输出结果。  为什么 这是怎么回事呢，这两种情况分别对应了什么原因和标准，Go 版本的变更有带来了什么影响？
不会输出任何结果 显然，这段程序是有一个 Goroutine 是正在执行死循环，也就是说他肯定无法被抢占。
这段程序中更没有涉及主动放弃执行权的调用（runtime.Gosched），又或是其他调用（可能会导致执行权转移）的行为。因此这个 Goroutine 是没机会溜号的，只能一直打工&amp;hellip;
那为什么主协程（Main Goroutine）会无法运行呢，其实原因是会优先调用休眠，但由于单核 CPU，其只有唯一的 P。唯一的 P 又一直在打工不愿意下班（执行 for 死循环，被迫无限加班）。
因此主协程永远没有机会呗调度，所以这个 Go 程序自然也就一直阻塞在了执行死循环的 Goroutine 中，永远无法下班（执行完毕，退出程序）。
正常输出结果 那为什么 Go1.14 及以后的版本，又能正常输出了呢？
主要还是在 Go1.14 实现了基于信号的抢占式调度，以此来解决上述一些仍然无法被抢占解决的场景。
主要原理是Go 程序在启动时，会在 runtime.sighandler 方法注册并且绑定 SIGURG 信号：
func mstartm0() {  ...  initsig(false) }  func initsig(preinit bool) {  for i := uint32(0); i &amp;lt; _NSIG; i&#43;&#43; {  ...  setsig(i, funcPC(sighandler))  } } 绑定相应的 runtime.doSigPreempt 抢占方法：
func sighandler(sig uint32, info *siginfo, ctxt unsafe.Pointer, gp *g) {  ...  if sig == sigPreempt &amp;amp;&amp;amp; debug.asyncpreemptoff == 0 {  // 执行抢占  doSigPreempt(gp, c)  } } 同时在调度的 runtime.sysmon 方法会调用 retake 方法处理一下两种场景：
 抢占阻塞在系统调用上的 P。 抢占运行时间过长的 G。  该方法会检测符合场景的 P，当满足上述两个场景之一时，就会发送信号给 M。M 收到信号后将会休眠正在阻塞的 Goroutine，调用绑定的信号方法，并进行重新调度。以此来解决这个问题。
注：在 Go 语言中，sysmon 会用于检测抢占。sysmon 是 Go 的 Runtime 的系统检测器，sysmon 可进行 forcegc、netpoll、retake 等一系列骚操作（via @xiaorui）。
总结 在这篇文章中，我们针对 ”单核 CPU，开两个 Goroutine，其中一个死循环，会怎么样？“ 这个问题进行了展开剖析。
针对不同 Go 语言版本，不同程序逻辑的表现形式都不同，但背后的基本原理都是与 Go 调度模型和抢占有关。
你是否有在这一块遇到问题呢，欢迎大家在留言区评论和交流。
</content>
    </entry>
    
     <entry>
        <title>Go 内存泄露之痛，这篇把 Go timer.After 问题根因讲透了！</title>
        <url>http://shanks.link/blog/2021/04/17/go-%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%E4%B9%8B%E7%97%9B%E8%BF%99%E7%AF%87%E6%8A%8A-go-timer.after-%E9%97%AE%E9%A2%98%E6%A0%B9%E5%9B%A0%E8%AE%B2%E9%80%8F%E4%BA%86/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 转载自煎鱼的blog
前几天在公众号分享了一篇 Go timer 源码解析的文章《难以驾驭的 Go timer，一文带你参透计时器的奥秘》。
如果大家也有兴趣共同交流，欢迎关注煎鱼的公众号，加我微信后拉你进群。
在评论区有小伙伴提到了经典的 timer.After 泄露问题，希望我能聊聊，这是一个不能不知的一个大 “坑”。
今天煎鱼就带大家来研讨一下这个问题。
timer.After 今天是男主角是Go 标准库 time 所提供的 After 方法。函数签名如下：
func After(d Duration) &amp;lt;-chan Time 该方法可以在一定时间（根据所传入的 Duration）后主动返回 time.Time 类型的 channel 消息。
在常见的场景下，我们会基于此方法做一些计时器相关的功能开发，例子如下：
func main() {  ch := make(chan string)  go func() {  time.Sleep(time.Second * 3)  ch &amp;lt;- &amp;#34;脑子进煎鱼了&amp;#34;  }()   select {  case _ = &amp;lt;-ch:  case &amp;lt;-time.After(time.Second * 1):  fmt.Println(&amp;#34;煎鱼出去了，超时了！！！&amp;#34;)  } } 在运行 1 秒钟后，输出结果：
煎鱼出去了，超时了！！！ 上述程序在在运行 1 秒钟后将触发 time.After 方法的定时消息返回，输出了超时的结果。
坑在哪里 从例子来看似乎非常正常，也没什么 “坑” 的样子。难道是 timer.After 方法的虚晃一枪？
我们再看一个不像是有问题例子，这在 Go 工程中经常能看见，只是大家都没怎么关注。
代码如下：
func main() {  ch := make(chan int, 10)  go func() {  in := 1  for {  in&#43;&#43;  ch &amp;lt;- in  }  }()   for {  select {  case _ = &amp;lt;-ch:  // do something...  continue  case &amp;lt;-time.After(3 * time.Minute):  fmt.Printf(&amp;#34;现在是：%d，我脑子进煎鱼了！&amp;#34;, time.Now().Unix())  }  } } 在上述代码中，我们构造了一个 for&#43;select&#43;channel 的一个经典的处理模式。
同时在 select&#43;case 中调用了 time.After 方法做超时控制，避免在 channel 等待时阻塞过久，引发其他问题。
看上去都没什么问题，但是细心一看。在运行了一段时间后，粗暴的利用 top 命令一看：
运行了一会后，10&#43;GB
我的 Go 工程的内存占用竟然已经达到了 10&#43;GB 之高，并且还在持续增长，非常可怕。
在所设置的超时时间到达后，Go 工程的内存占用似乎一时半会也没有要回退下去的样子，这，到底发生了什么事？
为什么 抱着一脸懵逼的煎鱼，我默默的掏出我早已埋好的 PProf，这是 Go 语言中最强的性能分析剖析工具，在我出版的 《Go 语言编程之旅》特意有花大量的篇幅大面积将讲解过。
在 Go 语言中，PProf 是用于可视化和分析性能分析数据的工具，PProf 以 profile.proto 读取分析样本的集合，并生成报告以可视化并帮助分析数据（支持文本和图形报告）。
我们直接用 go tool pprof 分析 Go 工程中函数内存申请情况，如下图：
PProf
从图来分析，可以发现是不断地在调用 time.After，从而导致计时器 time.NerTimer 的不断创建和内存申请。
这就非常奇怪了，因为我们的 Go 工程里只有几行代码与 time 相关联：
func main() {  ...  for {  select {  ...  case &amp;lt;-time.After(3 * time.Minute):  fmt.Printf(&amp;#34;现在是：%d，我脑子进煎鱼了！&amp;#34;, time.Now().Unix())  }  } } 由于 Demo 足够的小，我们相信这就是问题代码，但原因是什么呢？
原因在于 for&#43;select，再加上 time.After 的组合会导致内存泄露。因为 for在循环时，就会调用都 select 语句，因此在每次进行 select 时，都会重新初始化一个全新的计时器（Timer）。
我们这个计时器，是在 3 分钟后才会被触发去执行某些事，但重点在于计时器激活后，却又发现和 select 之间没有引用关系了，因此很合理的也就被 GC 给清理掉了，因为没有人需要 “我” 了。
要命的还在后头，被抛弃的 time.After 的定时任务还是在时间堆中等待触发，在定时任务未到期之前，是不会被 GC 清除的。
但很可惜，他 “永远” 不会到期了，也就是为什么我们的 Go 工程内存会不断飙高，其实是 time.After 产生的内存孤儿们导致了泄露。
解决办法 既然我们知道了问题的根因代码是不断的重复创建 time.After，又没法完整的走完释放的闭环，那解决办法也就有了。
改进后的代码如下：
func main() {  timer := time.NewTimer(3 * time.Minute)  defer timer.Stop()   ...  for {  select {  ...  case &amp;lt;-timer.C:  fmt.Printf(&amp;#34;现在是：%d，我脑子进煎鱼了！&amp;#34;, time.Now().Unix())  }  } } 经过一段时间的摸鱼后，再使用 PProf 进行采集和查看：
PProf
Go 进程的各项指标正常，完好的解决了这个内存泄露的问题。
总结 在今天这篇文章中，我们介绍了标准库 time 的基本常规使用，同时针对 Go 小伙伴所提出的 time.After 方法的使用不当，所导致的内存泄露进行了重现和问题解析。
其根因就在于 Go 语言时间堆的处理机制和常规 for&#43;select&#43;time.After 组合的下意识写法所导致的泄露。
不知道你在日常工作中有没有遇到过相似的问题呢，欢迎留言区评论和交流。
（大雾）突然想起我有一个朋友在公司里有看到过类似的代码&amp;hellip;
</content>
    </entry>
    
     <entry>
        <title>手撕 Go 面试官：Go 结构体是否可以比较，为什么？</title>
        <url>http://shanks.link/blog/2021/04/16/%E6%89%8B%E6%92%95-go-%E9%9D%A2%E8%AF%95%E5%AE%98go-%E7%BB%93%E6%9E%84%E4%BD%93%E6%98%AF%E5%90%A6%E5%8F%AF%E4%BB%A5%E6%AF%94%E8%BE%83%E4%B8%BA%E4%BB%80%E4%B9%88/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 转载自煎鱼的blog
今天的男主角，是 Go 工程师的必修技能，也是极容易踩坑的地方，就是 “Go 面试题：Go 结构体（struct）是否可以比较？”
如果可以比较，是为什么？如果不可以比较，又是为什么？
请在此处默念自己心目中的答案，再往和煎鱼一起研讨一波 Go 的技术哲学。
结构体是什么 在 Go 语言中有个基本类型，开发者们称之为结构体（struct）。是 Go 语言中非常常用的，基本定义：
type struct_variable_type struct {  member definition  member definition  ...  member definition } 简单示例：
package main  import &amp;#34;fmt&amp;#34;  type Vertex struct {  Name1 string  Name2 string }  func main() {  v := Vertex{&amp;#34;脑子进了&amp;#34;, &amp;#34;煎鱼&amp;#34;}  v.Name2 = &amp;#34;蒸鱼&amp;#34;  fmt.Println(v.Name2) } 输出结果：
蒸鱼 这部分属于基础知识，因此不再过多解释。如果看不懂，建议重学 Go 语言语法基础。
比较两下 例子一 接下来正式开始研讨 Go 结构体比较的问题，第一个例子如下：
type Value struct {  Name string  Gender string }  func main() {  v1 := Value{Name: &amp;#34;煎鱼&amp;#34;, Gender: &amp;#34;男&amp;#34;}  v2 := Value{Name: &amp;#34;煎鱼&amp;#34;, Gender: &amp;#34;男&amp;#34;}  if v1 == v2 {  fmt.Println(&amp;#34;脑子进煎鱼了&amp;#34;)  return  }   fmt.Println(&amp;#34;脑子没进煎鱼&amp;#34;) } 我们声明了两个变量，分别是 v1 和 v2。其都是 Value 结构体的实例化，是同一个结构体的两个实例。
他们的比较结果是什么呢，是输出 ”脑子进煎鱼了“，还是 ”脑子没进煎鱼“？
输出结果：
脑子进煎鱼了 最终输出结果是 ”脑子进煎鱼了“，初步的结论是可以结构体间比较的。皆大欢喜，那这篇文章是不是就要结束了？
当然不是&amp;hellip;很多人都会踩到这个 Go 语言的坑，真实情况是结构体是可比较，也不可比较的，不要误入歧途了，这是一个非常 &amp;ldquo;有趣&amp;rdquo; 的现象。
例子二 接下来继续改造上面的例子，我们在原本的结构体中增加了指针类型的引用。
第二个例子如下：
type Value struct {  Name string  Gender *string }  func main() {  v1 := Value{Name: &amp;#34;煎鱼&amp;#34;, Gender: new(string)}  v2 := Value{Name: &amp;#34;煎鱼&amp;#34;, Gender: new(string)}  if v1 == v2 {  fmt.Println(&amp;#34;脑子进煎鱼了&amp;#34;)  return  }   fmt.Println(&amp;#34;脑子没进煎鱼&amp;#34;) } 这段程序输出结果是什么呢，我们猜测一下，变量依然是同一结构体的两个实例，值的赋值方式和内容都是一样的，是否应当输出 “脑子进煎鱼了”？
答案是：脑子没进煎鱼。
例子三 我们继续不信邪，试试另外的基本类型，看看结果是不是还是相等的。
第三个例子如下：
type Value struct {  Name string  GoodAt []string }  func main() {  v1 := Value{Name: &amp;#34;煎鱼&amp;#34;, GoodAt: []string{&amp;#34;炸&amp;#34;, &amp;#34;煎&amp;#34;, &amp;#34;蒸&amp;#34;}}  v2 := Value{Name: &amp;#34;煎鱼&amp;#34;, GoodAt: []string{&amp;#34;炸&amp;#34;, &amp;#34;煎&amp;#34;, &amp;#34;蒸&amp;#34;}}  if v1 == v2 {  fmt.Println(&amp;#34;脑子进煎鱼了&amp;#34;)  return  }   fmt.Println(&amp;#34;脑子没进煎鱼&amp;#34;) } 这段程序输出结果是什么呢？
答案是：
# command-line-arguments ./main.go:15:8: invalid operation: v1 == v2 (struct containing []string cannot be compared) 程序运行就直接报错，IDE 也提示错误，一只煎鱼都没能输出出来。
例子四 那不同结构体，相同的值内容呢，能否进行比较？
第四个例子：
type Value1 struct {  Name string }  type Value2 struct {  Name string }  func main() {  v1 := Value1{Name: &amp;#34;煎鱼&amp;#34;}  v2 := Value2{Name: &amp;#34;煎鱼&amp;#34;}  if v1 == v2 {  fmt.Println(&amp;#34;脑子进煎鱼了&amp;#34;)  return  }   fmt.Println(&amp;#34;脑子没进煎鱼&amp;#34;) } 显然，会直接报错：
# command-line-arguments ./main.go:18:8: invalid operation: v1 == v2 (mismatched types Value1 and Value2) 那是不是就完全没法比较了呢？并不，我们可以借助强制转换来实现：
 if v1 == Value1(v2) {  fmt.Println(&amp;#34;脑子进煎鱼了&amp;#34;)  return  } 这样程序就会正常运行，且输出 “脑子进煎鱼了”。当然，若是不可比较类型，依然是不行的。
为什么 为什么 Go 结构体有的比较就是正常，有的就不行，甚至还直接报错了。难道是有什么 “潜规则” 吗？
在 Go 语言中，Go 结构体有时候并不能直接比较，当其基本类型包含：slice、map、function 时，是不能比较的。若强行比较，就会导致出现例子中的直接报错的情况。
而指针引用，其虽然都是 new(string)，从表象来看是一个东西，但其具体返回的地址是不一样的。
因此若要比较，则需改为：
func main() {  gender := new(string)  v1 := Value{Name: &amp;#34;煎鱼&amp;#34;, Gender: gender}  v2 := Value{Name: &amp;#34;煎鱼&amp;#34;, Gender: gender}  ... } 这样就可以保证两者的比较。如果我们被迫无奈，被要求一定要用结构体比较怎么办？
这时候可以使用反射方法 reflect.DeepEqual，如下：
func main() {  v1 := Value{Name: &amp;#34;煎鱼&amp;#34;, GoodAt: []string{&amp;#34;炸&amp;#34;, &amp;#34;煎&amp;#34;, &amp;#34;蒸&amp;#34;}}  v2 := Value{Name: &amp;#34;煎鱼&amp;#34;, GoodAt: []string{&amp;#34;炸&amp;#34;, &amp;#34;煎&amp;#34;, &amp;#34;蒸&amp;#34;}}  if reflect.DeepEqual(v1, v2) {  fmt.Println(&amp;#34;脑子进煎鱼了&amp;#34;)  return  }   fmt.Println(&amp;#34;脑子没进煎鱼&amp;#34;) } 这样子就能够正确的比较，输出结果为 “脑子进煎鱼了”。
例子中所用到的反射比较方法 reflect.DeepEqual 常用于判定两个值是否深度一致，其规则如下：
 相同类型的值是深度相等的，不同类型的值永远不会深度相等。 当数组值（array）的对应元素深度相等时，数组值是深度相等的。 当结构体（struct）值如果其对应的字段（包括导出和未导出的字段）都是深度相等的，则该值是深度相等的。 当函数（func）值如果都是零，则是深度相等；否则就不是深度相等。 当接口（interface）值如果持有深度相等的具体值，则深度相等。 &amp;hellip;  更具体的大家可到 golang.org/pkg/reflect/#DeepEqual 进行详细查看：
reflect.DeepEqual 完整说明
该方法对 Go 语言中的各种类型都进行了兼容处理和判别，由于这不是本文的重点，因此就不进一步展开了。
总结 在本文中，我们针对 Go 语言的结构体（struct）是否能够比较进行了具体例子的展开和说明。
其本质上还是对 Go 语言基本数据类型的理解问题，算是变形到结构体中的具体进一步拓展。
</content>
    </entry>
    
     <entry>
        <title>难以驾驭的 Go timer，一文带你参透计时器的奥秘</title>
        <url>http://shanks.link/blog/2021/04/16/%E9%9A%BE%E4%BB%A5%E9%A9%BE%E9%A9%AD%E7%9A%84-go-timer%E4%B8%80%E6%96%87%E5%B8%A6%E4%BD%A0%E5%8F%82%E9%80%8F%E8%AE%A1%E6%97%B6%E5%99%A8%E7%9A%84%E5%A5%A5%E7%A7%98/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 转载自煎鱼的blog
#Go进阶之旅1
大家好，我是煎鱼。久违的源码剖析系列，让我们一起努力，看看谁能坚持到最后，因为学习一定是给能够坚持重复啃和热衷于三连的人。
接下来正式开始今天的内容讲解，今天的男主角是计时器 timer。
在实际的应用工程中，我们常常会需要多久后，或定时去做某个事情。甚至在分析标准库 context 的父子级传播时，都能见到等待多久后自动触发取消事件的踪影。
而在 Go 语言中，能够完成这类运行的功能诉求就是标准库 time，在具体的功能范畴上我们称其为 “计时器“，是一个非常具有价值的一个模块。在这篇文章中我们将对其做进一步的分析和研讨。
什么是 timer 可以控制时间，确保应用程序中的某段代码在某个时刻运行。在 Go 语言中可以单次执行，也可以循环执行。
最常见的方式就是引用标准库 time 去做一些事情，普通开发者经常使用到的标准库代码是：
time.Now().Unix() 上述代码可用于获取当前时间的 Unix 时间戳，而在内部的具体实现上提供了Time、Timer 以及 Ticker 的各类配套方法。
timer 基本特性 Timer 演示代码：
func main() {  timer := time.NewTimer(2 * time.Second)  &amp;lt;-timer.C  fmt.Println(&amp;#34;我的脑子真的进煎鱼了！&amp;#34;) } 输出结果：
// 等待两秒... 我的脑子真的进煎鱼了！ 我们可以通过 time.NewTimer 方法定时在 2 秒进行程序的执行。而其还有个变种的用法，在做 channel 的源码剖析时有发现
func main() {  v := make(chan struct{})  timer := time.AfterFunc(2*time.Second, func() {  fmt.Println(&amp;#34;我想在这个点吃煎鱼！&amp;#34;)  v &amp;lt;- struct{}{}  })  defer timer.Stop()  &amp;lt;-v } 在等待 2 秒后，会立即调用 time.AfterFunc 所对应的匿名方法。在时间上我们也可以指定对应的具体时间，达到异步的定时执行等诉求。
Ticker 演示代码：
func main() {  ticker := time.NewTicker(time.Second)  defer ticker.Stop()  done := make(chan bool)  go func() {  time.Sleep(10 * time.Second)  done &amp;lt;- true  }()  for {  select {  case &amp;lt;-done:  fmt.Println(&amp;#34;Done!&amp;#34;)  return  case t := &amp;lt;-ticker.C:  fmt.Println(&amp;#34;炸煎鱼: &amp;#34;, t.Unix())  }  } } 输出结果：
// 每隔一秒输出一次 炸煎鱼: 1611666168 炸煎鱼: 1611666169 炸煎鱼: 1611666170 炸煎鱼: 1611666171 ... 我们通过 time.NewTicker 方法设定每 1 秒执行一次方法，因此在 for-select 中，我们会每 1 秒就可以自动 “炸一条煎鱼”，真是快乐极了。
而由于我们在 goroutine 中通过 sleep 方法的设定了 done 变量的输入，因此在 10 秒后就会结束炸煎鱼的循环输出，最终退出。
最小堆：四叉堆 在 Go 语言中，内置计时器的数据结构都会涉及到最小四叉堆，如下图所示：
整体来讲就是父节点一定比其子节点小，子节点之间没有任何关系和大小的要求。
数据结构 在 Go 语言中每个计时器运行时的基本单元是 runtime.timer：
type timer struct {  pp puintptr   when int64  period int64  f func(interface{}, uintptr)  arg interface{}  seq uintptr  nextwhen int64  status uint32 }  pp：计时器所在的处理器 P 的指针地址。 when：计时器被唤醒的时间。 period：计时器再次被唤醒的时间（when&#43;period）。 f：回调函数，每次在计时器被唤醒时都会调用。 arg：回调函数的参数，每次在计时器被唤醒时会将该参数项传入回调函数 f 中。 seq：回调函数的参数，该参数仅在 netpoll 的应用场景下使用。 nextwhen：当计时器状态为 timerModifiedXX 时，将会使用 nextwhen 的值设置到 where字段上。 status：计时器的当前状态值，计时器本身包含大量的枚举标识，这块会在后面介绍。  但这类基本单元都不会是对用户端暴露的结构体，在对外上我们直观见的最多的是 time.NewTimer 所创建的 Timer 结构体：
type Timer struct {  C &amp;lt;-chan Time  r runtimeTimer }  C：用于接收 Timer 所触发的事件，当计时器的消息事件（例如：到期）发生时，该 channel 会接收到通知。 r：与 runtime.timer 作用类似，内在属性保持一致。  同时在计时器运行模式上自 Go1.14 起发生了变更，runtime.timer 改为将每个 timer 均存储在对应的处理器 P 中
type p struct {  ...  timersLock mutex  timers []*timer  ... } 在处理器 P 上，timers 字段就是一个以最小四叉堆形式存储的媒介。在时序上，需要立刻执行，或说需要越早执行的，就越排在堆的越上面：
实现原理 在了解了计时器的基本特性和数据结构后，我们进一步展开，一层层剖析其原理，看看其是何物。在 Go 语言中，计时器在运行时涉及十种状态处理，分别涉及增、删、改以及重置等操作。
计时器所包含的状态如下：
   状态名 含义     timerNoStatus 计时器尚未设置状态   timerWaiting 等待计时器启动   timerRunning 运行计时器的回调方法   timerDeleted 计时器已经被删除，但仍然在某些 P 的堆中   timerRemoving 计时器即将被删除   timerRemoved 计时器已经停止，且不在任何 P 的堆中   timerModifying 计时器正在被修改   timerModifiedEarlier 计时器已被修改为更早的时间   timerModifiedLater 计时器已被修改为更晚的时间   timerMoving 计时器已经被修改，正在被移动    这时候可能就会有小伙伴疑惑，各种启动、删除、停止、启动是指代的是什么意思？为什么会涉及到 P 的管理？
创建计时器 接下来我们依然是从 NewTimer 和 NewTicker 方法开始入手：
func NewTimer(d Duration) *Timer {  c := make(chan Time, 1)  t := &amp;amp;Timer{  C: c,  r: runtimeTimer{  when: when(d),  f: sendTime,  arg: c,  },  }  startTimer(&amp;amp;t.r)  return t } 在该方法中，其主要包含如下动作：
 创建 Timer 对象，主要是 C 和 r 属性，含义与前面所表述的一致。 调用 startTimer 方法，启动计时器。  NewTicker 方法与 NewTimer 类似，主要是增加了 period 字段：
func NewTicker(d Duration) *Ticker {  c := make(chan Time, 1)  t := &amp;amp;Ticker{  C: c,  r: runtimeTimer{  when: when(d),  period: int64(d),  f: sendTime,  arg: c,  },  }  startTimer(&amp;amp;t.r)  return t } 在 Ticker 结构体中，period 字段用于表示计时器再次被唤醒的时间，可以便于做轮询触发。
启动计时器 在前面调用 NewTimer、NewTicker 方法时，会将新创建的新计时器 timer 加入到创建 timer 的 P 的最小堆中：
func addtimer(t *timer) {  if t.when &amp;lt; 0 {  t.when = maxWhen  }  if t.status != timerNoStatus {  throw(&amp;#34;addtimer called with initialized timer&amp;#34;)  }  t.status = timerWaiting   when := t.when   pp := getg().m.p.ptr()  lock(&amp;amp;pp.timersLock)  cleantimers(pp)  doaddtimer(pp, t)  unlock(&amp;amp;pp.timersLock)   wakeNetPoller(when) }  检查是否满足基本条件：新增计时器的边界处理，timerNoStatus 状态判断排除。 调用 cleantimers 方法：清理处理器 P 中的计时器队列，可以加快创建和删除计时器的程序的速度。 调用 doaddtimer 方法：将当前所新创建的 timer 新增到当前处理器 P 的堆中。 调用 wakeNetPoller 方法：唤醒网络轮询器中休眠的线程，检查计时器被唤醒的时间（when）是否在当前轮询预期运行的时间（pollerPollUntil）内，若是唤醒。  停止计时器 在计时器的运转中，一般会调用 timer.Stop() 方法来停止/终止/删除计时器。虽然说法多样。但大家的真实目的是一样的，就是让这个 timer 从轮询器中消失，也就是从处理器 P 的堆中移除 timer：
func deltimer(t *timer) bool {  for {  switch s := atomic.Load(&amp;amp;t.status); s {  case timerWaiting, timerModifiedLater:  // timerWaiting/timerModifiedLater -&amp;gt; timerDeleted  ...  case timerModifiedEarlier:  // timerModifiedEarlier -&amp;gt; timerModifying -&amp;gt; timerDeleted  ...  case timerDeleted, timerRemoving, timerRemoved:  // timerDeleted/timerRemoving/timerRemoved  return false  case timerRunning, timerMoving:  // timerRunning/timerMoving  osyield()  case timerNoStatus:  return false  case timerModifying:  osyield()  default:  badTimer()  }  } } 但移除也不是直接一个 delete 就完事的，其在真正的删除方法 deltimer 中遵循了基本的规则处理：
 timerWaiting/timerModifiedLater -&amp;gt; timerDeleted。 timerModifiedEarlier -&amp;gt; timerModifying -&amp;gt; timerDeleted。 timerDeleted/timerRemoving/timerRemoved -&amp;gt; 无需变更，已经满足条件。 timerRunning/timerMoving/timerModifying -&amp;gt; 正在执行、移动中，无法停止，等待下一次状态检查再处理。 timerNoStatus -&amp;gt; 无法停止，不满足条件。  上述五个基本流转逻辑就覆盖了 runtimer.deltimer 方法了，若有进一步需求的可通过传送门详细阅读。
修改/重置计时器 在应用程序的调度中，有时候因为逻辑产生了变更，我们需要重置计时器。这时候一般会调用timer.Reset() 方法来重新设置 Duration 值。
其表面对应的是 resetTimer 方法，但实际与修改计时器的 modtimer 方法是共用的：
func resettimer(t *timer, when int64) bool {  return modtimer(t, when, t.period, t.f, t.arg, t.seq) } 因此在这节中我们可以将重置和修改计时器放在一起分析。修改计时器，本质上是需要变更现有计时器，而在 Go 语言的计时器中是需要遵循基本规则，因此 modtimer 遵循下述规则处理：
 timerWaiting -&amp;gt; timerModifying -&amp;gt; timerModifiedXX timerModifiedXX -&amp;gt; timerModifying -&amp;gt; timerModifiedYY timerNoStatus -&amp;gt; timerModifying -&amp;gt; timerWaiting timerRemoved -&amp;gt; timerModifying -&amp;gt; timerWaiting timerDeleted -&amp;gt; timerModifying -&amp;gt; timerModifiedXX timerRunning -&amp;gt; 等待状态改变，才可以进行下一步 timerMoving -&amp;gt; 等待状态改变，才可以进行下一步 timerRemoving -&amp;gt; 等待状态改变，才可以进行下一步 timerModifying -&amp;gt; 等待状态改变，才可以进行下一步  func modtimer(t *timer, when, period int64, f func(interface{}, uintptr), arg interface{}, seq uintptr) bool {  ...  if wasRemoved {  t.when = when  pp := getg().m.p.ptr()  lock(&amp;amp;pp.timersLock)  doaddtimer(pp, t)  unlock(&amp;amp;pp.timersLock)   releasem(mp)  wakeNetPoller(when)  } else {  t.nextwhen = when  newStatus := uint32(timerModifiedLater)  if when &amp;lt; t.when {  newStatus = timerModifiedEarlier  }  ...  releasem(mp)   if newStatus == timerModifiedEarlier {  wakeNetPoller(when)  }  }   return pending } 在完成了计时器的状态处理后，会分为两种情况处理：
 待修改的计时器已经被删除：由于既有的计时器已经没有了，因此会调用 doaddtimer 方法创建一个新的计时器，并将原本的 timer 属性赋值过去，再调用 wakeNetPoller 方法在预定时间唤醒网络轮询。 正常逻辑处理：如果修改后的计时器的触发时间小于原本的触发时间，则修改该计时器的状态为 timerModifiedEarlier，并且调用 wakeNetPoller 方法在预定时间唤醒网络轮询。  触发计时器 在前面有提到 Go1.14 后，Go Timer 都已经归属到各个处理器 P 中去了，因此计时器的触发分为了两个部分：
 通过调度器在调度时进行计时器的触发。 通过系统监控检查并触发计时器（到期未执行）。  调度器触发 调度器的触发一共分两种情况，一种是在调度循环的时候调用 checkTimers 方法进行计时器的触发：
func schedule() {  _g_ := getg()  top:  pp := _g_.m.p.ptr()  pp.preempt = false   // 处理调度时的计时器触发  checkTimers(pp, 0)  ...   execute(gp, inheritTime) } 另外一种是当前处理器 P 没有可执行的 Timer，且没有可执行的 G。那么按照调度模型，就会去窃取其他计时器和 G：
func findrunnable() (gp *g, inheritTime bool) {  _g_ := getg()  top:  _p_ := _g_.m.p.ptr()  ...  now, pollUntil, _ := checkTimers(_p_, 0)  ... } 调度系统在计时器处不深究，我们进一步剖析具体触发计时器的 checkTimers 方法：
func checkTimers(pp *p, now int64) (rnow, pollUntil int64, ran bool) {  if atomic.Load(&amp;amp;pp.adjustTimers) == 0 {  next := int64(atomic.Load64(&amp;amp;pp.timer0When))  if next == 0 {  return now, 0, false  }  if now == 0 {  now = nanotime()  }  if now &amp;lt; next {  if pp != getg().m.p.ptr() || int(atomic.Load(&amp;amp;pp.deletedTimers)) &amp;lt;= int(atomic.Load(&amp;amp;pp.numTimers)/4) {  return now, next, false  }  }  }   lock(&amp;amp;pp.timersLock)   adjusttimers(pp)  ... }   起始先通过 pp.adjustTimers 检查当前处理器 P 中是否有需要处理的计时器。
   若无需执行的计时器，则直接返回。 若有，则判断下一个计时器待删除的计时器和处理器 P 上的计时器数量，若前者小于后者 1/4 则直接返回。    确定需要处理计时器后，通过调用 adjusttimers 方法重新根据时间将 timers 切片中 timer 的先后顺序重新排列（相当于 resort）。
  func checkTimers(pp *p, now int64) (rnow, pollUntil int64, ran bool) {  ...  rnow = now  if len(pp.timers) &amp;gt; 0 {  if rnow == 0 {  rnow = nanotime()  }  for len(pp.timers) &amp;gt; 0 {  if tw := runtimer(pp, rnow); tw != 0 {  if tw &amp;gt; 0 {  pollUntil = tw  }  break  }  ran = true  }  }  ... } 在前面调整了 timers 切片中的最小堆的排序后，将会调用 runtimer 方法去真正运行所需要执行的 timer，完成触计时器的发。
func checkTimers(pp *p, now int64) (rnow, pollUntil int64, ran bool) {  ...  if pp == getg().m.p.ptr() &amp;amp;&amp;amp; int(atomic.Load(&amp;amp;pp.deletedTimers)) &amp;gt; len(pp.timers)/4 {  clearDeletedTimers(pp)  }   unlock(&amp;amp;pp.timersLock)   return rnow, pollUntil, ran } 在最后扫尾阶段，如果当前 G 的处理器与调用 checkTimers 方法所传入的处理器一致，并且处理器中 timerDeleted 状态的计时器数量是处理器 P 堆中的计时器的 1/4 以上，则调用 clearDeletedTimers 方法对已为删除状态的的计时器进行清理。
系统监控触发 即使是通过每次调度器调度和窃取的时候触发，但毕竟是具有一定的随机和不确定性。
因此系统监控触发依然是一个兜底保障，在 Go 语言中 runtime.sysmon 方法承担了这一个责任，存在触发计时器的逻辑：
func sysmon() {  ...  for {  ...  next, _ := timeSleepUntil()   if debug.schedtrace &amp;lt;= 0 &amp;amp;&amp;amp; (sched.gcwaiting != 0 || atomic.Load(&amp;amp;sched.npidle) == uint32(gomaxprocs)) {  lock(&amp;amp;sched.lock)  if atomic.Load(&amp;amp;sched.gcwaiting) != 0 || atomic.Load(&amp;amp;sched.npidle) == uint32(gomaxprocs) {  if next &amp;gt; now {  ...  next, _ = timeSleepUntil()  lock(&amp;amp;sched.lock)  atomic.Store(&amp;amp;sched.sysmonwait, 0)  noteclear(&amp;amp;sched.sysmonnote)  }  idle = 0  delay = 20  }  unlock(&amp;amp;sched.lock)  }  ...  } } 在每次进行系统监控时，都会在流程上调用 timeSleepUntil 方法去获取下一个计时器应触发的时间，以及保存该计时器已打开的计时器堆的 P。
在获取完毕后会马上检查当前是否存在 GC，若是正在 STW 则获取调度互斥锁。若发现下一个计时器的触发时间已经过去，则重新调用 timeSleepUntil 获取下一个计时器的时间和相应 P 的地址。
func sysmon() {  ...  for {  ...  lock(&amp;amp;sched.sysmonlock)  {  now1 := nanotime()  if now1-now &amp;gt; 50*1000 /* 50µs */ {  next, _ = timeSleepUntil()  }  now = now1  }  ...  } } 检查 sched.sysmonlock 所花费的时间是否超过 50µs。若是，则有可能前面所获取的下一个计时器触发时间已过期，因此重新调用 timeSleepUntil 方法再次获取。
func sysmon() {  ...  for {  ...  lastpoll := int64(atomic.Load64(&amp;amp;sched.lastpoll))  if netpollinited() &amp;amp;&amp;amp; lastpoll != 0 &amp;amp;&amp;amp; lastpoll&#43;10*1000*1000 &amp;lt; now {  atomic.Cas64(&amp;amp;sched.lastpoll, uint64(lastpoll), uint64(now))  list := netpoll(0) // non-blocking - returns list of goroutines  if !list.empty() {  incidlelocked(-1)  injectglist(&amp;amp;list)  incidlelocked(1)  }  }  if next &amp;lt; now {  startm(nil, false)  }  } } 如果发现超过 10ms 的时间没有进行 netpoll 网络轮询，则主动调用 netpoll 方法触发轮询。
同时如果存在不可抢占的处理器 P，则调用 startm 方法来运行那些应该运行，但没有在运行的计时器。
运行计时器 runtimer 方法主要承担计时器的具体运行，同时也会针对计时器的不同状态（含删除、修改、等待等）都进行了对应的处理，也相当于是个大的集中处理中枢了。例如在timerDeleted 状态下的计时器将会进行删除。
其遵循下述规则处理
 timerNoStatus -&amp;gt; 恐慌：计时器未初始化 timerWaiting -&amp;gt; timerWaiting timerWaiting -&amp;gt; timerRunning -&amp;gt; timerNoStatus timerWaiting -&amp;gt; timerRunning -&amp;gt; timerWaiting timerModifying -&amp;gt; 等待状态改变，才可以进行下一步 timerModifiedXX -&amp;gt; timerMoving -&amp;gt; timerWaiting timerDeleted -&amp;gt; timerRemoving -&amp;gt; timerRemoved timerRunning -&amp;gt; 恐慌：并发调用 timerRemoved -&amp;gt; 恐慌：计时器堆不一致 timerRemoving -&amp;gt; 恐慌：计时器堆不一致 timerMoving -&amp;gt; 恐慌：计时器堆不一致  我们再根据时间状态机，去针对性的看看源码是如何实现的：
func runtimer(pp *p, now int64) int64 {  for {  t := pp.timers[0]  switch s := atomic.Load(&amp;amp;t.status); s {  case timerWaiting:  if t.when &amp;gt; now {  return t.when  }   runOneTimer(pp, t, now)  return 0   case timerDeleted:  ...  case timerModifiedEarlier, timerModifiedLater:  ...  case timerModifying:  osyield()  case timerNoStatus, timerRemoved:  badTimer()  case timerRunning, timerRemoving, timerMoving:  badTimer()  default:  badTimer()  }  } } 我们主要关注运行计时器，也就是 timerWaiting 状态下的处理，其首先会对触发时间（when）进行判定，若大于当前时间则直接返回（因为所需触发的时间未到）。否则将会调用 runOneTimer 方法去执行本次触发：
func runOneTimer(pp *p, t *timer, now int64) {  f := t.f  arg := t.arg  seq := t.seq   if t.period &amp;gt; 0 {  delta := t.when - now  t.when &#43;= t.period * (1 &#43; -delta/t.period)  siftdownTimer(pp.timers, 0)  if !atomic.Cas(&amp;amp;t.status, timerRunning, timerWaiting) {  badTimer()  }  updateTimer0When(pp)  } else {  dodeltimer0(pp)  }   unlock(&amp;amp;pp.timersLock)  f(arg, seq)  lock(&amp;amp;pp.timersLock) }   如果 period 大于 0，说明当前是 ticker，需要再次触发，因此还需要调整计时器的状态。
   重新计算下一次的触发时间，并且更新其在最小堆的位置。 调用 atomic.Cas 方法该计时器的状态从 timerRunning 原子修改为 timerWaiting 状态。 调用 updateTimer0When 方法设置处理器 P 的 timer0When 字段。    如果 period 等于 0，说明当前是 timer，只需要单次触发就可以了。
  在完成计时器的运行属性更新后，上互斥锁，调用计时器的回调方法 f，完成本次完整的触发流程。
总结 Go 语言的 Timer 其实已经改过了好几版，在 Go1.14 的正式大改版后。目前来看已经初步的到了一个新的阶段。其设计的模式主要围绕三块：
 在各个处理器 P 中，Timer 以最小四叉堆的存储方式在 timers 中。 在调度器的每轮调度中都会对计时器进行触发和检查。 在系统监听上 netpoll 会定时进行计时器的触发和检查。 在计时器的处理中，十个状态的流转和对应处理非常重要。  </content>
    </entry>
    
     <entry>
        <title>再见 Go 面试官：GMP 模型，为什么要有 P？</title>
        <url>http://shanks.link/blog/2021/04/16/%E5%86%8D%E8%A7%81-go-%E9%9D%A2%E8%AF%95%E5%AE%98gmp-%E6%A8%A1%E5%9E%8B%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%9C%89-p/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 转载自煎鱼的blog
最近金三银四，是面试的季节。在我的 Go 读者交流群里出现了许多小伙伴在讨论自己面试过程中所遇到的一些 Go 面试题。
今天的主角，是 Go 面试的万能题 GMP 模型的延伸题（疑问），那就是 ”GMP 模型，为什么要有 P？“
进一步推敲问题的背后，其实这个面试题本质是想问：”GMP 模型，为什么不是 G 和 M 直接绑定就完了，还要搞多一个 P 出来，那么麻烦，为的是什么，是要解决什么问题吗？“
这篇文章煎鱼就带你一同探索，GM、GMP 模型的变迁是因为什么原因。
GM 模型 在 Go1.1 之前 Go 的调度模型其实就是 GM 模型，也就是没有 P。
今天带大家一起回顾过去的设计。
解密 Go1.0 源码 我们了解一个东西的办法之一就是看源码，和煎鱼一起看看 Go1.0.1 的调度器源码的核心关键步骤：
static void schedule(G *gp) {  ...  schedlock();  if(gp != nil) {  ...  switch(gp-&amp;gt;status){  case Grunnable:  case Gdead:  // Shouldn&amp;#39;t have been running!  runtime·throw(&amp;#34;bad gp-&amp;gt;status in sched&amp;#34;);  case Grunning:  gp-&amp;gt;status = Grunnable;  gput(gp);  break;  }   gp = nextgandunlock();  gp-&amp;gt;readyonstop = 0;  gp-&amp;gt;status = Grunning;  m-&amp;gt;curg = gp;  gp-&amp;gt;m = m;  ...  runtime·gogo(&amp;amp;gp-&amp;gt;sched, 0); }  调用 schedlock 方法来获取全局锁。 获取全局锁成功后，将当前 Goroutine 状态从 Running（正在被调度） 状态修改为 Runnable（可以被调度）状态。 调用 gput 方法来保存当前 Goroutine 的运行状态等信息，以便于后续的使用。 调用 nextgandunlock 方法来寻找下一个可运行 Goroutine，并且释放全局锁给其他调度使用。 获取到下一个待运行的 Goroutine 后，将其运行状态修改为 Running。 调用 runtime·gogo 方法，将刚刚所获取到的下一个待执行的 Goroutine 运行起来，进入下一轮调度。  思考 GM 模型 通过对 Go1.0.1 的调度器源码剖析，我们可以发现一个比较有趣的点。那就是调度器本身（schedule 方法），在正常流程下，是不会返回的，也就是不会结束主流程。
G-M模型简图
他会不断地运行调度流程，GoroutineA 完成了，就开始寻找 GoroutineB，寻找到 B 了，就把已经完成的 A 的调度权交给 B，让 GoroutineB 开始被调度，也就是运行。
当然了，也有被正在阻塞（Blocked）的 G。假设 G 正在做一些系统、网络调用，那么就会导致 G 停滞。这时候 M（系统线程）就会被会重新放内核队列中，等待新的一轮唤醒。
GM 模型的缺点 这么表面的看起来，GM 模型似乎牢不可破，毫无缺陷。但为什么要改呢？
在 2012 年时 Dmitry Vyukov 发表了文章《Scalable Go Scheduler Design Doc》，目前也依然是各大研究 Go 调度器文章的主要对象，其在文章内讲述了整体的原因和考虑，下述内容将引用该文章。
当前（代指 Go1.0 的 GM 模型）的 Goroutine 调度器限制了用 Go 编写的并发程序的可扩展性，尤其是高吞吐量服务器和并行计算程序。
实现有如下的问题：
  存在单一的全局 mutex（Sched.Lock）和集中状态管理：
   mutex 需要保护所有与 goroutine 相关的操作（创建、完成、重排等），导致锁竞争严重。    Goroutine 传递的问题：
   goroutine（G）交接（G.nextg）：工作者线程（M&amp;rsquo;s）之间会经常交接可运行的 goroutine。 上述可能会导致延迟增加和额外的开销。每个 M 必须能够执行任何可运行的 G，特别是刚刚创建 G 的 M。    每个 M 都需要做内存缓存（M.mcache）：
   会导致资源消耗过大（每个 mcache 可以吸纳到 2M 的内存缓存和其他缓存），数据局部性差。    频繁的线程阻塞/解阻塞：
   在存在 syscalls 的情况下，线程经常被阻塞和解阻塞。这增加了很多额外的性能开销。    GMP 模型 为了解决 GM 模型的以上诸多问题，在 Go1.1 时，Dmitry Vyukov 在 GM 模型的基础上，新增了一个 P（Processor）组件。并且实现了 Work Stealing 算法来解决一些新产生的问题。
带来什么改变 加了 P 之后会带来什么改变呢？我们再更显式的讲一下。
 每个 P 有自己的本地队列，大幅度的减轻了对全局队列的直接依赖，所带来的效果就是锁竞争的减少。而 GM 模型的性能开销大头就是锁竞争。 每个 P 相对的平衡上，在 GMP 模型中也实现了 Work Stealing 算法，如果 P 的本地队列为空，则会从全局队列或其他 P 的本地队列中窃取可运行的 G 来运行，减少空转，提高了资源利用率。  为什么要有 P 这时候就有小伙伴会疑惑了，如果是想实现本地队列、Work Stealing 算法，那为什么不直接在 M 上加呢，M 也照样可以实现类似的功能。
为什么又再加多一个 P 组件？
结合 M（系统线程） 的定位来看，若这么做，有以下问题。
 一般来讲，M 的数量都会多于 P。像在 Go 中，M 的数量最大限制是 10000，P 的默认数量的 CPU 核数。另外由于 M 的属性，也就是如果存在系统阻塞调用，阻塞了 M，又不够用的情况下，M 会不断增加。 M 不断增加的话，如果本地队列挂载在 M 上，那就意味着本地队列也会随之增加。这显然是不合理的，因为本地队列的管理会变得复杂，且 Work Stealing 性能会大幅度下降。 M 被系统调用阻塞后，我们是期望把他既有未执行的任务分配给其他继续运行的，而不是一阻塞就导致全部停止。  因此使用 M 是不合理的，那么引入新的组件 P，把本地队列关联到 P 上，就能很好的解决这个问题。
总结 今天这篇文章结合了整个 Go 语言调度器的一些历史情况、原因分析以及解决方案说明。
”GMP 模型，为什么要有 P“ 这个问题就像是一道系统设计了解，因为现在很多人为了应对面试，会硬背 GMP 模型，或者是泡面式过了一遍。而理解其中真正背后的原因，才是我们要去学的要去理解。
知其然知其所以然，才可破局。
</content>
    </entry>
    
     <entry>
        <title>Go 群友提问：进程、线程都有 ID，为什么 Goroutine 没有 ID？</title>
        <url>http://shanks.link/blog/2021/04/16/go-%E7%BE%A4%E5%8F%8B%E6%8F%90%E9%97%AE%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E9%83%BD%E6%9C%89-id%E4%B8%BA%E4%BB%80%E4%B9%88-goroutine-%E6%B2%A1%E6%9C%89-id/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 转载自煎鱼的blog
今天的主角，是大家在既有语言基础的情况下，学 Goroutine 时会容易纠结的一点。就是 “进程、线程都有 ID，为什么 Goroutine 没有 GoroutineID？”。
这是为什么呢，怎么做那些跨协程处理呢？
GoroutineID 是什么 我们要知道，为什么大家会下意识的想去要 GoroutineID，下面引用 Go 语言圣经中的表述：
  在大多数支持多线程的操作系统和程序语言中，当前的线程都有一个独特的身份（ID），并且这个身份信息可以以一个普通值的形式被很容易地获取到，典型的可以是一个 integer 或者指针值。这种情况下我们做一个抽象化的 thread-local storage（线程本地存储，多线程编程中不希望其它线程访问的内容）就很容易，只需要以线程的 ID 作为 key 的一个 map 就可以解决问题，每一个线程以其 ID 就能从中获取到值，且和其它线程互不冲突。
  也就是指在常规的进程、线程中都有其 ID 的概念，我们可以在程序中通过 ID 来获取其他进程、线程中的数据，甚至是传输数据。就像一把钥匙一样，有了他干啥都可以。
GoroutineID 的概念也是类似的，也就是协程的 ID。我们下意识的就期望通过协程 ID 来进行跨协程的操作。
但，在 Go 语言中 GoroutineID 并没有显式获取的办法，这就要打个大大的疑惑了。
为什么没有 GoroutineID 为什么在 Go 语言中没有 GoroutineID 呢，是从一开始就没有的，还是，这样子设计的原因是什么呢？
其实 Go 语言在以前是有暴露方法去获取 GoroutineID 的，但在 Go1.4 后就把该方法给隐藏起来了，不建议大家使用。
也就是明面上没有 GoroutineID，是一个有意而为之的行为。原因是：根据以往的经验，认为 thread-local storage 存在被滥用的可能性，且带来许多不必要的复杂度。
简单来讲，Andrew Gerrand 的回答是 ”thread-local storage 的成本远远超过了它们的收益。它们只是不适合 Go 语言。”
潜在的问题   当 Goroutine 消失时：
   它的 Goroutine 本地存储将不会被 GC 化。(你可以得到 goid 的当前的 Goroutine，但你不能得到所有运行的 Goroutine 的列表)    如果处理程序自己产生了新的 Goroutine 怎么办？
   新的 Goroutine 失去了对既有的 Goroutine 本地存储。虽然你可以保证自己的代码不会产生其他的 Goroutine。 一般来说，你不能确保标准库或任何第三方代码不会这样做。    Go 应用程序的复杂度和心智负担等上升。
  滥用的场景 有一个对外提供 HTTP 服务的 Go 应用，也就是 Web Server。Go HTTP Server 都是采取每次请求新起一个协程的方式。
假设可以通过 GoroutineID 进行跨协程操纵，那么就有可能出现我的 Goroutine，不一定是由 “我” 自己决定的。可能其他正在处理的 GoroutineB 悄悄摸摸的改了我这个 GoroutineA 的行为。
这就有可能导致一个灾难问题，就是出问题时，你不知道是谁动了你的奶酪。查起问题来简直就是一个灾难。
若是自己维护的模块清楚还起码知道这事，假设你的前同事刚好离职了，你又在熟悉代码，一出问题。这锅那是死死的扣在了你的头上了。
如何获取 GoroutineID 刚刚我们提到是在明面上把 GoroutineID 给隐藏了，那暗面呢，是不是有其他办法可以获取到？
答案是：可以的。
通过骇客代码的方式可以获取到。在 Go 语言的标准库 http/2 的 gotrack 中，就有提供如下获取方法：
func main() {  go func() {  fmt.Println(&amp;#34;脑子进煎鱼了的 GoroutineID：&amp;#34;, curGoroutineID())  }()   time.Sleep(time.Second) }  func curGoroutineID() uint64 {  bp := littleBuf.Get().(*[]byte)  defer littleBuf.Put(bp)  b := *bp  b = b[:runtime.Stack(b, false)]  // Parse the 4707 out of &amp;#34;goroutine 4707 [&amp;#34;  b = bytes.TrimPrefix(b, goroutineSpace)  i := bytes.IndexByte(b, &amp;#39; &amp;#39;)  if i &amp;lt; 0 {  panic(fmt.Sprintf(&amp;#34;No space found in %q&amp;#34;, b))  }  b = b[:i]  n, err := parseUintBytes(b, 10, 64)  if err != nil {  panic(fmt.Sprintf(&amp;#34;Failed to parse goroutine ID out of %q: %v&amp;#34;, b, err))  }  return n }  var littleBuf = sync.Pool{  New: func() interface{} {  buf := make([]byte, 64)  return &amp;amp;buf  }, }  var goroutineSpace = []byte(&amp;#34;goroutine &amp;#34;) 输出结果为：
脑子进煎鱼了的 GoroutineID：18 结合 curGoroutineID 方法来看，可以通过对 Go 运行时的分析，也就是 runtime.Stack 从而得到 GoroutineID。
其作用，更多的是对进行跟踪和调试作用居多。因为官方并没有根据 GoroutineID 提供一系列跨协程操纵的方法。
也有如下开源库可以用于获取 GoroutineID（不过均多年未维护了）：
 davecheney/junk jtolio/gls tylerstillwater/gls  Go 团队的 Dave Cheney 对其所开源的 GoroutineID 库，评价：“If you use this package, you will go straight to hell.”：
davecheney/junk
也就是 “如果你使用这个包，你会直接下地狱。“，非常猛了，深深地劝退大家使用。
日常在哪里常见 如果大家经常做救火队长，去排查 Go 工程中的问题，例如：错误堆栈信息、PProf 性能分析等调试信息。
因此经常看到 GoroutineID，也就是 “goroutine #### […]”。
我们所看到的 #### 就是真实的 GoroutineID，剩余的信息就是一些堆栈跟踪和错误描述了。
应该使用 GoroutineID 吗？ 从结果来看，肯定是不推荐使用 GoroutineID 了。毕竟没有什么特别的好处，Go 团队也是反对的。
所以一般都会直接回答 ”无法获取 GoroutineID“，应当跟从语言设计理念，使用 Share Memory By Communicating 来实现跨协程的操纵会更合理。
总结 今天这篇文章我们根据 GoroutineID 的历史，作用，原因，骇客方法进行了逐一梳理，摸索了下里面究竟为何物。
进程、线程、协程的对比是一个面试中常被拿出来问的话题，而 GoroutineID 就是其中一点，这涉及到整个全局上的设计考虑。
你又是否遇到过 GoroutineID 使用和疑问的场景呢，欢迎大家一起留言讨论。
</content>
    </entry>
    
     <entry>
        <title>Go 语言中的一等公民：看似普通的函数，凭什么？</title>
        <url>http://shanks.link/blog/2021/04/16/go-%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E4%B8%80%E7%AD%89%E5%85%AC%E6%B0%91%E7%9C%8B%E4%BC%BC%E6%99%AE%E9%80%9A%E7%9A%84%E5%87%BD%E6%95%B0%E5%87%AD%E4%BB%80%E4%B9%88/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 转载自煎鱼的blog
在 Go 语言中，一提函数，大家提的最多的就是 “Go 语言的函数是一等公民”。这个定义来的非常突然，我们先了解一下什么是一等公民，他又凭什么？
根据维基百科的一等公民（First-class citizen）的定义：
 In programming language design, a first-class citizen (also type, object, entity, or value) in a given programming language is an entity which supports all the operations generally available to other entities. These operations typically include being passed as an argument, returned from a function, modified, and assigned to a variable.
 在编程语言设计中，给定编程语言中的一等公民（也就是类型，对象，实体或值）可以把函数赋值给变量，也可以把函数作为其它函数的参数或者返回值来直接使用。
Go 语言的函数也满足这个定义，因此常被称为 “一等公民”，非常有意思。了解清楚背景后，接下来进一步展开。
普通函数 在 Go 语言中普通函数的定义格式为 func [函数名](入参)(出参)，如下：
func callFuncA(x, y string) (s string, err error) {  return x &#43; y, nil }  func main() {  callFuncA(&amp;#34;炸&amp;#34;, &amp;#34;煎鱼&amp;#34;) } 在示例代码中声明了一个函数名为 callFuncA 的方法，他只允许在包内调用，因此首字母为小写。
其具有两个入参，分别是 x 和 y，类型都为 string。而出参为变量 s 和 err，类型分别为 string 和 error。
另外在函数体内返回值时，也可以采用快捷返回的方式：
func callFuncA(x, y string) (s string, err error) {  s = x &#43; y  return } 在出参时所声明的变量名称，是可以应用到自身函数的。因此若直接执行 return 则会隐式返回已经声明的出参变量。
在函数定义时，其入参还支持可变参数的语法：
func callFuncA(x ...string) (s string, err error) {  s = strings.Join(x, &amp;#34;,&amp;#34;)  return }  func main() {  fmt.Println(callFuncA(&amp;#34;炸&amp;#34;, &amp;#34;煎鱼&amp;#34;)) } 在入参变量上声明为 x ...string，则表示变量 x 是 string 类型的可变变量，能够在入参时传入多个 string 参数。
可变变量所传入的格式为切片（slice）类型，该类型我们会在后面的章节进行讲解，你可以理解为不受长度限制的动态数组：
[0: 炸 1: 煎鱼] 一般对可变变量的常见后续操作多是循环遍历处理，又或是进行拼接等操作。
匿名函数 Go 语言也默认支持匿名函数的声明，声明的方式与普通函数几乎一样：
func main() {  s := func(x, y string) (s string, err error) {  return x &#43; y, nil  }   s(&amp;#34;炸&amp;#34;, &amp;#34;煎鱼&amp;#34;) } 匿名函数可以在任意地方声明，且不需要定义函数名，如果在函数体后马上跟 () 则表示声明后立即执行：
func main() {  s, _ := func(x, y string) (s string, err error) {  return x &#43; y, nil  }(&amp;#34;炸&amp;#34;, &amp;#34;煎鱼&amp;#34;) } 而在所有的函数类使用中，有一点非常重要，那就是函数变量作用域的理解：
func main() {  x, y := &amp;#34;炸&amp;#34;, &amp;#34;煎鱼&amp;#34;  s, _ := func() (s string, err error) {  return x &#43; y, nil  }()  fmt.Println(s) } 该匿名函数没有形参，函数内部没有定义相应的变量，此时其读取的是全局的 x、y 变量的值，输出结果是 “炸煎鱼”。
func main() {  x, y := &amp;#34;炸&amp;#34;, &amp;#34;煎鱼&amp;#34;  _, _ = func(x, y string) (s string, err error) {  x = &amp;#34;吃&amp;#34;  return x &#43; y, nil  }(x, y)  fmt.Println(x, y) } 该匿名函数有形参，但是在函数内部又重新赋值了变量 x。那么最终外部所输出的变量 x的值是什么呢？输出结果是 “炸 煎鱼”。
为什么明明在函数内已经对变量 x 重新赋值，却依然没有改变全局变量 x 的值呢？
其本质原因是作用域不同，函数内部所修改的变量 x 是函数内的局部变量。而外部的是全局的变量，所归属的作用域不同。
结构方法 在结合结构体（struct）的方式下，可以声明归属于该结构体下的方法：
type T struct{}  func NewT() *T {  return &amp;amp;T{} }  func (t *T) callFuncA(x, y string) (s string, err error) {  return x &#43; y, nil }  func main() {  NewT().callFuncA(&amp;#34;炸&amp;#34;, &amp;#34;煎鱼&amp;#34;) } 具体的函数的使用方法与普通函数一样，无其他区别。
而与结构体有关的值传递、引用传递的方法调用将在具体后面的章节再展开。
内置函数 Go 语言本身有支持一些内置函数，这些内置函数的调用不需要引用第三方标准库。内置函数的作用是用于配合 Go 语言的常规使用，数量非常少。如下：
 用于获取某些类型的长度和容量：len、cap。 用于创建并分配某些类型的内存：new、make。 用于错误处理机制（异常恐慌、异常捕获）：panic、recover。 用于复制和新增切片（slice）：copy、append。 用于简单输出信息：print、println。 用于处理复数：complex、real、imag。  针对每个内置函数的真实使用场景，我们会在后续的章节再进一步展开，因为每个内置函数本质上都对应着各类型的使用场景。
总结 在本章节中，我们介绍了 Go 语言的函数为什么称是一等公民，并且针对函数的各类变形：普通函数、匿名函数、结构方法、内置函数进行了基本的说明。
面对新手入门最容易犯错的函数作用域问题，也进行了基本的梳理。这块建议大家要多多深入思考、理解，避免日后踩坑。
</content>
    </entry>
    
     <entry>
        <title>Go 面试题：Go interface 的一个 坑 及原理分析</title>
        <url>http://shanks.link/blog/2021/04/16/go-%E9%9D%A2%E8%AF%95%E9%A2%98go-interface-%E7%9A%84%E4%B8%80%E4%B8%AA-%E5%9D%91-%E5%8F%8A%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 以下内容转载自煎鱼的blog
Go 面试题：Go interface 的一个 “坑” 及原理分析 原创 陈煎鱼 脑子进煎鱼了 3月16日
收录于话题
#Go45
#面试题13
大家好，我是煎鱼。
前几天在读者交流群里看到一位小伙伴，针对 interface 的使用有了比较大的疑惑。
无独有偶，我也在网上看到有小伙伴在 Go 面试的时候被问到了：
来自网上博客的截图
今天特意分享出来让大家避开这个坑。
例子一 第一个例子，如下代码：
func main() {  var v interface{}  v = (*int)(nil)  fmt.Println(v == nil) } 你觉得输出结果是什么呢？
答案是：
false 为什么不是 true。明明都已经强行置为 nil 了。是不是 Go 编译器有问题？
例子二 第二个例子，如下代码：
func main() {  var data *byte  var in interface{}   fmt.Println(data, data == nil)  fmt.Println(in, in == nil)   in = data  fmt.Println(in, in == nil) } 你觉得输出结果是什么呢？
答案是：
&amp;lt;nil&amp;gt; true &amp;lt;nil&amp;gt; true &amp;lt;nil&amp;gt; false 这可就更奇怪了，为什么刚刚声明出来的 data 和 in 变量，确实是输出结果是 nil，判断结果也是 true。
怎么把变量 data 一赋予给变量 in，世界就变了？输出结果依然是 nil，但判定却变成了false。
和上面的第一个例子结果类似，真是神奇。
原因 interface 判断与想象中不一样的根本原因是，interface 并不是一个指针类型，虽然他看起来很像，以至于误导了不少人。
我们钻下去 interface，interface 共有两类数据结构：
 runtime.eface 结构体：表示不包含任何方法的空接口，也称为 empty interface。 runtime.iface 结构体：表示包含方法的接口。  看看这两者相应的底层数据结构：
type eface struct {  _type *_type  data unsafe.Pointer }  type iface struct {  tab *itab  data unsafe.Pointer } 你会发现 interface 不是单纯的值，而是分为类型和值。
所以传统认知的此 nil 并非彼 nil，必须得类型和值同时都为 nil 的情况下，interface 的 nil 判断才会为 true。
解决办法 与其说是解决方法，不如说是委婉的破局之道。在不改变类型的情况下，方法之一是利用反射（reflect），如下代码：
func main() {  var data *byte  var in interface{}   in = data  fmt.Println(IsNil(in)) }  func IsNil(i interface{}) bool {  vi := reflect.ValueOf(i)  if vi.Kind() == reflect.Ptr {  return vi.IsNil()  }  return false } 利用反射来做 nil 的值判断，在反射中会有针对 interface 类型的特殊处理，最终输出结果是：true，达到效果。
其他方法的话，就是改变原有的程序逻辑，例如：
 对值进行 nil 判断，再返回给 interface 设置。 返回具体的值类型，而不是返回 interface。  总结 Go interface 是 Go 语言中最常用的类型之一，大家用惯了 if err != nil 就很容易顺手就踩进去了。
建议大家要多留个心眼，如果对 interface 想要有更进一步的了解，可以看看我的这篇深入解析的文章：《一文吃透 Go 语言解密之接口 interface》。
小伙伴们有没有踩到过，或遇到过 interface 相关的 “坑” 呢？欢迎大家下方留言讨论，分享出来。
</content>
    </entry>
    
     <entry>
        <title>Go 群友提问：学习 defer 时很懵逼，这道不会做！</title>
        <url>http://shanks.link/blog/2021/04/16/go-%E7%BE%A4%E5%8F%8B%E6%8F%90%E9%97%AE%E5%AD%A6%E4%B9%A0-defer-%E6%97%B6%E5%BE%88%E6%87%B5%E9%80%BC%E8%BF%99%E9%81%93%E4%B8%8D%E4%BC%9A%E5%81%9A/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Go 群友提问：学习 defer 时很懵逼，这道不会做！ 转载自煎鱼的blog
前几天在读者交流群里看到一位小伙伴，在向大家咨询 Go 相关的技术问题。疑问是：“各位大佬，我在学习 defer 遇到闭包的时候很懵逼，谁比较明白，能指点？”
疑问 他的疑问是下面这道 Go 语言的 defer 题目，大家一起看看：
func main() {  var whatever [6]struct{}  for i := range whatever {  defer func() {  fmt.Println(i)  }()  } } 请自己先想一下输出的结果答案是什么。
这位小伙伴按自己的理解后，认为应当输出 xx。但最终的输出结果，可能与其思考的有所偏差，一时想不通。
解惑 这段程序的输出结果是：
5 5 5 5 5 5 为什么全是 5，为什么不是 0, 1, 2, 3, 4, 5 这样的输出结果呢？
其根本原因是闭包所导致的，有两点原因：
 在 for 循环结束后，局部变量 i 的值已经是 5 了，并且 defer的闭包是直接引用变量的 i。 结合defer 关键字的特性，可得知会在 main 方法主体结束后再执行。  结合上述，最终输出的结果是已经自增完毕的 5。
进一步思考 既然了解了为什么，我们再变形一下。再看看另外一种情况，代码如下：
func main() {  var whatever [6]struct{}  for i := range whatever {  defer func(i int) {  fmt.Println(i)  }(i)  } } 与第一个案例不同，我们这回把变量 i 传了进去。那么他的输出结果是什么呢？
这段程序的输出结果是：
5 4 3 2 1 0 为什么是 5, 4, 3, 2, 1, 0 呢，为什么不是 0, 1, 2, 3, 4, 5？（难道煎鱼敲错了吗？）
其根本原因在于两点：
 在 for 循环时，局部变量 i 已经传入进 defer func 中 ，属于值传递。其值在 defer语句声明时的时候就已经确定下来了。 结合 defer 关键字的特性，是按先进后出的顺序来执行的。  结合上述，最终输出的结果是 5, 4, 3, 2, 1, 0。
下一个疑问 没过一会，这位小伙伴又有了新的感悟。抛出了新的示例问题，如下：
func f1() (r int) {  defer func() {  r&#43;&#43;  }()  return 2 }  func f2() (r int) {  t := 5  defer func() {  t = t &#43; 5  }()  return t }  func f3() (r int) {  defer func(r int) {  r = r &#43; 5  }(r)  return 1 } 主函数：
func main() {  println(f1())  println(f2())  println(f3()) } 请自己先想一下输出的结果答案是什么。
这段程序的输出结果是：
3 5 1 为什么是 3, 5, 1 呢，而不是 0, 10, 5，又或是其他答案？
</content>
    </entry>
    
     <entry>
        <title>Go 群友提问：Goroutine 数量控制在多少合适，会影响 GC 和调度？</title>
        <url>http://shanks.link/blog/2021/04/16/go-%E7%BE%A4%E5%8F%8B%E6%8F%90%E9%97%AEgoroutine-%E6%95%B0%E9%87%8F%E6%8E%A7%E5%88%B6%E5%9C%A8%E5%A4%9A%E5%B0%91%E5%90%88%E9%80%82%E4%BC%9A%E5%BD%B1%E5%93%8D-gc-%E5%92%8C%E8%B0%83%E5%BA%A6/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 以下内容转载自煎鱼的blog
前几天在读者交流群里看到一位小伙伴，发出了一个致命提问，那就是：“单机的 goroutine 数量控制在多少比较合适？”。
也许你和群内小伙伴第一反应一样，会答复 “控制多少，我觉得没有定论”。
紧接着延伸出了更进一步的疑惑：“goroutine 太多了会影响 gc 和调度吧，主要是怎么预算这个数是合理的呢？”
这是本文要进行探讨的主体，因此本文的结构会是先探索基础知识，再一步步揭开，深入理解这个问题。
Goroutine 是什么 Go 语言作为一个新生编程语言，其令人喜爱的特性之一就是 goroutine。Goroutine 是一个由 Go 运行时管理的轻量级线程，一般称其为 “协程”。
go f(x, y, z) 操作系统本身是无法明确感知到 Goroutine 的存在的，Goroutine 的操作和切换归属于 “用户态” 中。
Goroutine 由特定的调度模式来控制，以 “多路复用” 的形式运行在操作系统为 Go 程序分配的几个系统线程上。
同时创建 Goroutine 的开销很小，初始只需要 2-4k 的栈空间。Goroutine 本身会根据实际使用情况进行自伸缩，非常轻量。
func say(s string) {  for i := 0; i &amp;lt; 9999999; i&#43;&#43; {  time.Sleep(100 * time.Millisecond)  fmt.Println(s)  } }  func main() {  go say(&amp;#34;煎鱼&amp;#34;)  say(&amp;#34;你好&amp;#34;) } 人称可以开几百几千万个的协程小霸王，是 Go 语言的得意之作之一。
调度是什么 既然有了用户态的代表 Goroutine，操作系统又看不到他。必然需要有某个东西去管理他，才能更好的运作起来。
这指的就是 Go 语言中的调度，最常见、面试最爱问的 GMP 模型。因此接下来将会给大家介绍一下 Go 调度的基础知识和流程。
下述内容摘自煎鱼和 p 神写的《Go 语言编程之旅》中的章节内容。
调度基础知识 Go scheduler 的主要功能是针对在处理器上运行的 OS 线程分发可运行的 Goroutine，而我们一提到调度器，就离不开三个经常被提到的缩写，分别是：
 G：Goroutine，实际上我们每次调用 go func 就是生成了一个 G。 P：Processor，处理器，一般 P 的数量就是处理器的核数，可以通过 GOMAXPROCS 进行修改。 M：Machine，系统线程。  这三者交互实际来源于 Go 的 M: N 调度模型。也就是 M 必须与 P 进行绑定，然后不断地在 M 上循环寻找可运行的 G 来执行相应的任务。
调度流程 我们以 GMP 模型的工作流程图进行简单分析，官方图如下:
![img](/img/GoGoroutine 数量控制/1.png)
 当我们执行 go func() 时，实际上就是创建一个全新的 Goroutine，我们称它为 G。 新创建的 G 会被放入 P 的本地队列（Local Queue）或全局队列（Global Queue）中，准备下一步的动作。需要注意的一点，这里的 P 指的是创建 G 的 P。 唤醒或创建 M 以便执行 G。 不断地进行事件循环 寻找在可用状态下的 G 进行执行任务 清除后，重新进入事件循环  在描述中有提到全局和本地这两类队列，其实在功能上来讲都是用于存放正在等待运行的 G，但是不同点在于，本地队列有数量限制，不允许超过 256 个。
并且在新建 G 时，会优先选择 P 的本地队列，如果本地队列满了，则将 P 的本地队列的一半的 G 移动到全局队列。
这可以理解为调度资源的共享和再平衡。
窃取行为 我们可以看到图上有 steal 行为，这是用来做什么的呢，我们都知道当你创建新的 G 或者 G 变成可运行状态时，它会被推送加入到当前 P 的本地队列中。
其实当 P 执行 G 完毕后，它也会 “干活”，它会将其从本地队列中弹出 G，同时会检查当前本地队列是否为空，如果为空会随机的从其他 P 的本地队列中尝试窃取一半可运行的 G 到自己的名下。
官方图如下：
![img](/img/GoGoroutine 数量控制/2.png)
在这个例子中，P2 在本地队列中找不到可以运行的 G，它会执行 work-stealing 调度算法，随机选择其它的处理器 P1，并从 P1 的本地队列中窃取了三个 G 到它自己的本地队列中去。
至此，P1、P2 都拥有了可运行的 G，P1 多余的 G 也不会被浪费，调度资源将会更加平均的在多个处理器中流转。
有没有什么限制 在前面的内容中，我们针对 Go 的调度模型和 Goroutine 做了一个基本介绍和分享。
接下来我们回到主题，思考 “goroutine 太多了，会不会有什么影响”。
在了解 GMP 的基础知识后，我们要知道在协程的运行过程中，真正干活的 GPM 又分别被什么约束？
煎鱼带大家分别从 GMP 来逐步分析。
M 的限制 第一，要知道在协程的执行中，真正干活的是 GPM 中的哪一个？
那势必是 M（系统线程） 了，因为 G 是用户态上的东西，最终执行都是得映射，对应到 M 这一个系统线程上去运行。
那么 M 有没有限制呢？
答案是：有的。在 Go 语言中，M 的默认数量限制是 10000，如果超出则会报错：
GO: runtime: program exceeds 10000-thread limit 通常只有在 Goroutine 出现阻塞操作的情况下，才会遇到这种情况。这可能也预示着你的程序有问题。
若确切是需要那么多，还可以通过 debug.SetMaxThreads 方法进行设置。
G 的限制 第二，那 G 呢，Goroutine 的创建数量是否有限制？
答案是：没有。但理论上会受内存的影响，假设一个 Goroutine 创建需要 4k（via @GoWKH）：
 4k * 80,000 = 320,000k ≈ 0.3G内存 4k * 1,000,000 = 4,000,000k ≈ 4G内存  以此就可以相对计算出来一台单机在通俗情况下，所能够创建 Goroutine 的大概数量级别。
注：Goroutine 创建所需申请的 2-4k 是需要连续的内存块。
P 的限制 第三，那 P 呢，P 的数量是否有限制，受什么影响？
答案是：有限制。P 的数量受环境变量 GOMAXPROCS 的直接影响。
环境变量 GOMAXPROCS 又是什么？在 Go 语言中，通过设置 GOMAXPROCS，用户可以调整调度中 P（Processor）的数量。
另一个重点在于，与 P 相关联的的 M（系统线程），是需要绑定 P 才能进行具体的任务执行的，因此 P 的多少会影响到 Go 程序的运行表现。
P 的数量基本是受本机的核数影响，没必要太过度纠结他。
那 P 的数量是否会影响 Goroutine 的数量创建呢？
答案是：不影响。且 Goroutine 多了少了，P 也该干嘛干嘛，不会带来灾难性问题。
何为之合理 在介绍完 GMP 各自的限制后，我们回到一个重点，就是 “Goroutine 数量怎么预算，才叫合理？”。
“合理” 这个词，是需要看具体场景来定义的，可结合上述对 GPM 的学习和了解。得出：
 M：有限制，默认数量限制是 10000，可调整。 G：没限制，但受内存影响。 P：受本机的核数影响，可大可小，不影响 G 的数量创建。  Goroutine 数量在 MG 的可控限额以下，多个把个、几十个，少几个其实没有什么影响，就可以称其为 “合理”。
真实情况 在真实的应用场景中，没法如此简单的定义。如果你 Goroutine：
 在频繁请求 HTTP，MySQL，打开文件等，那假设短时间内有几十万个协程在跑，那肯定就不大合理了（可能会导致 too many files open）。 常见的 Goroutine 泄露所导致的 CPU、Memory 上涨等，还是得看你的 Goroutine 里具体在跑什么东西。  还是得看 Goroutine 里面跑的是什么东西。
总结 在这篇文章中，分别介绍了 Goroutine、GMP、调度模型的基本知识，针对如下问题进行了展开：
 单机的 goroutine 数量控制在多少比较合适？ goroutine 太多了会影响 gc 和调度吧，主要是怎么预算这个数是合理的呢？  单机的 goroutine 数量只要控制在限额以下的，都可以认为是 “合理”。
真实场景得看具体里面跑的是什么，跑的如果是 “资源怪兽”，只运行几个 Goroutine 都可以跑死。
因此想定义 “预算”，就得看跑的什么了。
</content>
    </entry>
    
     <entry>
        <title>Go 面试题： new 和 make 是什么，差异在哪？</title>
        <url>http://shanks.link/blog/2021/04/16/go-%E9%9D%A2%E8%AF%95%E9%A2%98-new-%E5%92%8C-make-%E6%98%AF%E4%BB%80%E4%B9%88%E5%B7%AE%E5%BC%82%E5%9C%A8%E5%93%AA/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 转载自煎鱼的blog
Go 面试题： new 和 make 是什么，差异在哪？ 在 Go 语言中，有两个比较雷同的内置函数，分别是 new 和 make 方法，其主要用途都是用于分配相应类型的内存空间。
看上去 new 和 make 都是分配内存的，那他们有什么区别呢？这个细节点也成为了不少 Go 语言工程师的面试题之一，值得大家一看。
在这篇文章中我们将来解答这个问题。
基本特性 make 在 Go 语言中，内置函数 make 仅支持 slice、map、channel 三种数据类型的内存创建，其返回值是所创建类型的本身，而不是新的指针引用。
函数签名如下：
func make(t Type, size ...IntegerType) Type 具体使用示例：
func main() {  v1 := make([]int, 1, 5)  v2 := make(map[int]bool, 5)  v3 := make(chan int, 1)   fmt.Println(v1, v2, v3) } 在代码中，我们分别对三种类型调用了 make 函数进行了初始化。你会发现有的入参是有多个长度指定，有的没有。
这块的区别主要是长度（len）和容量（cap）的指定，有的类型是没有容量这一说法，因此自然也就无法指定。
输出结果：
[0] map[] 0xc000044070 有一个细节点要注意，调用 make 函数去初始化切片（slice）的类型时，会带有零值，需要明确是否需要。
见过不少的小伙伴在这上面踩坑。
new 在 Go 语言中，内置函数 new 可以对类型进行内存创建和初始化。其返回值是所创建类型的指针引用，与 make 函数在实质细节上存在区别。
函数签名如下：
func new(Type) *Type 具体使用示例：
type T struct {  Name string }  func main() {  v := new(T)  v.Name = &amp;#34;煎鱼&amp;#34; } 从上面的例子的效果来看，是不是似曾相似？其实与下面这种方式的一样的：
func main() {  v := T{}  v.Name = &amp;#34;煎鱼&amp;#34; } 输出结果均是：
&amp;amp;{Name:煎鱼} 其实 new 函数在日常工程代码中是比较少见的，因为他可被替代。
一般会直接用快捷的 T{} 来进行初始化，因为常规的结构体都会带有结构体的字面属性：
func NewT() *T {  return &amp;amp;T{Name: &amp;#34;煎鱼&amp;#34;} } 这种初始化方式更方便。
区别在哪里 可能会有的小伙伴会疑惑一点，就是 new 函数也能初始化 make 的三种类型：
 v1 := new(chan bool)  v2 := new(map[string]struct{}) 那 make 函数的区别，优势是什么呢？
本质上在于 make 函数在初始化时，会初始化 slice、chan、map 类型的内部数据结构，new 函数并不会。
例如：在 map 类型中，合理的长度（len）和容量（cap）可以提高效率和减少开销。
更进一步的区别：
  make 函数：
   能够分配并初始化类型所需的内存空间和结构，返回引用类型的本身。 具有使用范围的局限性，仅支持 channel、map、slice 三种类型。 具有独特的优势，make 函数会对三种类型的内部数据结构（长度、容量等）赋值。    new 函数：
   能够分配类型所需的内存空间，返回指针引用（指向内存的指针）。 可被替代，能够通过字面值快速初始化。 new出来的map是零值,可读，不可写!    总结 在这篇文章中，我们介绍了 Go 语言中 make 和 new 函数的使用，并针对其区别点进行了分析。
可能会有小伙伴疑惑，那 new 和 make 函数所初始化出来的内存，是分配在堆还是栈上呢？
这就涉及到 Go 语言中的 “逃逸分析” 了（我公众号前几天的文章有发），如果所初始化的变量不需要在当前作用域外生存，那么理论上就不需要初始化在堆上。
</content>
    </entry>
    
     <entry>
        <title>灵魂拷问 Go 语言：这个变量到底分配到哪里了？</title>
        <url>http://shanks.link/blog/2021/04/16/%E7%81%B5%E9%AD%82%E6%8B%B7%E9%97%AE-go-%E8%AF%AD%E8%A8%80%E8%BF%99%E4%B8%AA%E5%8F%98%E9%87%8F%E5%88%B0%E5%BA%95%E5%88%86%E9%85%8D%E5%88%B0%E5%93%AA%E9%87%8C%E4%BA%86/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 以下内容转载自煎鱼的blog
我们在写代码的时候，有时候会想这个变量到底分配到哪里了？这时候可能会有人说，在栈上，在堆上。信我准没错&amp;hellip;
但从结果上来讲你还是一知半解，这可不行，万一被人懵了呢。今天我们一起来深挖下 Go 在这块的奥妙，自己动手丰衣足食！
问题 type User struct {  ID int64  Name string  Avatar string }  func GetUserInfo() *User {  return &amp;amp;User{ID: 13746731, Name: &amp;#34;EDDYCJY&amp;#34;, Avatar: &amp;#34;https://avatars0.githubusercontent.com/u/13746731&amp;#34;} }  func main() {  _ = GetUserInfo() } 开局就是一把问号，带着问题进行学习。请问 main 调用 GetUserInfo 后返回的 &amp;amp;User{...}。这个变量是分配到栈上了呢，还是分配到堆上了？
什么是堆/栈 在这里并不打算详细介绍堆栈，仅简单介绍本文所需的基础知识。如下：
 堆（Heap）：一般来讲是人为手动进行管理，手动申请、分配、释放。一般所涉及的内存大小并不定，一般会存放较大的对象。另外其分配相对慢，涉及到的指令动作也相对多。 栈（Stack）：由编译器进行管理，自动申请、分配、释放。一般不会太大，我们常见的函数参数（不同平台允许存放的数量不同），局部变量等等都会存放在栈上。  今天我们介绍的 Go 语言，它的堆栈分配是通过 Compiler 进行分析，GC 去管理的，而对其的分析选择动作就是今天探讨的重点。
什么是逃逸分析 在编译程序优化理论中，逃逸分析是一种确定指针动态范围的方法，简单来说就是分析在程序的哪些地方可以访问到该指针。
通俗地讲，逃逸分析就是确定一个变量要放堆上还是栈上，规则如下：
 是否有在其他地方（非局部）被引用。只要有可能被引用了，那么它一定分配到堆上。否则分配到栈上。 即使没有被外部引用，但对象过大，无法存放在栈区上。依然有可能分配到堆上。  对此你可以理解为，逃逸分析是编译器用于决定变量分配到堆上还是栈上的一种行为。
在什么阶段确立逃逸 在编译阶段确立逃逸，注意并不是在运行时。
为什么需要逃逸 这个问题我们可以反过来想，如果变量都分配到堆上了会出现什么事情？例如：
 垃圾回收（GC）的压力不断增大。 申请、分配、回收内存的系统开销增大（相对于栈）。 动态分配产生一定量的内存碎片。  简单来说，就是频繁申请并分配堆内存是有一定 “代价” 的。会影响应用程序运行的效率，间接影响到整体系统。
因此 “按需分配” 最大限度的灵活利用资源，才是正确的治理之道。这就是为什么需要逃逸分析的原因，你觉得呢？
怎么确定是否逃逸 第一，通过编译器命令，就可以看到详细的逃逸分析过程。而指令集 -gcflags 用于将标识参数传递给 Go 编译器，涉及如下：
 -m 会打印出逃逸分析的优化策略，实际上最多总共可以用 4 个 -m，但是信息量较大，一般用 1 个就可以了。 -l 会禁用函数内联，在这里禁用掉 inline 能更好的观察逃逸情况，减少干扰。  $ go build -gcflags &amp;#39;-m -l&amp;#39; main.go 第二，通过反编译命令查看
$ go tool compile -S main.go 注：可以通过 go tool compile -help 查看所有允许传递给编译器的标识参数。
逃逸案例 案例一：指针 第一个案例是一开始抛出的问题，现在你再看看，想想，如下：
type User struct {  ID int64  Name string  Avatar string }  func GetUserInfo() *User {  return &amp;amp;User{ID: 13746731, Name: &amp;#34;EDDYCJY&amp;#34;, Avatar: &amp;#34;https://avatars0.githubusercontent.com/u/13746731&amp;#34;} }  func main() {  _ = GetUserInfo() } 执行命令观察一下，如下：
$ go build -gcflags &amp;#39;-m -l&amp;#39; main.go # command-line-arguments ./main.go:10:54: &amp;amp;User literal escapes to heap 通过查看分析结果，可得知 &amp;amp;User 逃到了堆里，也就是分配到堆上了。这是不是有问题啊&amp;hellip;再看看汇编代码确定一下，如下：
$ go tool compile -S main.go &amp;#34;&amp;#34;.GetUserInfo STEXT size=190 args=0x8 locals=0x18  0x0000 00000 (main.go:9) TEXT &amp;#34;&amp;#34;.GetUserInfo(SB), $24-8  ...  0x0028 00040 (main.go:10) MOVQ AX, (SP)  0x002c 00044 (main.go:10) CALL runtime.newobject(SB)  0x0031 00049 (main.go:10) PCDATA $2, $1  0x0031 00049 (main.go:10) MOVQ 8(SP), AX  0x0036 00054 (main.go:10) MOVQ $13746731, (AX)  0x003d 00061 (main.go:10) MOVQ $7, 16(AX)  0x0045 00069 (main.go:10) PCDATA $2, $-2  0x0045 00069 (main.go:10) PCDATA $0, $-2  0x0045 00069 (main.go:10) CMPL runtime.writeBarrier(SB), $0  0x004c 00076 (main.go:10) JNE 156  0x004e 00078 (main.go:10) LEAQ go.string.&amp;#34;EDDYCJY&amp;#34;(SB), CX  ... 我们将目光集中到 CALL 指令，发现其执行了 runtime.newobject 方法，也就是确实是分配到了堆上。这是为什么呢？
分析结果 这是因为 GetUserInfo() 返回的是指针对象，引用被返回到了方法之外了。因此编译器会把该对象分配到堆上，而不是栈上。
否则方法结束之后，局部变量就被回收了，岂不是翻车。所以最终分配到堆上是理所当然的
再想想 那你可能会想，那就是所有指针对象，都应该在堆上？并不。如下：
func main() {  str := new(string)  *str = &amp;#34;EDDYCJY&amp;#34; } 你想想这个对象会分配到哪里？如下：
$ go build -gcflags &amp;#39;-m -l&amp;#39; main.go # command-line-arguments ./main.go:4:12: main new(string) does not escape 显然，该对象分配到栈上了。很核心的一点就是它有没有被作用域之外所引用，而这里作用域仍然保留在 main 中，因此它没有发生逃逸。
案例二：未确定类型 func main() {  str := new(string)  *str = &amp;#34;EDDYCJY&amp;#34;   fmt.Println(str) } 执行命令观察一下，如下：
$ go build -gcflags &amp;#39;-m -l&amp;#39; main.go # command-line-arguments ./main.go:9:13: str escapes to heap ./main.go:6:12: new(string) escapes to heap ./main.go:9:13: main ... argument does not escape 通过查看分析结果，可得知 str 变量逃到了堆上，也就是该对象在堆上分配。但上个案例时它还在栈上，我们也就 fmt 输出了它而已。这&amp;hellip;到底发生了什么事？
分析结果 相对案例一，案例二只加了一行代码 fmt.Println(str)，问题肯定出在它身上。其原型：
func Println(a ...interface{}) (n int, err error) 通过对其分析，可得知当形参为 interface 类型时，在编译阶段编译器无法确定其具体的类型。因此会产生逃逸，最终分配到堆上。
如果你有兴趣追源码的话，可以看下内部的 reflect.TypeOf(arg).Kind() 语句，其会造成堆逃逸，而表象就是 interface 类型会导致该对象分配到堆上。
案例三、泄露参数 type User struct {  ID int64  Name string  Avatar string }  func GetUserInfo(u *User) *User {  return u }  func main() {  _ = GetUserInfo(&amp;amp;User{ID: 13746731, Name: &amp;#34;EDDYCJY&amp;#34;, Avatar: &amp;#34;https://avatars0.githubusercontent.com/u/13746731&amp;#34;}) } 执行命令观察一下，如下：
$ go build -gcflags &amp;#39;-m -l&amp;#39; main.go # command-line-arguments ./main.go:9:18: leaking param: u to result ~r1 level=0 ./main.go:14:63: main &amp;amp;User literal does not escape 我们注意到 leaking param 的表述，它说明了变量 u 是一个泄露参数。结合代码可得知其传给 GetUserInfo 方法后，没有做任何引用之类的涉及变量的动作，直接就把这个变量返回出去了。
因此这个变量实际上并没有逃逸，它的作用域还在 main() 之中，所以分配在栈上。
再想想 那你再想想怎么样才能让它分配到堆上？结合案例一，举一反三。修改如下：
type User struct {  ID int64  Name string  Avatar string }  func GetUserInfo(u User) *User {  return &amp;amp;u }  func main() {  _ = GetUserInfo(User{ID: 13746731, Name: &amp;#34;EDDYCJY&amp;#34;, Avatar: &amp;#34;https://avatars0.githubusercontent.com/u/13746731&amp;#34;}) } 执行命令观察一下，如下：
$ go build -gcflags &amp;#39;-m -l&amp;#39; main.go # command-line-arguments ./main.go:10:9: &amp;amp;u escapes to heap ./main.go:9:18: moved to heap: u 只要一小改，它就考虑会被外部所引用，因此妥妥的分配到堆上了
总结 在本文我给你介绍了逃逸分析的概念和规则，并列举了一些例子加深理解。但实际肯定远远不止这些案例，你需要做到的是掌握方法，遇到再看就好了。除此之外你还需要注意：
 静态分配到栈上，性能一定比动态分配到堆上好。 底层分配到堆，还是栈。实际上对你来说是透明的，不需要过度关心。 每个 Go 版本的逃逸分析都会有所不同（会改变，会优化）。 直接通过 go build -gcflags &#39;-m -l&#39; 就可以看到逃逸分析的过程和结果。 到处都用指针传递并不一定是最好的，要用对。  这块的知识点。我的建议是适当了解，但没必要硬记，因为 Go 语言每次升级都有可能会改。靠基础知识点加命令调试观察就好了。
像是曹大之前讲的 “你琢磨半天逃逸分析，一压测，瓶颈在锁上”，完全没必要过度在意&amp;hellip;
参考  Golang escape analysis FAQ 逃逸分析  </content>
    </entry>
    
     <entry>
        <title>Go1.16 新特性：Go mod 的后悔药，仅需这一招</title>
        <url>http://shanks.link/blog/2021/04/16/go1.16-%E6%96%B0%E7%89%B9%E6%80%A7go-mod-%E7%9A%84%E5%90%8E%E6%82%94%E8%8D%AF%E4%BB%85%E9%9C%80%E8%BF%99%E4%B8%80%E6%8B%9B/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 以下内容转载自煎鱼的blog
前几天 Go 官方正式发布了 1.16 版本。从这个版本起，环境变量 GO111MODULE 的默认值正式修改为 on。
这也意味着 Go modules 将更进一步推进其业务覆盖面，有新老项目共存的小伙伴建议手动将 GO111MODULE 调整为 auto。
Go1.16 针对 Go modules 放出了一个新特性，能够让维护第三方库（需含 Go mod）的开发者拥有反复吃 “后悔药” 的权力，可以提醒使用者已发布的 “脏” 版本存在问题及了解其原因。
这个新特性，对于许多维护和使用公共库（开源、企业等）的小伙伴简直是一个小福音，建议大家都应该要了解这个知识点。
在接下来文章中将进行详细说明和介绍。
后悔药：Go mod retract Go1.16 起可以在 go.mod 文件中使用 retract 指令来声明该第三方模块的某些发行版本不能被其他模块使用。
在使用场景上：在发现严重问题或无意发布某些版本后，模块的维护作者可以撤回该版本，支持撤回单个或多个版本。
以前没有办法解决，因此一旦出现就非常麻烦。对应两者的操作如下：
  维护者：
   删除有问题版本的 tag。 重新打一个新版本的 tag。    使用者：
   发现有问题的版本 tag 丢失，需手动介入。 不知道有问题，由于其他库依赖，因此被动升级而踩坑。    因此在本次 Go1.16 发布后，就拥有了一个半止损的新手段了，也可以作为 Go mod 自动更新的大坑的补全办法之一。
实战演练 为了方便演示，首先创建一个 Demo 项目（github.com/eddycjy/go-retract-demo），其含有一个基础方法：
package go_retract_demo  func HelloWorld() string {  return &amp;#34;001：脑子进煎鱼了！&amp;#34; } 另外有一个应用工程依赖了该第三方库，代码如下：
func main() {  // import demo &amp;#34;github.com/eddycjy/go-retract-demo&amp;#34;  s := demo.HelloWorld()  fmt.Println(s) } 对应的 go.mod 文件如下：
module github.com/eddycjy/awesomeProject  go 1.16  require github.com/eddycjy/go-retract-demo v0.0.1 retract 特性演示 但随着时间不断推移，第三方开源库 eddycjy/go-retract-demo 即将迭代到 v0.3.0 时，发现以往的 v0.2.0 是有 BUG 的。
需要紧急的在v0.3.0 版本把这个 BUG 修复并提醒出去。此时可以在 go.mod 文件中写入 retract 指令：
module github.com/eddycjy/go-retract-demo  go 1.16  // 因为煎鱼不小心敲错了... retract v0.2.0 指令上面为撤回的原因，后面是具体的版本。如果涉及多版本，可以如下编写：
retract (  v0.1.0  v0.2.0 ) retract 特性效果 成功发布最新版本 v0.3.0 版本并指定 retract 后。所有引用了该库的工程应用，执行 go list 就可以看到如下提醒：
$ go1.16 list -m -u all xxx/eddycjy/awesomeProject xxx/eddycjy/go-retract-demo v0.2.0 (retracted) [v0.3.0] 结合该命令，我们日常使用的 IDE（例如：GoLand），其在保存时是会默认执行 go list 命令的。在后续 IDE 支持后，就可以在编码时就快速发现有问题的版本和提示。
在手动执行 go get 时也会出现 warning 提示，会把 go.mod 文件上的原因注释显示出来：
$ go1.16 get github.com/eddycjy/go-retract-demo@v0.2.0 go: warning: github.com/eddycjy/go-retract-demo@v0.2.0: retracted by module author: 因为煎鱼不小心敲错了... go: to switch to the latest unretracted version, run:  go get github.com/eddycjy/go-retract-demo@latest 这样就能看到是哪个模块依赖，因为什么原因要求撤回了，非常直观。
总结 以往在出问题后每个个体需要跑去问维护者或者看 GitHub Commits，那样总归非常麻烦，很可能一来一回半个钟就没了。
新特性给予了 Go modules 软撤回版本的一个方法，能够把问题更直观的反馈到开发者的手中，再结合日常开发工具的话更是美哉。
但这个特性的完全应用目前也是有一定的阻碍的：
 国内模块代理：需要国内的模块代理也支持 retract ，否则即使你更新了版本也没有提示处理（此处是我的模块代理缓存问题）。 IDE：IDE 针对 retract 做一些支持，例如：文字颜色标红、黄等，能够便于开发者更好的识别。  你对 Go modules 的 retract 特性怎么看，欢迎一起留言讨论！
</content>
    </entry>
    
     <entry>
        <title>Go1.16 新特性：详解内存管理机制的变更</title>
        <url>http://shanks.link/blog/2021/04/16/go1.16-%E6%96%B0%E7%89%B9%E6%80%A7%E8%AF%A6%E8%A7%A3%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%9C%BA%E5%88%B6%E7%9A%84%E5%8F%98%E6%9B%B4/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 以下内容转载自煎鱼的blog
在上一篇 Go1.16 特性介绍的文章中我们有提到，从 v1.16 起，Go 在 Linux 下的默认内存管理策略会从MADV_FREE 改回 MADV_DONTNEED 策略。
这时候可能至少分两拨小伙伴，分别是：
 知道是什么，被这个问题 “折磨“ 过的，瞬间眼前一亮。 不知道是什么，出现了各种疑惑了，这说的都是些什么。  灵魂拷问 你有没有以下的疑问，或者是否清楚：
 文中所说的 MADV_FREE 是什么？ 文中所说的 MADV_DONTNEED 是什么？ 为什么特指 Go 语言的 Linux 环境？ 为什么是说从 MADV_FREE改回 MADV_DONTNEED？  在今天这篇文章中我们都将进一步的展开和说明，让我们一同来了解这个改来改去的内存机制到底是何物。
madvise 爱与恨 在 Linux 系统中，在 Go Runtime 中通过系统调用 madvise(addr, length, advise)方法，能够告诉内核如何处理从 addr 开始的 length 字节。
重点之一就是 ”如何处理“，在 Linux 下 Go 语言中目前支持两种策略，分别是（via @felix021）：
 MADV_DONTNEED：内核会在进程的页表中将这些页标记为 “未分配”，从而进程的 RSS 就会尽快释放和变小。OS 后续可以将对应的物理页分配给其他进程。 MADV_FREE：内核只会在页表中将这些进程页面标记为可回收，在需要的时候才回收这些页面。  所带来的影响 Go 语言官方恰好就在 2019 年的 Go1.12 做了如下调整。
 Go1.12 以前。 Go.12-Go1.15.  Go1.12 以前 Go Runtime 在 Linux 上默认使用的是 MADV_DONTNEED 策略。
 // 没有任何奇奇怪怪的判断  madvise(v, n, _MADV_DONTNEED) 从整体效果来看，进程 RSS 可以下降的比较快，但从性能效率上来看差点。
Go1.12-Go1.15 当前 Linux 内核版本 &amp;gt;=4.5 时，Go Runtime 在 Linux 上默认使用了性能更为高效的 MADV_FREE 策略。
 var advise uint32  if debug.madvdontneed != 0 {  advise = _MADV_DONTNEED  } else {  advise = atomic.Load(&amp;amp;adviseUnused)  }  if errno := madvise(v, n, int32(advise)); advise == _MADV_FREE &amp;amp;&amp;amp; errno != 0 {  // MADV_FREE was added in Linux 4.5. Fall back to MADV_DONTNEED if it is  // not supported.  atomic.Store(&amp;amp;adviseUnused, _MADV_DONTNEED)  madvise(v, n, _MADV_DONTNEED)  } 从整体效果来看，进程RSS 不会立刻下降，要等到系统有内存压力了才会释放占用，RSS 才会下降。
带来的副作用 故事往往不是那么的美好，显然在 Go1.12 起针对 madvise 的 MADV_FREE 策略的调整非常 “片面”。
来自社区微信群的小伙伴
结合社区里所遇到的案例可得知，该次调整带来了许多问题：
 引发用户体验的问题：Go issues 上总是出现以为内存泄露，但其实只是未满足条件，内存没有马上释放的案例。 混淆统计信息和监控工具的情况：在 Grafana 等监控上，发现容器进程内存较高，释放很慢，告警了，很慌。 导致与内存使用有关联的个别管理系统集成不良：例如 Kubernetes HPA ，或者自定义了扩缩容策略这类模式，难以评估。 挤压同主机上的其他应用资源：并不是所有的 Go 程序都一定独立跑在单一主机中，自然就会导致同一台主机上的其他应用受到挤压，这是难以评估的。  从社区反馈来看是问题多多，弊大于利。
官方本想着想着性能更好一些，但是在现实场景中引发了不少的新问题，甚至有提到和 Android 流程管理不兼容的情况。
有种 “捡了芝麻，丢了西瓜” 的感觉。
Go1.16：峰回路转 既然社区反馈的问题何其多，有没有人提呢？有，超级多。
多到提出修改回 MADV_DONTNEED 的 issues 仅花了 1-2 天的时间就讨论完毕。
很快得出结论且合并 CL 关闭 issues 了。
Go1.16 修改内容如下：
func parsedebugvars() {  // defaults  debug.cgocheck = 1  debug.invalidptr = 1  if GOOS == &amp;#34;linux&amp;#34; {  debug.madvdontneed = 1  }  ... } 直接指定回了 debug.madvdontneed = 1，简单粗暴。
总结 在本篇文章中，我们针对 Go 语言在 Linux 下的 madvise 方法的策略调整进行了历史介绍和说明，同时针对其调整所带来的的副作用及应对措施进行了一一介绍。
本次变更很好的印证了，牵一发动全身的说法。大家在后续应用这块时也要多加注意。
你觉得 Go1.16 这个特性变更怎么样呢？欢迎在评论区留言。
参考  runtime: default to MADV_DONTNEED on Linux 踩坑记：go 服务内存暴涨 Go 1.12 关于内存释放的一个改进  </content>
    </entry>
    
     <entry>
        <title>Go116新特性Goembed</title>
        <url>http://shanks.link/blog/2021/04/15/go116%E6%96%B0%E7%89%B9%E6%80%A7goembed/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Go1.16 新特性：一文快速上手 Go embed 以下内容转载自煎鱼的blog 大家好，我是正在沉迷学习煎鱼的煎鱼。 在以前，很多从其他语言转过来 Go 语言的同学会问到，或是踩到一个坑。就是以为 Go 语言所打包的二进制文件中会包含配置文件的联同编译和打包。 结果往往一把二进制文件挪来挪去，就无法把应用程序运行起来了。因为无法读取到静态文件的资源。 无法将静态资源编译打包进二进制文件的话，通常会有两种解决方法： 第一种是识别这类静态资源，是否需要跟着程序走。 第二种就是考虑将其打包进二进制文件中。 第二种情况的话，Go 以前是不支持的，大家就会去借助各种花式的开源库，例如：go-bindata/go-bindata 来实现。 但从在 Go1.16 起，Go 语言自身正式支持了该项特性，今天我们将通过这篇文章快速了解和学习这项特性。 基本使用
演示代码：
import _ &amp;#34;embed&amp;#34;  //go:embed hello.txt var s string  func main() {  print(s) } 我们首先在对应的目录下创建了 hello.txt 文件，并且写入文本内容 “吃煎鱼”。 在代码中编写了最为核心的 //go:embed hello.txt 注解。注解的格式很简单，就是 go:embed 指令声明，外加读取的内容的地址，可支持相对和绝对路径。 输出结果： 吃煎鱼 读取到静态文件中的内容后自动赋值给了变量 s，并且在主函数中成功输出。 而针对其他的基础类型，Go embed 也是支持的：
//go:embed hello.txt var s string  //go:embed hello.txt var b []byte  //go:embed hello.txt var f embed.FS  func main() {  print(s)  print(string(b))   data, _ := f.ReadFile(&amp;#34;hello.txt&amp;#34;)  print(string(data)) } 输出结果： 吃煎鱼 吃煎鱼 吃煎鱼 我们同时在一个代码文件中进行了多个 embed 的注解声明。 并且针对 string、slice、byte、fs 等多种类型进行了打包，也不需要过多的处理，非常便利。 拓展用法
除去基本用法完，embed 本身在指令上也支持多种变形：
//go:embed hello1.txt hello2.txt var f embed.FS  func main() {  data1, _ := f.ReadFile(&amp;#34;hello1.txt&amp;#34;)  fmt.Println(string(data1))   data2, _ := f.ReadFile(&amp;#34;hello2.txt&amp;#34;)  fmt.Println(string(data2)) } 在指定 go:embed 注解时可以一次性多个文件来读取，并且也可以一个变量多行注解： //go:embed hello1.txt //go:embed hello2.txt var f embed.FS 也可以通过在注解中指定目录 helloworld，再对应读取文件：
//go:embed helloworld var f embed.FS  func main() {  data1, _ := f.ReadFile(&amp;#34;helloworld/hello1.txt&amp;#34;)  fmt.Println(string(data1))   data2, _ := f.ReadFile(&amp;#34;helloworld/hello2.txt&amp;#34;)  fmt.Println(string(data2)) } 同时既然能够支持目录读取，也能支持贪婪模式的匹配： //go:embed helloworld/* var f embed.FS 可能会有小伙伴注意到，embed.FS 也能调各类文件系统的接口，其实本质是 embed.FS 实现了 io/fs 接口。 只读属性
在 embed 所提供的 FS 中，我们可以发现其都是打开和只读方法： type FS func (f FS) Open(name string) (fs.File, error) func (f FS) ReadDir(name string) ([]fs.DirEntry, error) func (f FS) ReadFile(name string) ([]byte, error) 根据此也可以确定 embed 所打包进二进制文件的内容只允许读取，不允许变更。 更抽象来讲就是在编译期就确定了 embed 的内容，在运行时不允许修改，保证了一致性。 总结
通过 Go1.16 正式提供的 embed 特性，可以实现原生就支持静态资源文件的嵌入。整体如下： 在功能上：能够将静态资源嵌入二进制文件中，在运行时可以打开和读取相关的打包后的静态文件。 在安全上：是在编译期编译嵌入，在运行时不支持修改。 在使用上： 支持单文件读取：go:embed hello.txt。 支持多文件读取：go:embed hello1.txt、go:embed hello2.txt。 支持目录读取：go:embed helloworld。 支持贪婪匹配：go:embed helloworld/*。 总的来讲，Go1.16 embed 特性很好的填补了 Go 语言在打包静态文件资源的一块原生空白领域。同时也说明了 Go 官方的确在不断地吸收社区的一些良好的想法和经验。
</content>
    </entry>
    
     <entry>
        <title>上下文Context</title>
        <url>http://shanks.link/blog/2021/04/15/%E4%B8%8A%E4%B8%8B%E6%96%87context/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 以下内容转载自面向信仰编程
6.1 上下文 Context # 上下文 context.Context Go 语言中用来设置截止日期、同步信号，传递请求相关值的结构体。上下文与 Goroutine 有比较密切的关系，是 Go 语言中独特的设计，在其他编程语言中我们很少见到类似的概念。
context.Context 是 Go 语言在 1.7 版本中引入标准库的接口1，该接口定义了四个需要实现的方法，其中包括：
 Deadline — 返回 context.Context 被取消的时间，也就是完成工作的截止日期； Done — 返回一个 Channel，这个 Channel 会在当前工作完成或者上下文被取消后关闭，多次调用 Done 方法会返回同一个 Channel； Err — 返回 context.Context 结束的原因，它只会在 Done 方法对应的 Channel 关闭时返回非空的值； 如果 context.Context 被取消，会返回 Canceled 错误； 如果 context.Context 超时，会返回 DeadlineExceeded 错误； Value — 从 context.Context 中获取键对应的值，对于同一个上下文来说，多次调用 Value 并传入相同的 Key 会返回相同的结果，该方法可以用来传递请求特定的数据；  type Context interface { 	Deadline() (deadline time.Time, ok bool) 	Done() &amp;lt;-chan struct{} 	Err() error 	Value(key interface{}) interface{} } context 包中提供的 context.Background、context.TODO、context.WithDeadline 和 context.WithValue 函数会返回实现该接口的私有结构体，我们会在后面详细介绍它们的工作原理。
6.1.1 设计原理 # 在 Goroutine 构成的树形结构中对信号进行同步以减少计算资源的浪费是 context.Context 的最大作用。Go 服务的每一个请求都是通过单独的 Goroutine 处理的2，HTTP/RPC 请求的处理器会启动新的 Goroutine 访问数据库和其他服务。
如下图所示，我们可能会创建多个 Goroutine 来处理一次请求，而 context.Context 的作用是在不同 Goroutine 之间同步请求特定数据、取消信号以及处理请求的截止日期。
图 6-1 Context 与 Goroutine 树
每一个 context.Context 都会从最顶层的 Goroutine 一层一层传递到最下层。context.Context 可以在上层 Goroutine 执行出现错误时，将信号及时同步给下层。
图 6-2 不使用 Context 同步信号
如上图所示，当最上层的 Goroutine 因为某些原因执行失败时，下层的 Goroutine 由于没有接收到这个信号所以会继续工作；但是当我们正确地使用 context.Context 时，就可以在下层及时停掉无用的工作以减少额外资源的消耗：
图 6-3 使用 Context 同步信号
我们可以通过一个代码片段了解 context.Context 是如何对信号进行同步的。在这段代码中，我们创建了一个过期时间为 1s 的上下文，并向上下文传入 handle 函数，该方法会使用 500ms 的时间处理传入的请求：
func main() { 	ctx, cancel := context.WithTimeout(context.Background(), 1*time.Second) 	defer cancel()  	go handle(ctx, 500*time.Millisecond) 	select { 	case &amp;lt;-ctx.Done(): 	fmt.Println(&amp;#34;main&amp;#34;, ctx.Err()) 	} }  func handle(ctx context.Context, duration time.Duration) { 	select { 	case &amp;lt;-ctx.Done(): 	fmt.Println(&amp;#34;handle&amp;#34;, ctx.Err()) 	case &amp;lt;-time.After(duration): 	fmt.Println(&amp;#34;process request with&amp;#34;, duration) 	} } 因为过期时间大于处理时间，所以我们有足够的时间处理该请求，运行上述代码会打印出下面的内容：
$ go run context.go process request with 500ms main context deadline exceeded handle 函数没有进入超时的 select 分支，但是 main 函数的 select 却会等待 context.Context 超时并打印出 main context deadline exceeded。
如果我们将处理请求时间增加至 1500ms，整个程序都会因为上下文的过期而被中止，：
$ go run context.go main context deadline exceeded handle context deadline exceeded 相信这两个例子能够帮助各位读者理解 context.Context 的使用方法和设计原理 — 多个 Goroutine 同时订阅 ctx.Done() 管道中的消息，一旦接收到取消信号就立刻停止当前正在执行的工作。
6.1.2 默认上下文  context 包中最常用的方法还是 context.Background、context.TODO，这两个方法都会返回预先初始化好的私有变量 background 和 todo，它们会在同一个 Go 程序中被复用：
func Background() Context { 	return background }  func TODO() Context { 	return todo } 这两个私有变量都是通过 new(emptyCtx) 语句初始化的，它们是指向私有结构体 context.emptyCtx 的指针，这是最简单、最常用的上下文类型：
type emptyCtx int  func (*emptyCtx) Deadline() (deadline time.Time, ok bool) { 	return }  func (*emptyCtx) Done() &amp;lt;-chan struct{} { 	return nil }  func (*emptyCtx) Err() error { 	return nil }  func (*emptyCtx) Value(key interface{}) interface{} { 	return nil } 从上述代码中，我们不难发现 context.emptyCtx 通过空方法实现了 context.Context 接口中的所有方法，它没有任何功能。
图 6-4 Context 层级关系
从源代码来看，context.Background 和 context.TODO 也只是互为别名，没有太大的差别，只是在使用和语义上稍有不同：
context.Background 是上下文的默认值，所有其他的上下文都应该从它衍生出来； context.TODO 应该仅在不确定应该使用哪种上下文时使用； 在多数情况下，如果当前函数没有上下文作为入参，我们都会使用 context.Background 作为起始的上下文向下传递。
6.1.3 取消信号 context.WithCancel 函数能够从 context.Context 中衍生出一个新的子上下文并返回用于取消该上下文的函数。一旦我们执行返回的取消函数，当前上下文以及它的子上下文都会被取消，所有的 Goroutine 都会同步收到这一取消信号。
golang-parent-cancel-context
我们直接从 context.WithCancel 函数的实现来看它到底做了什么：
func WithCancel(parent Context) (ctx Context, cancel CancelFunc) { 	c := newCancelCtx(parent) 	propagateCancel(parent, &amp;amp;c) 	return &amp;amp;c, func() { c.cancel(true, Canceled) } } context.newCancelCtx 将传入的上下文包装成私有结构体 context.cancelCtx； context.propagateCancel 会构建父子上下文之间的关联，当父上下文被取消时，子上下文也会被取消：
func propagateCancel(parent Context, child canceler) { 	done := parent.Done() 	if done == nil { 	return // 父上下文不会触发取消信号 	} 	select { 	case &amp;lt;-done: 	child.cancel(false, parent.Err()) // 父上下文已经被取消 	return 	default: 	}  	if p, ok := parentCancelCtx(parent); ok { 	p.mu.Lock() 	if p.err != nil { 	child.cancel(false, p.err) 	} else { 	p.children[child] = struct{}{} 	} 	p.mu.Unlock() 	} else { 	go func() { 	select { 	case &amp;lt;-parent.Done(): 	child.cancel(false, parent.Err()) 	case &amp;lt;-child.Done(): 	} 	}() 	} } 上述函数总共与父上下文相关的三种不同的情况：
 当 parent.Done() == nil，也就是 parent 不会触发取消事件时，当前函数会直接返回； 当 child 的继承链包含可以取消的上下文时，会判断 parent 是否已经触发了取消信号； 如果已经被取消，child 会立刻被取消； 如果没有被取消，child 会被加入 parent 的 children 列表中，等待 parent 释放取消信号； 当父上下文是开发者自定义的类型、实现了 context.Context 接口并在 Done() 方法中返回了非空的管道时； 运行一个新的 Goroutine 同时监听 parent.Done() 和 child.Done() 两个 Channel； 在 parent.Done() 关闭时调用 child.cancel 取消子上下文； context.propagateCancel 的作用是在 parent 和 child 之间同步取消和结束的信号，保证在 parent 被取消时，child 也会收到对应的信号，不会出现状态不一致的情况。  context.cancelCtx 实现的几个接口方法也没有太多值得分析的地方，该结构体最重要的方法是 context.cancelCtx.cancel，该方法会关闭上下文中的 Channel 并向所有的子上下文同步取消信号：
func (c *cancelCtx) cancel(removeFromParent bool, err error) { 	c.mu.Lock() 	if c.err != nil { 	c.mu.Unlock() 	return 	} 	c.err = err 	if c.done == nil { 	c.done = closedchan 	} else { 	close(c.done) 	} 	for child := range c.children { 	child.cancel(false, err) 	} 	c.children = nil 	c.mu.Unlock()  	if removeFromParent { 	removeChild(c.Context, c) 	} } 除了 context.WithCancel 之外，context 包中的另外两个函数 context.WithDeadline 和 context.WithTimeout 也都能创建可以被取消的计时器上下文 context.timerCtx：
func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) { 	return WithDeadline(parent, time.Now().Add(timeout)) }  func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) { 	if cur, ok := parent.Deadline(); ok &amp;amp;&amp;amp; cur.Before(d) { 	return WithCancel(parent) 	} 	c := &amp;amp;timerCtx{ 	cancelCtx: newCancelCtx(parent), 	deadline: d, 	} 	propagateCancel(parent, c) 	dur := time.Until(d) 	if dur &amp;lt;= 0 { 	c.cancel(true, DeadlineExceeded) // 已经过了截止日期 	return c, func() { c.cancel(false, Canceled) } 	} 	c.mu.Lock() 	defer c.mu.Unlock() 	if c.err == nil { 	c.timer = time.AfterFunc(dur, func() { 	c.cancel(true, DeadlineExceeded) 	}) 	} 	return c, func() { c.cancel(true, Canceled) } } context.WithDeadline 在创建 context.timerCtx 的过程中判断了父上下文的截止日期与当前日期，并通过 time.AfterFunc 创建定时器，当时间超过了截止日期后会调用 context.timerCtx.cancel 同步取消信号。
context.timerCtx 内部不仅通过嵌入 context.cancelCtx 结构体继承了相关的变量和方法，还通过持有的定时器 timer 和截止时间 deadline 实现了定时取消的功能：
type timerCtx struct { 	cancelCtx 	timer *time.Timer // Under cancelCtx.mu.  	deadline time.Time }  func (c *timerCtx) Deadline() (deadline time.Time, ok bool) { 	return c.deadline, true }  func (c *timerCtx) cancel(removeFromParent bool, err error) { 	c.cancelCtx.cancel(false, err) 	if removeFromParent { 	removeChild(c.cancelCtx.Context, c) 	} 	c.mu.Lock() 	if c.timer != nil { 	c.timer.Stop() 	c.timer = nil 	} 	c.mu.Unlock() } context.timerCtx.cancel 方法不仅调用了 context.cancelCtx.cancel，还会停止持有的定时器减少不必要的资源浪费。
6.1.4 传值方法 在最后我们需要了解如何使用上下文传值，context 包中的 context.WithValue 能从父上下文中创建一个子上下文，传值的子上下文使用 context.valueCtx 类型：
func WithValue(parent Context, key, val interface{}) Context { 	if key == nil { 	panic(&amp;#34;nil key&amp;#34;) 	} 	if !reflectlite.TypeOf(key).Comparable() { 	panic(&amp;#34;key is not comparable&amp;#34;) 	} 	return &amp;amp;valueCtx{parent, key, val} } context.valueCtx 结构体会将除了 Value 之外的 Err、Deadline 等方法代理到父上下文中，它只会响应 context.valueCtx.Value 方法，该方法的实现也很简单：
type valueCtx struct { 	Context 	key, val interface{} }  func (c *valueCtx) Value(key interface{}) interface{} { 	if c.key == key { 	return c.val 	} 	return c.Context.Value(key) } 如果 context.valueCtx 中存储的键值对与 context.valueCtx.Value 方法中传入的参数不匹配，就会从父上下文中查找该键对应的值直到某个父上下文中返回 nil 或者查找到对应的值。
6.1.5 小结 Go 语言中的 context.Context 的主要作用还是在多个 Goroutine 组成的树中同步取消信号以减少对资源的消耗和占用，虽然它也有传值的功能，但是这个功能我们还是很少用到。
在真正使用传值的功能时我们也应该非常谨慎，使用 context.Context 进行传递参数请求的所有参数一种非常差的设计，比较常见的使用场景是传递请求对应用户的认证令牌以及用于进行分布式追踪的请求 ID。
6.1.6 延伸阅读 Package context · Golang Go Concurrency Patterns: Context Using context cancellation in Go
</content>
    </entry>
    
     <entry>
        <title>一文吃透 Go 语言解密之上下文 context</title>
        <url>http://shanks.link/blog/2021/04/15/%E4%B8%80%E6%96%87%E5%90%83%E9%80%8F-go-%E8%AF%AD%E8%A8%80%E8%A7%A3%E5%AF%86%E4%B9%8B%E4%B8%8A%E4%B8%8B%E6%96%87-context/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 一文吃透 Go 语言解密之上下文 context 转载自煎鱼的blog
上下文（Context）是 Go 语言中非常有特色的一个特性， 在 Go 1.7 版本中正式引入新标准库 context。
其主要的作用是在 goroutine 中进行上下文的传递，而在传递信息中又包含了 goroutine 的运行控制、上下文信息传递等功能。
为加强大家对 Go 语言的 context 的设计，本文将对标准库 context 进行深入剖析，看看他里面到底暗含了何物，又为何能够做那么多事。
整体的描述结构是：“了解 context 特性，熟悉 context 流程，剖析 context 原理” 三个板块进行。目录如下：
什么是 context Go 语言的独有的功能之一 Context，最常听说开发者说的一句话就是 “函数的第一个形参真的要传 ctx 吗？”，第二句话可能是 “有没有什么办法不传，就能达到传入的效果？”，听起来非常魔幻。
在 Go 语言中 context 作为一个 “一等公民” 的标准库，许多的开源库都一定会对他进行支持，因为标准库 context 的定位是上下文控制。会在跨 goroutine 中进行传播：
本质上 Go 语言是基于 context 来实现和搭建了各类 goroutine 控制的，并且与 select-case联合，就可以实现进行上下文的截止时间、信号控制、信息传递等跨 goroutine 的操作，是 Go 语言协程的重中之重。
context 基本特性 演示代码：
func main() {  parentCtx := context.Background()  ctx, cancel := context.WithTimeout(parentCtx, 1*time.Millisecond)  defer cancel()   select {  case &amp;lt;-time.After(1 * time.Second):  fmt.Println(&amp;#34;overslept&amp;#34;)  case &amp;lt;-ctx.Done():  fmt.Println(ctx.Err())  } } 输出结果：
context deadline exceeded 我们通过调用标准库 context.WithTimeout 方法针对 parentCtx 变量设置了超时时间，并在随后调用 select-case 进行 context.Done 方法的监听，最后由于达到截止时间。因此逻辑上 select 走到了 context.Err 的 case 分支，最终输出 context deadline exceeded。
除了上述所描述的方法外，标准库 context 还支持下述方法：
func WithCancel(parent Context) (ctx Context, cancel CancelFunc) func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) type Context  func Background() Context  func TODO() Context  func WithValue(parent Context, key, val interface{}) Context  WithCancel：基于父级 context，创建一个可以取消的新 context。 WithDeadline：基于父级 context，创建一个具有截止时间（Deadline）的新 context。 WithTimeout：基于父级 context，创建一个具有超时时间（Timeout）的新 context。 Background：创建一个空的 context，一般常用于作为根的父级 context。 TODO：创建一个空的 context，一般用于未确定时的声明使用。 WithValue：基于某个 context 创建并存储对应的上下文信息。  context 本质 我们在基本特性中介绍了不少 context 的方法，其基本大同小异。看上去似乎不难，接下来我们看看其底层的基本原理和设计。
context 相关函数的标准返回如下：
func WithXXXX(parent Context, xxx xxx) (Context, CancelFunc) 其返回值分别是 Context 和 CancelFunc，接下来我们将进行分析这两者的作用。
接口 \1. Context 接口：
type Context interface {  Deadline() (deadline time.Time, ok bool)  Done() &amp;lt;-chan struct{}  Err() error  Value(key interface{}) interface{} }  Deadline：获取当前 context 的截止时间。 Done：获取一个只读的 channel，类型为结构体。可用于识别当前 channel 是否已经被关闭，其原因可能是到期，也可能是被取消了。 Err：获取当前 context 被关闭的原因。 Value：获取当前 context 对应所存储的上下文信息。  \2. Canceler 接口：
type canceler interface {  cancel(removeFromParent bool, err error)  Done() &amp;lt;-chan struct{} }  cancel：调用当前 context 的取消方法。 Done：与前面一致，可用于识别当前 channel 是否已经被关闭。  基础结构 在标准库 context 的设计上，一共提供了四类 context 类型来实现上述接口。分别是 emptyCtx、cancelCtx、timerCtx 以及 valueCtx。
emptyCtx 在日常使用中，常常使用到的 context.Background 方法，又或是 context.TODO 方法。
源码如下：
var (  background = new(emptyCtx)  todo = new(emptyCtx) )  func Background() Context {  return background }  func TODO() Context {  return todo } 其本质上都是基于 emptyCtx 类型的基本封装。而 emptyCtx 类型本质上是实现了 Context 接口：
type emptyCtx int  func (*emptyCtx) Deadline() (deadline time.Time, ok bool) {  return }  func (*emptyCtx) Done() &amp;lt;-chan struct{} {  return nil }  func (*emptyCtx) Err() error {  return nil }  func (*emptyCtx) Value(key interface{}) interface{} {  return nil } 实际上 emptyCtx 类型的 context 的实现非常简单，因为他是空 context 的定义，因此没有 deadline，更没有 timeout，可以认为就是一个基础空白 context 模板。
cancelCtx 在调用 context.WithCancel 方法时，我们会涉及到 cancelCtx 类型，其主要特性是取消事件。源码如下：
func WithCancel(parent Context) (ctx Context, cancel CancelFunc) {  c := newCancelCtx(parent)  propagateCancel(parent, &amp;amp;c)  return &amp;amp;c, func() { c.cancel(true, Canceled) } }  func newCancelCtx(parent Context) cancelCtx {  return cancelCtx{Context: parent} } 其中的 newCancelCtx 方法将会生成出一个可以取消的新 context，如果该 context 执行取消，与其相关联的子 context 以及对应的 goroutine 也会收到取消信息。
首先 main goroutine 创建并传递了一个新的 context 给 goroutine b，此时 goroutine b 的 context 是 main goroutine context 的子集：
传递过程中，goroutine b 再将其 context 一个个传递给了 goroutine c、d、e。最后在运行时 goroutine b 调用了 cancel 方法。使得该 context 以及其对应的子集均接受到取消信号，对应的 goroutine 也进行了响应。
接下来我们针对 cancelCtx 类型来进一步看看：
type cancelCtx struct {  Context   mu sync.Mutex // protects following fields  done chan struct{} // created lazily, closed by first cancel call  children map[canceler]struct{} // set to nil by the first cancel call  err error // set to non-nil by the first cancel call } 该结构体所包含的属性也比较简单，主要是 children 字段，其包含了该 context 对应的所有子集 context，便于在后续发生取消事件的时候进行逐一通知和关联。
而其他的属性主要用于并发控制（互斥锁）、取消信息和错误的写入：
func (c *cancelCtx) Value(key interface{}) interface{} {  if key == &amp;amp;cancelCtxKey {  return c  }  return c.Context.Value(key) }  func (c *cancelCtx) Done() &amp;lt;-chan struct{} {  c.mu.Lock()  if c.done == nil {  c.done = make(chan struct{})  }  d := c.done  c.mu.Unlock()  return d }  func (c *cancelCtx) Err() error {  c.mu.Lock()  err := c.err  c.mu.Unlock()  return err } 在上述代码中可以留意到，done 属性（只读 channel）是在真正调用到 Done 方法时才会去创建。需要配合 select-case 来使用。
timerCtx 在调用 context.WithTimeout 方法时，我们会涉及到 timerCtx 类型，其主要特性是 Timeout 和 Deadline 事件，源码如下：
func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) {  return WithDeadline(parent, time.Now().Add(timeout)) }  func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) {  ...  c := &amp;amp;timerCtx{  cancelCtx: newCancelCtx(parent),  deadline: d,  } } 你可以发现 timerCtx 类型是基于 cancelCtx 类型的。我们再进一步看看 timerCtx 结构体：
type timerCtx struct {  cancelCtx  timer *time.Timer // Under cancelCtx.mu.   deadline time.Time } 其实 timerCtx 类型也就是 cancelCtx 类型，加上 time.Timer 和对应的 Deadline，也就是包含了时间属性的控制。
我们进一步看看其配套的 cancel 方法，思考一下其是如何进行取消动作的：
func (c *timerCtx) Deadline() (deadline time.Time, ok bool) {  return c.deadline, true }  func (c *timerCtx) cancel(removeFromParent bool, err error) {  c.cancelCtx.cancel(false, err)  if removeFromParent {  removeChild(c.cancelCtx.Context, c)  }  c.mu.Lock()  if c.timer != nil {  c.timer.Stop()  c.timer = nil  }  c.mu.Unlock() } 先会调用 cancelCtx 类型的取消事件。若存在父级节点，则移除当前 context 子节点，最后停止定时器并进行定时器重置。而 Deadline 或 Timeout 的行为则由 timerCtx 的 WithDeadline 方法实现：
func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) {  if cur, ok := parent.Deadline(); ok &amp;amp;&amp;amp; cur.Before(d) {  // The current deadline is already sooner than the new one.  return WithCancel(parent)  }  ... } 该方法会先进行前置判断，若父级节点的 Deadline 时间早于当前所指定的 Deadline 时间，将会直接生成一个 cancelCtx 的 context。
func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) {  ...  c := &amp;amp;timerCtx{  cancelCtx: newCancelCtx(parent),  deadline: d,  }  propagateCancel(parent, c)  dur := time.Until(d)  if dur &amp;lt;= 0 {  c.cancel(true, DeadlineExceeded) // deadline has already passed  return c, func() { c.cancel(false, Canceled) }  }  c.mu.Lock()  defer c.mu.Unlock()  if c.err == nil {  c.timer = time.AfterFunc(dur, func() {  c.cancel(true, DeadlineExceeded)  })  }  return c, func() { c.cancel(true, Canceled) } } 接下来将会正式生成成为一个 timeCtx 类型，并将其加入到父级 context 是 children 属性中。最后进行当前时间与 Deadline 时间的计算，并通过调用 time.AfterFunc 在到期后自动调用 cancel 方法发起取消事件，自然也就会触发父子级的事件传播。
valueCtx 在调用 context.WithValue 方法时，我们会涉及到 valueCtx 类型，其主要特性是涉及上下文信息传递，源码如下：
func WithValue(parent Context, key, val interface{}) Context {  ...  if !reflectlite.TypeOf(key).Comparable() {  panic(&amp;#34;key is not comparable&amp;#34;)  }  return &amp;amp;valueCtx{parent, key, val} } 你会发现 valueCtx 结构体也非常的简单，核心就是键值对：
type valueCtx struct {  Context  key, val interface{} } 其在配套方法上也不会太复杂，基本就是要求可比较，接着就是存储匹配：
func (c *valueCtx) Value(key interface{}) interface{} {  if c.key == key {  return c.val  }  return c.Context.Value(key) } 这时候你可能又有疑问了，那多个父子级 context 是如何实现跨 context 的上下文信息获取的？
这秘密其实在上面的 valueCtx 和 Value 方法中有所表现：
本质上 valueCtx 类型是一个单向链表，会在调用 Value 方法时先查询自己的节点是否有该值。若无，则会通过自身存储的上层父级节点的信息一层层向上寻找对应的值，直到找到为止。
而在实际的工程应用中，你会发现各大框架，例如：gin、grpc 等。他都是有自己再实现一套上下文信息的传输的二次封装，本意也是为了更好的管理和观察上下文信息。
context 取消事件 在我们针对 context 的各类延伸类型和源码进行了分析后。我们进一步提出一个疑问点，context 是如何实现跨 goroutine 的取消事件并传播开来的，是如何实现的？
这个问题的答案就在于 WithCancel 和 WithDeadline 都会涉及到 propagateCancel 方法，其作用是构建父子级的上下文的关联关系，若出现取消事件时，就会进行处理：
func propagateCancel(parent Context, child canceler) {  done := parent.Done()  if done == nil {  return  }   select {  case &amp;lt;-done:  child.cancel(false, parent.Err())  return  default:  }  ... }  当父级上下文（parent）的 Done 结果为 nil 时，将会直接返回，因为其不会具备取消事件的基本条件，可能该 context 是 Background、TODO 等方法产生的空白 context。 当父级上下文（parent）的 Done 结果不为 nil 时，则发现父级上下文已经被取消，作为其子级，该 context 将会触发取消事件并返回父级上下文的取消原因。  func propagateCancel(parent Context, child canceler) {  ...  if p, ok := parentCancelCtx(parent); ok {  p.mu.Lock()  if p.err != nil {  child.cancel(false, p.err)  } else {  if p.children == nil {  p.children = make(map[canceler]struct{})  }  p.children[child] = struct{}{}  }  p.mu.Unlock()  } else {  atomic.AddInt32(&amp;amp;goroutines, &#43;1)  go func() {  select {  case &amp;lt;-parent.Done():  child.cancel(false, parent.Err())  case &amp;lt;-child.Done():  }  }()  } } 经过前面一个代码片段的判断，已得知父级 context 未触发取消事件，当前父级和子级 context 均正常（未取消）。
将会执行以下流程：
 调用 parentCancelCtx 方法找到具备取消功能的父级 context。并将当前 context，也就是 child 加入到 父级 context 的 children 列表中，等待后续父级 context 的取消事件通知和响应。 调用 parentCancelCtx 方法没有找到，将会启动一个新的 goroutine 去监听父子 context 的取消事件通知。  通过对 context 的取消事件和整体源码分析，可得知 cancelCtx 类型的上下文包含了其下属的所有子节点信息：
也就是其在 children 属性的 map[canceler]struct{} 存储结构上就已经支持了子级关系的查找，也就自然可以进行取消事件传播了。
而具体的取消事件的实际行为，则是在前面提到的 propagateCancel 方法中，会在执行例如cacenl 方法时，会对父子级上下文分别进行状态判断，若满足则进行取消事件，并传播给子级同步取消。
总结 作为 Go 语言的核心功能之一，其实标准库 context 非常的短小精悍，使用的都是基本的数据结构和理念。既满足了跨 goroutine 的调控控制，像是并发、超时控制等。
同时也满足了上下文的信息传递。在工程应用中，例如像是链路ID、公共参数、鉴权校验等，都会使用到 context 作为媒介。
目前官方对于 context 的建议是作为方法的首参数传入，虽有些麻烦，但也有人选择将其作为结构体中的一个属性传入。但这也会带来一些心智负担，需要识别是否重新 new 一个。
也有人提出希望 Go2 取消掉 context，换成另外一种方法，但总体而言目前未见到正式的提案，这是我们都需要再思考的。
</content>
    </entry>
    
     <entry>
        <title>一文吃透 Go 语言解密之接口 interface</title>
        <url>http://shanks.link/blog/2021/04/15/%E4%B8%80%E6%96%87%E5%90%83%E9%80%8F-go-%E8%AF%AD%E8%A8%80%E8%A7%A3%E5%AF%86%E4%B9%8B%E6%8E%A5%E5%8F%A3-interface/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 一文吃透 Go 语言解密之接口 interface 转载自煎鱼的blog
自古流传着一个传言&amp;hellip;在 Go 语言面试的时候必有人会问接口（interface）的实现原理。这又是为什么？为何对接口如此执着？
实际上，Go 语言的接口设计在整体扮演着非常重要的角色，没有他，很多程序估计都跑的不愉快了。
在 Go 语言的语义上，只要某个类型实现了所定义的一组方法集，则就认为其就是同一种类型，是一个东西。大家常常称其为鸭子类型（Duck typing），因为其与鸭子类型类型的定义相对吻合。
在维基百科中，鸭子类型的谚语定义为 ”If it looks like a duck, swims like a duck, and quacks like a duck, then it probably is a duck.“，翻译过来就是 ”如果它看起来像鸭子，像鸭子一样游泳，像鸭子一样嘎嘎叫，那他就可以认为是鸭子“。
回归到 Go 语言，在接口之下，接口又蕴含了怎么样的底层结构，其设计原理和思考又是什么呢？我们不能只看表面，接下来在这一章节中都会进行一一分析和道来。看看其深层到底是何 “物”。
本文目录：
什么是 interface Go 语言中的接口声明：
type Human interface {  Say(s string) error } 关键字主体为 type xxx interface，紧接着可以在方括号中编写方法集，用于声明和定义该接口所包含的方法集。
更进一步的代码演示：
type Human interface {  Say(s string) error }  type TestA string  func (t TestA) Say(s string) error {  fmt.Printf(&amp;#34;煎鱼：%s\n&amp;#34;, s)  return nil }  func main() {  var h Human  var t TestA  _ = t.Say(&amp;#34;炸鸡翅&amp;#34;)  h = t  _ = h.Say(&amp;#34;烤羊排&amp;#34;) } 输出结果：
煎鱼：炸鸡翅 煎鱼：烤羊排 我们在上述代码中，声明了一个名为 Human 的 interface，其包含一个 Say 方法。同时我们声明了一个 TestA 类型，也有自己的一个 Say 方法。他们两者的方法入参和出参类型均为一样。
而与此同时，我们在主函数 main 中通过声明和赋值，成功将类型为 TestA 的变量 t 赋给了类型为 Human 的变量 h，也就是说两者只因有了个 Say 方法，在 Go 语言的编译器中就认为他们是 “一样” 的了，这也就是业界中常说的鸭子类型。
数据结构 通过上面的功能代码一看，似乎 Go 语言非常优秀。一个接口，不同的类型，2 个包含相同的方法，也能够对标到一起。
接口到底是怎么实现的呢？底层数据结构又是什么？带着问题，我们开始深挖细节之路。
在 Go 语言中，接口的底层数据结构在运行时一共分为两类结构体（struct），分别是：
 runtime.eface 结构体：表示不包含任何方法的空接口，也称为 empty interface。 runtime.iface 结构体：表示包含方法的接口。  runtime.eface 首先我们来介绍 eface，看看 “他” 到底是何许人也。源码如下：
type eface struct {  _type *_type  data unsafe.Pointer } 其表示不包含任何方法的空接口。在结构上来讲 eface 非常简单，就两个属性，分别是 _type 和 data 属性，分别代表底层的指向的类型信息和指向的值信息指针。
再进一步到 type 属性里看看，其包含的类型信息更多：
type _type struct {  size uintptr  ptrdata uintptr  hash uint32  tflag tflag  align uint8  fieldAlign uint8  kind uint8  equal func(unsafe.Pointer, unsafe.Pointer) bool  gcdata *byte  str nameOff  ptrToThis typeOff }  size：类型的大小。 ptrdata：包含所有指针的内存前缀的大小。 hash：类型的 hash 值。此处提前计算好，可以避免在哈希表中计算。 tflag：额外的类型信息标志。此处为类型的 flag 标志，主要用于反射。 align：对应变量与该类型的内存对齐大小。 fieldAlign：对应类型的结构体的内存对齐大小。 kind：类型的枚举值。包含 Go 语言中的所有类型，例如：kindBool、kindInt、kindInt8、kindInt16 等。 equal：用于比较此对象的回调函数。 gcdata：存储垃圾收集器的 GC 类型数据。  总结一句，就是类型信息所需的信息都会存储在这里面，其中包含字节大小、类型标志、内存对齐、GC 等相关属性。而在 eface 来讲，其由于没有方法集的包袱，因此只需要存储类型和值信息的指针即可，非常简单。
runtime.iface 其次就是我们日常在应用程序中应用的较多的 iface，源码如下：
type iface struct {  tab *itab  data unsafe.Pointer } 与 eface 结构体类型一样，主要也是分为类型和值信息，分别对应 tab 和 data 属性。但是我们再加思考一下，为什么 iface 能藏住那么多的方法集呢，难道施了黑魔法？
为了解密，我们进一步深入看看 itab 结构体。源码如下：
type itab struct {  inter *interfacetype  _type *_type  hash uint32  _ [4]byte  fun [1]uintptr }  inter：接口的类型信息。 _type：具体类型信息 hash：_type.hash 的副本，用于目标类型和接口变量的类型对比判断。 fun：底层数组，存储接口的方法集的具体实现的地址，其包含一组函数指针，实现了接口方法的动态分派，且每次在接口发生变更时都会更新。  对应 func 属性会在后面的章节进一步展开讲解，便于大家对于接口中的函数指针管理的使用和理解，在此可以先行思考长度为 1 的 uintptr 数组是如何做到存储多方法的？
接下来我们进一步展开 interfacetype 结构体。源码如下：
type nameOff int32 type typeOff int32  type imethod struct {  name nameOff  ityp typeOff }  type interfacetype struct {  typ _type  pkgpath name  mhdr []imethod }  _type：接口的具体类型信息。 pkgpath：接口的包（package）名信息。 mhdr：接口所定义的函数列表。  而相对应 interfacetype，还有各种类型的 type。例如：maptype、arraytype、chantype、slicetype 等，都是针对具体的类型做的具体类型定义：
type arraytype struct {  typ _type  elem *_type  slice *_type  len uintptr }  type chantype struct {  typ _type  elem *_type  dir uintptr } ... 若有兴趣自行翻看 runtime 里相应源码即可，都是一些基本数据结构信息的存储和配套方法，就不在此一一展开讲解了。
小结 总结来讲，接口的数据结构基本表示形式比较简单，就是类型和值描述。再根据其具体的区别，例如是否包含方法集，具体的接口类型等进行组合使用。
值接收者和指针接收者 在接口的具体应用使用场景中，有一个是大家常常会碰到，甚至会对其产生较大纠结心里的东西。那就是到底用值接收者，又或是用指针接收者来声明。
演示说明 演示代码如下：
type Human interface {  Say(s string) error  Eat(s string) error }  type TestA struct{}  func (t TestA) Say(s string) error {  fmt.Printf(&amp;#34;说煎鱼：%s\n&amp;#34;, s)  return nil }  func (t *TestA) Eat(s string) error {  fmt.Printf(&amp;#34;吃煎鱼：%s\n&amp;#34;, s)  return nil }  func main() {  var h Human = &amp;amp;TestA{}  _ = h.Say(&amp;#34;催更&amp;#34;)  _ = h.Eat(&amp;#34;真香&amp;#34;) } 在 Human 接口中，其包含 Say 和 Eat 方法，并且在 TestA 结构体中我们进行了针对性的实现。
具体的区别就是：
 在 Say 方法中是值接收对象，如：(t TestA)。 在 Eat 方法中是指针接收对象，如：(t *TestA)。  最终的输出结果：
说煎鱼：催更 吃煎鱼：真香 值和指针 如果我们将演示代码的主函数 main 改成下述这样：
func main() {  var h Human = TestA{}  _ = h.Say(&amp;#34;催更&amp;#34;)  _ = h.Eat(&amp;#34;真香&amp;#34;) } 你觉得这段代码还能正常运行吗？在编译时会出现如下报错信息：
# command-line-arguments ./main.go:23:6: cannot use TestA literal (type TestA) as type Human in assignment:  TestA does not implement Human (Eat method has pointer receiver) 显然是不能的。因为接口校验不对，编译器过不了。其根本原因在于 Eat 是指针接收者。而当声明改为 TestA{} 后，其就会变成值对象，所以不匹配。
这时候又会出现新的问题，为什么在上面代码声明为 &amp;amp;TestA{} 时，那肯定是指针引用了，那为什么 Say 方法又能正常运行，不会报错呢？
其实 TestA{} 实现了 Say 方法，那么 &amp;amp;TestA{} 也能自动拥有该方法。显然，这是 Go 语言自身在背后做了一些事情。
因此如果我们实现了一个值对象的接收者时，也会相应拥有了一个指针接收者。两者并不会互相影响，因为值对象会产生值拷贝，对象会独立开来。
而指针对象的接收者不行，因为指针引用的对象，在应用上是期望能够直接对源接收者的值进行修改，若又支持值接收者，显然是不符合其语义的。
两者怎么用 既然支持值接收，又支持指针接收。那平时在工程应用开发中，到底用谁？还是说随便用？
其实问题的答案，在前面就有提到。本质上还是要看你业务逻辑所期望修改的是什么？还是说程序很严谨，每次都重新 new 一个，是值又或是指针引用对于程序逻辑的结果都没有任何的影响。
总结一下，如果你想使用指针接收者，可以想想是否有以下诉求：
 期望接收者直接修改能够直接修改源值。 期望在大结构体的情况下，性能更好，可以在理论上避免每次值拷贝，但也会有增加别的开销，需要具体情况具体权衡。  但若应用场景没什么区别，只是个人习惯问题就不用过于纠结了，适度统一也是很重要的一环。
类型断言 在 Go 语言中使用接口，必搭配一个 “技能”。那就是进行类型断言（type assertion）：
var i interface{} = &amp;#34;吃煎鱼&amp;#34;  // 进行变量断言，若不判断容易出现 panic s := i.(string)  // 进行安全断言 s, ok := i.(string) 在 switch case 中，还有另外一种写法：
var i interface{} = &amp;#34;炸煎鱼&amp;#34;  // 进行 switch 断言 switch i.(type) { case string:  // do something... case int:  // do something... case float64:  // do something... } 采取的是 (变量).(type) 的调用方式，再给予 case 不同的类型进行判断识别。在 Go 语言的背后，类型断言其实是在编译器翻译后，根据 iface 和 eface 分别对应了下述方法：
func assertI2I2(inter *interfacetype, i iface) (r iface, b bool) {  tab := i.tab  if tab == nil {  return  }  if tab.inter != inter {  tab = getitab(inter, tab._type, true)  if tab == nil {  return  }  }  r.tab = tab  r.data = i.data  b = true  return } func assertI2I(inter *interfacetype, i iface) (r iface)  func assertE2I2(inter *interfacetype, e eface) (r iface, b bool) func assertE2I(inter *interfacetype, e eface) (r iface) 主要是根据接口的类型信息进行一轮判断和识别，基本就完成了。主要核心在于 getitab 方法，会在后面进行统一介绍和说明。
类型转换 演示代码如下：
func main() {  x := &amp;#34;煎鱼&amp;#34;  var v interface{} = x  fmt.Println(v) } 查看汇编代码：
 0x0021 00033 (main.go:9) LEAQ go.string.&amp;#34;煎鱼&amp;#34;(SB), AX  0x0028 00040 (main.go:9) MOVQ AX, (SP)  0x002c 00044 (main.go:9) MOVQ $6, 8(SP)  0x0035 00053 (main.go:9) PCDATA $1, $0  0x0035 00053 (main.go:9) CALL runtime.convTstring(SB)  0x003a 00058 (main.go:9) MOVQ 16(SP), AX  0x003f 00063 (main.go:10) XORPS X0, X0 主要对应了 runtime.convTstring 方法。同时很显然其是根据类型来区分来方法：
func convTstring(val string) (x unsafe.Pointer) {  if val == &amp;#34;&amp;#34; {  x = unsafe.Pointer(&amp;amp;zeroVal[0])  } else {  x = mallocgc(unsafe.Sizeof(val), stringType, true)  *(*string)(x) = val  }  return }  func convT16(val uint16) (x unsafe.Pointer) func convT32(val uint32) (x unsafe.Pointer) func convT64(val uint64) (x unsafe.Pointer) func convTstring(val string) (x unsafe.Pointer) func convTslice(val []byte) (x unsafe.Pointer) func convT2Enoptr(t *_type, elem unsafe.Pointer) (e eface) func convT2I(tab *itab, elem unsafe.Pointer) (i iface) ... 动态分派 前面有提到接口中的 fun [1]uintptr 属性会可以存储接口的方法集，但不知道为什么。
接下来我们将进行具体的分析，演示代码：
type Human interface {  Say(s string) error  Eat(s string) error  Walk(s string) error }  type TestA string  func (t TestA) Say(s string) error {  fmt.Printf(&amp;#34;煎鱼：%s\n&amp;#34;, s)  return nil } func (t TestA) Eat(s string) error {  fmt.Printf(&amp;#34;煎鱼：%s\n&amp;#34;, s)  return nil }  func (t TestA) Walk(s string) error {  fmt.Printf(&amp;#34;煎鱼：%s\n&amp;#34;, s)  return nil }  func main() {  var h Human  var t TestA  h = t  _ = h.Eat(&amp;#34;烤羊排&amp;#34;)  _ = h.Say(&amp;#34;炸鸡翅&amp;#34;)  _ = h.Walk(&amp;#34;去炸鸡翅&amp;#34;) } 存储方式 执行 go build -gcflags &#39;-l&#39; -o awesomeProject . 编译后，再次执行 go tool objdump -s &amp;quot;main&amp;quot; awesomeProject。
查看具体的汇编代码：
 LEAQ go.itab.main.TestA,main.Human(SB), AX  TESTB AL, 0(AX)  MOVQ 0x10(SP), AX  MOVQ AX, 0x28(SP)  MOVQ go.itab.main.TestA,main.Human&#43;32(SB), CX  MOVQ AX, 0(SP)  LEAQ go.string.*&#43;3048(SB), DX  MOVQ DX, 0x8(SP)  MOVQ $0x9, 0x10(SP)  CALL CX  MOVQ go.itab.main.TestA,main.Human&#43;24(SB), AX  MOVQ 0x28(SP), CX  MOVQ CX, 0(SP)  LEAQ go.string.*&#43;3057(SB), DX  MOVQ DX, 0x8(SP)  MOVQ $0x9, 0x10(SP)  CALL AX  MOVQ go.itab.main.TestA,main.Human&#43;40(SB), AX  MOVQ 0x28(SP), CX  MOVQ CX, 0(SP)  LEAQ go.string.*&#43;4973(SB), CX  MOVQ CX, 0x8(SP)  MOVQ $0xc, 0x10(SP)  CALL AX 结合来看，虽然 fun 属性的类型是 [1]uintptr，只有一个元素，但其实就是存放了接口方法集的首个方法的地址信息,接着根据顺序往后计算并获取就好了。也就是说其是存在一定规律的。在存入方法时就决定了，所以获取也能明确。
我们进一步展开，看看 itab hash table 是如何获取和新增的。
获取 itab 元素 getitab 方法的主要作用是获取 itab 元素，若不存在则新增。源码如下：
func getitab(inter *interfacetype, typ *_type, canfail bool) *itab {  // 省略一些边界、异常处理  var m *itab   t := (*itabTableType)(atomic.Loadp(unsafe.Pointer(&amp;amp;itabTable)))  if m = t.find(inter, typ); m != nil {  goto finish  }   lock(&amp;amp;itabLock)  if m = itabTable.find(inter, typ); m != nil {  unlock(&amp;amp;itabLock)  goto finish  }   m = (*itab)(persistentalloc(unsafe.Sizeof(itab{})&#43;uintptr(len(inter.mhdr)-1)*sys.PtrSize, 0, &amp;amp;memstats.other_sys))  m.inter = inter  m._type = typ  m.hash = 0  m.init()  itabAdd(m)  unlock(&amp;amp;itabLock) finish:  if m.fun[0] != 0 {  return m  }   panic(&amp;amp;TypeAssertionError{concrete: typ, asserted: &amp;amp;inter.typ, missingMethod: m.init()}) }   调用 atomic.Loadp 方法加载并查找现有的 itab hash table，看看是否是否可以找到所需的 itab 元素。
  若没有找到，则调用 lock 方法对 itabLock 上锁，并进行重试（再一次查找）。
   若找到，则跳到 finish 标识的收尾步骤。 若没有找到，则新生成一个 itab 元素，并调用 itabAdd 方法新增到全局的 hash table 中。    返回 fun 属性的首位地址，继续后续业务逻辑。
  新增 itab 元素 itabAdd 方法的主要作用是将所生成好的 itab 元素新增到 itab hash table 中。源码如下：
func itabAdd(m *itab) {  // 省略一些边界、异常处理  t := itabTable  if t.count &amp;gt;= 3*(t.size/4) { // 75% load factor  t2 := (*itabTableType)(mallocgc((2&#43;2*t.size)*sys.PtrSize, nil, true))  t2.size = t.size * 2  iterate_itabs(t2.add)  if t2.count != t.count {  throw(&amp;#34;mismatched count during itab table copy&amp;#34;)  }   atomicstorep(unsafe.Pointer(&amp;amp;itabTable), unsafe.Pointer(t2))  t = itabTable  }  t.add(m) }  检查 itab hash table 的容量情况，查看容量情况是否已经满足大于或等于 75%。 若满足扩容策略，则调用 mallocgc 方法申请内存，按既有 size 大小扩容双倍容量。 若不满足扩容策略，则直接新增 itab 元素到 hash table 中。  总结 在本文中，我们先介绍了 Go 语言接口的 runtime.eface 和 runtime.iface 两个基本数据结构，其代表了一切的开端。
随后针对值接受者和指针接收者进行了详细的说明，同时日常用的较多的类型断言和转换也一一进行了描述。
最后对接口的多方法这个神秘的地方进行了基本分析和了解，相信这一番轮流吸收下来，能够打开大家对接口的一个新的理解。
</content>
    </entry>
    
     <entry>
        <title>一文带你解密 Go 语言之通道 channel</title>
        <url>http://shanks.link/blog/2021/04/15/%E4%B8%80%E6%96%87%E5%B8%A6%E4%BD%A0%E8%A7%A3%E5%AF%86-go-%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%80%9A%E9%81%93-channel/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 转载自煎鱼的blog
今天这篇文章主要是针对 Go channel 的重点分析，一开始写的时候以为范围不会太大，但洋洋洒洒还是写破了万字，成为了一篇覆盖面较广和有一定深度的长文分析。
Go 语言中的一大利器那就是能够非常方便的使用 go 关键字来进行各种并发，而并发后又必然会涉及通信。
Channel 自然而然就成为了 Go 语言开发者中必须要明白明了的一个 “东西” 了，更别提实际工程应用和日常面试了，属于必知必会。
本文目录：
什么是 channel 在 Go 语言中，channel 可以称其为通道，也可以叫管道。channel 主要常见于与 goroutine&#43;select 搭配使用，再结合语录的描述。可以知道 channel 就是用于 goroutine 的数据通信：
演示代码如下：
func main() {  ch := make(chan string)  go func() {  ch &amp;lt;- &amp;#34;煎鱼&amp;#34;  }()   msg := &amp;lt;-ch  fmt.Println(msg) } 在 goroutine1 中写入 “煎鱼” 到变量 ch 中，goroutine2 监听变量 ch，并阻塞等待读取到值 “煎鱼” 最终返回，结束流程。
在此 channel 承载着一个衔接器的桥梁：
这也是 channel 的经典思想了，不要通过共享内存来通信，而是通过通信来实现内存共享（Do not communicate by sharing memory; instead, share memory by communicating）。
从模式上来看，其就是在多个 goroutine 借助 channel 来传输数据，实现了跨 goroutine 间的数据传输，多者独立运行，不需要强关联，更不影响对方的 goroutine 状态。不存在 goroutine1 对 goroutine2 进行直传的情况。
这里思考一个问题，那 goroutine1 和 goroutine2 又怎么互相知道自己的数据 ”到“ 了呢？
channel 基本特性 在 Go 语言中，channel 的关键字为 chan，数据流向的表现方式为 &amp;lt;-，代码解释方向是从左到右，据此就能明白通道的数据流转方向了。
channel 共有两种模式，分别是：双向和单向；三种表现方式，分别是：声明双向通道：chan T、声明只允许发送的通道：chan &amp;lt;- T、声明只允许接收的通道：&amp;lt;- chan T。
channel 中还分为 “无缓冲 channel” 和 “缓冲 channel”。
演示代码如下：
// 无缓冲 ch1 := make(chan int)  // 缓冲区为 3 ch2 := make(chan int, 3) 接下来我们进一步展开这两类来看。
无缓冲 channel 无缓冲的 channel（unbuffered channel），其缓冲区大小则默认为 0。在功能上其接受者会阻塞等待并阻塞应用程序，直至收到通信和接收到数据。
这种常用于两个 goroutine 间互相同步等待的应用场景：
缓冲 channel 有缓存的 channel（buffered channel），其缓存区大小是根据所设置的值来调整。在功能上，若缓冲区未满则不会阻塞，会源源不断的进行传输。当缓冲区满了后，发送者就会阻塞并等待。而当缓冲区为空时，接受者就会阻塞并等待，直至有新的数据：
在实际的应用场景中，两者根据业务情况选用就可以了，不需要太过纠结于两者是否有性能差距，没意义。
channel 本质 channel 听起来实现了一个非常酷的东西，也是日常工作中常常会被面试官问到的问题。
但其实 channel 并没有那么的 &amp;ldquo;神秘&amp;rdquo;，就是一个环形队列的配合。
接下来我们一步步的剖开 channel，看看里面到底是什么，怎么实现的跨 goroutine 通信，数据结构又是什么，两者又如何实现数据传输的？
基本原理 本质上 channel 在设计上就是环形队列。其包含发送方队列、接收方队列，加上互斥锁 mutex 等结构。
channel 是一个有锁的环形队列：
数据结构 hchan 结构体是 channel 在运行时的具体表现形式：
// src/runtime/chan.go type hchan struct {  qcount uint  dataqsiz uint  buf unsafe.Pointer  elemsize uint16  closed uint32  elemtype *_type  sendx uint  recvx uint  recvq waitq  sendq waitq   lock mutex }  qcount：队列中的元素总数量。 dataqsiz：循环队列的长度。 buf：指向长度为 dataqsiz 的底层数组，仅有当 channel 为缓冲型的才有意义。 elemsize：能够接受和发送的元素大小。 closed：是否关闭。 elemtype：能够接受和发送的元素类型。 sendx：已发送元素在循环队列中的索引位置。 recvx：已接收元素在循环队列中的索引位置。 recvq：接受者的 sudog 等待队列（缓冲区不足时阻塞等待的 goroutine）。 sendq：发送者的 sudog 等待队列。  在数据结构中，我们可以看到 recvq 和 sendq，其表现为等待队列，其类型为 runtime.waitq 的双向链表结构：
type waitq struct {  first *sudog  last *sudog } 且无论是 first 属性又或是 last，其类型都为 runtime.sudog 结构体：
type sudog struct {  g *g   next *sudog  prev *sudog  elem unsafe.Pointer  ... }  g：指向当前的 goroutine。 next：指向下一个 g。 prev：指向上一个 g。 elem：数据元素，可能会指向堆栈。  sudog 是 Go 语言中用于存放协程状态为阻塞的 goroutine 的双向链表抽象，你可以直接理解为一个正在等待的 goroutine 就可以了。
在后续的实现原理分析中，基本围绕着上述数据结构进行大量的讨论，建议可以认真思考一下。
channel 实现原理 在了解了 channel 的基本原理后，我们进入到与应用工程中更紧密相关的部分，那就是 channel 的四大块操作，分别是：“创建、发送、接收、关闭”。
我们将针对这四块进行细致的分析和讲解。因此接下来的内容比较庞大，内容上将分为两个角度来讲述，分别是先从源码角度进行分析，再进行图示汇总。以便于大家更好的理解和思考
创建 chan 创建 channel 的演示代码：
ch := make(chan string) 其在编译器翻译后对应 runtime.makechan 或 runtime.makechan64 方法：
// 通用创建方法 func makechan(t *chantype, size int) *hchan  // 类型为 int64 的进行特殊处理 func makechan64(t *chantype, size int64) *hchan 通过前面我们得知 channel 的基本单位是 hchan 结构体，那么在创建 channel 时，究竟还需要做什么是呢？
我们一起分析一下 makechan 方法，就能知道了。
源码如下：
// src/runtime/chan.go func makechan(t *chantype, size int) *hchan {  elem := t.elem  mem, _ := math.MulUintptr(elem.size, uintptr(size))   var c *hchan  switch {  case mem == 0:  c = (*hchan)(mallocgc(hchanSize, nil, true))  c.buf = c.raceaddr()  case elem.ptrdata == 0:  c = (*hchan)(mallocgc(hchanSize&#43;mem, nil, true))  c.buf = add(unsafe.Pointer(c), hchanSize)  default:  c = new(hchan)  c.buf = mallocgc(mem, elem, true)  }   c.elemsize = uint16(elem.size)  c.elemtype = elem  c.dataqsiz = uint(size)  lockInit(&amp;amp;c.lock, lockRankHchan)   return c } 创建 channel 的逻辑主要分为三大块：
 当前 channel 不存在缓冲区，也就是元素大小为 0 的情况下，就会调用 mallocgc 方法分配一段连续的内存空间。 当前 channel 存储的类型存在指针引用，就会连同 hchan 和底层数组同时分配一段连续的内存空间。 通用情况，默认分配相匹配的连续内存空间。  需要注意到一块特殊点，那就是 channel 的创建都是调用的 mallocgc 方法，也就是 channel 都是创建在堆上的。因此 channel 是会被 GC 回收的，自然也不总是需要 close 方法来进行显示关闭了。
从整体上来讲，makechan 方法的逻辑比较简单，就是创建 hchan 并分配合适的 buf 大小的堆上内存空间。
发送数据 channel 发送数据的演示代码：
go func() {  ch &amp;lt;- &amp;#34;煎鱼&amp;#34; }() 其在编译器翻译后对应 runtime.chansend1 方法：
func chansend1(c *hchan, elem unsafe.Pointer) {  chansend(c, elem, true, getcallerpc()) } 其作为编译后的入口方法，实则指向真正的实现逻辑，也就是 chansend 方法。
前置处理 在第一部分中，我们先看看 chan 发送的一些前置判断和处理：
func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool {  if c == nil {  if !block {  return false  }  gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2)  throw(&amp;#34;unreachable&amp;#34;)  }   if !block &amp;amp;&amp;amp; c.closed == 0 &amp;amp;&amp;amp; full(c) {  return false  }   // 省略一些调试相关  ... }  func full(c *hchan) bool {  if c.dataqsiz == 0 {  return c.recvq.first == nil  }   return c.qcount == c.dataqsiz } 一开始 chansend 方法在会先判断当前的 channel 是否为 nil。若为 nil，在逻辑上来讲就是向 nil channel 发送数据，就会调用 gopark 方法使得当前 Goroutine 休眠，进而出现死锁崩溃，表象就是出现 panic 事件来快速失败。
紧接着会对非阻塞的 channel 进行一个上限判断，看看是否快速失败。
失败的场景如下：
 若非阻塞且未关闭，同时底层数据 dataqsiz 大小为 0（缓冲区无元素），则会返回失败。。 若是 qcount 与 dataqsiz 大小相同（缓冲区已满）时，则会返回失败。  上互斥锁 在完成了 channel 的前置判断后，即将在进入发送数据的处理前，channel 会进行上锁：
func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool {  ...  lock(&amp;amp;c.lock) } 上锁后就能保住并发安全。另外我们也可以考虑到，这种场景会相对依赖单元测试的覆盖，因为一旦没考虑周全，漏上锁了，基本就会出问题。
直接发送 在正式开始发送前，加锁之后，会对 channel 进行一次状态判断（是否关闭）：
func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool {  ...  if c.closed != 0 {  unlock(&amp;amp;c.lock)  panic(plainError(&amp;#34;send on closed channel&amp;#34;))  }   if sg := c.recvq.dequeue(); sg != nil {  send(c, sg, ep, func() { unlock(&amp;amp;c.lock) }, 3)  return true  } } 这种情况是最为基础的，也就是当前 channel 有正在阻塞等待的接收方，那么只需要直接发送就可以了。
缓冲发送 非直接发送，那么就考虑第二种场景，判断 channel 缓冲区中是否还有空间：
func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool {  ...  if c.qcount &amp;lt; c.dataqsiz {  qp := chanbuf(c, c.sendx)  typedmemmove(c.elemtype, qp, ep)  c.sendx&#43;&#43;  if c.sendx == c.dataqsiz {  c.sendx = 0  }  c.qcount&#43;&#43;  unlock(&amp;amp;c.lock)  return true  }   if !block {  unlock(&amp;amp;c.lock)  return false  } } 会对缓冲区进行判定（qcount 和 dataqsiz 字段），以此识别缓冲区的剩余空间。紧接进行如下操作：
 调用 chanbuf 方法，以此获得底层缓冲数据中位于 sendx 索引的元素指针值。 调用 typedmemmove 方法，将所需发送的数据拷贝到缓冲区中。 数据拷贝后，对 sendx 索引自行自增 1。同时若 sendx 与 dataqsiz 大小一致，则归 0（环形队列）。 自增完成后，队列总数同时自增 1。解锁互斥锁，返回结果。  至此针对缓冲区的数据操作完成。但若没有走进缓冲区处理的逻辑，则会判断当前是否阻塞 channel，若为非阻塞，将会解锁并直接返回失败。
配合图示如下：
阻塞发送 在进行了各式各样的层层筛选后，接下来进入阻塞等待发送的过程：
func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool {  ...  gp := getg()  mysg := acquireSudog()  mysg.releasetime = 0  if t0 != 0 {  mysg.releasetime = -1  }   mysg.elem = ep  mysg.waitlink = nil  mysg.g = gp  mysg.isSelect = false  mysg.c = c  gp.waiting = mysg  gp.param = nil  c.sendq.enqueue(mysg)   atomic.Store8(&amp;amp;gp.parkingOnChan, 1)  gopark(chanparkcommit, unsafe.Pointer(&amp;amp;c.lock), waitReasonChanSend, traceEvGoBlockSend, 2)   KeepAlive(ep) }  调用 getg 方法获取当前 goroutine 的指针，用于后续发送数据。 调用 acquireSudog 方法获取 sudog 结构体，并设置当前 sudog 具体的待发送数据信息和状态。 调用 c.sendq.enqueue 方法将刚刚所获取的 sudog 加入待发送的等待队列。 调用 gopark 方法挂起当前 goroutine（会记录执行位置），状态为 waitReasonChanSend，阻塞等待 channel。 调用 KeepAlive 方法保证待发送的数据值是活跃状态，也就是分配在堆上，避免被 GC 回收。  配合图示如下：
在当前 goroutine 被挂起后，其将会在 channel 能够发送数据后被唤醒：
func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool {  ...  // 从这里开始唤醒，并恢复阻塞的发送操作  if mysg != gp.waiting {  throw(&amp;#34;G waiting list is corrupted&amp;#34;)  }  gp.waiting = nil  gp.activeStackChans = false  if gp.param == nil {  if c.closed == 0 {  throw(&amp;#34;chansend: spurious wakeup&amp;#34;)  }  panic(plainError(&amp;#34;send on closed channel&amp;#34;))  }  gp.param = nil  if mysg.releasetime &amp;gt; 0 {  blockevent(mysg.releasetime-t0, 2)  }  mysg.c = nil  releaseSudog(mysg)  return true } 唤醒 goroutine（调度器在停止 g 时会记录运行线程和方法内执行的位置）并完成 channel 的阻塞数据发送动作后。进行基本的参数检查，确保是符合要求的（纵深防御），接着开始取消 mysg 上的 channel 绑定和 sudog 的释放。
至此完成所有类别的 channel 数据发送管理。
接收数据 channel 接受数据的演示代码：
msg := &amp;lt;-ch  msg, ok := &amp;lt;-ch 两种方法在编译器翻译后分别对应 runtime.chanrecv1 和 runtime.chanrecv2 两个入口方法，其再在内部再进一步调用 runtime.chanrecv 方法：
需要注意，发送和接受 channel 是相对的，也就是其核心实现也是相对的。因此在理解时也可以结合来看。
前置处理 func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) {  if c == nil {  if !block {  return  }  gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2)  throw(&amp;#34;unreachable&amp;#34;)  } 一开始时 chanrecv 方法会判断其是否为 nil channel。
场景如下：
 若 channel 是 nil channel，且为阻塞接收则调用 gopark 方法挂起当前 goroutine。 若 channel 是非阻塞模式，则直接返回。  而接下来对于非阻塞模式的 channel 会进行快速失败检查，检测 channel 是否已经准备好接收。
 if !block &amp;amp;&amp;amp; empty(c) {  if atomic.Load(&amp;amp;c.closed) == 0 {  return  }   if empty(c) {  if ep != nil {  typedmemclr(c.elemtype, ep)  }  return true, false  }  }  ... } 其分以下几种情况：
 无缓冲区：循环队列为 0 及等待队列 sendq 内没有 goroutine 正在等待。 有缓冲区：缓冲区数组为空。  随后会对 channel 的 closed 状态进行判断，因为 channel 是无法重复打开的，需要确定当前 channel 是否为未关闭状态。再确定接收失败，返回。
但若是 channel 已经关闭且不存在缓存数据了，则会清理 ep 指针中的数据并返回。
直接接收 当发现 channel 上有正在阻塞等待的发送方时，则直接进行接收：
func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) {   lock(&amp;amp;c.lock)   if sg := c.sendq.dequeue(); sg != nil {  recv(c, sg, ep, func() { unlock(&amp;amp;c.lock) }, 3)  return true, true  }  ... } 缓冲接收 当发现 channel 的缓冲区中有元素时：
func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) {   if c.qcount &amp;gt; 0 {  qp := chanbuf(c, c.recvx)  if ep != nil {  typedmemmove(c.elemtype, ep, qp)  }  typedmemclr(c.elemtype, qp)  c.recvx&#43;&#43;  if c.recvx == c.dataqsiz {  c.recvx = 0  }  c.qcount--  unlock(&amp;amp;c.lock)  return true, true  }   if !block {  unlock(&amp;amp;c.lock)  return false, false  }  ... } 将会调用 chanbuf 方法根据 recvx 的索引位置取出数据，找到要接收的元素进行处理。若所接收到的数据和所传入的变量均不为空，则会调用 typedmemmove 方法将缓冲区中的数据拷贝到所传入的变量中。
最后数据拷贝完毕后，进行各索引项和队列总数的自增增减，并调用 typedmemclr 方法进行内存数据的清扫。
阻塞接收 当发现 channel 上既没有待发送的 goroutine，缓冲区也没有数据时。将会进入到最后一个阶段阻塞接收：
func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) {   gp := getg()  mysg := acquireSudog()  mysg.releasetime = 0  if t0 != 0 {  mysg.releasetime = -1  }   mysg.elem = ep  mysg.waitlink = nil  gp.waiting = mysg  mysg.g = gp  mysg.isSelect = false  mysg.c = c  gp.param = nil  c.recvq.enqueue(mysg)   atomic.Store8(&amp;amp;gp.parkingOnChan, 1)  gopark(chanparkcommit, unsafe.Pointer(&amp;amp;c.lock), waitReasonChanReceive, traceEvGoBlockRecv, 2)  ... } 这一块接收逻辑与发送也基本类似，主体就是获取当前 goroutine，构建 sudog 结构保存当前待接收数据（发送方）的地址信息，并将 sudog 加入等待接收队列。最后调用 gopark 方法挂起当前 goroutine，等待唤醒。
func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) {   // 被唤醒后从此处开始  if mysg != gp.waiting {  throw(&amp;#34;G waiting list is corrupted&amp;#34;)  }  gp.waiting = nil  gp.activeStackChans = false  if mysg.releasetime &amp;gt; 0 {  blockevent(mysg.releasetime-t0, 2)  }  closed := gp.param == nil  gp.param = nil  mysg.c = nil  releaseSudog(mysg)  return true, !closed } 被唤醒后，将恢复现场，回到对应的执行点，完成最后的扫尾工作。
关闭 chan 关闭 channel 主要是涉及到 close 关键字：
close(ch) 其对应的编译器翻译方法为 closechan 方法：
func closechan(c *hchan) 前置处理 func closechan(c *hchan) {  if c == nil {  panic(plainError(&amp;#34;close of nil channel&amp;#34;))  }   lock(&amp;amp;c.lock)  if c.closed != 0 {  unlock(&amp;amp;c.lock)  panic(plainError(&amp;#34;close of closed channel&amp;#34;))  }   c.closed = 1  ... } 基本检查和关闭标志设置，保证 channel 不为 nil 和未关闭，保证边界。
释放接收方 在完成了异常边界判断和标志设置后，会将接受者的 sudog 等待队列（recvq）加入到待清除队列 glist 中：
func closechan(c *hchan) {   var glist gList  for {  sg := c.recvq.dequeue()  if sg == nil {  break  }  if sg.elem != nil {  typedmemclr(c.elemtype, sg.elem)  sg.elem = nil  }  if sg.releasetime != 0 {  sg.releasetime = cputicks()  }  gp := sg.g  gp.param = nil  if raceenabled {  raceacquireg(gp, c.raceaddr())  }  glist.push(gp)  }  ... } 所取出并加入的 goroutine 状态需要均为 _Gwaiting，以保证后续的新一轮调度。
释放发送方 同样，与释放接收方一样。会将发送方也加入到到待清除队列 glist 中：
func closechan(c *hchan) {   // release all writers (they will panic)  for {  sg := c.sendq.dequeue()  if sg == nil {  break  }  sg.elem = nil  if sg.releasetime != 0 {  sg.releasetime = cputicks()  }  gp := sg.g  gp.param = nil  if raceenabled {  raceacquireg(gp, c.raceaddr())  }  glist.push(gp)  }  unlock(&amp;amp;c.lock)  ... } 协程调度 将所有 glist 中的 goroutine 状态从 _Gwaiting 设置为 _Grunnable 状态，等待调度器的调度：
func closechan(c *hchan) {   // Ready all Gs now that we&amp;#39;ve dropped the channel lock.  for !glist.empty() {  gp := glist.pop()  gp.schedlink = 0  goready(gp, 3)  } } 后续所有的 goroutine 允许被重新调度后。若原本还在被动阻塞的发送方或接收方，将重获自由，后续该干嘛就去干嘛了，再跑回其所属的应用流程。
channel send/recv 分析 send send 方法承担向 channel 发送具体数据的功能：
func send(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) {  if sg.elem != nil {  sendDirect(c.elemtype, sg, ep)  sg.elem = nil  }  gp := sg.g  unlockf()  gp.param = unsafe.Pointer(sg)  if sg.releasetime != 0 {  sg.releasetime = cputicks()  }  goready(gp, skip&#43;1) }  func sendDirect(t *_type, sg *sudog, src unsafe.Pointer) {  dst := sg.elem  typeBitsBulkBarrier(t, uintptr(dst), uintptr(src), t.size)  memmove(dst, src, t.size) }   调用 sendDirect 方法将待发送的数据直接拷贝到待接收变量的内存地址（执行栈）。
   例如：msg := &amp;lt;-ch 语句，也就是将数据从 ch 直接拷贝到了 msg 的内存地址。    调用 sg.g 属性， 从 sudog 中获取等待接收数据的 goroutine，并传递后续唤醒所需的参数。
  调用 goready 方法唤醒需接收数据的 goroutine，期望从 _Gwaiting 状态调度为 _Grunnable。
  recv recv 方法承担在 channel 中接收具体数据的功能：
func recv(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) {  if c.dataqsiz == 0 {  if ep != nil {  recvDirect(c.elemtype, sg, ep)  }  } else {  qp := chanbuf(c, c.recvx)  if ep != nil {  typedmemmove(c.elemtype, ep, qp)  }  typedmemmove(c.elemtype, qp, sg.elem)  c.recvx&#43;&#43;  if c.recvx == c.dataqsiz {  c.recvx = 0  }  c.sendx = c.recvx // c.sendx = (c.sendx&#43;1) % c.dataqsiz  }  sg.elem = nil  gp := sg.g  unlockf()  gp.param = unsafe.Pointer(sg)  if sg.releasetime != 0 {  sg.releasetime = cputicks()  }  goready(gp, skip&#43;1) } 该方法在接受上分为两种情况，分别是直接接收和缓冲接收：
  直接接收（不存在缓冲区）：
   调用 recvDirect 方法，其作用与 sendDirect 方法相对，会直接从发送方的 goroutine 调用栈中将数据拷贝过来到接收方的 goroutine。    缓冲接收（存在缓冲区）：
   调用 chanbuf 方法，根据 recvx 索引的位置读取缓冲区元素，并将其拷贝到接收方的内存地址。 拷贝完毕后，对 sendx 和 recvx 索引位置进行调整。    最后还是常规的 goroutine 调度动作，会调用 goready 方法来唤醒当前所处理的 sudog 的对应 goroutine。那么在下一轮调度时，既然已经接收了数据，自然发送方也就会被唤醒。
总结 在本文中我们针对 Go 语言的 channel 进行了基本概念的分析和讲解，同时还针对 channel 的设计原理和四大操作（创建、发送、接收、关闭）进行了源码分析和图示分析。
初步看过一遍后，再翻看。不难发现，Go 的 channel 设计并不复杂，记住他的数据结构就是带缓存的环形队列，再加上对称的 sendq、recvq 等双向链表的辅助属性，就能勾画出 channel 的基本逻辑流转模型。
在具体的数据传输上，都是围绕着 “边界上下限处理，上互斥锁，阻塞/非阻塞，缓冲/非缓冲，缓存出队列，拷贝数据，解互斥锁，协程调度” 在不断地流转处理。在基本逻辑上也是相对重合的，因为发送和接收，创建和关闭总是相对的。
如果更进一步深入探讨，还可以围绕着 CSP 模型、goroutine 调度等进一步的思考和理解。这一块会在后续的章节中再一步展开。
</content>
    </entry>
    
     <entry>
        <title>解密 Go 语言之反射 reflect</title>
        <url>http://shanks.link/blog/2021/04/15/%E8%A7%A3%E5%AF%86-go-%E8%AF%AD%E8%A8%80%E4%B9%8B%E5%8F%8D%E5%B0%84-reflect/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 解密 Go 语言之反射 reflect 转载自煎鱼的blog
大家好，我是煎鱼。今天是 2020 年的最后一天，让我们一起继续愉快的学习吧 ：）。
在所有的语言中，反射这一功能基本属于必不可少的模块。
虽说 “反射” 这个词让人根深蒂固，但更多的还是 WHY。反射到底是什么，反射又是基于什么法则实现的？
今天我们通过这篇文章来一一揭晓，以 Go 语言为例，了解反射到底为何物，其底层又是如何实现的。
反射是什么 在计算机学中，反射是指计算机程序在运行时（runtime）可以访问、检测和修改它本身状态或行为的一种能力。
用比喻来说，反射就是程序在运行的时候能够 “观察” 并且修改自己的行为（来自维基百科）。
简单来讲就是，应用程序能够在运行时观察到变量的值，并且能够修改他。
一个例子 最常见的 reflect 标准库例子，如下：
import (  &amp;#34;fmt&amp;#34;  &amp;#34;reflect&amp;#34; )  func main() {  rv := []interface{}{&amp;#34;hi&amp;#34;, 42, func() {}}  for _, v := range rv {  switch v := reflect.ValueOf(v); v.Kind() {  case reflect.String:  fmt.Println(v.String())  case reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:  fmt.Println(v.Int())  default:  fmt.Printf(&amp;#34;unhandled kind %s&amp;#34;, v.Kind())  }  } } 输出结果：
hi 42 unhandled kind func 在程序中主要是声明了 rv 变量，变量类型为 interface{}，其包含 3 个不同类型的值，分别是字符串、数字、闭包。
而在使用 interface{} 时常见于不知道入参者具体的基本类型是什么，那么我们就会用 interface{} 类型来做一个伪 “泛型”。
此时又会引出一个新的问题，既然入参是 interface{}，那么出参时呢？
Go 语言是强类型语言，入参是 interface{}，出参也肯定是跑不了的，因此必然离不开类型的判断，这时候就要用到反射，也就是 reflect 标准库。反射过后又再进行 (type) 的类型断言。
这就是我们在编写程序时最常遇见的一个反射使用场景。
Go reflect reflect 标准库中，最核心的莫过于 reflect.Type 和 reflect.Value 类型。而在反射中所使用的方法都围绕着这两者进行，其方法主要含义如下：
 TypeOf 方法：用于提取入参值的类型信息。 ValueOf 方法：用于提取存储的变量的值信息。  reflect.TypeOf 演示程序：
func main() {  blog := Blog{&amp;#34;煎鱼&amp;#34;}  typeof := reflect.TypeOf(blog)  fmt.Println(typeof.String()) } 输出结果：
main.Blog 从输出结果中，可得出 reflect.TypeOf 成功解析出 blog 变量的类型是 main.Blog，也就是连 package 都知道了。
通过人识别的角度来看似乎很正常，但程序就不是这样了。他是怎么知道 “他” 是哪个 package 下的什么呢？
我们一起追一下源码看看：
func TypeOf(i interface{}) Type {  eface := *(*emptyInterface)(unsafe.Pointer(&amp;amp;i))  return toType(eface.typ) } 从源码层面来看，TypeOf 方法中主要涉及三块操作，分别如下：
 使用 unsafe.Pointer 方法获取任意类型且可寻址的指针值。 利用 emptyInterface 类型进行强制的 interface 类型转换。 调用 toType 方法转换为可供外部使用的 Type 类型。  而这之中信息量最大的是 emptyInterface 结构体中的 rtype 类型：
type rtype struct {  size uintptr  ptrdata uintptr  hash uint32  tflag tflag  align uint8  fieldAlign uint8  kind uint8  equal func(unsafe.Pointer, unsafe.Pointer) bool  gcdata *byte  str nameOff  ptrToThis typeOff } 在使用上最重要的是 rtype 类型，其实现了 Type 类型的所有接口方法，因此他可以直接作为 Type 类型返回。
而 Type 本质上是一个接口实现，其包含了获取一个类型所必要的所有方法：
type Type interface {  // 适用于所有类型  // 返回该类型内存对齐后所占用的字节数  Align() int   // 仅作用于 strcut 类型  // 返回该类型内存对齐后所占用的字节数  FieldAlign() int   // 返回该类型的方法集中的第 i 个方法  Method(int) Method   // 根据方法名获取对应方法集中的方法  MethodByName(string) (Method, bool)   // 返回该类型的方法集中导出的方法的数量。  NumMethod() int   // 返回该类型的名称  Name() string  ... } 建议大致过一遍，了解清楚有哪些方法，再针对向看就好。
主体思想是给自己大脑建立一个索引，便于后续快速到 pkg.go.dev 上查询即可。
reflect.ValueOf 演示程序：
func main() {  var x float64 = 3.4  fmt.Println(&amp;#34;value:&amp;#34;, reflect.ValueOf(x)) } 输出结果：
value: 3.4 从输出结果中，可得知通过 reflect.ValueOf 成功获取到了变量 x 的值为 3.4。与 reflect.TypeOf 形成一个相匹配，一个负责获取类型，一个负责获取值。
那么 reflect.ValueOf 是怎么获取到值的呢，核心源码如下：
func ValueOf(i interface{}) Value {  if i == nil {  return Value{}  }   escapes(i)   return unpackEface(i) }  func unpackEface(i interface{}) Value {  e := (*emptyInterface)(unsafe.Pointer(&amp;amp;i))  t := e.typ  if t == nil {  return Value{}  }  f := flag(t.Kind())  if ifaceIndir(t) {  f |= flagIndir  }  return Value{t, e.word, f} } 从源码层面来看，ValueOf 方法中主要涉及如下几个操作：
 调用 escapes 让变量 i 逃逸到堆上。 将变量 i 强制转换为 emptyInterface 类型。 将所需的信息（其中包含值的具体类型和指针）组装成 reflect.Value 类型后返回。  何时类型转换 在调用 reflect 进行一系列反射行为时，Go 又是在什么时候进行的类型转换呢？
毕竟我们传入的是 float64，而函数如参数是 inetrface 类型。
查看汇编如下:
$ go tool compile -S main.go  ...  0x0058 00088 ($GOROOT/src/reflect/value.go:2817) LEAQ type.float64(SB), CX  0x005f 00095 ($GOROOT/src/reflect/value.go:2817) MOVQ CX, reflect.dummy&#43;8(SB)  0x0066 00102 ($GOROOT/src/reflect/value.go:2817) PCDATA $0, $-2  0x0066 00102 ($GOROOT/src/reflect/value.go:2817) CMPL runtime.writeBarrier(SB), $0  0x006d 00109 ($GOROOT/src/reflect/value.go:2817) JNE 357  0x0073 00115 ($GOROOT/src/reflect/value.go:2817) MOVQ AX, reflect.dummy&#43;16(SB)  0x007a 00122 ($GOROOT/src/reflect/value.go:2348) PCDATA $0, $-1  0x007a 00122 ($GOROOT/src/reflect/value.go:2348) MOVQ CX, reflect.i&#43;64(SP)  0x007f 00127 ($GOROOT/src/reflect/value.go:2348) MOVQ AX, reflect.i&#43;72(SP)  ... 显然，Go 语言会在编译阶段就会完成分析，且进行类型转换。这样子 reflect 真正所使用的就是 interface 类型了。
reflect.Set 演示程序：
func main() {  i := 2.33  v := reflect.ValueOf(&amp;amp;i)  v.Elem().SetFloat(6.66)  log.Println(&amp;#34;value: &amp;#34;, i) } 输出结果：
value: 6.66 从输出结果中，我们可得知在调用 reflect.ValueOf 方法后，我们利用 SetFloat 方法进行了值变更。
核心的方法之一就是 Setter 相关的方法，我们可以一起看看其源码是怎么实现的：
func (v Value) Set(x Value) {  v.mustBeAssignable()  x.mustBeExported() // do not let unexported x leak  var target unsafe.Pointer  if v.kind() == Interface {  target = v.ptr  }  x = x.assignTo(&amp;#34;reflect.Set&amp;#34;, v.typ, target)  if x.flag&amp;amp;flagIndir != 0 {  typedmemmove(v.typ, v.ptr, x.ptr)  } else {  *(*unsafe.Pointer)(v.ptr) = x.ptr  } }  检查反射对象及其字段是否可以被设置。 检查反射对象及其字段是否导出（对外公开）。 调用 assignTo 方法创建一个新的反射对象并对原本的反射对象进行覆盖。 根据 assignTo 方法所返回的指针值，对当前反射对象的指针进行值的修改。  简单来讲就是，检查是否可以设置，接着创建一个新的对象，最后对其修改。是一个非常标准的赋值流程。
反射三大定律 Go 语言中的反射，其归根究底都是在实现三大定律：
 Reflection goes from interface value to reflection object. Reflection goes from reflection object to interface value. To modify a reflection object, the value must be settable.  我们将针对这核心的三大定律进行介绍和说明，以此来理解 Go 反射里的各种方法是基于什么理念实现的。
第一定律 反射的第一定律是：“反射可以从接口值（interface）得到反射对象”。
示例代码：
func main() {  var x float64 = 3.4  fmt.Println(&amp;#34;type:&amp;#34;, reflect.TypeOf(x)) } 输出结果：
type: float64 可能有读者就迷糊了，我明明在代码中传入的变量 x，他的类型是 float64。怎么就成从接口值得到反射对象了。
其实不然，虽然在代码中我们所传入的变量基本类型是 float64，但是 reflect.TypeOf 方法入参是 interface{}，本质上 Go 语言内部对其是做了类型转换的。这一块会在后面会进一步展开说明。
第二定律 反射的第二定律是：“可以从反射对象得到接口值（interface）”。其与第一条定律是相反的定律，可以是互相补充了。
示例代码：
func main() {  vo := reflect.ValueOf(3.4)  vf := vo.Interface().(float64)  log.Println(&amp;#34;value:&amp;#34;, vf) } 输出结果：
value: 3.4 可以看到在示例代码中，变量 vo 已经是反射对象，然后我们可以利用其所提供的的 Interface 方法获取到接口值（interface），并最后强制转换回我们原始的变量类型。
第三定律 反射的第三定律是：“要修改反射对象，该值必须可以修改”。第三条定律看上去与第一、第二条均无直接关联，但却是必不可少的，因为反射在工程实践中，目的一就是可以获取到值和类型，其二就是要能够修改他的值。
否则反射出来只能看，不能动，就会造成这个反射很鸡肋。例如：应用程序中的配置热更新，必然会涉及配置项相关的变量变动，大多会使用到反射来变动初始值。
示例代码：
func main() {  i := 2.33  v := reflect.ValueOf(&amp;amp;i)  v.Elem().SetFloat(6.66)  log.Println(&amp;#34;value: &amp;#34;, i) } 输出结果：
value: 6.66 单从结果来看，变量 i 的值确实从 2.33 变成了 6.66，似乎非常完美。
但是单看代码，似乎有些 “问题”，怎么设置一个反射值这么 ”麻烦“：
 为什么必须传入变量 i 的指针引用？ 为什么变量 v 在设置前还需要 Elem 一下？  本叛逆的 Gophper 表示我就不这么设置，行不行呢，会不会出现什么问题：
func main() {  i := 2.33  reflect.ValueOf(i).SetFloat(6.66)  log.Println(&amp;#34;value: &amp;#34;, i) } 报错信息：
panic: reflect: reflect.Value.SetFloat using unaddressable value  goroutine 1 [running]: reflect.flag.mustBeAssignableSlow(0x8e)  /usr/local/Cellar/go/1.15/libexec/src/reflect/value.go:259 &#43;0x138 reflect.flag.mustBeAssignable(...)  /usr/local/Cellar/go/1.15/libexec/src/reflect/value.go:246 reflect.Value.SetFloat(0x10b2980, 0xc00001a0b0, 0x8e, 0x401aa3d70a3d70a4)  /usr/local/Cellar/go/1.15/libexec/src/reflect/value.go:1609 &#43;0x37 main.main()  /Users/eddycjy/go-application/awesomeProject/main.go:10 &#43;0xc5 根据上述提示可知，由于使用 “使用不可寻址的值”，因此示例程序无法正常的运作下去。并且这是一个 reflect 标准库本身就加以防范了的硬性要求。
这么做的原因在于，Go 语言的函数调用的传递都是值拷贝的，因此若不传指针引用，单纯值传递，那么肯定是无法变动反射对象的源值的。因此 Go 标准库就对其进行了逻辑判断，避免出现问题。
因此期望变更反射对象的源值时，我们必须主动传入对应变量的指针引用，并且调用 reflect 标准库的 Elem 方法来获取指针所指向的源变量，并且最后调用 Set 相关方法来进行设置。
总结 通过本文我们学习并了解了 Go 反射是如何使用，又是基于什么定律设计的。另外我们稍加关注，不难发现 Go 的反射都是基于接口（interface）来实现的，更进一步来讲，Go 语言中运行时的功能很多都是基于接口来实现的。
整体来讲，Go 反射是围绕着三者进行的，分别是 Type、Value 以及 Interface，三者相辅相成，而反射本质上与 Interface 存在直接关系，Interface 这一块的内容我们也将在后续的文章进行进一步的剖析。
欢迎持续关注。
</content>
    </entry>
    
     <entry>
        <title>干货满满的 Go Modules 知识分享</title>
        <url>http://shanks.link/blog/2021/04/14/%E5%B9%B2%E8%B4%A7%E6%BB%A1%E6%BB%A1%E7%9A%84-go-modules-%E7%9F%A5%E8%AF%86%E5%88%86%E4%BA%AB/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 转载自煎鱼的blog
大家好，我是煎鱼。
马上 2021 年了，Go 也即将在明年发布 Go1.16。但 Go Modules 仍然是大家关注的话题之一。早期汇总过傲飞分享的 《Go Modules、Go Module Proxy 和 goproxy.cn》。
今天正式在自己公众号分享出来，希望对大家的学习有所帮助。
前言 Go 1.11 推出的模块（Modules）为 Go 语言开发者打开了一扇新的大门，理想化的依赖管理解决方案使得 Go 语言朝着计算机编程史上的第一个依赖乌托邦（Deptopia）迈进。
随着模块一起推出的还有模块代理协议（Module proxy protocol），通过这个协议我们可以实现 Go 模块代理（Go module proxy），也就是依赖镜像。
Go 1.13 的发布为模块带来了大量的改进，所以模块的扶正就是这次 Go 1.13 发布中开发者能直接感觉到的最大变化。
目录   Go Modules 简介
  快速迁移项目至 Go Modules
  使用 Go Modules 时常遇见的坑
   坑 1:判断项目是否启用了 Go Modules 坑 2:管理 Go 的环境变量 坑 3:从 dep、glide 等迁移至 Go Modules 坑 4:拉取私有模块 坑 5:更新现有的模块 坑 6:主版本号    Go Module Proxy 简介
  Goproxy 中国(goproxy.cn)
  Go Modules 简介 Go modules (前身 vgo) 是 Go team (Russ Cox) 强推的一个理想化的类语言级依赖管理解决方案，它是和 Go1.11 一同发布的，在 Go1.13 做了大量的优化和调整，目前已经变得比较不错，如果你想用 Go modules，但还停留在 1.11/1.12 版本的话，强烈建议升级。
三个关键字 强推 首先这并不是乱说的，因为 Go modules 确实是被强推出来的，如下：
 之前：大家都知道在 Go modules 之前还有一个叫 dep 的项目，它也是 Go 的一个官方的实验性项目，目的同样也是为了解决 Go 在依赖管理方面的短板。在 Russ Cox 还没有提出 Go modules 的时候，社区里面几乎所有的人都认为 dep 肯定就是未来 Go 官方的依赖管理解决方案了。 后来：谁都没想到半路杀出个程咬金，Russ Cox 义无反顾地推出了 Go modules，这瞬间导致一石激起千层浪，让社区炸了锅。大家一致认为 Go team 实在是太霸道、太独裁了，连个招呼都不打一声。我记得当时有很多人在网上跟 Russ Cox 口水战，各种依赖管理解决方案的专家都冒出来发表意见，讨论范围甚至一度超出了 Go 语言的圈子触及到了其他语言的领域。  理想化 从他强制要求使用语义化版本控制这一点来说就很理想化了，如下：
 Go modules 狠到如果你的 Tag 没有遵循语义化版本控制那么它就会忽略你的 Tag，然后根据你的 Commit 时间和哈希值再为你生成一个假定的符合语义化版本控制的版本号。 Go modules 还默认认为，只要你的主版本号不变，那这个模块版本肯定就不包含 Breaking changes，因为语义化版本控制就是这么规定的啊。是不是很理想化。  类语言级： 这个关键词其实是我自己瞎编的，我只是单纯地个人认为 Go modules 在设计上就像个语言级特性一样，比如如果你的主版本号发生变更，那么你的代码里的 import path 也得跟着变，它认为主版本号不同的两个模块版本是完全不同的两个模块。此外，Go moduels 在设计上跟 go 整个命令都结合得相当紧密，无处不在，所以我才说它是一个有点儿像语言级的特性，虽然不是太严谨。
推 Go Modules 的人是谁 那么在上文中提到的 Russ Cox 何许人也呢，很多人应该都知道他，他是 Go 这个项目目前代码提交量最多的人，甚至是第二名的两倍还要多。
Russ Cox 还是 Go 现在的掌舵人（大家应该知道之前 Go 的掌舵人是 Rob Pike，但是听说由于他本人不喜欢特朗普执政所以离开了美国，然后他岁数也挺大的了，所以也正在逐渐交权，不过现在还是在参与 Go 的发展）。
Russ Cox 的个人能力相当强，看问题的角度也很独特，这也就是为什么他刚一提出 Go modules 的概念就能引起那么大范围的响应。虽然是被强推的，但事实也证明当下的 Go modules 表现得确实很优秀，所以这表明一定程度上的 “独裁” 还是可以接受的，至少可以保证一个项目能更加专一地朝着一个方向发展。
总之，无论如何 Go modules 现在都成了 Go 语言的一个密不可分的组件。
GOPATH Go modules 出现的目的之一就是为了解决 GOPATH 的问题，也就相当于是抛弃 GOPATH 了。
Opt-in Go modules 还处于 Opt-in 阶段，就是你想用就用，不用就不用，不强制你。但是未来很有可能 Go2 就强制使用了。
&amp;ldquo;module&amp;rdquo; != &amp;ldquo;package&amp;rdquo; 有一点需要纠正，就是“模块”和“包”，也就是 “module” 和 “package” 这两个术语并不是等价的，是 “集合” 跟 “元素” 的关系，“模块” 包含 “包”，“包” 属于 “模块”，一个 “模块” 是零个、一个或多个 “包” 的集合。
Go Modules 相关属性 go.mod module example.com/foobar  go 1.13  require (  example.com/apple v0.1.2  example.com/banana v1.2.3  example.com/banana/v2 v2.3.4  example.com/pineapple v0.0.0-20190924185754-1b0db40df49a )  exclude example.com/banana v1.2.4 replace example.com/apple v0.1.2 =&amp;gt; example.com/rda v0.1.0 replace example.com/banana =&amp;gt; example.com/hugebanana go.mod 是启用了 Go moduels 的项目所必须的最重要的文件，它描述了当前项目（也就是当前模块）的元信息，每一行都以一个动词开头，目前有以下 5 个动词:
 module：用于定义当前项目的模块路径。 go：用于设置预期的 Go 版本。 require：用于设置一个特定的模块版本。 exclude：用于从使用中排除一个特定的模块版本。 replace：用于将一个模块版本替换为另外一个模块版本。  这里的填写格式基本为包引用路径&#43;版本号，另外比较特殊的是 go $version，目前从 Go1.13 的代码里来看，还只是个标识作用，暂时未知未来是否有更大的作用。
go.sum go.sum 是类似于比如 dep 的 Gopkg.lock 的一类文件，它详细罗列了当前项目直接或间接依赖的所有模块版本，并写明了那些模块版本的 SHA-256 哈希值以备 Go 在今后的操作中保证项目所依赖的那些模块版本不会被篡改。
example.com/apple v0.1.2 h1:WXkYYl6Yr3qBf1K79EBnL4mak0OimBfB0XUf9Vl28OQ= example.com/apple v0.1.2/go.mod h1:xHWCNGjB5oqiDr8zfno3MHue2Ht5sIBksp03qcyfWMU= example.com/banana v1.2.3 h1:qHgHjyoNFV7jgucU8QZUuU4gcdhfs8QW1kw68OD2Lag= example.com/banana v1.2.3/go.mod h1:HSdplMjZKSmBqAxg5vPj2TmRDmfkzw&#43;cTzAElWljhcU= example.com/banana/v2 v2.3.4 h1:zl/OfRA6nftbBK9qTohYBJ5xvw6C/oNKizR7cZGl3cI= example.com/banana/v2 v2.3.4/go.mod h1:eZbhyaAYD41SGSSsnmcpxVoRiQ/MPUTjUdIIOT9Um7Q= ... 我们可以看到一个模块路径可能有如下两种：
example.com/apple v0.1.2 h1:WXkYYl6Yr3qBf1K79EBnL4mak0OimBfB0XUf9Vl28OQ= example.com/apple v0.1.2/go.mod h1:xHWCNGjB5oqiDr8zfno3MHue2Ht5sIBksp03qcyfWMU= 前者为 Go modules 打包整个模块包文件 zip 后再进行 hash 值，而后者为针对 go.mod 的 hash 值。他们两者，要不就是同时存在，要不就是只存在 go.mod hash。
那什么情况下会不存在 zip hash 呢，就是当 Go 认为肯定用不到某个模块版本的时候就会省略它的 zip hash，就会出现不存在 zip hash，只存在 go.mod hash 的情况。
GO111MODULE 这个环境变量主要是 Go modules 的开关，主要有以下参数：
 auto：只在项目包含了 go.mod 文件时启用 Go modules，在 Go 1.13 中仍然是默认值，详见 ：golang.org/issue/31857。 on：无脑启用 Go modules，推荐设置，未来版本中的默认值，让 GOPATH 从此成为历史。 off：禁用 Go modules。  GOPROXY 这个环境变量主要是用于设置 Go 模块代理，主要如下：
  它的值是一个以英文逗号 “,” 分割的 Go module proxy 列表（稍后讲解）
   作用：用于使 Go 在后续拉取模块版本时能够脱离传统的 VCS 方式从镜像站点快速拉取。它拥有一个默认：https://proxy.golang.org,direct，但很可惜 proxy.golang.org 在中国无法访问，故而建议使用 goproxy.cn 作为替代，可以执行语句：go env -w GOPROXY=https://goproxy.cn,direct。 设置为 “off” ：禁止 Go 在后续操作中使用任 何 Go module proxy。    刚刚在上面，我们可以发现值列表中有 “direct” ，它又有什么作用呢。其实值列表中的 “direct” 为特殊指示符，用于指示 Go 回源到模块版本的源地址去抓取(比如 GitHub 等)，当值列表中上一个 Go module proxy 返回 404 或 410 错误时，Go 自动尝试列表中的下一个，遇见 “direct” 时回源，遇见 EOF 时终止并抛出类似 “invalid version: unknown revision&amp;hellip;” 的错误。
GOSUMDB 它的值是一个 Go checksum database，用于使 Go 在拉取模块版本时(无论是从源站拉取还是通过 Go module proxy 拉取)保证拉取到的模块版本数据未经篡改，也可以是“off”即禁止 Go 在后续操作中校验模块版本
 格式 1：&amp;lt;SUMDB_NAME&amp;gt;&#43;&amp;lt;PUBLIC_KEY&amp;gt;。 格式 2：&amp;lt;SUMDB_NAME&amp;gt;&#43;&amp;lt;PUBLIC_KEY&amp;gt; &amp;lt;SUMDB_URL&amp;gt;。 拥有默认值：sum.golang.org (之所以没有按照上面的格式是因为 Go 对默认值做了特殊处理)。 可被 Go module proxy 代理 (详见：Proxying a Checksum Database)。 sum.golang.org 在中国无法访问，故而更加建议将 GOPROXY 设置为 goproxy.cn，因为 goproxy.cn支持代理 sum.golang.org。  Go Checksum Database Go checksum database 主要用于保护 Go 不会从任何源头拉到被篡改过的非法 Go 模块版本，其作用（左）和工作机制（右）如下图：
如果有兴趣的小伙伴可以看看 Proposal: Secure the Public Go Module Ecosystem，有详细介绍其算法机制，如果想简单一点，查看 go help module-auth 也是一个不错的选择。
GONOPROXY/GONOSUMDB/GOPRIVATE 这三个环境变量都是用在当前项目依赖了私有模块，也就是依赖了由 GOPROXY 指定的 Go module proxy 或由 GOSUMDB 指定 Go checksum database 无法访问到的模块时的场景
 它们三个的值都是一个以英文逗号 “,” 分割的模块路径前缀，匹配规则同 path.Match。 其中 GOPRIVATE 较为特殊，它的值将作为 GONOPROXY 和 GONOSUMDB 的默认值，所以建议的最佳姿势是只是用 GOPRIVATE。  在使用上来讲，比如 GOPRIVATE=*.corp.example.com 表示所有模块路径以 corp.example.com 的下一级域名 (如 team1.corp.example.com) 为前缀的模块版本都将不经过 Go module proxy 和 Go checksum database，需要注意的是不包括 corp.example.com 本身。
Global Caching 这个主要是针对 Go modules 的全局缓存数据说明，如下：
 同一个模块版本的数据只缓存一份，所有其他模块共享使用。 目前所有模块版本数据均缓存在 $GOPATH/pkg/mod和 $GOPATH/pkg/sum 下，未来或将移至 $GOCACHE/mod和$GOCACHE/sum 下( 可能会在当 $GOPATH 被淘汰后)。 可以使用 go clean -modcache 清理所有已缓存的模块版本数据。  另外在 Go1.11 之后 GOCACHE 已经不允许设置为 off 了，我想着这也是为了模块数据缓存移动位置做准备，因此大家应该尽快做好适配。
快速迁移项目至 Go Modules   第一步: 升级到 Go 1.13。
  第二步: 让 GOPATH 从你的脑海中完全消失，早一步踏入未来。
   修改 GOBIN 路径（可选）：go env -w GOBIN=$HOME/bin。 打开 Go modules：go env -w GO111MODULE=on。 设置 GOPROXY：go env -w GOPROXY=https://goproxy.cn,direct # 在中国是必须的，因为它的默认值被墙了。    第三步(可选): 按照你喜欢的目录结构重新组织你的所有项目。
  第四步: 在你项目的根目录下执行 go mod init &amp;lt;OPTIONAL_MODULE_PATH&amp;gt; 以生成 go.mod 文件。
  第五步: 想办法说服你身边所有的人都去走一下前四步。
  迁移后 go get 行为的改变   用 go help module-get 和 go help gopath-get分别去了解 Go modules 启用和未启用两种状态下的 go get 的行为
  用 go get 拉取新的依赖
   拉取最新的版本(优先择取 tag)：go get golang.org/x/text@latest 拉取 master 分支的最新 commit：go get golang.org/x/text@master 拉取 tag 为 v0.3.2 的 commit：go get golang.org/x/text@v0.3.2 拉取 hash 为 342b231 的 commit，最终会被转换为 v0.3.2：go get golang.org/x/text@342b2e 用 go get -u 更新现有的依赖 用 go mod download 下载 go.mod 文件中指明的所有依赖 用 go mod tidy 整理现有的依赖 用 go mod graph 查看现有的依赖结构 用 go mod init 生成 go.mod 文件 (Go 1.13 中唯一一个可以生成 go.mod 文件的子命令)    用 go mod edit 编辑 go.mod 文件
  用 go mod vendor 导出现有的所有依赖 (事实上 Go modules 正在淡化 Vendor 的概念)
  用 go mod verify 校验一个模块是否被篡改过
  这里我们注意到有两点比较特别，分别是：
 第一点：为什么 “拉取 hash 为 342b231 的 commit，最终会被转换为 v0.3.2” 呢。这是因为虽然我们设置了拉取 @342b2e commit，但是因为 Go modules 会与 tag 进行对比，若发现对应的 commit 与 tag 有关联，则进行转换。 第二点：为什么不建议使用 go mod vendor，因为 Go modules 正在淡化 Vendor 的概念，很有可能 Go2 就去掉了。  使用 Go Modules 时常遇见的坑 坑 1: 判断项目是否启用了 Go Modules 坑 2: 管理 Go 的环境变量 这里主要是提到 Go1.13 新增了 go env -w 用于写入环境变量，而写入的地方是 os.UserConfigDir 所返回的路径，需要注意的是 go env -w 不会覆写。
坑 3: 从 dep、glide 等迁移至 Go Modules 这里主要是指从旧有的依赖包管理工具（dep/glide 等）进行迁移时，因为 BUG 的原因会导致不经过 GOPROXY 的代理，解决方法有如下两个：
 手动创建一个 go.mod 文件，再执行 go mod tidy 进行补充。 上代理，相当于不使用 GOPROXY 了。  坑 4:拉取私有模块 这里主要想涉及两块知识点，如下：
 GOPROXY 是无权访问到任何人的私有模块的，所以你放心，安全性没问题。 GOPROXY 除了设置模块代理的地址以外，还需要增加 “direct” 特殊标识才可以成功拉取私有库。  坑 5:更新现有的模块 坑 6:主版本号 Go Module Proxy 简介 在这里再次强调了 Go Module Proxy 的作用（图左），以及其对应的协议交互流程（图右），有兴趣的小伙伴可以认真看一下。
Q&amp;amp;A Q：如何解决 Go 1.13 在从 GitLab 拉取模块版本时遇到的，Go 错误地按照非期望值的路径寻找目标模块版本结果致使最终目标模块拉取失败的问题？
**A：**GitLab 中配合 goget 而设置的 &amp;lt;meta&amp;gt; 存在些许问题，导致 Go 1.13 错误地识别了模块的具体路径，这是个 Bug，据说在 GitLab 的新版本中已经被修复了，详细内容可以看 https://github.com/golang/go/issues/34094 这个 Issue。然后目前的解决办法的话除了升级 GitLab 的版本外，还可以参考 https://github.com/developer-learning/night-reading-go/issues/468#issuecomment-535850154 这条回复。
Q：使用 Go modules 时可以同时依赖同一个模块的不同的两个或者多个小版本（修订版本号不同）吗？
**A：**不可以的，Go modules 只可以同时依赖一个模块的不同的两个或者多个大版本（主版本号不同）。比如可以同时依赖 example.com/foobar@v1.2.3 和 example.com/foobar/v2@v2.3.4，因为他们的模块路径（module path）不同，Go modules 规定主版本号不是 v0 或者 v1 时，那么主版本号必须显式地出现在模块路径的尾部。但是，同时依赖两个或者多个小版本是不支持的。比如如果模块 A 同时直接依赖了模块 B 和模块 C，且模块 A 直接依赖的是模块 C 的 v1.0.0 版本，然后模块 B 直接依赖的是模块 C 的 v1.0.1 版本，那么最终 Go modules 会为模块 A 选用模块 C 的 v1.0.1 版本而不是模块 A 的 go.mod 文件中指明的 v1.0.0 版本。
这是因为 Go modules 认为只要主版本号不变，那么剩下的都可以直接升级采用最新的。但是如果采用了最新的结果导致项目 Break 掉了，那么 Go modules 就会 Fallback 到上一个老的版本，比如在前面的例子中就会 Fallback 到 v1.0.0 版本。
Q：在 go.sum 文件中的一个模块版本的 Hash 校验数据什么情况下会成对出现，什么情况下只会存在一行？
**A：**通常情况下，在 go.sum 文件中的一个模块版本的 Hash 校验数据会有两行，前一行是该模块的 ZIP 文件的 Hash 校验数据，后一行是该模块的 go.mod 文件的 Hash 校验数据。但是也有些情况下只会出现一行该模块的 go.mod 文件的 Hash 校验数据，而不包含该模块的 ZIP 文件本身的 Hash 校验数据，这个情况发生在 Go modules 判定为你当前这个项目完全用不到该模块，根本也不会下载该模块的 ZIP 文件，所以就没必要对其作出 Hash 校验保证，只需要对该模块的 go.mod 文件作出 Hash 校验保证即可，因为 go.mod 文件是用得着的，在深入挖取项目依赖的时候要用。
Q：能不能更详细地讲解一下 go.mod 文件中的 replace 动词的行为以及用法？
**A：**这个 replace 动词的作用是把一个“模块版本”替换为另外一个“模块版本”，这是“模块版本”和“模块版本（module path）”之间的替换，“=&amp;gt;”标识符前面的内容是待替换的“模块版本”的“模块路径”，后面的内容是要替换的目标“模块版本”的所在地，即路径，这个路径可以是一个本地磁盘的相对路径，也可以是一个本地磁盘的绝对路径，还可以是一个网络路径，但是这个目标路径并不会在今后你的项目代码中作为你“导入路径（import path）”出现，代码里的“导入路径”还是得以你替换成的这个目标“模块版本”的“模块路径”作为前缀。
另外需要注意，Go modules 是不支持在 “导入路径” 里写相对路径的。举个例子，如果项目 A 依赖了模块 B，比如模块 B 的“模块路径”是 example.com/b，然后它在的磁盘路径是 ~/b，在项目 A 里的 go.mod 文件中你有一行 replace example.com/b=&amp;gt;~/b，然后在项目 A 里的代码中的“导入路基”就是 import&amp;quot;example.com/b&amp;quot;，而不是 import&amp;quot;~/b&amp;quot;，剩下的工作是 Go modules 帮你自动完成了的。
然后就是我在分享中也提到了， exclude 和 replace 这两个动词只作用于当前主模块，也就是当前项目，它所依赖的那些其他模块版本中如果出现了你待替换的那个模块版本的话，Go modules 还是会为你依赖的那个模块版本去拉取你的这个待替换的模块版本。
举个例子，比如项目 A 直接依赖了模块 B 和模块 C，然后模块 B 也直接依赖了模块 C，那么你在项目 A 中的 go.mod 文件里的 replace c=&amp;gt;~/some/path/c 是只会影响项目 A 里写的代码中，而模块 B 所用到的还是你 replace 之前的那个 c，并不是你替换成的 ~/some/path/c 这个。
总结 在 Go1.13 发布后，接触 Go modules 和 Go module proxy 的人越来越多，经常在各种群看到各种小伙伴在咨询，包括我自己也贡献了好几枚 “坑”。
因此我觉得傲飞的这一次 《Go Modules、Go Module Proxy 和 goproxy.cn》的技术分享，非常的有实践意义。
如果后续大家还有什么建议或问题，欢迎随时来讨论。
进一步阅读  night-reading-go/issues/468 B站：【Go 夜读】第 61 期 Go Modules、Go Module Proxy 和 goproxy.cn youtube：【Go 夜读】第 61 期 Go Modules、Go Module Proxy 和 goproxy.cn  </content>
    </entry>
    
     <entry>
        <title>Go 错误处理：用 panic 取代 err != nil 的模式</title>
        <url>http://shanks.link/blog/2021/04/14/go-%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86%E7%94%A8-panic-%E5%8F%96%E4%BB%A3-err-nil-%E7%9A%84%E6%A8%A1%E5%BC%8F/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Go 错误处理：用 panic 取代 err != nil 的模式 转载自煎鱼的blog
前段时间我分享了文章 《先睹为快，Go2 Error 的挣扎之路》后，和一位朋友进行了一次深度交流，他给我分享了他们项目组对于 Go 错误处理的方式调整。
简单来讲，就是在业务代码中使用 panic 的方式来替代 “永无止境” 的 if err != nil。
我们一起来看看是怎么做，又有什么优缺点，互相学习一轮。
为什么想替换 在 Go 语言中 if err != nil 写的太多，还要管方法声明各种，嫌麻烦又不方便：
err := foo() if err != nil {  //do something..  return err }  err := foo() if err != nil {  //do something..  return err }  err := foo() if err != nil {  //do something..  return err }  err := foo() if err != nil {  //do something..  return err } 上述还是示例代码，比较直面。若是在工程实践，还得各种 package 跳来跳去加 if err != nil，讲更繁琐，要去关心整体的上下游。
其余更具体的就不赘述了，可以关注我的公众号翻看先前的文章。
怎么替换 err != nil 不想写 if err != nil 的代码，方式之一就是用 panic 来替代他。
示例代码如下：
func GetFish(db *sql.DB, name string) []string {  rows, err := db.Query(&amp;#34;select name from users where `name` = ?&amp;#34;, name)  if err != nil {  panic(err)  }  defer rows.Close()   var names []string  for rows.Next() {  var name string  err := rows.Scan(&amp;amp;name)  if err != nil {  panic(err)  }   names = append(names, name)  }   err = rows.Err()  if err != nil {  panic(err)  }   return names } 在上述业务代码中，我们通过 panic 的方式取代了 return err 的函数返回，自然其所关联的下游业务代码也就不需要编写 if err != nil 的代码：
func main() {  fish1 := GetFish(db, &amp;#34;煎鱼&amp;#34;)  fish2 := GetFish(db, &amp;#34;咸鱼&amp;#34;)  fish3 := GetFish(db, &amp;#34;摸鱼&amp;#34;)  ... } 同时在转换为使用 panic 模式的错误机制后，我们必须要在外层增加 recover 方法：
func AppRecovery() gin.HandlerFunc {  return func(c *gin.Context) {  defer func() {  if err := recover(); err != nil {  if _, ok := err.(AppErr); ok {  // do something...  } else {  panic(err)  }  }  }()  } } 每次 panic 后根据其抛出的错误进行断言，识别是否定制的 AppErr 错误类型，若是则可以进行一系列的处理动作。
否则可继续向上 panic 抛出给顶级的 Recovery 方法进行处理。
这就是一个相对完整的 panic 错误链路处理了。
优缺点   从优点上来讲：
   整体代码结构看起来更加的简洁，仅专注于实现逻辑即可。 不需要关注和编写冗杂的 if err != nil 的错误处理代码。    从缺点上来讲：
   认知负担的增加，需要参加项目的每一个新老同学都清楚该模式，要做一个基本规范或培训。 存在一定的性能开销，每次 panic 都存在用户态的上下文切换。 存在一定的风险性，一旦 panic 没有 recover 住，就会导致事故。 Go 官方并不推荐，与 panic 本身的定义相违背，也就是 panic 与 error 的概念混淆。    总结 在今天这篇文章给大家分享了如何使用 panic 的方式来处理 Go 的错误，其必然有利必有有弊，需要做一个权衡了。
</content>
    </entry>
    
     <entry>
        <title>先睹为快，Go2 Error 的挣扎之路</title>
        <url>http://shanks.link/blog/2021/04/14/%E5%85%88%E7%9D%B9%E4%B8%BA%E5%BF%ABgo2-error-%E7%9A%84%E6%8C%A3%E6%89%8E%E4%B9%8B%E8%B7%AF/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 先睹为快，Go2 Error 的挣扎之路 转载自煎鱼的blog
自从 Go 语言在国内火热以来，除去泛型，其次最具槽点的就是 Go 对错误的处理方式，一句经典的 if err != nil 暗号就能认出你是一个 Go 语言爱好者。
err 里藏的是什么
自然，大家对 Go error 的关注度更是高涨，Go team 也是，因此在 Go 2 Draft Designs 中正式提到了 error handling（错误处理）的相关草案，希望能够在未来正式的解决这个问题。
在今天这篇文章中，我们将一同跟踪 Go2 error，看看他是怎么 “挣扎” 的，能不能破局？
为什么要吐槽 Go1 要吐槽 Go1 error，就得先知道为什么大家到底是在喷 Error 哪里处理的不好。在 Go 语言中，error 其实本质上只是个 Error 的 interface：
type error interface {  Error() string } 实际的应用场景如下：
func main() {  x, err := foo()  if err != nil {  // handle error  } } 单纯的看这个例子似乎没什么问题，但工程大了后呢？
显然 if err != nil 的逻辑是会堆积在工程代码中，Go 代码里的 if err != nil 甚至会达到工程代码量的 30% 以上：
func main() {  x, err := foo()  if err != nil {  // handle error  }  y, err := foo()  if err != nil {  // handle error  }  z, err := foo()  if err != nil {  // handle error  }  s, err := foo()  if err != nil {  // handle error  } } 暴力的对比一下，就发现四行函数调用，十二行错误，还要苦练且精通 IDE 的快速折叠功能，还是比较麻烦的。
另外既然是错误处理，那肯定不单单是一个 return err 了。在工程实践中，项目代码都是层层嵌套的，如果直接写成：
if err != nil {  return err } 在实际工程中肯定是不行。你怎么知道具体是哪里抛出来的错误信息，实际出错时只能瞎猜。大家又想出了 PlanB，那就是加各种描述信息：
if err != nil {  logger.Errorf(&amp;#34;煎鱼报错 err：%v&amp;#34;, err)  return err } 虽然看上去人模人样的，在实际出错时，也会遇到新的问题，因为你要去查这个错误是从哪里抛出来的，没有调用堆栈，单纯几句错误描述是难以定位的。
这时候就会发展成到处打错误日志：
func main() {  err := bar()  if err != nil {  logger.Errorf(&amp;#34;bar err：%v&amp;#34;, err)  }  ... }  func bar() error {  _, err := foo()  if err != nil {  logger.Errorf(&amp;#34;foo err：%v&amp;#34;, err)  return err  }   return nil }  func foo() ([]byte, error) {  s, err := json.Marshal(&amp;#34;hello world.&amp;#34;)  if err != nil {  logger.Errorf(&amp;#34;json.Marshal err：%v&amp;#34;, err)  return nil, err  }   return s, nil } 虽然到处打了日志，就会变成错误日志非常多，一旦出问题，人肉可能短时间内识别不出来。
最常见的就是到 IDE 上 ctrl &#43; f 搜索是在哪出错。同时在实际应用中我们会自定义一些错误类型，在 Go 则需要各种判断和处理：
if err := dec.Decode(&amp;amp;val); err != nil {  if serr, ok := err.(*json.SyntaxError); ok {  ...  }  return err } 你得判断不等于 nil，还得对自定义的错误类型进行断言，整体来讲比较繁琐。
汇总来讲，Go1 错误处理的问题至少有：
 在工程实践中，if err != nil 写的烦，代码中一大堆错误处理的判断，占了相当的比例，不够优雅。 在排查问题时，Go 的 err 并没有其他堆栈信息，只能自己增加描述信息，层层叠加，打一大堆日志，排查很麻烦。 在验证和测试错误时，要自定义错误（各种判断和断言）或者被迫用字符串校验。  Go1.13 的挽尊 在 2019 年 09 月，Go1.13 正式发布。其中两个比较大的两个关注点分别是包依赖管理 Go modules 的转正，以及错误处理 errors 标准库的改进：
Error wrapping
在本次改进中，errors 标准库引入了 Wrapping Error 的概念，并增加了 Is/As/Unwarp 三个方法，用于对所返回的错误进行二次处理和识别。
同时也是将 Go2 error 预规划中没有破坏 Go1 兼容性的相关功能提前实现了。
简单来讲，Go1.13 后 Go 的 error 就可以嵌套了，并提供了三个配套的方法。例子：
func main() {  e := errors.New(&amp;#34;脑子进煎鱼了&amp;#34;)  w := fmt.Errorf(&amp;#34;快抓住：%w&amp;#34;, e)  fmt.Println(w)  fmt.Println(errors.Unwrap(w)) } 输出结果：
$ go run main.go 快抓住：脑子进煎鱼了 脑子进煎鱼了 在上述代码中，变量 w 就是一个嵌套一层的 error。最外层是 “快抓住：”，此处调用 %w 意味着 Wrapping Error 的嵌套生成。因此最终输出了 “快抓住：脑子进煎鱼了”。
需要注意的是，Go 并没有提供 Warp 方法，而是直接扩展了 fmt.Errorf 方法。而下方的输出由于直接调用了 errors.Unwarp 方法，因此将 “取” 出一层嵌套，最终直接输出 “脑子进煎鱼了”。
对 Wrapping Error 有了基本理解后，我们简单介绍一下三个配套方法：
func Is(err, target error) bool func As(err error, target interface{}) bool func Unwrap(err error) error errors.Is 方法签名：
func Is(err, target error) bool 方法例子：
func main() {  if _, err := os.Open(&amp;#34;non-existing&amp;#34;); err != nil {  if errors.Is(err, os.ErrNotExist) {  fmt.Println(&amp;#34;file does not exist&amp;#34;)  } else {  fmt.Println(err)  }  }  } errors.Is 方法的作用是判断所传入的 err 和 target 是否同一类型，如果是则返回 true。
errors.As 方法签名：
func As(err error, target interface{}) bool 方法例子：
func main() {  if _, err := os.Open(&amp;#34;non-existing&amp;#34;); err != nil {  var pathError *os.PathError  if errors.As(err, &amp;amp;pathError) {  fmt.Println(&amp;#34;Failed at path:&amp;#34;, pathError.Path)  } else {  fmt.Println(err)  }  }  } errors.As 方法的作用是从 err 错误链中识别和 target 相同的类型，如果可以赋值，则返回 true。
errors.Unwarp 方法签名：
func Unwrap(err error) error 方法例子：
func main() {  e := errors.New(&amp;#34;脑子进煎鱼了&amp;#34;)  w := fmt.Errorf(&amp;#34;快抓住：%w&amp;#34;, e)  fmt.Println(w)  fmt.Println(errors.Unwrap(w)) } 该方法的作用是将嵌套的 error 解析出来，若存在多级嵌套则需要调用多次 Unwarp 方法。
民间自救 pkg/errors Go1 的 error 处理固然存在许多问题，因此在 Go1.13 前，早已有 “民间” 发现没有上下文调试信息在实际工程应用中存在严重的体感问题。
因此 github.com/pkg/errors 在 2016 年诞生了，该库也已经受到了极大的关注。
官方例子如下：
type stackTracer interface {  StackTrace() errors.StackTrace }  err, ok := errors.Cause(fn()).(stackTracer) if !ok {  panic(&amp;#34;oops, err does not implement stackTracer&amp;#34;) }  st := err.StackTrace() fmt.Printf(&amp;#34;%&#43;v&amp;#34;, st[0:2]) // top two frames  // Example output: // github.com/pkg/errors_test.fn // /home/dfc/src/github.com/pkg/errors/example_test.go:47 // github.com/pkg/errors_test.Example_stackTrace // /home/dfc/src/github.com/pkg/errors/example_test.go:127 简单来讲，就是对 Go1 error 的上下文处理进行了优化和处理，例如类型断言、调用堆栈等。若有兴趣的小伙伴可以自行到 github.com/pkg/errors 进行学习。
另外你可能会发现 Go1.13 新增的 Wrapping Error 体系与 pkg/errors 有些相像。
你并没有体会错，Go team 接纳了相关的意见，对 Go1 进行了调整，但调用堆栈这块因综合原因暂时没有纳入。
Go2 error 要解决什么问题 在前面我们聊了 Go1 error 的许多问题，以及 Go1.13 和 pkg/errors 的自救和融合。你可能会疑惑，那&amp;hellip;Go2 error 还有出场的机会吗？即使 Go1 做了这些事情，Go1 error 还有问题吗？
并没有解决，if err != nil 依旧一把梭，目前社区声音依然认为 Go 语言的错误处理要改进。
Go2 error proposal 在 2018 年 8 月，官方正式公布了 Go 2 Draft Designs，其中包含泛型和错误处理机制改进的初步草案：
Go2 Draft Designs
注：Go1.13 正式将一些不破坏 Go1 兼容性的 Error 特性加入到了 main branch，也就是前面提到的 Wrapping Error。
错误处理（Error Handling） 第一个要解决的问题就是大量 if err != nil 的问题，针对此提出了 Go2 error handling 的草案设计。
简单例子：
if err != nil {  return err } 优化后的方案如下：
func CopyFile(src, dst string) error {  handle err {  return fmt.Errorf(&amp;#34;copy %s %s: %v&amp;#34;, src, dst, err)  }   r := check os.Open(src)  defer r.Close()   w := check os.Create(dst)  handle err {  w.Close()  os.Remove(dst) // (only if a check fails)  }   check io.Copy(w, r)  check w.Close()  return nil } 主函数：
func main() {  handle err {  log.Fatal(err)  }   hex := check ioutil.ReadAll(os.Stdin)  data := check parseHexdump(string(hex))  os.Stdout.Write(data) } 该提案引入了两种新的语法形式，首先是 check 关键字，其可以选中一个表达式 check f(x, y, z) 或 check err，其将会标识这是一个显式的错误检查。
其次引入了 handle 关键字，用于定义错误处理程序流转，逐级上抛，依此类推，直到处理程序执行 return 语句，才正式结束。
错误值打印（Error Printing） 第二个要解决的问题是错误值（Error Values）、错误检查（Error Inspection）的问题，其引申出错误值打印（Error Printing）的问题，也可以认为是错误格式化的不便利。
官方针对此提出了提出了 Error Values 和 Error Printing 的草案设计。
简单例子如下：
if err != nil {  return fmt.Errorf(&amp;#34;write users database: %v&amp;#34;, err) } 优化后的方案如下：
package errors  type Wrapper interface {  Unwrap() error }  func Is(err, target error) bool func As(type E)(err error) (e E, ok bool) 该提案增加了错误链的 Wrapping Error 概念，并同时增加 errors.Is 和 errors.As 的方法，与前面说到的 Go1.13 的改进一致，不再赘述。
需要留意的是，Go1.13 并没有实现 %&#43;v 输出调用堆栈的需求，因为此举会破坏 Go1 兼容性和产生一些性能问题，大概会在 Go2 加入。
try-catch 不香吗 社区中另外一股声音就是直指 Go 语言反人类不用 try-catch 的机制，在社区内也产生了大量的探讨，具体可以看看相关的提案 Proposal: A built-in Go error check function, &amp;ldquo;try&amp;rdquo;。
目前该提案已被拒绝，具体可参见 go/issues/32437#issuecomment-512035919 和 Why does Go not have exceptions。
总结 在这篇文章中，我们介绍了目前 Go1 Error 的现状，概括了大家对 Go 语言错误处理的常见问题和意见。
同时还介绍了在这几年间，Go team 针对 Go2、Go1.13 Error 的持续优化和探索。
欢迎评论区留言：现在 Go2 error proposal 你是否认可？为什么？
参考  全成大佬的Golang error 的突围 为什么 Go 语言的 Error Handling 是一个败笔 Go语言(golang)新发布的1.13中的Error Wrapping深度分析  </content>
    </entry>
    
     <entry>
        <title>setjmp和longjmp函数使用详解</title>
        <url>http://shanks.link/blog/2021/04/14/setjmp%E5%92%8Clongjmp%E5%87%BD%E6%95%B0%E4%BD%BF%E7%94%A8%E8%AF%A6%E8%A7%A3/</url>
        <categories>
          <category>c</category>
        </categories>
        <tags>
          <tag>c</tag>
        </tags>
        <content type="html"> 转载自大米粒的blog
在网上看到的，觉得很有用，copy过来的。
非局部跳转语句&amp;mdash;setjmp和longjmp函数。非局部指的是，这不是由普通C语言goto，语句在一个函数内实施的跳转，而是在栈上跳过若干调用帧，返回到当前函数调用路径上的某一个函数中。
#include &amp;lt;setjmp.h&amp;gt;Int setjmp(jmp_buf env);  返回值：若直接调用则返回0，若从longjmp调用返回则返回非0值的longjmp中的val值 Void longjmp(jmp_buf env,int val);  调用此函数则返回到语句setjmp所在的地方，其中env 就是setjmp中的 env，而val 则是使setjmp的返回值变为val。  当检查到一个错误时,则以两个参数调用longjmp函数，第一个就是在调用setjmp时所用的env，第二个参数是具有非0值的val，它将成为从setjmp处返回的值。使用第二个参数的原因是对于一个setjmp可以有多个longjmp。 #include &amp;lt;stdio.h&amp;gt;#include &amp;lt;setjmp.h&amp;gt; static jmp_buf buf;  void second(void) {  printf(&amp;#34;second\n&amp;#34;); // 打印  longjmp(buf,1); // 跳回setjmp的调用处 - 使得setjmp返回值为1 }  void first(void) {  second();  printf(&amp;#34;first\n&amp;#34;); // 不可能执行到此行 }  int main() {  if ( ! setjmp(buf) ) {  first(); // 进入此行前，setjmp返回0  } else { // 当longjmp跳转回，setjmp返回1，因此进入此行  printf(&amp;#34;main\n&amp;#34;); // 打印  }   return 0; } 上述程序将输出:
second main 注意到虽然first()子程序被调用，&amp;ldquo;first&amp;quot;不可能被打印。&amp;ldquo;main&amp;quot;被打印，因为条件语句if ( ! setjmp(buf) )被执行第二次。　使用setjmp和longjmp要注意以下几点：
  setjmp与longjmp结合使用时，它们必须有严格的先后执行顺序，也即先调用setjmp函数，之后再调用longjmp函数，以恢复到先前被保存的“程序执行点”。否则，如果在setjmp调用之前，执行longjmp函数，将导致程序的执行流变的不可预测，很容易导致程序崩溃而退出
  longjmp必须在setjmp调用之后，而且longjmp必须在setjmp的作用域之内。具体来说，在一个函数中使用setjmp来初始化一个全局标号，然后只要该函数未曾返回，那么在其它任何地方都可以通过longjmp调用来跳转到 setjmp的下一条语句执行。实际上setjmp函数将发生调用处的局部环境保存在了一个jmp_buf的结构当中，只要主调函数中对应的内存未曾释放 （函数返回时局部内存就失效了），那么在调用longjmp的时候就可以根据已保存的jmp_buf参数恢复到setjmp的地方执行。
  </content>
    </entry>
    
     <entry>
        <title>万字长文 | 从实践到原理，带你参透 gRPC</title>
        <url>http://shanks.link/blog/2021/04/13/%E4%B8%87%E5%AD%97%E9%95%BF%E6%96%87-%E4%BB%8E%E5%AE%9E%E8%B7%B5%E5%88%B0%E5%8E%9F%E7%90%86%E5%B8%A6%E4%BD%A0%E5%8F%82%E9%80%8F-grpc/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 转载自煎鱼的blog
万字长文 | 从实践到原理，带你参透 gRPC 原创 陈煎鱼 脑子进煎鱼了 2020-12-14
大家好，我是煎鱼。
gRPC 在 Go 语言中大放异彩，越来越多的小伙伴在使用，最近也在公司安利了一波，希望这一篇文章能带你一览 gRPC 的巧妙之处，本文篇幅比较长，请做好阅读准备。
本文目录如下：
简述 gRPC 是一个高性能、开源和通用的 RPC 框架，面向移动和 HTTP/2 设计。目前提供 C、Java 和 Go 语言版本，分别是：grpc, grpc-java, grpc-go. 其中 C 版本支持 C, C&#43;&#43;, Node.js, Python, Ruby, Objective-C, PHP 和 C# 支持。
gRPC 基于 HTTP/2 标准设计，带来诸如双向流、流控、头部压缩、单 TCP 连接上的多复用请求等特性。这些特性使得其在移动设备上表现更好，更省电和节省空间占用。
调用模型 1、客户端（gRPC Stub）调用 A 方法，发起 RPC 调用。
2、对请求信息使用 Protobuf 进行对象序列化压缩（IDL）。
3、服务端（gRPC Server）接收到请求后，解码请求体，进行业务逻辑处理并返回。
4、对响应结果使用 Protobuf 进行对象序列化压缩（IDL）。
5、客户端接受到服务端响应，解码请求体。回调被调用的 A 方法，唤醒正在等待响应（阻塞）的客户端调用并返回响应结果。
调用方式 一、Unary RPC：一元 RPC Server type SearchService struct{}  func (s *SearchService) Search(ctx context.Context, r *pb.SearchRequest) (*pb.SearchResponse, error) {  return &amp;amp;pb.SearchResponse{Response: r.GetRequest() &#43; &amp;#34; Server&amp;#34;}, nil }  const PORT = &amp;#34;9001&amp;#34;  func main() {  server := grpc.NewServer()  pb.RegisterSearchServiceServer(server, &amp;amp;SearchService{})   lis, err := net.Listen(&amp;#34;tcp&amp;#34;, &amp;#34;:&amp;#34;&#43;PORT)  ...   server.Serve(lis) }  创建 gRPC Server 对象，你可以理解为它是 Server 端的抽象对象。 将 SearchService（其包含需要被调用的服务端接口）注册到 gRPC Server。的内部注册中心。这样可以在接受到请求时，通过内部的 “服务发现”，发现该服务端接口并转接进行逻辑处理。 创建 Listen，监听 TCP 端口。 gRPC Server 开始 lis.Accept，直到 Stop 或 GracefulStop。  Client func main() {  conn, err := grpc.Dial(&amp;#34;:&amp;#34;&#43;PORT, grpc.WithInsecure())  ...  defer conn.Close()   client := pb.NewSearchServiceClient(conn)  resp, err := client.Search(context.Background(), &amp;amp;pb.SearchRequest{  Request: &amp;#34;gRPC&amp;#34;,  })  ... }  创建与给定目标（服务端）的连接句柄。 创建 SearchService 的客户端对象。 发送 RPC 请求，等待同步响应，得到回调后返回响应结果。  二、Server-side streaming RPC：服务端流式 RPC Server func (s *StreamService) List(r *pb.StreamRequest, stream pb.StreamService_ListServer) error {  for n := 0; n &amp;lt;= 6; n&#43;&#43; {  stream.Send(&amp;amp;pb.StreamResponse{  Pt: &amp;amp;pb.StreamPoint{  ...  },  })  }   return nil } Client func printLists(client pb.StreamServiceClient, r *pb.StreamRequest) error {  stream, err := client.List(context.Background(), r)  ...   for {  resp, err := stream.Recv()  if err == io.EOF {  break  }  ...  }   return nil } 三、Client-side streaming RPC：客户端流式 RPC Server func (s *StreamService) Record(stream pb.StreamService_RecordServer) error {  for {  r, err := stream.Recv()  if err == io.EOF {  return stream.SendAndClose(&amp;amp;pb.StreamResponse{Pt: &amp;amp;pb.StreamPoint{...}})  }  ...   }   return nil } Client func printRecord(client pb.StreamServiceClient, r *pb.StreamRequest) error {  stream, err := client.Record(context.Background())  ...   for n := 0; n &amp;lt; 6; n&#43;&#43; {  stream.Send(r)  }   resp, err := stream.CloseAndRecv()  ...   return nil } 四、Bidirectional streaming RPC：双向流式 RPC Server func (s *StreamService) Route(stream pb.StreamService_RouteServer) error {  for {  stream.Send(&amp;amp;pb.StreamResponse{...})  r, err := stream.Recv()  if err == io.EOF {  return nil  }  ...  }   return nil } Client func printRoute(client pb.StreamServiceClient, r *pb.StreamRequest) error {  stream, err := client.Route(context.Background())  ...   for n := 0; n &amp;lt;= 6; n&#43;&#43; {  stream.Send(r)  resp, err := stream.Recv()  if err == io.EOF {  break  }  ...  }   stream.CloseSend()   return nil } 客户端与服务端是如何交互的 在开始分析之前，我们要先 gRPC 的调用有一个初始印象。那么最简单的就是对 Client 端调用 Server 端进行抓包去剖析，看看整个过程中它都做了些什么事。如下图：
 Magic SETTINGS HEADERS DATA SETTINGS WINDOW_UPDATE PING HEADERS DATA HEADERS WINDOW_UPDATE PING  我们略加整理发现共有十二个行为，是比较重要的。在开始分析之前，建议你自己先想一下，它们的作用都是什么？大胆猜测一下，带着疑问去学习效果更佳。
行为分析 Magic Magic 帧的主要作用是建立 HTTP/2 请求的前言。在 HTTP/2 中，要求两端都要发送一个连接前言，作为对所使用协议的最终确认，并确定 HTTP/2 连接的初始设置，客户端和服务端各自发送不同的连接前言。
而上图中的 Magic 帧是客户端的前言之一，内容为 PRI * HTTP/2.0\r\n\r\nSM\r\n\r\n，以确定启用 HTTP/2 连接。
SETTINGS SETTINGS 帧的主要作用是设置这一个连接的参数，作用域是整个连接而并非单一的流。
而上图的 SETTINGS 帧都是空 SETTINGS 帧，图一是客户端连接的前言（Magic 和 SETTINGS 帧分别组成连接前言）。图二是服务端的。另外我们从图中可以看到多个 SETTINGS 帧，这是为什么呢？是因为发送完连接前言后，客户端和服务端还需要有一步互动确认的动作。对应的就是带有 ACK 标识 SETTINGS 帧。
HEADERS HEADERS 帧的主要作用是存储和传播 HTTP 的标头信息。我们关注到 HEADERS 里有一些眼熟的信息，分别如下：
 method：POST scheme：http path：/proto.SearchService/Search authority：:10001 content-type：application/grpc user-agent：grpc-go/1.20.0-dev  你会发现这些东西非常眼熟，其实都是 gRPC 的基础属性，实际上远远不止这些，只是设置了多少展示多少。例如像平时常见的 grpc-timeout、grpc-encoding 也是在这里设置的。
DATA DATA 帧的主要作用是装填主体信息，是数据帧。而在上图中，可以很明显看到我们的请求参数 gRPC 存储在里面。只需要了解到这一点就可以了。
HEADERS, DATA, HEADERS 在上图中 HEADERS 帧比较简单，就是告诉我们 HTTP 响应状态和响应的内容格式。
在上图中 DATA 帧主要承载了响应结果的数据集，图中的 gRPC Server 就是我们 RPC 方法的响应结果。
在上图中 HEADERS 帧主要承载了 gRPC 状态 和 gRPC 状态消息，图中的 grpc-status 和 grpc-message 就是我们的 gRPC 调用状态的结果。
其它步骤 WINDOW_UPDATE 主要作用是管理和流的窗口控制。通常情况下打开一个连接后，服务器和客户端会立即交换 SETTINGS 帧来确定流控制窗口的大小。默认情况下，该大小设置为约 65 KB，但可通过发出一个 WINDOW_UPDATE 帧为流控制设置不同的大小。
PING/PONG 主要作用是判断当前连接是否仍然可用，也常用于计算往返时间。其实也就是 PING/PONG，大家对此应该很熟。
小结  在建立连接之前，客户端/服务端都会发送连接前言（Magic&#43;SETTINGS），确立协议和配置项。 在传输数据时，是会涉及滑动窗口（WINDOW_UPDATE）等流控策略的。 传播 gRPC 附加信息时，是基于 HEADERS 帧进行传播和设置；而具体的请求/响应数据是存储的 DATA 帧中的。 请求/响应结果会分为 HTTP 和 gRPC 状态响应两种类型。 客户端发起 PING，服务端就会回应 PONG，反之亦可。  这块 gRPC 的基础使用，你可以看看我另外的 《gRPC 入门系列》，相信对你一定有帮助。
浅谈理解 服务端 为什么四行代码，就能够起一个 gRPC Server，内部做了什么逻辑。你有想过吗？接下来我们一步步剖析，看看里面到底是何方神圣。
一、初始化 // grpc.NewServer() func NewServer(opt ...ServerOption) *Server {  opts := defaultServerOptions  for _, o := range opt {  o(&amp;amp;opts)  }  s := &amp;amp;Server{  lis: make(map[net.Listener]bool),  opts: opts,  conns: make(map[io.Closer]bool),  m: make(map[string]*service),  quit: make(chan struct{}),  done: make(chan struct{}),  czData: new(channelzData),  }  s.cv = sync.NewCond(&amp;amp;s.mu)  ...   return s } 这块比较简单，主要是实例 grpc.Server 并进行初始化动作。涉及如下：
 lis：监听地址列表。 opts：服务选项，这块包含 Credentials、Interceptor 以及一些基础配置。 conns：客户端连接句柄列表。 m：服务信息映射。 quit：退出信号。 done：完成信号。 czData：用于存储 ClientConn，addrConn 和 Server 的 channelz 相关数据。 cv：当优雅退出时，会等待这个信号量，直到所有 RPC 请求都处理并断开才会继续处理。  二、注册 pb.RegisterSearchServiceServer(server, &amp;amp;SearchService{}) 步骤一：Service API interface // search.pb.go type SearchServiceServer interface {  Search(context.Context, *SearchRequest) (*SearchResponse, error) }  func RegisterSearchServiceServer(s *grpc.Server, srv SearchServiceServer) {  s.RegisterService(&amp;amp;_SearchService_serviceDesc, srv) } 还记得我们平时编写的 Protobuf 吗？在生成出来的 .pb.go 文件中，会定义出 Service APIs interface 的具体实现约束。而我们在 gRPC Server 进行注册时，会传入应用 Service 的功能接口实现，此时生成的 RegisterServer 方法就会保证两者之间的一致性。
步骤二：Service API IDL 你想乱传糊弄一下？不可能的，请乖乖定义与 Protobuf 一致的接口方法。但是那个 &amp;amp;_SearchService_serviceDesc 又有什么作用呢？代码如下：
// search.pb.go var _SearchService_serviceDesc = grpc.ServiceDesc{  ServiceName: &amp;#34;proto.SearchService&amp;#34;,  HandlerType: (*SearchServiceServer)(nil),  Methods: []grpc.MethodDesc{  {  MethodName: &amp;#34;Search&amp;#34;,  Handler: _SearchService_Search_Handler,  },  },  Streams: []grpc.StreamDesc{},  Metadata: &amp;#34;search.proto&amp;#34;, } 这看上去像服务的描述代码，用来向内部表述 “我” 都有什么。涉及如下:
 ServiceName：服务名称 HandlerType：服务接口，用于检查用户提供的实现是否满足接口要求 Methods：一元方法集，注意结构内的 Handler 方法，其对应最终的 RPC 处理方法，在执行 RPC 方法的阶段会使用。 Streams：流式方法集 Metadata：元数据，是一个描述数据属性的东西。在这里主要是描述 SearchServiceServer 服务  步骤三：Register Service func (s *Server) register(sd *ServiceDesc, ss interface{}) {  ...  srv := &amp;amp;service{  server: ss,  md: make(map[string]*MethodDesc),  sd: make(map[string]*StreamDesc),  mdata: sd.Metadata,  }  for i := range sd.Methods {  d := &amp;amp;sd.Methods[i]  srv.md[d.MethodName] = d  }  for i := range sd.Streams {  ...  }  s.m[sd.ServiceName] = srv } 在最后一步中，我们会将先前的服务接口信息、服务描述信息给注册到内部 service 去，以便于后续实际调用的使用。涉及如下：
 server：服务的接口信息 md：一元服务的 RPC 方法集 sd：流式服务的 RPC 方法集 mdata：metadata，元数据  小结 在这一章节中，主要介绍的是 gRPC Server 在启动前的整理和注册行为，看上去很简单，但其实一切都是为了后续的实际运行的预先准备。因此我们整理一下思路，将其串联起来看看，如下：
三、监听 接下来到了整个流程中，最重要也是大家最关注的监听/处理阶段，核心代码如下：
func (s *Server) Serve(lis net.Listener) error {  ...  var tempDelay time.Duration  for {  rawConn, err := lis.Accept()  if err != nil {  if ne, ok := err.(interface {  Temporary() bool  }); ok &amp;amp;&amp;amp; ne.Temporary() {  if tempDelay == 0 {  tempDelay = 5 * time.Millisecond  } else {  tempDelay *= 2  }  if max := 1 * time.Second; tempDelay &amp;gt; max {  tempDelay = max  }  ...  timer := time.NewTimer(tempDelay)  select {  case &amp;lt;-timer.C:  case &amp;lt;-s.quit:  timer.Stop()  return nil  }  continue  }  ...  return err  }  tempDelay = 0   s.serveWG.Add(1)  go func() {  s.handleRawConn(rawConn)  s.serveWG.Done()  }()  } } Serve 会根据外部传入的 Listener 不同而调用不同的监听模式，这也是 net.Listener 的魅力，灵活性和扩展性会比较高。而在 gRPC Server 中最常用的就是 TCPConn，基于 TCP Listener 去做。接下来我们一起看看具体的处理逻辑，如下：
 循环处理连接，通过 lis.Accept 取出连接，如果队列中没有需处理的连接时，会形成阻塞等待。 若 lis.Accept 失败，则触发休眠机制，若为第一次失败那么休眠 5ms，否则翻倍，再次失败则不断翻倍直至上限休眠时间 1s，而休眠完毕后就会尝试去取下一个 “它”。 若 lis.Accept 成功，则重置休眠的时间计数和启动一个新的 goroutine 调用 handleRawConn 方法去执行/处理新的请求，也就是大家很喜欢说的 “每一个请求都是不同的 goroutine 在处理”。 在循环过程中，包含了 “退出” 服务的场景，主要是硬关闭和优雅重启服务两种情况。  客户端 一、创建拨号连接 // grpc.Dial(&amp;#34;:&amp;#34;&#43;PORT, grpc.WithInsecure()) func DialContext(ctx context.Context, target string, opts ...DialOption) (conn *ClientConn, err error) {  cc := &amp;amp;ClientConn{  target: target,  csMgr: &amp;amp;connectivityStateManager{},  conns: make(map[*addrConn]struct{}),  dopts: defaultDialOptions(),  blockingpicker: newPickerWrapper(),  czData: new(channelzData),  firstResolveEvent: grpcsync.NewEvent(),  }  ...  chainUnaryClientInterceptors(cc)  chainStreamClientInterceptors(cc)   ... } grpc.Dial 方法实际上是对于 grpc.DialContext 的封装，区别在于 ctx 是直接传入 context.Background。其主要功能是创建与给定目标的客户端连接，其承担了以下职责：
 初始化 ClientConn 初始化（基于进程 LB）负载均衡配置 初始化 channelz 初始化重试规则和客户端一元/流式拦截器 初始化协议栈上的基础信息 相关 context 的超时控制 初始化并解析地址信息 创建与服务端之间的连接  连没连 之前听到有的人说调用 grpc.Dial 后客户端就已经与服务端建立起了连接，但这对不对呢？我们先鸟瞰全貌，看看正在跑的 goroutine。如下：
我们可以有几个核心方法一直在等待/处理信号，通过分析底层源码可得知。涉及如下：
func (ac *addrConn) connect() func (ac *addrConn) resetTransport() func (ac *addrConn) createTransport(addr resolver.Address, copts transport.ConnectOptions, connectDeadline time.Time) func (ac *addrConn) getReadyTransport() 在这里主要分析 goroutine 提示的 resetTransport 方法，看看都做了啥。核心代码如下：
func (ac *addrConn) resetTransport() {  for i := 0; ; i&#43;&#43; {  if ac.state == connectivity.Shutdown {  return  }  ...  connectDeadline := time.Now().Add(dialDuration)  ac.updateConnectivityState(connectivity.Connecting)  newTr, addr, reconnect, err := ac.tryAllAddrs(addrs, connectDeadline)  if err != nil {  if ac.state == connectivity.Shutdown {  return  }  ac.updateConnectivityState(connectivity.TransientFailure)  timer := time.NewTimer(backoffFor)  select {  case &amp;lt;-timer.C:  ...  }  continue  }   if ac.state == connectivity.Shutdown {  newTr.Close()  return  }  ...  if !healthcheckManagingState {  ac.updateConnectivityState(connectivity.Ready)  }  ...   if ac.state == connectivity.Shutdown {  return  }  ac.updateConnectivityState(connectivity.TransientFailure)  } } 在该方法中会不断地去尝试创建连接，若成功则结束。否则不断地根据 Backoff 算法的重试机制去尝试创建连接，直到成功为止。从结论上来讲，单纯调用 DialContext 是异步建立连接的，也就是并不是马上生效，处于 Connecting 状态，而正式下要到达 Ready 状态才可用。
真的连了吗 在抓包工具上提示一个包都没有，那么这算真正连接了吗？我认为这是一个表述问题，我们应该尽可能的严谨。如果你真的想通过 DialContext 方法就打通与服务端的连接，则需要调用 WithBlock 方法，虽然会导致阻塞等待，但最终连接会到达 Ready 状态（握手成功）。如下图：
二、实例化 Service API type SearchServiceClient interface {  Search(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error) }  type searchServiceClient struct {  cc *grpc.ClientConn }  func NewSearchServiceClient(cc *grpc.ClientConn) SearchServiceClient {  return &amp;amp;searchServiceClient{cc} } 这块就是实例 Service API interface，比较简单。
三、调用 // search.pb.go func (c *searchServiceClient) Search(ctx context.Context, in *SearchRequest, opts ...grpc.CallOption) (*SearchResponse, error) {  out := new(SearchResponse)  err := c.cc.Invoke(ctx, &amp;#34;/proto.SearchService/Search&amp;#34;, in, out, opts...)  if err != nil {  return nil, err  }  return out, nil } proto 生成的 RPC 方法更像是一个包装盒，把需要的东西放进去，而实际上调用的还是 grpc.invoke 方法。如下：
func invoke(ctx context.Context, method string, req, reply interface{}, cc *ClientConn, opts ...CallOption) error {  cs, err := newClientStream(ctx, unaryStreamDesc, cc, method, opts...)  if err != nil {  return err  }  if err := cs.SendMsg(req); err != nil {  return err  }  return cs.RecvMsg(reply) } 通过概览，可以关注到三块调用。如下：
 newClientStream：获取传输层 Trasport 并组合封装到 ClientStream 中返回，在这块会涉及负载均衡、超时控制、 Encoding、 Stream 的动作，与服务端基本一致的行为。 cs.SendMsg：发送 RPC 请求出去，但其并不承担等待响应的功能。 cs.RecvMsg：阻塞等待接受到的 RPC 方法响应结果。  连接 // clientconn.go func (cc *ClientConn) getTransport(ctx context.Context, failfast bool, method string) (transport.ClientTransport, func(balancer.DoneInfo), error) {  t, done, err := cc.blockingpicker.pick(ctx, failfast, balancer.PickOptions{  FullMethodName: method,  })  if err != nil {  return nil, nil, toRPCErr(err)  }  return t, done, nil } 在 newClientStream 方法中，我们通过 getTransport 方法获取了 Transport 层中抽象出来的 ClientTransport 和 ServerTransport，实际上就是获取一个连接给后续 RPC 调用传输使用。
四、关闭连接 // conn.Close() func (cc *ClientConn) Close() error {  defer cc.cancel()  ...  cc.csMgr.updateState(connectivity.Shutdown)  ...  cc.blockingpicker.close()  if rWrapper != nil {  rWrapper.close()  }  if bWrapper != nil {  bWrapper.close()  }   for ac := range conns {  ac.tearDown(ErrClientConnClosing)  }  if channelz.IsOn() {  ...  channelz.AddTraceEvent(cc.channelzID, ted)  channelz.RemoveEntry(cc.channelzID)  }  return nil } 该方法会取消 ClientConn 上下文，同时关闭所有底层传输。涉及如下：
 Context Cancel 清空并关闭客户端连接 清空并关闭解析器连接 清空并关闭负载均衡连接 添加跟踪引用 移除当前通道信息  Q&amp;amp;A 1. gRPC Metadata 是通过什么传输？ 2. 调用 grpc.Dial 会真正的去连接服务端吗？ 会，但是是异步连接的，连接状态为正在连接。但如果你设置了 grpc.WithBlock 选项，就会阻塞等待（等待握手成功）。另外你需要注意，当未设置 grpc.WithBlock 时，ctx 超时控制对其无任何效果。
3. 调用 ClientConn 不 Close 会导致泄露吗？ 会，除非你的客户端不是常驻进程，那么在应用结束时会被动地回收资源。但如果是常驻进程，你又真的忘记执行 Close 语句，会造成的泄露。如下图：
3.1. 客户端
3.2. 服务端
3.3. TCP
4. 不控制超时调用的话，会出现什么问题？ 短时间内不会出现问题，但是会不断积蓄泄露，积蓄到最后当然就是服务无法提供响应了。如下图：
5. 为什么默认的拦截器不可以传多个？ func chainUnaryClientInterceptors(cc *ClientConn) {  interceptors := cc.dopts.chainUnaryInts  if cc.dopts.unaryInt != nil {  interceptors = append([]UnaryClientInterceptor{cc.dopts.unaryInt}, interceptors...)  }  var chainedInt UnaryClientInterceptor  if len(interceptors) == 0 {  chainedInt = nil  } else if len(interceptors) == 1 {  chainedInt = interceptors[0]  } else {  chainedInt = func(ctx context.Context, method string, req, reply interface{}, cc *ClientConn, invoker UnaryInvoker, opts ...CallOption) error {  return interceptors[0](ctx, method, req, reply, cc, getChainUnaryInvoker(interceptors, 0, invoker), opts...)  }  }  cc.dopts.unaryInt = chainedInt } 当存在多个拦截器时，取的就是第一个拦截器。因此结论是允许传多个，但并没有用。
6. 真的需要用到多个拦截器的话，怎么办？ 可以使用 go-grpc-middleware 提供的 grpc.UnaryInterceptor 和 grpc.StreamInterceptor 链式方法，方便快捷省心。
单单会用还不行，我们再深剖一下，看看它是怎么实现的。核心代码如下：
func ChainUnaryClient(interceptors ...grpc.UnaryClientInterceptor) grpc.UnaryClientInterceptor {  n := len(interceptors)  if n &amp;gt; 1 {  lastI := n - 1  return func(ctx context.Context, method string, req, reply interface{}, cc *grpc.ClientConn, invoker grpc.UnaryInvoker, opts ...grpc.CallOption) error {  var (  chainHandler grpc.UnaryInvoker  curI int  )   chainHandler = func(currentCtx context.Context, currentMethod string, currentReq, currentRepl interface{}, currentConn *grpc.ClientConn, currentOpts ...grpc.CallOption) error {  if curI == lastI {  return invoker(currentCtx, currentMethod, currentReq, currentRepl, currentConn, currentOpts...)  }  curI&#43;&#43;  err := interceptors[curI](currentCtx, currentMethod, currentReq, currentRepl, currentConn, chainHandler, currentOpts...)  curI--  return err  }   return interceptors[0](ctx, method, req, reply, cc, chainHandler, opts...)  }  }  ... } 当拦截器数量大于 1 时，从 interceptors[1] 开始递归，每一个递归的拦截器 interceptors[i] 会不断地执行，最后才真正的去执行 handler 方法。同时也经常有人会问拦截器的执行顺序是什么，通过这段代码你得出结论了吗？
7. 频繁创建 ClientConn 有什么问题？ 这个问题我们可以反向验证一下，假设不公用 ClientConn 看看会怎么样？如下:
func BenchmarkSearch(b *testing.B) {  for i := 0; i &amp;lt; b.N; i&#43;&#43; {  conn, err := GetClientConn()  if err != nil {  b.Errorf(&amp;#34;GetClientConn err: %v&amp;#34;, err)  }  _, err = Search(context.Background(), conn)  if err != nil {  b.Errorf(&amp;#34;Search err: %v&amp;#34;, err)  }  } } 输出结果：
 ... connection error: desc = &amp;#34;transport: Error while dialing dial tcp :10001: socket: too many open files&amp;#34;  ... connection error: desc = &amp;#34;transport: Error while dialing dial tcp :10001: socket: too many open files&amp;#34;  ... connection error: desc = &amp;#34;transport: Error while dialing dial tcp :10001: socket: too many open files&amp;#34;  ... connection error: desc = &amp;#34;transport: Error while dialing dial tcp :10001: socket: too many open files&amp;#34; FAIL exit status 1 当你的应用场景是存在高频次同时生成/调用 ClientConn 时，可能会导致系统的文件句柄占用过多。这种情况下你可以变更应用程序生成/调用 ClientConn 的模式，又或是池化它，这块可以参考 grpc-go-pool 项目。
8. 客户端请求失败后会默认重试吗？ 会不断地进行重试，直到上下文取消。而重试时间方面采用 backoff 算法作为的重连机制，默认的最大重试时间间隔是 120s。
9. 为什么要用 HTTP/2 作为传输协议？ 许多客户端要通过 HTTP 代理来访问网络，gRPC 全部用 HTTP/2 实现，等到代理开始支持 HTTP/2 就能透明转发 gRPC 的数据。不光如此，负责负载均衡、访问控制等等的反向代理都能无缝兼容 gRPC，比起自己设计 wire protocol 的 Thrift，这样做科学不少。@ctiller @滕亦飞
10. 在 Kubernetes 中 gRPC 负载均衡有问题？ gRPC 的 RPC 协议是基于 HTTP/2 标准实现的，HTTP/2 的一大特性就是不需要像 HTTP/1.1 一样，每次发出请求都要重新建立一个新连接，而是会复用原有的连接。
所以这将导致 kube-proxy 只有在连接建立时才会做负载均衡，而在这之后的每一次 RPC 请求都会利用原本的连接，那么实际上后续的每一次的 RPC 请求都跑到了同一个地方。
注：使用 k8s service 做负载均衡的情况下
总结  gRPC 基于 HTTP/2 &#43; Protobuf。 gRPC 有四种调用方式，分别是一元、服务端/客户端流式、双向流式。 gRPC 的附加信息都会体现在 HEADERS 帧，数据在 DATA 帧上。 Client 请求若使用 grpc.Dial 默认是异步建立连接，当时状态为 Connecting。 Client 请求若需要同步则调用 WithBlock()，完成状态为 Ready。 Server 监听是循环等待连接，若没有则休眠，最大休眠时间 1s；若接收到新请求则起一个新的 goroutine 去处理。 grpc.ClientConn 不关闭连接，会导致 goroutine 和 Memory 等泄露。 任何内/外调用如果不加超时控制，会出现泄漏和客户端不断重试。 特定场景下，如果不对 grpc.ClientConn 加以调控，会影响调用。 拦截器如果不用 go-grpc-middleware 链式处理，会覆盖。 在选择 gRPC 的负载均衡模式时，需要谨慎。  参考  http://doc.oschina.net/grpc https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md https://juejin.im/post/5b88a4f56fb9a01a0b31a67e https://www.ibm.com/developerworks/cn/web/wa-http2-under-the-hood/index.html https://github.com/grpc/grpc-go/issues/1953 https://www.zhihu.com/question/52670041  </content>
    </entry>
    
     <entry>
        <title>必须要学的 Go 进程诊断工具 gops</title>
        <url>http://shanks.link/blog/2021/04/13/%E5%BF%85%E9%A1%BB%E8%A6%81%E5%AD%A6%E7%9A%84-go-%E8%BF%9B%E7%A8%8B%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7-gops/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 转载自煎鱼的blog
必须要学的 Go 进程诊断工具 gops 在类 Unix 系统中，我们常常会使用 ps 命令来查看系统当前所运行的进程信息，该命令为我们提供了较大的帮助，能够快速的定位到某些进程的运行情况和状态。
而在 Go 语言中，也有类似的命令工具，那就是 gops[1]（Go Process Status）。
gops 是由 Google 官方出品的一个命令行工具，与 ps 命令的功能类似，能够查看并诊断当前系统中 Go 程序的运行状态及内部情况，在一些使用场景中具有较大的存在意义，属于常用工具。
在本文中我们将对 gops 进行全面的使用和介绍。
基本使用
我们先创建一个示例项目，然后在项目根目录执行下述模块安装命令：
$ go get -u github.com/google/gops 写入如下启动代码：
import (  ...  &amp;#34;github.com/google/gops/agent&amp;#34; )  func main() {  // 创建并监听 gops agent，gops 命令会通过连接 agent 来读取进程信息  // 若需要远程访问，可配置 agent.Options{Addr: &amp;#34;0.0.0.0:6060&amp;#34;}，否则默认仅允许本地访问  if err := agent.Listen(agent.Options{}); err != nil {  log.Fatalf(&amp;#34;agent.Listen err: %v&amp;#34;, err)  }   http.HandleFunc(&amp;#34;/hello&amp;#34;, func(w http.ResponseWriter, r *http.Request) {  _, _ = w.Write([]byte(`Go语言编程之旅`))  })  _ := http.ListenAndServe(&amp;#34;:6060&amp;#34;, http.DefaultServeMux) } 在完成示例启动代码的写入后，我们启动该程序，并在命令行执行 gops 命令进行查看：
3739 3725 main * go1.14 /private/var/folders/jm/.../b001/exe/main 3725 71093 go go1.14 /usr/local/Cellar/go/1.14/libexec/bin/go 62357 46131 go go1.14 /usr/local/Cellar/go/1.14/libexec/bin/go 3872 3742 gops go1.14 /Users/eddycjy/go/bin/gops 62379 62357 main go1.14 /private/var/folders/jm/.../b001/exe/main ... 在上述输出中，你很快就发现有一点不一样，那就是为什么某一行的输出结果中会包含一个 * 符号，如下：
3739 3725 main * go1.14 /private/var/folders/jm/.../b001/exe/main 这实际上代表着该 Go 进程，包含了 agent，因此它可以启用更强大的诊断功能，包括当前堆栈跟踪，Go版本，内存统计信息等等。
在最后也有一个 main 的 Go 进程，它不包含 * 符号，这意味着它是一个普通的 Go 程序，也就是没有植入 agent，只能使用最基本的功能。
常规命令 gops 工具包含了大量的分析命令，我们可以通过 gops help 进行查看：
$ gops help gops is a tool to list and diagnose Go processes.  Usage:  gops &amp;lt;cmd&amp;gt; &amp;lt;pid|addr&amp;gt; ...  gops &amp;lt;pid&amp;gt; # displays process info  gops help # displays this help message  Commands:  stack Prints the stack trace.  gc Runs the garbage collector and blocks until successful.  setgc Sets the garbage collection target percentage.  memstats Prints the allocation and garbage collection stats.  version Prints the Go version used to build the program.  stats Prints runtime stats.  trace Runs the runtime tracer for 5 secs and launches &amp;#34;go tool trace&amp;#34;.  pprof-heap Reads the heap profile and launches &amp;#34;go tool pprof&amp;#34;.  pprof-cpu Reads the CPU profile and launches &amp;#34;go tool pprof&amp;#34;. 在接下来的小节中，我们将针对几个常用的分析功能进行概要分析。
查看指定进程信息 $ gops &amp;lt;pid&amp;gt; parent PID: 3725 threads: 7 memory usage: 0.042% cpu usage: 0.003% username: eddycjy cmd&#43;args: /var/folders/jm/pk20jr_s74x49kqmyt87n2800000gn/T/go-build943691423/b001/exe/main elapsed time: 10:56 local/remote: 127.0.0.1:59369 &amp;lt;-&amp;gt; :0 (LISTEN) local/remote: *:6060 &amp;lt;-&amp;gt; :0 (LISTEN) 获取 Go 进程的概要信息，包括父级PID、线程数、内存/CPU使用率、运行者的账户名、进程的启动命令行参数、启动后所经过的时间以及 gops 的 agent 监听信息（若无植入 agent，则没有这项信息）。
查看调用栈信息 $ gops stack 3739 goroutine 19 [running]: runtime/pprof.writeGoroutineStacks(0x1385aa0, 0xc000132038, 0x30, 0xd0)  ...  /Users/eddycjy/go/src/github.com/google/gops/agent/agent.go:185 &#43;0x1af github.com/google/gops/agent.listen()  /Users/eddycjy/go/src/github.com/google/gops/agent/agent.go:133 &#43;0x2bf created by github.com/google/gops/agent.Listen  /Users/eddycjy/go/src/github.com/google/gops/agent/agent.go:111 &#43;0x36b  goroutine 1 [IO wait]: internal/poll.runtime_pollWait(0x2f55e38, 0x72, 0x0)  /usr/local/Cellar/go/1.14/libexec/src/runtime/netpoll.go:203 &#43;0x55  ... 获取对应进程的代码调用堆栈信息，可用于分析调用链路。
查看内存使用情况 $ gops memstats 3739 alloc: 1.15MB (1205272 bytes) total-alloc: 1.15MB (1205272 bytes) sys: 69.45MB (72827136 bytes) lookups: 0 mallocs: 644 frees: 12 heap-alloc: 1.15MB (1205272 bytes) heap-sys: 63.66MB (66748416 bytes) heap-idle: 62.05MB (65060864 bytes) heap-in-use: 1.61MB (1687552 bytes) heap-released: 62.02MB (65028096 bytes) heap-objects: 632 ... 获取 Go 在运行时的当前内存使用情况，主要是 runtime.MemStats[2] 的相关字段信息。
查看运行时信息 $ gops stats 3739 goroutines: 2 OS threads: 8 GOMAXPROCS: 4 num CPU: 4 获取 Go 运行时的基本信息，包括当前的 Goroutine 数量、系统线程、GOMAXPROCS 数值以及当前系统的 CPU 核数。
查看 trace 信息 $ gops trace 3739 Tracing now, will take 5 secs... Trace dump saved to: /var/folders/jm/pk20jr_s74x49kqmyt87n2800000gn/T/trace092133110 Parsing trace... Splitting trace... Opening browser. Trace viewer is listening on http://127.0.0.1:53811 与 go tool trace 作用基本一致。
查看 profile 信息 $ gops pprof-cpu 3739 Profiling CPU now, will take 30 secs... Profile dump saved to: /var/folders/jm/pk20jr_s74x49kqmyt87n2800000gn/T/profile563685966 Binary file saved to: /var/folders/jm/pk20jr_s74x49kqmyt87n2800000gn/T/binary265411413 File: binary265411413 Type: cpu ... (pprof)  $ gops pprof-heap 3739 Profile dump saved to: /var/folders/jm/pk20jr_s74x49kqmyt87n2800000gn/T/profile967076057 Binary file saved to: /var/folders/jm/pk20jr_s74x49kqmyt87n2800000gn/T/binary904879716 File: binary904879716 Type: inuse_space ... (pprof) 与 go tool pprof 作用基本一致。
你怎么知道我是谁 在学习了 gops 的使用后，我们突然发现一个问题，那就是 gops 是怎么知道哪些进程是与 Go 相关的进程？
如果是植入了 agent 的应用程序还好说，可以理解为埋入了识别点。但实际情况是，没有植入 agent 的 Go 程序也被识别到了，说明 gops 本身并不是这么实现的，考虑植入agent 应当只是用于诊断信息的拓展使用，并不是一个识别点，那么 gops 到底是怎么发现哪些进程是 Go 相关的呢？
我们回归问题的前置需求，假设我们想知道哪些进程与 Go 相关，那么第一步我们要先知道我们当前系统中都运行了哪些进程，这些记录在哪里有？
认真思考一下，答案也就呼之欲出了，假设是 Linux 相关的系统下，其会将进程所有的相关信息都按照约定的数据结构写入 /proc 目录下，因此我们有充分的怀疑认为 gops 就是从 /proc 目录下读取到相关信息的，源代码如下：
func PidsWithContext(ctx context.Context) ([]int32, error) {  var ret []int32   d, err := os.Open(common.HostProc())  if err != nil {  return nil, err  }  defer d.Close()   fnames, err := d.Readdirnames(-1)  if err != nil {  return nil, err  }  for _, fname := range fnames {  pid, err := strconv.ParseInt(fname, 10, 32)  if err != nil {  continue  }  ret = append(ret, int32(pid))  }   return ret, nil }  // common.HostProc func HostProc(combineWith ...string) string {  return GetEnv(&amp;#34;HOST_PROC&amp;#34;, &amp;#34;/proc&amp;#34;, combineWith...) } 在上述代码中，该方法通过调用 os.Open 方法打开了 proc 目录，并利用 Readdirnames 方法对该目录进行了扫描，最终获取到了所有需要 pid，最终完成其使命，返回了所有 pid。
在确定了 gops 是通过扫描 /proc 目录得到的进程信息后，我们又遇到了一个新的疑问点，那就是 gops 是怎么确定这个进程是 Go 进程，又怎么知道它的具体版本信息的呢，源代码如下：
func isGo(pr ps.Process) (path, version string, agent, ok bool, err error) {  ...  path, _ = pr.Path()  if err != nil {  return  }  var versionInfo goversion.Version  versionInfo, err = goversion.ReadExe(path)  if err != nil {  return  }  ok = true  version = versionInfo.Release  pidfile, err := internal.PIDFile(pr.Pid())  if err == nil {  _, err := os.Stat(pidfile)  agent = err == nil  }  return path, version, agent, ok, nil } 我们可以看到该方法的主要作用是根据扫描 /proc 目录所得到的二进制文件地址中查找相关的标识，用于判断其是否 Go 程序，如果是 Go 程序，那么它将会返回该进程的 pid、二进制文件的名称以及二进制文件的完整存储路径，判断的标识如下：
 if name == &amp;#34;runtime.main&amp;#34; || name == &amp;#34;main.main&amp;#34; {  isGo = true  }  if name == &amp;#34;runtime.buildVersion&amp;#34; {  isGo = true  } 而关于所编译的 Go 语言的版本，Go 编译器会在二进制文件中打入 runtime.buildVersion标识，这个标识能够快速我们快速识别它的编译信息，而 gops 也正正是利用了这一点。
我们可以利用 gdb 来进行查看 Go 所编译的二进制文件的版本信息，如下：
$ export GOFLAGS=&amp;#34;-ldflags=-compressdwarf=false&amp;#34; &amp;amp;&amp;amp; go build .  $ gdb awesomeProject ... (gdb) p &amp;#39;runtime.buildVersion&amp;#39; $1 = 0x131bbb0 &amp;#34;go1.14&amp;#34; 在上述输出中，我们先对示例项目进行了编译，然后利用 gdb 中查看了 runtime.buildVersion 变量，最终可得知编译这个 Go 程序的版本是 Go1.14。
但在编译时，有一点需要注意，就是我们在编译时指定了 export GOFLAGS=&amp;quot;-ldflags=-compressdwarf=false&amp;quot; 参数。
如果不进行指定的话，就会出现 Reading symbols from awesomeProject...(no debugging symbols found)...done. 的相关报错，会将会影响部分功能使用。
这是因为在 Go1.11 版本开始，进行了调试信息的压缩，目的是为了减小所编译的二进制文件大小，但 Mac 上的 gdb 无法理解压缩的 DWARF，因此会产生问题。
需要进行指定在调试时不进行 DWARF 的压缩，便于 Mac 上的 gdb 使用。
需要注意的一点 假设我们在一些特殊场景下希望对 Go 所编译的二进制文件进行压缩，那么在最后我们常常会使用到 upx 工具来减少其整体大小，命令如下：
$ upx awesomeProject 这时候我们再重新运行所编译的 awesomeProject 文件，这时候需要思考的是，gops 能不能识别到它是一个 Go 程序呢？
答案是不行的，经过 upx 压缩后的二进制文件将无法被识别为 Go 程序，并且在我所使用的 gops v0.3.7版本中，由于这类加壳进程的存在，执行 gops 命令直接出现了空指针调用的恐慌（panic），显然，这是一个 BUG，大家在实际环境中需要多加留意，如果要使用 gops 则尽量不要使用 upx 进行压缩。
总结 在本文中我们针对 Google 官方出品的 gops 进行了基本使用和原理性的部分剖析。
如果你仔细研读了，就会发现其实 gops 几乎包含了大部分 Go 剖析工具的功能，是名副其实的进程诊断工具。
gops 集成了大量 Go 业界中常用的分析链，在排查问题上也会非常的方便，不需要一个个单独找特定工具在哪里，只需要使用 gops 即可，而更深层次的使用可以根据实际情况进行更一步的了解。
参考资料 [1]gops: https://github.com/google/gops[2]runtime.MemStats: https://golang.org/pkg/runtime/#MemStats
</content>
    </entry>
    
     <entry>
        <title>为什么 Go 占用那么多的虚拟内存？</title>
        <url>http://shanks.link/blog/2021/04/13/%E4%B8%BA%E4%BB%80%E4%B9%88-go-%E5%8D%A0%E7%94%A8%E9%82%A3%E4%B9%88%E5%A4%9A%E7%9A%84%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 转载自煎鱼的blog
前段时间，某同学说某服务的容器因为超出内存限制，不断地重启，问我们是不是有内存泄露，赶紧排查，然后解决掉，省的出问题。
我们大为震惊，赶紧查看监控&#43;报警系统和性能分析，发现应用指标压根就不高，不像有泄露的样子。
问题到底是出在哪里了呢，我们进入某个容器里查看了 top 的系统指标：
PID VSZ RSS ... COMMAND 67459 2007m 136m ... ./eddycjy-server 看上去也没什么大开销的东西，就一个 Go 进程？就这？
再定眼一看，某同学就说 VSZ 那么高，而某云上的容器内存指标居然恰好和 VSZ 的值相接近，因此就怀疑是不是 VSZ 所导致的，觉得存在一定的关联关系。
这个猜测的结果到底是否正确呢？
基础知识 本篇文章将主要围绕 Go 进程的 VSZ 来进行剖析，看看到底它为什么那么 &amp;ldquo;高&amp;rdquo;。
第一节为前置的补充知识，大家可按顺序阅读。
什么是 VSZ VSZ 是该进程所能使用的虚拟内存总大小，它包括进程可以访问的所有内存，其中包括了被换出的内存（Swap）、已分配但未使用的内存以及来自共享库的内存。
为什么要虚拟内存 在前面我们有了解到 VSZ 其实就是该进程的虚拟内存总大小，那如果我们想了解 VSZ 的话，那我们得先了解 “为什么要虚拟内存？”。
本质上来讲，在一个系统中的进程是与其他进程共享 CPU 和主存资源的。
因此在现代的操作系统中，多进程的使用非常的常见，如果太多的进程需要太多的内存，在没有虚拟内存的情况下，物理内存很可能会不够用，就会导致其中有些任务无法运行，更甚至会出现一些很奇怪的现象。
例如 “某一个进程不小心写了另一个进程使用的内存”，就会造成内存破坏，因此虚拟内存是非常重要的一个媒介。
虚拟内存包含了什么 虚拟内存，又分为：
 内核虚拟内存。 进程虚拟内存。  每一个进程的虚拟内存都是独立的， 内部结构如下图所示。
在内核虚拟内存中，包含了内核中的代码和数据结构。
内核虚拟内存中的某些区域会被映射到所有进程共享的物理页面中去，因此你会看到 ”内核虚拟内存“ 中实际上是包含了 ”物理内存“ 的，它们两者存在映射关系。
而从应用场景上来讲，每个进程也会去共享内核的代码和全局数据结构，因此就会被映射到所有进程的物理页面中去。
虚拟内存的重要能力 为了更有效地管理内存并且减少出错，现代系统提供了一种对主存的抽象概念，也就是今天的主角，叫做虚拟内存（VM）。
虚拟内存是硬件异常、硬件地址翻译、主存、磁盘文件和内核软件交互的地方，它为每个进程提供了一个大的、一致的和私有的地址空间，虚拟内存提供了三个重要的能力：
 它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，它高效地使用了主存。 它为每个进程提供了一致的地址空间，从而简化了内存管理。 它保护了每个进程的地址空间不被其他进程破坏。  小结 上面发散的可能比较多，简单来讲，对于本文我们重点关注这些知识点，如下：
 虚拟内存它是有各式各样内存交互的地方，它包含的不仅仅是 &amp;ldquo;自己&amp;rdquo;，而在本文中，我们只需要关注 VSZ，也就是进程虚拟内存，它包含了你的代码、数据、堆、栈段和共享库。 虚拟内存作为内存保护的工具，能够保证进程之间的内存空间独立，不受其他进程的影响，因此每一个进程的 VSZ 大小都不一样，互不影响。 虚拟内存的存在，系统给各进程分配的内存之和是可以大于实际可用的物理内存的，因此你也会发现你进程的物理内存总是比虚拟内存低的多的多。  排查问题 在了解了基础知识后，我们正式开始排查问题，第一步我们先编写一个测试程序，看看没有什么业务逻辑的 Go 程序，它初始的 VSZ 是怎么样的。
测试 应用代码：
func main() {  r := gin.Default()  r.GET(&amp;#34;/ping&amp;#34;, func(c *gin.Context) {  c.JSON(200, gin.H{  &amp;#34;message&amp;#34;: &amp;#34;pong&amp;#34;,  })  })  r.Run(&amp;#34;:8001&amp;#34;) } 查看进程情况：
$ ps aux 67459 USER PID %CPU %MEM VSZ RSS ... eddycjy 67459 0.0 0.0 4297048 960 ... 从结果上来看，VSZ 为 4297048K，也就是 4G 左右，咋一眼看过去还是挺吓人的，明明没有什么业务逻辑，但是为什么那么高呢，真是令人感到好奇。
确认有没有泄露 在未知的情况下，我们可以首先看下 runtime.MemStats 和 pprof，确定应用到底有没有泄露。不过我们这块是演示程序，什么业务逻辑都没有，因此可以确定和应用没有直接关系。
# runtime.MemStats # Alloc = 1298568 # TotalAlloc = 1298568 # Sys = 71893240 # Lookups = 0 # Mallocs = 10013 # Frees = 834 # HeapAlloc = 1298568 # HeapSys = 66551808 # HeapIdle = 64012288 # HeapInuse = 2539520 # HeapReleased = 64012288 # HeapObjects = 9179 ... Go FAQ 接着我第一反应是去翻了 Go FAQ（因为看到过，有印象），其问题为 &amp;ldquo;Why does my Go process use so much virtual memory?&amp;quot;，回答如下：
 The Go memory allocator reserves a large region of virtual memory as an arena for allocations. This virtual memory is local to the specific Go process; the reservation does not deprive other processes of memory.
To find the amount of actual memory allocated to a Go process, use the Unix top command and consult the RES (Linux) or RSIZE (macOS) columns.
 这个 FAQ 是在 2012 年 10 月 提交 的，这么多年了也没有更进一步的说明，再翻了 issues 和 forum，一些关闭掉的 issue 都指向了 FAQ，这显然无法满足我的求知欲，因此我继续往下探索，看看里面到底都摆了些什么。
查看内存映射 在上图中，我们有提到进程虚拟内存，主要包含了你的代码、数据、堆、栈段和共享库，那初步怀疑是不是进程做了什么内存映射，导致了大量的内存空间被保留呢，为了确定这一点，我们通过如下命令去排查：
$ vmmap --wide 67459 ... ==== Non-writable regions for process 67459 REGION TYPE START - END [ VSIZE RSDNT DIRTY SWAP] PRT/MAX SHRMOD PURGE REGION DETAIL __TEXT 00000001065ff000-000000010667b000 [ 496K 492K 0K 0K] r-x/rwx SM=COW /bin/zsh __LINKEDIT 0000000106687000-0000000106699000 [ 72K 44K 0K 0K] r--/rwx SM=COW /bin/zsh MALLOC metadata 000000010669b000-000000010669c000 [ 4K 4K 4K 0K] r--/rwx SM=COW DefaultMallocZone_0x10669b000 zone structure ... __TEXT 00007fff76c31000-00007fff76c5f000 [ 184K 168K 0K 0K] r-x/r-x SM=COW /usr/lib/system/libxpc.dylib __LINKEDIT 00007fffe7232000-00007ffff32cb000 [192.6M 17.4M 0K 0K] r--/r-- SM=COW dyld shared cache combined __LINKEDIT ...  ==== Writable regions for process 67459 REGION TYPE START - END [ VSIZE RSDNT DIRTY SWAP] PRT/MAX SHRMOD PURGE REGION DETAIL __DATA 000000010667b000-0000000106682000 [ 28K 28K 28K 0K] rw-/rwx SM=COW /bin/zsh ... __DATA 0000000106716000-000000010671e000 [ 32K 28K 28K 4K] rw-/rwx SM=COW /usr/lib/zsh/5.3/zsh/zle.so __DATA 000000010671e000-000000010671f000 [ 4K 4K 4K 0K] rw-/rwx SM=COW /usr/lib/zsh/5.3/zsh/zle.so __DATA 0000000106745000-0000000106747000 [ 8K 8K 8K 0K] rw-/rwx SM=COW /usr/lib/zsh/5.3/zsh/complete.so __DATA 000000010675a000-000000010675b000 [ 4K 4K 4K 0K] rw- ... 这块主要是利用 macOS 的 vmmap 命令去查看内存映射情况，这样就可以知道这个进程的内存映射情况，从输出分析来看，这些关联共享库占用的空间并不大，导致 VSZ 过高的根本原因不在共享库和二进制文件上，但是并没有发现大量保留内存空间的行为，这是一个问题点。
注：若是 Linux 系统，可使用 cat /proc/PID/maps 或 cat /proc/PID/smaps 查看。
查看系统调用 既然在内存映射中，我们没有明确的看到保留内存空间的行为，那我们接下来看看该进程的系统调用，确定一下它是否存在内存操作的行为，如下：
$ sudo dtruss -a ./awesomeProject ...  4374/0x206a2: 15620 6 3 mprotect(0x1BC4000, 0x1000, 0x0) = 0 0 ...  4374/0x206a2: 15781 9 4 sysctl([CTL_HW, 3, 0, 0, 0, 0] (2), 0x7FFEEFBFFA64, 0x7FFEEFBFFA68, 0x0, 0x0) = 0 0  4374/0x206a2: 15783 3 1 sysctl([CTL_HW, 7, 0, 0, 0, 0] (2), 0x7FFEEFBFFA64, 0x7FFEEFBFFA68, 0x0, 0x0) = 0 0  4374/0x206a2: 15899 7 2 mmap(0x0, 0x40000, 0x3, 0x1002, 0xFFFFFFFFFFFFFFFF, 0x0) = 0x4000000 0  4374/0x206a2: 15930 3 1 mmap(0xC000000000, 0x4000000, 0x0, 0x1002, 0xFFFFFFFFFFFFFFFF, 0x0) = 0xC000000000 0  4374/0x206a2: 15934 4 2 mmap(0xC000000000, 0x4000000, 0x3, 0x1012, 0xFFFFFFFFFFFFFFFF, 0x0) = 0xC000000000 0  4374/0x206a2: 15936 2 0 mmap(0x0, 0x2000000, 0x3, 0x1002, 0xFFFFFFFFFFFFFFFF, 0x0) = 0x59B7000 0  4374/0x206a2: 15942 2 0 mmap(0x0, 0x210800, 0x3, 0x1002, 0xFFFFFFFFFFFFFFFF, 0x0) = 0x4040000 0  4374/0x206a2: 15947 2 0 mmap(0x0, 0x10000, 0x3, 0x1002, 0xFFFFFFFFFFFFFFFF, 0x0) = 0x1BD0000 0  4374/0x206a2: 15993 3 0 madvise(0xC000000000, 0x2000, 0x8) = 0 0  4374/0x206a2: 16004 2 0 mmap(0x0, 0x10000, 0x3, 0x1002, 0xFFFFFFFFFFFFFFFF, 0x0) = 0x1BE0000 0 ... 在这小节中，我们通过 macOS 的 dtruss 命令监听并查看了运行这个程序所进行的所有系统调用，发现了与内存管理有一定关系的方法如下：
 mmap：创建一个新的虚拟内存区域，但这里需要注意，就是当系统调用 mmap 时，它只是从虚拟内存中申请了一段空间出来，并不会去分配和映射真实的物理内存，而当你访问这段空间的时候，才会在当前时间真正的去分配物理内存。那么对应到我们实际应用的进程中，那就是 VSZ 的增长后，而该内存空间又未正式使用的话，物理内存是不会有增长的。 madvise：提供有关使用内存的建议，例如：MADV_NORMAL、MADV_RANDOM、MADV_SEQUENTIAL、MADV_WILLNEED、MADV_DONTNEED 等等。 mprotect：设置内存区域的保护情况，例如：PROT_NONE、PROT_READ、PROT_WRITE、PROT_EXEC、PROT_SEM、PROT_SAO、PROT_GROWSUP、PROT_GROWSDOWN 等等。 sysctl：在内核运行时动态地修改内核的运行参数。  在此比较可疑的是 mmap 方法，它在 dtruss 的最终统计中一共调用了 10 余次，我们可以相信它在 Go Runtime 的时候进行了大量的虚拟内存申请。
我们再接着往下看，看看到底是在什么阶段进行了虚拟内存空间的申请。
注：若是 Linux 系统，可使用 strace 命令。
查看 Go Runtime 启动流程 通过上述的分析，我们可以知道在 Go 程序启动的时候 VSZ 就已经不低了，并且确定不是共享库等的原因，且程序在启动时系统调用确实存在 mmap 等方法的调用。
那么我们可以充分怀疑 Go 在初始化阶段就保留了该内存空间。那我们第一步要做的就是查看一下 Go 的引导启动流程，看看是在哪里申请的。
引导过程如下：
graph TD A(rt0_darwin_amd64.s:8&amp;lt;br/&amp;gt;_rt0_amd64_darwin) --&amp;gt;|JMP| B(asm_amd64.s:15&amp;lt;br/&amp;gt;_rt0_amd64) B --&amp;gt; |JMP|C(asm_amd64.s:87&amp;lt;br/&amp;gt;runtime-rt0_go) C --&amp;gt; D(runtime1.go:60&amp;lt;br/&amp;gt;runtime-args) D --&amp;gt; E(os_darwin.go:50&amp;lt;br/&amp;gt;runtime-osinit) E --&amp;gt; F(proc.go:472&amp;lt;br/&amp;gt;runtime-schedinit) F --&amp;gt; G(proc.go:3236&amp;lt;br/&amp;gt;runtime-newproc) G --&amp;gt; H(proc.go:1170&amp;lt;br/&amp;gt;runtime-mstart) H --&amp;gt; I(在新创建的 p 和 m 上运行 runtime-main)  runtime-osinit：获取 CPU 核心数。 runtime-schedinit：初始化程序运行环境（包括栈、内存分配器、垃圾回收、P等）。 runtime-newproc：创建一个新的 G 和 绑定 runtime.main。 runtime-mstart：启动线程 M。  注：来自@曹大的 《Go 程序的启动流程》和@全成的 《Go 程序是怎样跑起来的》，推荐大家阅读。
初始化运行环境 显然，我们要研究的是 runtime 里的 schedinit 方法，如下：
func schedinit() {  ...  stackinit()  mallocinit()  mcommoninit(_g_.m)  cpuinit() // must run before alginit  alginit() // maps must not be used before this call  modulesinit() // provides activeModules  typelinksinit() // uses maps, activeModules  itabsinit() // uses activeModules   msigsave(_g_.m)  initSigmask = _g_.m.sigmask   goargs()  goenvs()  parsedebugvars()  gcinit()  ... } 从用途来看，非常明显， mallocinit 方法会进行内存分配器的初始化，我们继续往下看。
初始化内存分配器 mallocinit 接下来我们正式的分析一下 mallocinit 方法，在引导流程中， mallocinit 主要承担 Go 程序的内存分配器的初始化动作，而今天主要是针对虚拟内存地址这块进行拆解，如下：
func mallocinit() {  ...  if sys.PtrSize == 8 {  for i := 0x7f; i &amp;gt;= 0; i-- {  var p uintptr  switch {  case GOARCH == &amp;#34;arm64&amp;#34; &amp;amp;&amp;amp; GOOS == &amp;#34;darwin&amp;#34;:  p = uintptr(i)&amp;lt;&amp;lt;40 | uintptrMask&amp;amp;(0x0013&amp;lt;&amp;lt;28)  case GOARCH == &amp;#34;arm64&amp;#34;:  p = uintptr(i)&amp;lt;&amp;lt;40 | uintptrMask&amp;amp;(0x0040&amp;lt;&amp;lt;32)  case GOOS == &amp;#34;aix&amp;#34;:  if i == 0 {  continue  }  p = uintptr(i)&amp;lt;&amp;lt;40 | uintptrMask&amp;amp;(0xa0&amp;lt;&amp;lt;52)  case raceenabled:  ...  default:  p = uintptr(i)&amp;lt;&amp;lt;40 | uintptrMask&amp;amp;(0x00c0&amp;lt;&amp;lt;32)  }  hint := (*arenaHint)(mheap_.arenaHintAlloc.alloc())  hint.addr = p  hint.next, mheap_.arenaHints = mheap_.arenaHints, hint  }  } else {  ...  } }  判断当前是 64 位还是 32 位的系统。 从 0x7fc000000000~0x1c000000000 开始设置保留地址。 判断当前 GOARCH、GOOS 或是否开启了竞态检查，根据不同的情况申请不同大小的连续内存地址，而这里的 p 是即将要要申请的连续内存地址的开始地址。 保存刚刚计算的 arena 的信息到 arenaHint 中。  可能会有小伙伴问，为什么要判断是 32 位还是 64 位的系统，这是因为不同位数的虚拟内存的寻址范围是不同的，因此要进行区分，否则会出现高位的虚拟内存映射问题。而在申请保留空间时，我们会经常提到 arenaHint 结构体，它是 arenaHints链表里的一个节点，结构如下：
type arenaHint struct {  addr uintptr  down bool  next *arenaHint }  addr：arena 的起始地址 down：是否最后一个 arena next：下一个 arenaHint 的指针地址  那么这里疯狂提到的 arena 又是什么东西呢，这其实是 Go 的内存管理中的概念，Go Runtime 会把申请的虚拟内存分为三个大块，如下：
 spans：记录 arena 区域页号和 mspan 的映射关系。 bitmap：标识 arena 的使用情况，在功能上来讲，会用于标识 arena 的哪些空间地址已经保存了对象。 arean：arean 其实就是 Go 的堆区，是由 mheap 进行管理的，它的 MaxMem 是 512GB-1。而在功能上来讲，Go 会在初始化的时候申请一段连续的虚拟内存空间地址到 arean 保留下来，在真正需要申请堆上的空间时再从 arean 中取出来处理，这时候就会转变为物理内存了。  在这里的话，你需要理解 arean 区域在 Go 内存里的作用就可以了。
mmap 我们刚刚通过上述的分析，已经知道 mallocinit 的用途了，但是你可能还是会有疑惑，就是我们之前所看到的 mmap 系统调用，和它又有什么关系呢，怎么就关联到一起了，接下来我们先一起来看看更下层的代码，如下：
func sysAlloc(n uintptr, sysStat *uint64) unsafe.Pointer {  p, err := mmap(nil, n, _PROT_READ|_PROT_WRITE, _MAP_ANON|_MAP_PRIVATE, -1, 0)  ...  mSysStatInc(sysStat, n)  return p }  func sysReserve(v unsafe.Pointer, n uintptr) unsafe.Pointer {  p, err := mmap(v, n, _PROT_NONE, _MAP_ANON|_MAP_PRIVATE, -1, 0)  ... }  func sysMap(v unsafe.Pointer, n uintptr, sysStat *uint64) {  ...  munmap(v, n)  p, err := mmap(v, n, _PROT_READ|_PROT_WRITE, _MAP_ANON|_MAP_FIXED|_MAP_PRIVATE, -1, 0)  ... } 在 Go Runtime 中存在着一系列的系统级内存调用方法，本文涉及的主要如下：
 sysAlloc：从 OS 系统上申请清零后的内存空间，调用参数是 _PROT_READ|_PROT_WRITE, _MAP_ANON|_MAP_PRIVATE，得到的结果需进行内存对齐。 sysReserve：从 OS 系统中保留内存的地址空间，这时候还没有分配物理内存，调用参数是 _PROT_NONE, _MAP_ANON|_MAP_PRIVATE，得到的结果需进行内存对齐。 sysMap：通知 OS 系统我们要使用已经保留了的内存空间，调用参数是 _PROT_READ|_PROT_WRITE, _MAP_ANON|_MAP_FIXED|_MAP_PRIVATE。  看上去好像很有道理的样子，但是 mallocinit 方法在初始化时，到底是在哪里涉及了 mmap 方法呢，表面看不出来，如下：
for i := 0x7f; i &amp;gt;= 0; i-- {  ...  hint := (*arenaHint)(mheap_.arenaHintAlloc.alloc())  hint.addr = p  hint.next, mheap_.arenaHints = mheap_.arenaHints, hint } 实际上在调用 mheap_.arenaHintAlloc.alloc() 时，调用的是 mheap 下的 sysAlloc 方法，而 sysAlloc 又会与 mmap 方法产生调用关系，并且这个方法与常规的 sysAlloc 还不大一样，如下：
var mheap_ mheap ... func (h *mheap) sysAlloc(n uintptr) (v unsafe.Pointer, size uintptr) {  ...  for h.arenaHints != nil {  hint := h.arenaHints  p := hint.addr  if hint.down {  p -= n  }  if p&#43;n &amp;lt; p {  v = nil  } else if arenaIndex(p&#43;n-1) &amp;gt;= 1&amp;lt;&amp;lt;arenaBits {  v = nil  } else {  v = sysReserve(unsafe.Pointer(p), n)  }  ... } 你可以惊喜的发现 mheap.sysAlloc 里其实有调用 sysReserve 方法，而 sysReserve 方法又正正是从 OS 系统中保留内存的地址空间的特定方法，是不是很惊喜，一切似乎都串起来了。
小结 在本节中，我们先写了一个测试程序，然后根据非常规的排查思路进行了一步步的跟踪怀疑，整体流程如下：
 通过 top 或 ps 等命令，查看进程运行情况，分析基础指标。 通过 pprof 或 runtime.MemStats 等工具链查看应用运行情况，分析应用层面是否有泄露或者哪儿高。 通过 vmmap 命令，查看进程的内存映射情况，分析是不是进程虚拟空间内的某个区域比较高，例如：共享库等。 通过 dtruss 命令，查看程序的系统调用情况，分析可能出现的一些特殊行为，例如：在分析中我们发现 mmap 方法调用的比例是比较高的，那我们有充分的理由怀疑 Go 在启动时就进行了大量的内存空间保留。 通过上述的分析，确定可能是在哪个环节申请了那么多的内存空间后，再到 Go Runtime 中去做进一步的源码分析，因为源码面前，了无秘密，没必要靠猜。  从结论上而言，VSZ（进程虚拟内存大小）与共享库等没有太大的关系，主要与 Go Runtime 存在直接关联，也就是在前图中表示的运行时堆（malloc）。转换到 Go Runtime 里，就是在 mallocinit 这个内存分配器的初始化阶段里进行了一定量的虚拟空间的保留。
而保留虚拟内存空间时，受什么影响，又是一个哲学问题。从源码上来看，主要如下：
 受不同的 OS 系统架构（GOARCH/GOOS）和位数（32/64 位）的影响。 受内存对齐的影响，计算回来的内存空间大小是需要经过对齐才会进行保留。  总结 我们通过一步步地分析，讲解了 Go 会在哪里，又会受什么因素，去调用了什么方法保留了那么多的虚拟内存空间，但是我们肯定会忧心进程虚拟内存（VSZ）高，会不会存在问题呢，我分析如下：
 VSZ 并不意味着你真正使用了那些物理内存，因此是不需要担心的。 VSZ 并不会给 GC 带来压力，GC 管理的是进程实际使用的物理内存，而 VSZ 在你实际使用它之前，它并没有过多的代价。 VSZ 基本都是不可访问的内存映射，也就是它并没有内存的访问权限（不允许读、写和执行）。  思考 看到这里舒一口气，因为 Go VSZ 的高，并不会对我们产生什么非常实质性的问题，但是又仔细一想，为什么 Go 要申请那么多的虚拟内存呢？
总体考虑如下：
 Go 的设计是考虑到 arena 和 bitmap 的后续使用，先提早保留了整个内存地址空间。 Go Runtime 和应用的逐步使用，肯定也会开始实际的申请和使用内存，这时候 arena 和 bitmap 的内存分配器就只需要将事先申请好的内存地址空间保留更改为实际可用的物理内存就好了，这样子可以极大的提高效能。  参考
 High virtual memory allocation by golang GO MEMORY MANAGEMENT GoBigVirtualSize GoProgramMemoryUse 曹大的 Go 程序的启动流程 全成大佬的 Go 程序是怎样跑起来的 欧神的 go-under-the-hood  </content>
    </entry>
    
     <entry>
        <title>详解 Go 程序的启动流程，你知道 g0，m0 是什么吗？</title>
        <url>http://shanks.link/blog/2021/04/13/%E8%AF%A6%E8%A7%A3-go-%E7%A8%8B%E5%BA%8F%E7%9A%84%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E4%BD%A0%E7%9F%A5%E9%81%93-g0m0-%E6%98%AF%E4%BB%80%E4%B9%88%E5%90%97/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 转载自煎鱼的blog
详解 Go 程序的启动流程，你知道 g0，m0 是什么吗？ 大家好，我是煎鱼。
自古应用程序均从 Hello World 开始，你我所写的 Go 语言亦然：
import &amp;#34;fmt&amp;#34;  func main() {  fmt.Println(&amp;#34;hello world.&amp;#34;) } 这段程序的输出结果为 hello world.，就是这么的简单又直接。但这时候又不禁思考了起来，这个 hello world. 是怎么输出来，经历了什么过程。
真是非常的好奇，今天我们就一起来探一探 Go 程序的启动流程。其中涉及到 Go Runtime 的调度器启动，g0，m0 又是什么？
车门焊死，正式开始吸鱼之路。
Go 引导阶段 查找入口 首先编译上文提到的示例程序：
$ GOFLAGS=&amp;#34;-ldflags=-compressdwarf=false&amp;#34; go build 在命令中指定了 GOFLAGS 参数，这是因为在 Go1.11 起，为了减少二进制文件大小，调试信息会被压缩。导致在 MacOS 上使用 gdb 时无法理解压缩的 DWARF 的含义是什么（而我恰恰就是用的 MacOS）。
因此需要在本次调试中将其关闭，再使用 gdb 进行调试，以此达到观察的目的：
$ gdb awesomeProject (gdb) info files Symbols from &amp;#34;/Users/eddycjy/go-application/awesomeProject/awesomeProject&amp;#34;. Local exec file:  `/Users/eddycjy/go-application/awesomeProject/awesomeProject&amp;#39;, file type mach-o-x86-64.  Entry point: 0x1063c80  0x0000000001001000 - 0x00000000010a6aca is .text  ... (gdb) b *0x1063c80 Breakpoint 1 at 0x1063c80: file /usr/local/Cellar/go/1.15/libexec/src/runtime/rt0_darwin_amd64.s, line 8. 通过 Entry point 的调试，可看到真正的程序入口在 runtime 包中，不同的计算机架构指向不同。例如：
 MacOS 在 src/runtime/rt0_darwin_amd64.s。 Linux 在 src/runtime/rt0_linux_amd64.s。  其最终指向了 rt0_darwin_amd64.s 文件，这个文件名称非常的直观：
Breakpoint 1 at 0x1063c80: file /usr/local/Cellar/go/1.15/libexec/src/runtime/rt0_darwin_amd64.s, line 8. rt0 代表 runtime0 的缩写，指代运行时的创世，超级奶爸：
 darwin 代表目标操作系统（GOOS）。 amd64 代表目标操作系统架构（GOHOSTARCH）。  同时 Go 语言还支持更多的目标系统架构，例如：AMD64、AMR、MIPS、WASM 等：
源码目录
若有兴趣可到 src/runtime 目录下进一步查看，这里就不一一介绍了。
入口方法 在 rt0_linux_amd64.s 文件中，可发现 _rt0_amd64_darwin JMP 跳转到了 _rt0_amd64 方法：
TEXT _rt0_amd64_darwin(SB),NOSPLIT,$-8  JMP _rt0_amd64(SB) ... 紧接着又跳转到 runtime·rt0_go 方法：
TEXT _rt0_amd64(SB),NOSPLIT,$-8  MOVQ 0(SP), DI // argc  LEAQ 8(SP), SI // argv  JMP runtime·rt0_go(SB) 该方法将程序输入的 argc 和 argv 从内存移动到寄存器中。
栈指针（SP）的前两个值分别是 argc 和 argv，其对应参数的数量和具体各参数的值。
开启主线 程序参数准备就绪后，正式初始化的方法落在 runtime·rt0_go 方法中：
TEXT runtime·rt0_go(SB),NOSPLIT,$0  ...  CALL runtime·check(SB)  MOVL 16(SP), AX // copy argc  MOVL AX, 0(SP)  MOVQ 24(SP), AX // copy argv  MOVQ AX, 8(SP)  CALL runtime·args(SB)  CALL runtime·osinit(SB)  CALL runtime·schedinit(SB)   // create a new goroutine to start program  MOVQ $runtime·mainPC(SB), AX // entry  PUSHQ AX  PUSHQ $0 // arg size  CALL runtime·newproc(SB)  POPQ AX  POPQ AX   // start this M  CALL runtime·mstart(SB)  ...  runtime.check：运行时类型检查，主要是校验编译器的翻译工作是否正确，是否有 “坑”。基本代码均为检查 int8 在 unsafe.Sizeof 方法下是否等于 1 这类动作。 runtime.args：系统参数传递，主要是将系统参数转换传递给程序使用。 runtime.osinit：系统基本参数设置，主要是获取 CPU 核心数和内存物理页大小。 runtime.schedinit：进行各种运行时组件的初始化，包含调度器、内存分配器、堆、栈、GC 等一大堆初始化工作。会进行 p 的初始化，并将 m0 和某一个 p 进行绑定。 runtime.main：主要工作是运行 main goroutine，虽然在runtime·rt0_go 中指向的是$runtime·mainPC，但实质指向的是 runtime.main。 runtime.newproc：创建一个新的 goroutine，且绑定 runtime.main 方法（也就是应用程序中的入口 main 方法）。并将其放入 m0 绑定的p的本地队列中去，以便后续调度。 runtime.mstart：启动 m，调度器开始进行循环调度。  在 runtime·rt0_go 方法中，其主要是完成各类运行时的检查，系统参数设置和获取，并进行大量的 Go 基础组件初始化。
初始化完毕后进行主协程（main goroutine）的运行，并放入等待队列（GMP 模型），最后调度器开始进行循环调度。
小结 根据上述源码剖析，可以得出如下 Go 应用程序引导的流程图：
Go 程序引导过程
在 Go 语言中，实际的运行入口并不是用户日常所写的 main func，更不是 runtime.main 方法，而是从 rt0_*_amd64.s 开始，最终再一路 JMP 到 runtime·rt0_go 里去，再在该方法里完成一系列 Go 自身所需要完成的绝大部分初始化动作。
其中整体包括：
 运行时类型检查、系统参数传递、CPU 核数获取及设置、运行时组件的初始化（调度器、内存分配器、堆、栈、GC 等）。 运行 main goroutine。 运行相应的 GMP 等大量缺省行为。 涉及到调度器相关的大量知识。  后续将会继续剖析将进一步剖析 runtime·rt0_go 里的爱与恨，尤其像是 runtime.main、runtime.schedinit 等调度方法，都有非常大的学习价值，有兴趣的小伙伴可以持续关注。
Go 调度器初始化 知道了 Go 程序是怎么引导起来的之后，我们需要了解 Go Runtime 中调度器是怎么流转的。
runtime.mstart 这里主要关注 runtime.mstart 方法：
func mstart() {  // 获取 g0  _g_ := getg()   // 确定栈边界  osStack := _g_.stack.lo == 0  if osStack {  size := _g_.stack.hi  if size == 0 {  size = 8192 * sys.StackGuardMultiplier  }  _g_.stack.hi = uintptr(noescape(unsafe.Pointer(&amp;amp;size)))  _g_.stack.lo = _g_.stack.hi - size &#43; 1024  }  _g_.stackguard0 = _g_.stack.lo &#43; _StackGuard  _g_.stackguard1 = _g_.stackguard0   // 启动 m，进行调度器循环调度  mstart1()   // 退出线程  if mStackIsSystemAllocated() {  osStack = true  }  mexit(osStack) }  调用 getg 方法获取 GMP 模型中的 g，此处获取的是 g0。 通过检查 g 的执行栈 _g_.stack 的边界（堆栈的边界正好是 lo, hi）来确定是否为系统栈。若是，则根据系统栈初始化 g 执行栈的边界。 调用 mstart1 方法启动系统线程 m，进行调度器循环调度。 调用 mexit 方法退出系统线程 m。  runtime.mstart1 这么看来其实质逻辑在 mstart1 方法，我们继续往下剖析：
func mstart1() {  // 获取 g，并判断是否为 g0  _g_ := getg()  if _g_ != _g_.m.g0 {  throw(&amp;#34;bad runtime·mstart&amp;#34;)  }   // 初始化 m 并记录调用方 pc、sp  save(getcallerpc(), getcallersp())  asminit()  minit()   // 设置信号 handler  if _g_.m == &amp;amp;m0 {  mstartm0()  }  // 运行启动函数  if fn := _g_.m.mstartfn; fn != nil {  fn()  }   if _g_.m != &amp;amp;m0 {  acquirep(_g_.m.nextp.ptr())  _g_.m.nextp = 0  }  schedule() }  调用 getg 方法获取 g。并且通过前面绑定的 _g_.m.g0 判断所获取的 g 是否 g0。若不是，则直接抛出致命错误。因为调度器仅在 g0 上运行。 调用 minit 方法初始化 m，并记录调用方的 PC、SP，便于后续 schedule 阶段时的复用。 若确定当前的 g 所绑定的 m 是 m0，则调用 mstartm0 方法，设置信号 handler。该动作必须在 minit 方法之后，这样 minit 方法可以提前准备好线程，以便能够处理信号。 若当前 g 所绑定的 m 有启动函数，则运行。否则跳过。 若当前 g 所绑定的 m 不是 m0，则需要调用 acquirep 方法获取并绑定 p，也就是 m 与 p 绑定。 调用 schedule 方法进行正式调度。  忙活了一大圈，终于进入到开题的主菜了，原来潜伏的很深的 schedule 方法才是真正做调度的方法，其他都是前置处理和准备数据。
由于篇幅问题，schedule 方法会放到下篇再继续剖析，我们先聚焦本篇的一些细节点。
问题深剖 不过到这里篇幅也已经比较长了，积累了不少问题。我们针对在 Runtime 中出镜率最高的两个元素进行剖析：
 m0 是什么，作用是？ g0 是什么，作用是？  m0 m0 是 Go Runtime 所创建的第一个系统线程，一个 Go 进程只有一个 m0，也叫主线程。
从多个方面来看：
 数据结构：m0 和其他创建的 m 没有任何区别。 创建过程：m0 是进程在启动时应该汇编直接复制给 m0 的，其他后续的 m 则都是 Go Runtime 内自行创建的。 变量声明：m0 和常规 m 一样，m0 的定义就是 var m0 m，没什么特别之处。  g0 g 一般分为三种，分别是：
 执行用户任务的叫做 g。 执行 runtime.main 的 main goroutine。 执行调度任务的叫 g0。。  g0 比较特殊，每一个 m 都只有一个 g0（仅此只有一个 g0），且每个 m 都只会绑定一个 g0。在 g0 的赋值上也是通过汇编赋值的，其余后续所创建的都是常规的 g。
从多个方面来看：
 数据结构：g0 和其他创建的 g 在数据结构上是一样的，但是存在栈的差别。在 g0 上的栈分配的是系统栈，在 Linux 上栈大小默认固定 8MB，不能扩缩容。而常规的 g 起始只有 2KB，可扩容。 运行状态：g0 和常规的 g 不一样，没有那么多种运行状态，也不会被调度程序抢占，调度本身就是在 g0 上运行的。 变量声明：g0 和常规 g，g0 的定义就是 var g0 g，没什么特别之处。  小结 在本章节中我们讲解了 Go 调度器初始化的一个过程，分别涉及：
 runtime.mstart。 runtime.mstart1。  基于此也了解到了在调度器初始化过程中，需要准备什么，初始化什么。另外针对调度过程中最常提到的 m0、g0 的概念我们进行了梳理和说明。
总结 在今天这篇文章中，我们详细的介绍了 Go 语言的引导启动过程中的所有流程和初始化动作。
同时针对调度器的初始化进行了初步分析，详细介绍了 m0、g0 的用途和区别。在下一篇文章中我们将进一步对真正调度的 schedule 方法进行详解，这块也是个硬骨头了。
</content>
    </entry>
    
     <entry>
        <title>go单例模式</title>
        <url>http://shanks.link/blog/2021/04/05/go%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原文链接
Go语言中的单例模式 在过去的几年中，Go语言的发展是惊人的，并且吸引了很多由其他语言（Python、PHP、Ruby）转向Go语言的跨语言学习者。
在过去的很长时间里，很多开发人员和初创公司都习惯使用Python、PHP或Ruby快速开发功能强大的系统，并且大多数情况下都不需要担心内部事务如何工作，也不需要担心线程安全性和并发性。直到最近几年，多线程高并发的系统开始流行起来，我们现在不仅需要快速开发功能强大的系统，而且还要保证被开发的系统能够足够快速运行。（我们真是太难了图片）
对于被Go语言天生支持并发的特性吸引来的跨语言学习者来说，我觉着掌握Go语言的语法并不是最难的，最难的是突破既有的思维定势，真正理解并发和使用并发来解决实际问题。
Go语言太容易实现并发了，以至于它在很多地方被不正确的使用了。
常见的错误 有一些错误是很常见的，比如不考虑并发安全的单例模式。就像下面的示例代码：
package singleton  type singleton struct {}  var instance *singleton  func GetInstance() *singleton {  if instance == nil {  instance = &amp;amp;singleton{} // 不是并发安全的  }  return instance } 在上述情况下，多个goroutine可以执行第一个检查，并且它们都将创建该singleton类型的实例并相互覆盖。无法保证它将在此处返回哪个实例，并且对该实例的其他进一步操作可能与开发人员的期望不一致。
不好的原因是，如果有代码保留了对该单例实例的引用，则可能存在具有不同状态的该类型的多个实例，从而产生潜在的不同代码行为。这也成为调试过程中的一个噩梦，并且很难发现该错误，因为在调试时，由于运行时暂停而没有出现任何错误，这使非并发安全执行的可能性降到了最低，并且很容易隐藏开发人员的问题。
激进的加锁 也有很多对这种并发安全问题的糟糕解决方案。使用下面的代码确实能解决并发安全问题，但会带来其他潜在的严重问题，通过加锁把对该函数的并发调用变成了串行。
var mu Sync.Mutex  func GetInstance() *singleton {  mu.Lock() // 如果实例存在没有必要加锁  defer mu.Unlock()   if instance == nil {  instance = &amp;amp;singleton{}  }  return instance } 在上面的代码中，我们可以看到在创建单例实例之前通过引入Sync.Mutex和获取Lock来解决并发安全问题。问题是我们在这里执行了过多的锁定，即使我们不需要这样做，在实例已经创建的情况下，我们应该简单地返回缓存的单例实例。在高度并发的代码基础上，这可能会产生瓶颈，因为一次只有一个goroutine可以获得单例实例。
因此，这不是最佳方法。我们必须考虑其他解决方案。
Check-Lock-Check模式 在C &#43;&#43;和其他语言中，确保最小程度的锁定并且仍然是并发安全的最佳和最安全的方法是在获取锁定时利用众所周知的Check-Lock-Check模式。该模式的伪代码表示如下。
if check() {  lock() {  if check() {  // 在这里执行加锁安全的代码  }  } } 该模式背后的思想是，你应该首先进行检查，以最小化任何主动锁定，因为IF语句的开销要比加锁小。其次，我们希望等待并获取互斥锁，这样在同一时刻在那个块中只有一个执行。但是，在第一次检查和获取互斥锁之间，可能有其他goroutine获取了锁，因此，我们需要在锁的内部再次进行检查，以避免用另一个实例覆盖了实例。
如果将这种模式应用于我们的GetInstance()方法，我们会写出类似下面的代码：
func GetInstance() *singleton {  if instance == nil { // 不太完美 因为这里不是完全原子的  mu.Lock()  defer mu.Unlock()   if instance == nil {  instance = &amp;amp;singleton{}  }  }  return instance } 通过使用sync/atomic这个包，我们可以原子化加载并设置一个标志，该标志表明我们是否已初始化实例。
import &amp;#34;sync&amp;#34; import &amp;#34;sync/atomic&amp;#34;  var initialized uint32 ... // 此处省略  func GetInstance() *singleton {   if atomic.LoadUInt32(&amp;amp;initialized) == 1 { // 原子操作  return instance  }   mu.Lock()  defer mu.Unlock()   if initialized == 0 {  instance = &amp;amp;singleton{}  atomic.StoreUint32(&amp;amp;initialized, 1)  }   return instance } 但是……这看起来有点繁琐了，我们其实可以通过研究Go语言和标准库如何实现goroutine同步来做得更好。
Go语言惯用的单例模式 我们希望利用Go惯用的方式来实现这个单例模式。我们在标准库sync中找到了Once类型。它能保证某个操作仅且只执行一次。下面是来自Go标准库的源码（部分注释有删改）。
// Once is an object that will perform exactly one action. type Once struct {  // done indicates whether the action has been performed.  // It is first in the struct because it is used in the hot path.  // The hot path is inlined at every call site.  // Placing done first allows more compact instructions on some architectures (amd64/x86),  // and fewer instructions (to calculate offset) on other architectures.  done uint32  m Mutex }  func (o *Once) Do(f func()) {  if atomic.LoadUint32(&amp;amp;o.done) == 0 { // check  // Outlined slow-path to allow inlining of the fast-path.  o.doSlow(f)  } }  func (o *Once) doSlow(f func()) {  o.m.Lock() // lock  defer o.m.Unlock()   if o.done == 0 { // check  defer atomic.StoreUint32(&amp;amp;o.done, 1)  f()  } } 这说明我们可以借助这个实现只执行一次某个函数/方法，once.Do()的用法如下：
once.Do(func() {  // 在这里执行安全的初始化 }) 下面就是单例实现的完整代码，该实现利用sync.Once类型去同步对GetInstance()的访问，并确保我们的类型仅被初始化一次。
package singleton  import (  &amp;#34;sync&amp;#34; )  type singleton struct {}  var instance *singleton var once sync.Once  func GetInstance() *singleton {  once.Do(func() {  instance = &amp;amp;singleton{}  })  return instance } 因此，使用sync.Once包是安全地实现此目标的首选方式，类似于Objective-C和Swift（Cocoa）实现dispatch_once方法来执行类似的初始化。
结论 当涉及到并发和并行代码时，需要对代码进行更仔细的检查。始终让你的团队成员执行代码审查，因为这样的事情很容易就会被发现。
所有刚转到Go语言的新开发人员都必须真正了解并发安全性如何工作以更好地改进其代码。即使Go语言本身通过允许你在对并发性知识知之甚少的情况下设计并发代码，也完成了许多繁重的工作。在某些情况下，单纯的依靠语言特性也无能为力，你仍然需要在开发代码时应用最佳实践。
翻译自http://marcio.io/2015/07/singleton-pattern-in-go/，考虑到可读性内容与原文略有差异。
</content>
    </entry>
    
     <entry>
        <title>Golang 切片与函数参数陷阱</title>
        <url>http://shanks.link/blog/2021/04/05/golang-%E5%88%87%E7%89%87%E4%B8%8E%E5%87%BD%E6%95%B0%E5%8F%82%E6%95%B0%E9%99%B7%E9%98%B1/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原文链接
线性结构是计算机最常用的数据结构之一。无论是数组（arrary）还是链表（list），在编程中不可或缺。golang也有数组，不同于别的语言，golang还提供了切片（slice）。切片比数组有更好的灵活性，具有某些动态特性。然而切片又不像动态语言的列表（Python list）。不明白切片的基本实现，写程序的时候容易掉“坑”里。 slice参数 本来写一个堆排序，使用了golang的slice来做堆，可是发现在pop数据的时候，切片不改变。进而引发了golang函数切片的参数，是传值还是传引用呢？我们知道slice相比array是引用类型。那么直觉上告诉我们如果函数修改了参数的切片，那么外层的切片变量也会变啦。
func main() {   slice := []int{0, 1, 2, 3}  fmt.Printf(&amp;#34;slice: %v slice addr %p \n&amp;#34;, slice, &amp;amp;slice)   ret := changeSlice(slice)  fmt.Printf(&amp;#34;slice: %v ret: %v slice addr %p \n&amp;#34;, slice, &amp;amp;slice, ret) }  func changeSlice(s []int) []int {  s[1] = 111  return s } 结果和假设的一样：
 slice: [0 1 2 3], slice addr: 0xc4200660c0 slice: [0 111 2 3], ret: [0 111 2 3], slice addr: 0xc4200660c0 changeSlice函数修改了切片，变量 slice也跟着修改了。可是如果轻易就下结论，切片参数是按照引用传递，那么下面的现象就需要一种说法了：  func changeSlice(s []int) []int {  fmt.Printf(&amp;#34;func: %p \n&amp;#34;, &amp;amp;s)  s[1] = 111  return s } 我们在函数中打出参数 s 的地址，可以看见这个地址和main函数中的slice竟然不是同一个。为了了解这个，我们需要了解golang中的slice基本实现。
slice基本实现 Golang中的slice，是一个看似array却不是array的复合结构。切片顾名思义，就是数组切下来的一个片段。slice结构大致存储了三个部分，第一部分为指向底层数组的指针ptr，其次是切片的大小len和切片的容量cap：
 &#43;--------&#43; | | | ptr |&#43;------------&#43;-------&#43;-----------&#43; | | | | &#43;--------&#43; | | | | | | | | | | | len 5 | | | | | | | &#43;--------&#43; v v | | &#43;-----&#43;-----&#43;-----&#43;-----&#43;----&#43; | | | | | | | | | cap 5 | [5]int | 0 | 1 | 2 | 3 | 4 | | | &#43;-----&#43;-----&#43;-----&#43;-----&#43;----&#43; &#43;--------&#43; slice := arr[1:4] arr := [5]int{0,1,2,3,4}  有一个数组arr是一个包含五个int类型的结构，它的切片slice只是从其取了 1到3这几个数字。我们同样可以再生成一个切片 slice2 := arr[2:5], 所取的就是数组后面的连续块。他们共同使用arr作为底层的结构，可以看见共用了数字的第3，4个元素。修改其中任何一个，都能改变两个切片的值。
func main() {   arr := [5]int{0, 1, 2, 3, 4}  fmt.Println(arr)   slice := arr[1:4]  slice2 := arr[2:5]   fmt.Printf(&amp;#34;arr %v, slice1 %v, slice2 %v, %p %p %p\n&amp;#34;, arr, slice, slice2, &amp;amp;arr, &amp;amp;slice, &amp;amp;slice2)   fmt.Printf(&amp;#34;arr[2]%p slice[1] %p slice2[0]%p\n&amp;#34;, &amp;amp;arr[2], &amp;amp;slice[1], &amp;amp;slice2[0])   arr[2] = 2222   fmt.Printf(&amp;#34;arr %v, slice1 %v, slice2 %v\n&amp;#34;, arr, slice, slice2)    slice[1] = 1111   fmt.Printf(&amp;#34;arr %v, slice1 %v, slice2 %v\n&amp;#34;, arr, slice, slice2)  } 输出的值为：
[0 1 2 3 4] arr [0 1 2 3 4], slice1 [1 2 3], slice2 [2 3 4], 0xc42006e0c0 0xc4200660c0 0xc4200660e0 arr[2]0xc42006e0d0 slice[1] 0xc42006e0d0 slice2[0]0xc42006e0d0 arr [0 1 2222 3 4], slice1 [1 2222 3], slice2 [2222 3 4] arr [0 1 1111 3 4], slice1 [1 1111 3], slice2 [1111 3 4] 由此可见，数组的切片，只是从数组上切一段数据下来，不同的切片，其实是共享这些底层的数据数据。不过这些切片本身是不一样的对象，其内存地址都不一样。
从数组中切一块下来形成切片很好理解，有时候我们用make函数创建切片，实际上golang会在底层创建一个匿名的数组。如果从新的slice再切，那么新创建的两个切片都共享这个底层的匿名数组。
func main() {   slice := make([]int, 5)  for i:=0; i&amp;lt;len(slice);i&#43;&#43;{  slice[i] = i  }  fmt.Printf(&amp;#34;slice %v \n&amp;#34;, slice)   slice2 := slice[1:4]  fmt.Printf(&amp;#34;slice %v, slice2 %v \n&amp;#34;, slice, slice2)   slice[1] = 1111  fmt.Printf(&amp;#34;slice %v, slice2 %v \n&amp;#34;, slice, slice2) } 输出如下：
slice [0 1 2 3 4] slice [0 1 2 3 4], slice2 [1 2 3] slice [0 1111 2 3 4], slice2 [1111 2 3] slice的复制 既然slice的创建依赖于数组，有时候新生成的slice会修改，但是又不想修改原来的切片或者数组。此时就需要针对原来的切片进行复制了。
func main() {   slice := []int{0, 1, 2, 3, 4}   slice2 := slice[1:4]   slice3 := make([]int, len(slice2))   for i, e := range slice2 {  slice3[i] = e  }   fmt.Printf(&amp;#34;slice %v, slice3 %v \n&amp;#34;, slice, slice3)   slice[1] = 1111   fmt.Printf(&amp;#34;slice %v, slice3 %v \n&amp;#34;, slice, slice3) } 输出：
slice [0 1 2 3 4], slice3 [1 2 3] slice [0 1111 2 3 4], slice3 [1 2 3] 由此可见，新创建的slice3，不会因为slice和slice2的修改而改变slice3。复制很有用，因此golang实现了一个内建的函数copy， copy有两个参数，第一个参数是复制后的对象，第二个是复制前的数组切片对象。
func main() {   slice := []int{0, 1, 2, 3, 4}  slice2 := slice[1:4]   slice4 := make([]int, len(slice2))   copy(slice4, slice2)   fmt.Printf(&amp;#34;slice %v, slice4 %v \n&amp;#34;, slice, slice4)  slice[1] = 1111  fmt.Printf(&amp;#34;slice %v, slice4 %v \n&amp;#34;, slice, slice4) } slice4是从slice2中copy生成，slice和slice4底层的匿名数组是不一样的。因此修改他们不会影响彼此。
slice 追加 append 简介
创建复制切片都是常用的操作，还有一个追加元素或者追加数组也是很常用的功能。golang提供了append函数用于给切片追加元素。append第一个参数为原切片，随后是一些可变参数，用于将要追加的元素或多个元素。
func main() {   slice := make([]int, 1, 2)  slice[0] = 111   fmt.Printf(&amp;#34;slice %v, slice addr %p, len %d, cap %d \n&amp;#34;, slice, &amp;amp;slice, len(slice), cap(slice))   slice = append(slice, 222)  fmt.Printf(&amp;#34;slice %v, slice addr %p, len %d, cap %d \n&amp;#34;, slice, &amp;amp;slice, len(slice), cap(slice))   slice = append(slice, 333)  fmt.Printf(&amp;#34;slice %v, slice addr %p, len %d, cap %d \n&amp;#34;, slice, &amp;amp;slice, len(slice), cap(slice))  } 输出结果为：
slice [111], slice addr 0xc4200660c0, len 1, cap 2 slice [111 222], slice addr 0xc4200660c0, len 2, cap 2 slice [111 222 333], slice addr 0xc4200660c0, len 3, cap 4 切片容量
无论数组还是切片，都有长度限制。也就是追加切片的时候，如果元素正好在切片的容量范围内，直接在尾部追加一个元素即可。如果超出了最大容量，再追加元素就需要针对底层的数组进行复制和扩容操作了。
这里有一个切片容量的概念，从数组中切数据，切片的容量应该是切片的最后一个数据，和数组剩下元素的大小，再加上现有切片的大小。
数组 [0, 1, 2, 3, 4] 中，数组有5个元素。如果切片 s = [1, 2, 3]，那么3在数组的索引为3，也就是数组还剩最后一个元素的大小，加上s已经有3个元素，因此最后s的容量为 1 &#43; 3 = 4。如果切片是 s1 = [4]，4的索引再数组中是最大的了，数组空余的元素为0，那么s1的容量为 0 &#43; 1 = 1。具体如下表：
切片	切片字面量	数组剩下空间	长度	容量 s[1:3]	[1 2]	2	2	4 s[1:1]	[]	4	0	4 s[4:4]	[]	1	0	1 s[4:5]	[4]	0	1	1 尽管上面的第二个和第三个切片的长度一样，但是他们的容量不一样。容量与最终append的策略有关系。
append简单实现
我们已经知道，切片都依赖底层的数组结构，即使是直接创建的切片，也会生成一个匿名的数组。使用append时候，本质上是针对底层依赖的数组进行操作。如果切片的容量大于长度，给切片追加元素其实是修改底层数中，切片元素后面的元素。如果容量满了，就不能在原来的数组上修改，而是要创建一个新的数组，当然golang是通过创建一个新的切片实现的，因为新切片必然也有一个新的数组，并且这个数组的长度是原来的2倍，使用动态规划算法的简单实现。
func main() {   arr := [3]int{0, 1, 2}   slice := arr[1:2]   fmt.Printf(&amp;#34;arr %v len %d, slice %v len %d, cap %d, \n&amp;#34;, arr, len(arr), slice, len(slice), cap(slice))   slice[0] = 333   fmt.Printf(&amp;#34;arr %v len %d, slice %v len %d, cap %d, \n&amp;#34;, arr, len(arr), slice, len(slice), cap(slice))   slice = append(slice, 4444)   fmt.Printf(&amp;#34;arr %v len %d, slice %v len %d, cap %d, \n&amp;#34;, arr, len(arr), slice, len(slice), cap(slice))   slice = append(slice, 5555)   fmt.Printf(&amp;#34;arr %v len %d, slice %v len %d, cap %d, \n&amp;#34;, arr, len(arr), slice, len(slice), cap(slice))   slice[0] = 333   fmt.Printf(&amp;#34;arr %v len %d, slice %v len %d, cap %d, \n&amp;#34;, arr, len(arr), slice, len(slice), cap(slice)) } 输出：
arr [0 1 2] len 3, slice [1] len 1, cap 2, arr [0 333 2] len 3, slice [333] len 1, cap 2, arr [0 333 444] len 3, slice [333 444] len 2, cap 2, arr [0 333 444] len 3, slice [333 444 555] len 3, cap 4, arr [0 333 444] len 3, slice [333 444 555] len 3, cap 4, 小于容量的append
重输出，我们来画一下这个动态过程的图示：
 &#43;----&#43;----&#43;----&#43; &#43;----&#43;----&#43;----&#43; &#43;----&#43;----&#43;----&#43; | | | | | | | | | | | |  arr | 0 | 1 | 2 | arr | 0 |333 | 2 | arr | 0 |333 |444 | &#43;&amp;mdash;-&#43;&amp;mdash;-&#43;&amp;mdash;-&#43; &#43;&amp;mdash;-&#43;&amp;mdash;-&#43;&amp;mdash;-&#43; &#43;&amp;mdash;-&#43;&amp;mdash;-&#43;&amp;mdash;-&#43; ^ ^ ^ ^ | | | | | | | | | slic0] = 333 | slice = append(slice, 444) &#43;&amp;mdash;-&#43; | &#43;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;&amp;gt; | &#43;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-&amp;gt; | | | | &#43;&amp;ndash;&#43;&amp;ndash;&#43;&amp;mdash;-&#43;&amp;mdash;-&#43; &#43;&amp;ndash;&#43;&amp;ndash;&#43;&amp;mdash;-&#43;&amp;mdash;-&#43; &#43;&amp;ndash;&#43;&amp;ndash;&#43;&amp;mdash;-&#43;&amp;mdash;-&#43; | | | | | | | | | | | | | p | 1 | 2 | | p | 1 | 2 | | p | 2 | 2 | &#43;&amp;mdash;&amp;ndash;&#43;&amp;mdash;-&#43;&amp;mdash;-&#43; &#43;&amp;mdash;&amp;ndash;&#43;&amp;mdash;-&#43;&amp;mdash;-&#43; &#43;&amp;mdash;&amp;ndash;&#43;&amp;mdash;-&#43;&amp;mdash;-&#43;
 slice :=arr[1:2] slice :=arr[1:2] slice :=arr[1:2]  arr 是一个含有三个元素的数组，slice从arr中切了一个元素，由于切片的最后一个元素1是数组的索引是1，距离数组的最大长度还是1，因此slice的容量为2。当修改slice的第一个元素，由于slice底层是arr数组，因此arr的第二个元素也相应被修改。使用append方法给slice追加元素的时候，由于slice的容量还未满，因此等同于扩展了slice指向数组的内容，可以理解为重新切了一个数组内容附给slice，同时修改了数组的内容。
超出容量的append
如果接着append一个元素，那么数组肯定越界。此时append的原理大致如下：
  创建一个新的临时切片t，t的长度和slice切片的长度一样，但是t的容量是slice切片的2倍，一个动态规划的方式。新建切片的时候，底层也创建了一个匿名的数组，数组的长度和切片容量一样。
  复制s里面的元素到t里，即填入匿名数组中。然后把t赋值给slice，现在slice的指向了底层的匿名数组。
  转变成小于容量的append方法。 &#43;&amp;mdash;-&#43;&amp;mdash;-&#43;&amp;mdash;-&#43; &#43;&amp;mdash;-&#43;&amp;mdash;-&#43;&amp;mdash;-&#43;&amp;mdash;-&#43;&amp;mdash;-&#43;&amp;mdash;-&#43; | | | | | | | | | | | arr | 0 |333 |444 | | 333| 444| | | | | &#43;&amp;mdash;-&#43;&amp;mdash;-&#43;&amp;mdash;-&#43; &#43;&amp;mdash;-&#43;&amp;mdash;-&#43;&amp;mdash;-&#43;&amp;mdash;-&#43;&amp;mdash;-&#43;&amp;mdash;-&#43; ^ ^ ^ ^ | | | | | | &#43;&amp;mdash;&amp;ndash;&#43; &#43;&amp;mdash;-&#43; &#43;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;gt; | | | | &#43; &#43;&amp;ndash;&#43;&amp;ndash;&#43;&amp;mdash;-&#43;&amp;mdash;-&#43; &#43;&amp;mdash;&amp;ndash;&#43;&amp;mdash;&amp;ndash;&#43;&amp;mdash;&amp;ndash;&#43; | | | | | | | | | p | 2 | 2 | | p | 2 | 6 | &#43;&amp;mdash;&amp;ndash;&#43;&amp;mdash;-&#43;&amp;mdash;-&#43; &#43;&amp;mdash;&amp;ndash;&#43;&amp;mdash;&amp;ndash;&#43;&amp;mdash;&amp;ndash;&#43;
 slice :=arr[1:2] t := make([]int, len=2, cap=6) &#43; | | | | v &#43;----&#43;----&#43;----&#43;----&#43;----&#43;----&#43; | | | | | | | | 333| 444|555 | | | | &#43;----&#43;----&#43;----&#43;----&#43;----&#43;----&#43; ^ ^ | | &#43;----&#43;----&#43; | | &#43; &#43;-----&#43;-----&#43;-----&#43; | | | | | p | 3 | 6 | &#43;-----&#43;-----&#43;-----&#43; slice = t    上面的图示描述了大于容量的时候append的操作原理。新生成的切片其依赖的数组和原来的数组就没有关系了，因此在修改新的切片元素，旧的数组也不会有关系。至于临时的切片t，将会被golang的gc回收。当然arr或它衍生的切片都没有应用的时候，也会被gc所回收。
slice和array的关系十分密切，通过两者的合理构建，既能实现动态灵活的线性结构，也能提供访问元素的高效性能。当然，这种结构也不是完美无暇，共用底层数组，在部分修改操作的时候，可能带来副作用，同时如果一个很大的数组，那怕只有一个元素被切片应用，那么剩下的数组都不会被垃圾回收，这往往也会带来额外的问题。
作为函数参数的切片 直接改变切片
回到最开始的问题，当函数的参数是切片的时候，到底是传值还是传引用？从changeSlice函数中打出的参数s的地址，可以看出肯定不是传引用，毕竟引用都是一个地址才对。然而changeSlice函数内改变了s的值，也改变了原始变量slice的值，这个看起来像引用的现象，实际上正是我们前面讨论的切片共享底层数组的实现。
即切片传递的时候，传的是数组的值，等效于从原始切片中再切了一次。原始切片slice和参数s切片的底层数组是一样的。因此修改函数内的切片，也就修改了数组。
 &#43;-----&#43;----&#43;-----&#43; | | | | &#43;-----------------------------&#43;| p | 3 | 3 | | &#43; &#43;-----&#43;----&#43;-----&#43; | | | | s | | | | v v &#43;----&#43;----&#43;-----&#43; | | | | arr | 0 | 1 | 2 | &#43;----&#43;----&#43;-----&#43; ^ ^ | | | | &#43;-----------&#43; | | &#43;-&#43;--&#43;----&#43;-----&#43; | | | | | p | 3 | 3 | &#43;----&#43;----&#43;-----&#43; slice  例如下面的代码：
 slice := make([]int, 2, 3)  for i := 0; i &amp;lt; len(slice); i&#43;&#43; {  slice[i] = i  }   fmt.Printf(&amp;#34;slice %v %p \n&amp;#34;, slice, &amp;amp;slice)   ret := changeSlice(slice)  fmt.Printf(&amp;#34;slice %v %p, ret %v \n&amp;#34;, slice, &amp;amp;slice, ret)   ret[1] = 1111   fmt.Printf(&amp;#34;slice %v %p, ret %v \n&amp;#34;, slice, &amp;amp;slice, ret) }  func changeSlice(s []int) []int {  fmt.Printf(&amp;#34;func s %v %p \n&amp;#34;, s, &amp;amp;s)  s = append(s, 3)  return s } 输出：
slice [0 1] 0xc42000a1e0 func s [0 1] 0xc42000a260 slice [0 1] 0xc42000a1e0, ret [0 1 3] slice [0 1111] 0xc42000a1e0, ret [0 1111 3] 从输出可以看出，当slice传递给函数的时候，新建了切片s。在函数中给s进行了append一个元素，由于此时s的容量足够到，并没有生成新的底层数组。当修改返回的ret的时候，ret也共用了底层的数组，因此修改ret的原始，相应的也看到了slice的改变。
append 操作
如果在函数内，append操作超过了原始切片的容量，将会有一个新建底层数组的过程，那么此时再修改函数返回切片，应该不会再影响原始切片。例如下面代码：
 func main() {  slice := make([]int, 2, 2)  for i := 0; i &amp;lt; len(slice); i&#43;&#43; {  slice[i] = i  }   fmt.Printf(&amp;#34;slice %v %p \n&amp;#34;, slice, &amp;amp;slice)   ret := changeSlice(slice)  fmt.Printf(&amp;#34;slice %v %p, ret %v \n&amp;#34;, slice, &amp;amp;slice, ret)   ret[1] = -1111   fmt.Printf(&amp;#34;slice %v %p, ret %v \n&amp;#34;, slice, &amp;amp;slice, ret) }  func changeSlice(s []int) []int {  fmt.Printf(&amp;#34;func s %v %p \n&amp;#34;, s, &amp;amp;s)  s[0] = -1  s = append(s, 3)  s[1] = 1111  return s } 输出：
slice [0 1] 0xc42000a1a0 func s [0 1] 0xc42000a200 slice [-1 1] 0xc42000a1a0, ret [-1 1111 3] slice [-1 1] 0xc42000a1a0, ret [-1 -1111 3] 从输出可以很清楚的看到了我们的猜想。 即函数中先改变s第一个元素的值，由于slice和s都共用了底层数组，因此无论原始切片slice还是ret，第一个元素都是-1.然后append操作之后，因为超出了s的容量，因此会新建底层数组，虽然s变量没变，但是他的底层数组变了，此时修改s第一个元素，并不会影响原始的slice切片。也就是slice[1]还是1，而ret[1]则是-1。最后在外面修改ret[1]为 -1111，也不会影响原始的切片slice。
通过上面的分析，我们大致可以下结论，slice或者array作为函数参数传递的时候，本质是传值而不是传引用。传值的过程复制一个新的切片，这个切片也指向原始变量的底层数组。（个人感觉称之为传切片可能比传值的表述更准确）。函数中无论是直接修改切片，还是append创建新的切片，都是基于共享切片底层数组的情况作为基础。也就是最外面的原始切片是否改变，取决于函数内的操作和切片本身容量。
传引用方式
array和slice作为参数传递的过程基本上是一样的，即传递他们切片。有时候我们需要处理传递引用的形式。golang提供了指针很方便实现类似的功能。
func main() {  slice := []int{0, 1}  fmt.Printf(&amp;#34;slice %v %p \n&amp;#34;, slice, &amp;amp;slice)   changeSlice(&amp;amp;slice)  fmt.Printf(&amp;#34;slice %v %p \n&amp;#34;, slice, &amp;amp;slice)   slice[1] = -1111   fmt.Printf(&amp;#34;slice %v %p \n&amp;#34;, slice, &amp;amp;slice) }  func changeSlice(s *[]int) {  fmt.Printf(&amp;#34;func s %v %p \n&amp;#34;, *s, s)  (*s)[0] = -1  *s = append(*s, 3)  (*s)[1] = 1111 } 输出如下：
slice [0 1] 0xc42000a1e0 func s [0 1] 0xc42000a1e0 slice [-1 1111 3] 0xc42000a1e0 slice [-1 -1111 3] 0xc42000a1e0 从输出可以看到，传递给函数的是slice的指针，函数内对对s的操作本质上都是对slice的操作。并且也可以从函数内打出的s地址看到，至始至终就只有一个切片。虽然在append过程中会出现临时的切片或数组。
总结 golang提供了array和slice两种序列结构。其中array是值类型。slice则是复合类型。slice是基于array实现的。slice的第一个内容为指向数组的指针，然后是其长度和容量。通过array的切片可以切出slice，也可以使用make创建slice，此时golang会生成一个匿名的数组。
因为slice依赖其底层的array，修改slice本质是修改array，而array又是有大小限制，当超过slice的容量，即数组越界的时候，需要通过动态规划的方式创建一个新的数组块。把原有的数据复制到新数组，这个新的array则为slice新的底层依赖。
数组还是切片，在函数中传递的不是引用，是另外一种值类型，即通过原始变量进行切片传入。函数内的操作即对切片的修改操作了。当然，如果为了修改原始变量，可以指定参数的类型为指针类型。传递的就是slice的内存地址。函数内的操作都是根据内存地址找到变量本身。
参考资料：Go 切片：用法和本质
</content>
    </entry>
    
     <entry>
        <title>go 汇编入门 如何学习Golang？万字详文教你Go语言入门</title>
        <url>http://shanks.link/blog/2021/04/04/go-%E6%B1%87%E7%BC%96%E5%85%A5%E9%97%A8-%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0golang%E4%B8%87%E5%AD%97%E8%AF%A6%E6%96%87%E6%95%99%E4%BD%A0go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 作者：ivansli，腾讯开发工程师
 在深入学习 Golang 的 runtime 和标准库实现的时候发现，如果对 Golang 汇编没有一定了解的话，很难深入了解其底层实现机制。在这里整理总结了一份基础的 Golang 汇编入门知识，通过学习之后能够对其底层实现有一定的认识。
 0. 为什么写本文 平时业务中一直使用 PHP 编写代码，但是一直对 Golang 比较感兴趣，闲暇、周末之余会看一些 Go 底层源码。
近日在分析 go 的某些特性底层功能实现时发现：有些又跟 runtime 运行时有关，而要掌握这一部分的话，有一道坎是绕不过去的，那就是 Go 汇编。索性就查阅了很多大佬们写的资料，在阅读之余整理总结了一下，并在这里分享给大家。
 本文使用 Go 版本为 go1.14.1
 1. 为什么需要汇编 众所周知，在计算机的世界里，只有 2 种类型。那就是：0 和 1。
计算机工作是由一系列的机器指令进行驱动的，这些指令又是一组二进制数字，其对应计算机的高低电平。而这些机器指令的集合就是机器语言，这些机器语言在最底层是与硬件一一对应的。
显而易见，这样的机器指令有一个致命的缺点：可阅读性太差（恐怕也只有天才和疯子才有能力把控得了）。
为了解决可读性的问题以及代码编辑的需求，于是就诞生了最接近机器的语言：汇编语言（在我看来，汇编语言更像一种助记符，这些人们容易记住的每一条助记符都映射着一条不容易记住的由 0、1 组成的机器指令。你觉得像不像域名与 IP 地址的关系呢？）。
1.1 程序的编译过程 以 C 语言为例来说，从 hello.c 的源码文件到 hello 可执行文件，经过编译器处理，大致分为几个阶段：
编译器在不同的阶段会做不同的事情，但是有一步是可以确定的，那就是：源码会被编译成汇编，最后才是二进制。
2. 程序与进程 源码经过编译之后，得到一个二进制的可执行文件。文件这两个字也就表明，目前得到的这个文件跟其他文件对比，除了是具有一定的格式（Linux 中是 ELF 格式，即：可运行可链接。executable linkable formate）的二进制组成，并没什么区别。
在 Linux 中文件类型大致分为 7 种：
 b: 块设备文件 c：字符设备文件 d：目录 -：普通文件 l：链接 s：socket p：管道
 通过上面可以看到，可执行文件 main 与源码文件 main.go，都是同一种类型，属于普通文件。（当然了，在 Unix 中有一句很经典的话：一切皆文件）。
那么，问题来了：
 什么是程序？ 什么是进程？ 2.1 程序 维基百科告诉我们：程序是指一组指示计算机或其他具有消息处理能力设备每一步动作的指令，通常用某种程序设计语言编写，运行于某种目标体系结构上。  从某个层面来看，可以把程序分为静态程序、动态程序： 静态程序：单纯的指具有一定格式的可执行二进制文件。 动态程序：则是静态可执行程序文件被加载到内存之后的一种运行时模型（又称为进程）。
2.2 进程 首先，要知道的是，进程是分配系统资源的最小单位，线程(带有时间片的函数)是系统调度的最小单位。进程包含线程，线程所属于进程。
创建进程一般使用 fork 方法(通常会有个拉起程序，先 fork 自身生成一个子进程。然后，在该子进程中通过 exec 函数把对应程序加载进来，进而启动目标进程。当然，实际上要复杂得多)，而创建线程则是使用 pthread 线程库。
以 32 位 Linux 操作系统为例，进程经典的虚拟内存结构模型如下图所示：
其中，有两处结构是静态程序所不具有的，那就是运行时堆(heap)与运行时栈(stack)。
运行时堆从低地址向高地址增长，申请的内存空间需要程序员自己或者由 GC 释放。 运行时栈从高地址向低地址增长，内存空间在当前栈桢调用结束之后自动释放(并不是清除其所占用内存中数据，而是通过栈顶指针 SP 的移动，来标识哪些内存是正在使用的)。
3. Go 汇编 对于 Go 编译器而言，其输出的结果是一种抽象可移植的汇编代码，这种汇编（Go 的汇编是基于 Plan9 的汇编）并不对应某种真实的硬件架构。Go 的汇编器会使用这种伪汇编，再为目标硬件生成具体的机器指令。
伪汇编这一个额外层可以带来很多好处，最主要的一点是方便将 Go 移植到新的架构上。
相关的信息可以参考 Rob Pike 的 The Design of the Go Assembler。
 要了解 Go 的汇编器最重要的是要知道 Go 的汇编器不是对底层机器的直接表示，即 Go 的汇编器没有直&amp;gt;接使用目标机器的汇编指令。Go 汇编器所用的指令，一部分与目标机器的指令一一对应，而另外一部分则不是。这是因为编译器套件不需要汇编器直接参与常规的编译过程。 相反，编译器使用了一种半抽象的指令集，并且部分指令是在代码生成后才被选择的。汇编器基于这种半抽象的形式工作，所以虽然你看到的是一条 MOV 指令，但是工具链针对对这条指令实际生成可能完全不是一个移动指令，也许会是清除或者加载。也有可能精确的对应目标平台上同名的指令。概括来说，特定于机器的指令会&amp;gt;以他们的本尊出现， 然而对于一些通用的操作，如内存的移动以及子程序的调用以及返回通常都做了抽象。细节因架构不同而不一样，我们对这样的不精确性表示歉意，情况并不明确。 汇编器程序的工作是对这样半抽象指令集进行解析并将其转变为可以输入到链接器的指令。 The most important thing to know about Go’s assembler is that it is not a direct representation of the underlying machine. Some of the details map precisely to the machine, but some do not. This is because the compiler suite needs no assembler pass in the usual pipeline. Instead, the compiler operates on a kind of semi-abstract instruction set, and instruction selection occurs partly after code generation. The assembler works on the semi-abstract form, so when you see an instruction like MOV what the toolchain actually generates for that operation might not be a move instruction at all, perhaps a clear or load. Or it might correspond exactly to the machine instruction with that name. In general, machine-specific operations tend to appear as themselves, while more general concepts like memory move and subroutine call and return are more abstract. The details vary with architecture, and we apologize for the imprecision; the situation is not well-defined. The assembler program is a way to parse a description of that semi-abstract instruction set and turn it into instructions to be input to the linker.
 Go 汇编使用的是caller-save模式，被调用函数的入参参数、返回值都由调用者维护、准备。因此，当需要调用一个函数时，需要先将这些工作准备好，才调用下一个函数，另外这些都需要进行内存对齐，对齐的大小是 sizeof(uintptr)。
3.1 几个概念 在深入了解 Go 汇编之前，需要知道的几个概念：
 栈：进程、线程、goroutine 都有自己的调用栈，先进后出（FILO） 栈帧：可以理解是函数调用时，在栈上为函数所分配的内存区域 调用者：caller，比如：A 函数调用了 B 函数，那么 A 就是调用者 被调者：callee，比如：A 函数调用了 B 函数，那么 B 就是被调者 3.2 Go 的核心寄存器 go 汇编中有 4 个核心的伪寄存器，这 4 个寄存器是编译器用来维护上下文、特殊标识等作用的：  ble data-draft-node=&amp;ldquo;block&amp;rdquo; data-draft-type=&amp;ldquo;table&amp;rdquo; data-size=&amp;ldquo;normal&amp;rdquo; data-row-style=&amp;ldquo;normal&amp;rdquo;&amp;gt;
 FP: 使用如 symbol&#43;offset(FP)的方式，引用 callee 函数的入参参数。例如 arg0&#43;0(FP)，arg1&#43;8(FP)，使用 FP 必须加 symbol ，否则无法通过编译(从汇编层面来看，symbol 没有什么用，加 symbol 主要是为了提升代码可读性)。 另外，需要注意的是：往往在编写 go 汇编代码时，要站在 callee 的角度来看(FP)，在 callee 看来，(FP)指向的是 caller 调用 callee 时传递的第一个参数的位置。 假如当前的 callee 函数是 add，在 add 的代码中引用 FP，该 FP 指向的位置不在 callee 的 stack frame 之内。而是在 caller 的 stack frame 上，指向调用 add 函数时传递的第一个参数的位置，经常在 callee 中用symbol&#43;offset(FP)来获取入参的参数值。 SB: 全局静态基指针，一般用在声明函数、全局变量中。 SP: 该寄存器也是最具有迷惑性的寄存器，因为会有伪 SP 寄存器和硬件 SP 寄存器之分。 plan9 的这个伪 SP 寄存器指向当前栈帧第一个局部变量的结束位置(为什么说是结束位置，可以看下面寄存器内存布局图)，使用形如 symbol&#43;offset(SP) 的方式，引用函数的局部变量。offset 的合法取值是 [-framesize, 0)，注意是个左闭右开的区间。假如局部变量都是 8 字节，那么第一个局部变量就可以用 localvar0-8(SP) 来表示。与硬件寄存器 SP 是两个不同的东西，在栈帧 size 为 0 的情况下，伪寄存器 SP 和硬件寄存器 SP 指向同一位置。 手写汇编代码时，如果是 symbol&#43;offset(SP)形式，则表示伪寄存器 SP。如果是 offset(SP)则表示硬件寄存器 SP。 务必注意：对于编译输出(go tool compile -S / go tool objdump)的代码来讲，所有的 SP 都是硬件 SP 寄存器，无论是否带 symbol（这一点非常具有迷惑性，需要慢慢理解。往往在分析编译输出的汇编时，看到的就是硬件 SP 寄存器）。 PC: 实际上就是在体系结构的知识中常见的 pc 寄存器，在 x86 平台下对应 ip 寄存器，amd64 上则是 rip。除了个别跳转之外，手写 plan9 汇编代码时，很少用到 PC 寄存器。 通过上面的讲解，想必已经对 4 个核心寄存器的区别有了一定的认识（或者是更加的迷惑、一头雾水）。那么，需要留意的是：如果是在分析编译输出的汇编代码时，要重点看 SP、SB 寄存器（FP 寄存器在这里是看不到的）。如果是，在手写汇编代码，那么要重点看 FP、SP 寄存器。  3.2.1 伪寄存器的内存模型 下图描述了栈桢与各个寄存器的内存关系模型，值得注意的是要站在 callee 的角度来看。
有一点需要注意的是，return addr 也是在 caller 的栈上的，不过往栈上插 return addr 的过程是由 CALL 指令完成的（在分析汇编时，是看不到关于 addr 相关空间信息的。在分配栈空间时，addr 所占用空间大小不包含在栈帧大小内）。
在 AMD64 环境，伪 PC 寄存器其实是 IP 指令计数器寄存器的别名。伪 FP 寄存器对应的是 caller 函数的帧指针，一般用来访问 callee 函数的入参参数和返回值。伪 SP 栈指针对应的是当前 callee 函数栈帧的底部（不包括参数和返回值部分），一般用于定位局部变量。伪 SP 是一个比较特殊的寄存器，因为还存在一个同名的 SP 真寄存器，真 SP 寄存器对应的是栈的顶部。
在编写 Go 汇编时，当需要区分伪寄存器和真寄存器的时候只需要记住一点：伪寄存器一般需要一个标识符和偏移量为前缀，如果没有标识符前缀则是真寄存器。比如(SP)、&#43;8(SP)没有标识符前缀为真 SP 寄存器，而 a(SP)、b&#43;8(SP)有标识符为前缀表示伪寄存器。
3.2.2 几点说明 我们这里对容易混淆的几点简单进行说明：
 伪 SP 和硬件 SP 不是一回事，在手写汇编代码时，伪 SP 和硬件 SP 的区分方法是看该 SP 前是否有 symbol。如果有 symbol，那么即为伪寄存器，如果没有，那么说明是硬件 SP 寄存器。 伪 SP 和 FP 的相对位置是会变的，所以不应该尝试用伪 SP 寄存器去找那些用 FP&#43;offset 来引用的值，例如函数的入参和返回值。 官方文档中说的伪 SP 指向 stack 的 top，可能是有问题的。其指向的局部变量位置实际上是整个栈的栈底（除 caller BP 之外），所以说 bottom 更合适一些。 在 go tool objdump/go tool compile -S 输出的代码中，是没有伪 SP 和 FP 寄存器的，我们上面说的区分伪 SP 和硬件 SP 寄存器的方法，对于上述两个命令的输出结果是没法使用的。在编译和反汇编的结果中，只有真实的 SP 寄存器。 3.2.3 IA64 和 plan9 的对应关系 在 plan9 汇编里还可以直接使用的 amd64 的通用寄存器，应用代码层面会用到的通用寄存器主要是: rax, rbx, rcx, rdx, rdi, rsi, r8~r15 这些寄存器，虽然 rbp 和 rsp 也可以用，不过 bp 和 sp 会被用来管理栈顶和栈底，最好不要拿来进行运算。  plan9 中使用寄存器不需要带 r 或 e 的前缀，例如 rax，只要写 AX 即可: MOVQ $101, AX = mov rax, 101
下面是通用通用寄存器的名字在 IA64 和 plan9 中的对应关系:
3.3 常用操作指令 下面列出了常用的几个汇编指令（指令后缀Q 说明是 64 位上的汇编指令）
ble data-draft-node=&amp;ldquo;block&amp;rdquo; data-draft-type=&amp;ldquo;table&amp;rdquo; data-size=&amp;ldquo;normal&amp;rdquo; data-row-style=&amp;ldquo;normal&amp;rdquo;&amp;gt;
4. 汇编分析 说了那么多，it is code show time。
4.1 如何输出 Go 汇编 对于写好的 go 源码，生成对应的 Go 汇编，大概有下面几种
  方法 1 先使用 go build -gcflags &amp;ldquo;-N -l&amp;rdquo; main.go 生成对应的可执行二进制文件 再使用 go tool objdump -s &amp;ldquo;main.&amp;rdquo; main 反编译获取对应的汇编 反编译时 &amp;ldquo;main.&amp;rdquo; 表示只输出 main 包中相关的汇编 &amp;ldquo;main.main&amp;rdquo; 则表示只输出 main 包中 main 方法相关的汇编
  方法 2 使用 go tool compile -S -N -l main.go 这种方式直接输出汇编
  方法 3 使用go build -gcflags=&amp;quot;-N -l -S&amp;quot; main.go 直接输出汇编 注意： 在使用这些命令时，加上对应的 flag，否则某些逻辑会被编译器优化掉，而看不到对应完整的汇编代码
   -l 禁止内联 -N 编译时，禁止优化 -S 输出汇编代码
 4.2 Go 汇编示例 go 示例代码
package main  func add(a, b int) int{  sum := 0 // 不设置该局部变量sum，add栈空间大小会是0  sum = a&#43;b  return sum }  func main(){  println(add(1,2)) } 编译 go 源代码，输出汇编
go tool compile -N -l -S main.go 截取主要汇编如下：
&amp;#34;&amp;#34;.add STEXT nosplit size=60 args=0x18 locals=0x10  0x0000 00000 (main.go:3) TEXT &amp;#34;&amp;#34;.add(SB), NOSPLIT, $16-24  0x0000 00000 (main.go:3) SUBQ $16, SP ;;生成add栈空间  0x0004 00004 (main.go:3) MOVQ BP, 8(SP)  0x0009 00009 (main.go:3) LEAQ 8(SP), BP  ;; ...omitted FUNCDATA stuff...  0x000e 00014 (main.go:3) MOVQ $0, &amp;#34;&amp;#34;.~r2&#43;40(SP) ;;初始化返回值  0x0017 00023 (main.go:4) MOVQ $0, &amp;#34;&amp;#34;.sum(SP) ;;局部变量sum赋为0  0x001f 00031 (main.go:5) MOVQ &amp;#34;&amp;#34;.a&#43;24(SP), AX ;;取参数a  0x0024 00036 (main.go:5) ADDQ &amp;#34;&amp;#34;.b&#43;32(SP), AX ;;等价于AX=a&#43;b  0x0029 00041 (main.go:5) MOVQ AX, &amp;#34;&amp;#34;.sum(SP) ;;赋值局部变量sum  0x002d 00045 (main.go:6) MOVQ AX, &amp;#34;&amp;#34;.~r2&#43;40(SP) ;;设置返回值  0x0032 00050 (main.go:6) MOVQ 8(SP), BP  0x0037 00055 (main.go:6) ADDQ $16, SP ;;清除add栈空间  0x003b 00059 (main.go:6) RET  ......  &amp;#34;&amp;#34;.main STEXT size=107 args=0x0 locals=0x28  0x0000 00000 (main.go:9) TEXT &amp;#34;&amp;#34;.main(SB), $40-0  ......  0x000f 00015 (main.go:9) SUBQ $40, SP ;; 生成main栈空间  0x0013 00019 (main.go:9) MOVQ BP, 32(SP)  0x0018 00024 (main.go:9) LEAQ 32(SP), BP  ;; ...omitted FUNCDATA stuff...  0x001d 00029 (main.go:10) MOVQ $1, (SP) ;;add入参：1  0x0025 00037 (main.go:10) MOVQ $2, 8(SP) ;;add入参：2  0x002e 00046 (main.go:10) CALL &amp;#34;&amp;#34;.add(SB) ;;调用add函数  0x0033 00051 (main.go:10) MOVQ 16(SP), AX  0x0038 00056 (main.go:10) MOVQ AX, &amp;#34;&amp;#34;..autotmp_0&#43;24(SP)  0x003d 00061 (main.go:10) CALL runtime.printlock(SB)  0x0042 00066 (main.go:10) MOVQ &amp;#34;&amp;#34;..autotmp_0&#43;24(SP), AX  0x0047 00071 (main.go:10) MOVQ AX, (SP)  0x004b 00075 (main.go:10) CALL runtime.printint(SB)  0x0050 00080 (main.go:10) CALL runtime.printnl(SB)  0x0055 00085 (main.go:10) CALL runtime.printunlock(SB)  0x005a 00090 (main.go:11) MOVQ 32(SP), BP  0x005f 00095 (main.go:11) ADDQ $40, SP ;;清除main栈空间  0x0063 00099 (main.go:11) RET  ...... 这里列举了一个简单的 int 类型加法示例，实际开发中会遇到各种参数类型，要复杂的多，这里只是抛砖引玉 :)
4.3 Go 汇编解析 针对 4.2 输出汇编，对重要核心代码进行分析。
4.3.1 add 函数汇编解析 TEXT &amp;ldquo;&amp;quot;.add(SB), NOSPLIT|ABIInternal, $16-24 TEXT &amp;ldquo;&amp;quot;.add TEXT 指令声明了 &amp;ldquo;&amp;quot;.add 是 .text 代码段的一部分，并表明跟在这个声明后的是函数的函数体。在链接期，&amp;ldquo;&amp;ldquo;这个空字符会被替换为当前的包名: 也就是说，&amp;rdquo;&amp;quot;.add 在链接到二进制文件后会变成 main.add
(SB) SB 是一个虚拟的伪寄存器，保存静态基地址(static-base) 指针，即我们程序地址空间的开始地址。 &amp;ldquo;&amp;quot;.add(SB) 表明我们的符号位于某个固定的相对地址空间起始处的偏移位置 (最终是由链接器计算得到的)。换句话来讲，它有一个直接的绝对地址: 是一个全局的函数符号。
NOSPLIT: 向编译器表明不应该插入 stack-split 的用来检查栈需要扩张的前导指令。 在我们 add 函数的这种情况下，编译器自己帮我们插入了这个标记: 它足够聪明地意识到，由于 add 没有任何局部变量且没有它自己的栈帧，所以一定不会超出当前的栈。不然，每次调用函数时，在这里执行栈检查就是完全浪费 CPU 时间了。
$0-16
如何学习Golang？万字详文教你Go语言入门
24 指定了调用方传入的参数&#43;返回值大小（24 字节=入参 a、b 大小8字节*2&#43;返回值8字节）
 通常来讲，帧大小后一般都跟随着一个参数大小，用减号分隔。(这不是一个减法操作，只是一种特殊的语法) 帧大小 $24-8 意味着这个函数有 24 个字节的帧以及 8 个字节的参数，位于调用者的帧上。如果 NOSPLIT 没有在 TEXT 中指定，则必须提供参数大小。对于 Go 原型的汇编函数，go vet 会检查参数大小是否正确。 In the general case, the frame size is followed by an argument size, separated by a minus sign. (It’s not a subtraction, just idiosyncratic syntax.) The frame size $24-8 states that the function has a 24-byte frame and is called with 8 bytes of argument, which live on the caller’s frame. If NOSPLIT is not specified for the TEXT, the argument size must be provided. For assembly functions with Go prototypes, go vet will check that the argument size is correct.
  SUBQ $16, SP SP 为栈顶指针，该语句等价于 SP-=16（由于栈空间是向下增长的，所以开辟栈空间时为减操作），表示生成 16 字节大小的栈空间。 MOVQ $0, &amp;ldquo;&amp;rdquo;.~r2&#43;40(SP) 此时的 SP 为 add 函数栈的栈顶指针，40(SP)的位置则是 add 返回值的位置，该位置位于 main 函数栈空间内。 该语句设置返回值类型的 0 值，即初始化返回值，防止得到脏数据（返回值类型为 int，int 的 0 值为 0）。 MOVQ &amp;ldquo;&amp;quot;.a&#43;24(SP), AX 从 main 函数栈空间获取入参 a 的值，存到寄存器 AX ADDQ &amp;ldquo;&amp;quot;.b&#43;32(SP), AX 从 main 函数栈空间获取入参 b 的值，与寄存器 AX 中存储的 a 值相加，结果存到 AX。 相当于 AX=a&#43;b MOVQ AX, &amp;ldquo;&amp;rdquo;.~r2&#43;40(SP) 把 a&#43;b 的结果放到 main 函数栈中, add(a&#43;b)返回值所在的位置 ADDQ $16, SP 归还 add 函数占用的栈空间 4.3.2 函数栈桢结构模型 根据 4.2 对应汇编绘制的函数栈桢结构模型  还记得前面提到的，Go 汇编使用的是caller-save模式，被调用函数的参数、返回值、栈位置都需要由调用者维护、准备吗？
在函数栈桢结构中可以看到，add()函数的入参以及返回值都由调用者 main()函数维护。 也正是因为如此，GO 有了其他语言不具有的，支持多个返回值的特性。
4.4 Go 汇编语法 这里重点讲一下函数声明、变量声明。
4.4.1 函数声明 来看一个典型的 Go 汇编函数定义
// func add(a, b int) int // 该add函数声明定义在同一个 package name 下的任意 .go文件中 // 只有函数头，没有实现  // add函数的Go汇编实现 // pkgname 默认是 &amp;#34;&amp;#34; TEXT pkgname·add(SB), NOSPLIT, $16-24  MOVQ a&#43;0(FP), AX  ADDQ b&#43;8(FP), AX  MOVQ AX, ret&#43;16(FP)  RET Go 汇编实现为什么是 TEXT 开头？ 仔细观察上面的进程内存布局图就会发现，我们的代码在是存储在.text 段中的，这里也就是一种约定俗成的起名方式。实际上在 plan9 中 TEXT 是一个指令，用来定义一个函数。
定义中的 pkgname 是可以省略的，(非想写也可以写上，不过写上 pkgname 的话，在重命名 package 之后还需要改代码，默认为&amp;rdquo;&amp;rdquo;) 编译器会在链接器自动加上所属的包名称。
中点 · 比较特殊，是一个 unicode 的中点，该点在 mac 下的输入方法是 option&#43;shift&#43;9。在程序被链接之后，所有的中点·都会被替换为句号.，比如你的方法是runtime·main，在编译之后的程序里的符号则是runtime.main。
简单总结一下, Go 汇编实现函数声明，格式为:
 静态基地址(static-base) 指针  |  | add函数入参&#43;返回值总大小  | | TEXT pkgname·add(SB),NOSPLIT,$16-24  | | | 函数所属包名 函数名 add函数栈帧大小 函数栈帧大小：局部变量&#43;可能需要的额外调用函数的参数空间的总大小，不包括调用其它函数时的 ret address 的大小。 (SB): SB 是一个虚拟寄存器，保存了静态基地址(static-base) 指针，即我们程序地址空间的开始地址。 &amp;ldquo;&amp;quot;.add(SB) 表明我们的符号位于某个固定的相对地址空间起始处的偏移位置 (最终是由链接器计算得到的)。换句话来讲，它有一个直接的绝对地址: 是一个全局的函数符号。 NOSPLIT: 向编译器表明，不应该插入 stack-split 的用来检查栈需要扩张的前导指令。在我们 add 函数的这种情况下，编译器自己帮我们插入了这个标记: 它足够聪明地意识到，add 不会超出当前的栈，因此没必要调用函数时在这里执行栈检查。 4.4.2 变量声明 汇编里的全局变量，一般是存储在.rodata或者.data段中。对应到 Go 代码，就是已初始化过的全局的 const、var 变量/常量。
使用 DATA 结合 GLOBL 来定义一个变量。
DATA 的用法为:
DATA symbol&#43;offset(SB)/width, value 大多数参数都是字面意思，不过这个 offset 需要注意：其含义是该值相对于符号 symbol 的偏移，而不是相对于全局某个地址的偏移。
GLOBL 汇编指令用于定义名为 symbol 的全局变量，变量对应的内存宽度为 width，内存宽度部分必须用常量初始化。
GLOBL ·symbol(SB), width 下面是定义了多个变量的例子:
DATA ·age&#43;0(SB)/4, $8 ;; 数值8为 4字节 GLOBL ·age(SB), RODATA, $4  DATA ·pi&#43;0(SB)/8, $3.1415926 ;; 数值3.1415926为float64, 8字节 GLOBL ·pi(SB), RODATA, $8  DATA ·year&#43;0(SB)/4, $2020 ;; 数值2020为 4字节 GLOBL ·year(SB), RODATA, $4   ;; 变量hello 使用2个DATA来定义 DATA ·hello&#43;0(SB)/8, $&amp;#34;hello my&amp;#34; ;; `hello my` 共8个字节 DATA ·hello&#43;8(SB)/8, $&amp;#34; world&amp;#34; ;; ` world` 共8个字节(3个空格) GLOBL ·hello(SB), RODATA, $16 ;; `hello my world` 共16个字节   DATA ·hello&amp;lt;&amp;gt;&#43;0(SB)/8, $&amp;#34;hello my&amp;#34; ;; `hello my` 共8个字节 DATA ·hello&amp;lt;&amp;gt;&#43;8(SB)/8, $&amp;#34; world&amp;#34; ;; ` world` 共8个字节(3个空格) GLOBL ·hello&amp;lt;&amp;gt;(SB), RODATA, $16 ;; `hello my world` 共16个字节 大部分都比较好理解，不过这里引入了新的标记&amp;lt;&amp;gt;，这个跟在符号名之后，表示该全局变量只在当前文件中生效，类似于 C 语言中的 static。如果在另外文件中引用该变量的话，会报 relocation target not found 的错误。
5. 手写汇编实现功能 在 Go 源码中会看到一些汇编写的代码，这些代码跟其他 go 代码一起组成了整个 go 的底层功能实现。 下面，我们通过一个简单的 Go 汇编代码示例来实现两数相加功能。
5.1 使用 Go 汇编实现 add 函数 Go 代码
package main  func add(a, b int64) int64  func main(){  println(add(2,3)) } Go 源码中 add()函数只有函数签名，没有具体的实现（使用 GO 汇编实现）
使用 Go 汇编实现的 add()函数
TEXT ·add(SB), $0-24 ;; add栈空间为0，入参&#43;返回值大小=24字节  MOVQ x&#43;0(FP), AX ;; 从main中取参数：2  ADDQ y&#43;8(FP), AX ;; 从main中取参数：3   MOVQ AX, ret&#43;16(FP) ;; 保存结果到返回值   RET 把 Go 源码与 Go 汇编编译到一起(我这里，这两个文件在同一个目录)
go build -gcflags &amp;ldquo;-N -l&amp;rdquo; . 我这里目录为 demo1，所以得到可执行程序 demo1，运行得到结果：5
5.2 反编译可执行程序 对 5.1 中得到的可执行程序 demo1 使用 objdump 进行反编译，获取汇编代码
go tool objdump -s &amp;#34;main\.&amp;#34; demo1 得到汇编
&amp;hellip;&amp;hellip;
TEXT main.main(SB) /root/go/src/demo1/main.go  main.go:5 0x4581d0 64488b0c25f8ffffff MOVQ FS:0xfffffff8, CX  main.go:5 0x4581d9 483b6110 CMPQ 0x10(CX), SP  main.go:5 0x4581dd 7655 JBE 0x458234  main.go:5 0x4581df 4883ec28 SUBQ $0x28, SP ;;生成main栈桢  main.go:5 0x4581e3 48896c2420 MOVQ BP, 0x20(SP)  main.go:5 0x4581e8 488d6c2420 LEAQ 0x20(SP), BP  main.go:6 0x4581ed 48c7042402000000 MOVQ $0x2, 0(SP) ;;参数值 2  main.go:6 0x4581f5 48c744240803000000 MOVQ $0x3, 0x8(SP) ;;参数值 3  main.go:6 0x4581fe e83d000000 CALL main.add(SB);;call add  main.go:6 0x458203 488b442410 MOVQ 0x10(SP), AX  main.go:6 0x458208 4889442418 MOVQ AX, 0x18(SP)  main.go:6 0x45820d e8fe2dfdff CALL runtime.printlock(SB)  main.go:6 0x458212 488b442418 MOVQ 0x18(SP), AX  main.go:6 0x458217 48890424 MOVQ AX, 0(SP)  main.go:6 0x45821b e87035fdff CALL runtime.printint(SB)  main.go:6 0x458220 e87b30fdff CALL runtime.printnl(SB)  main.go:6 0x458225 e8662efdff CALL runtime.printunlock(SB)  main.go:7 0x45822a 488b6c2420 MOVQ 0x20(SP), BP  main.go:7 0x45822f 4883c428 ADDQ $0x28, SP  main.go:7 0x458233 c3 RET  main.go:5 0x458234 e89797ffff CALL runtime.morestack_noctxt(SB)  main.go:5 0x458239 eb95 JMP main.main(SB) ;; 反编译得到的汇编与add_amd64.s文件中的汇编大致操作一致 TEXT main.add(SB) /root/go/src/demo1/add_amd64.s add_amd64.s:2 0x458240 488b442408 MOVQ 0x8(SP), AX ;; 获取第一个参数 add_amd64.s:3 0x458245 4803442410 ADDQ 0x10(SP), AX ;;参数a&#43;参数b add_amd64.s:5 0x45824a 4889442418 MOVQ AX, 0x18(SP) ;;保存计算结果 add_amd64.s:7 0x45824f c3 RET 通过上面操作，可知：
 (FP)伪寄存器，只有在编写 Go 汇编代码时使用。FP 伪寄存器指向 caller 传递给 callee 的第一个参数 使用 go tool compile / go tool objdump 得到的汇编中看不到(FP)寄存器的踪影 6. Go 调试工具 这里推荐 2 个 Go 代码调试工具。  6.1 gdb 调试 Go 代码 测试代码
package main  type Ier interface{  add(a, b int) int  sub(a, b int) int }  type data struct{  a, b int }  func (*data) add(a, b int) int{  return a&#43;b }  func (*data) sub(a, b int) int{  return a-b }  func main(){  var t Ier = &amp;amp;data{3,4}   println(t.add(1,2))  println(t.sub(3,2)) } 编译 go build -gcflags &amp;ldquo;-N -l&amp;rdquo; -o main
使用 GDB 调试
&amp;gt; gdb main  GNU gdb (GDB) Red Hat Enterprise Linux 7.6.1-80.el7 Copyright (C) 2013 Free Software Foundation, Inc. License GPLv3&#43;: GNU GPL version 3 or later http://gnu.org/licenses/gpl.html This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type &amp;#34;show copying&amp;#34; and &amp;#34;show warranty&amp;#34; for details. This GDB was configured as &amp;#34;x86_64-redhat-linux-gnu&amp;#34;. For bug reporting instructions, please see: &amp;lt;http://www.gnu.org/software/gdb/bugs/&amp;gt;... Reading symbols from /root/go/src/interface/main...done. Loading Go Runtime support. (gdb) list // 显示源码 14 func (*data) add(a, b int) int{ 15 return a&#43;b 16 } 17 18 func (*data) sub(a, b int) int{ 19 return a-b 20 } 21 22 23 func main(){ (gdb) list 24 var t Ier = &amp;amp;data{3,4} 25 26 println(t.add(1,2)) 27 println(t.sub(3,2)) 28 } 29 (gdb) b 26 // 在源码26行处设置断点 Breakpoint 1 at 0x45827c: file /root/go/src/interface/main.go, line 26. (gdb) r Starting program: /root/go/src/interface/main  Breakpoint 1, main.main () at /root/go/src/interface/main.go:26 26 println(t.add(1,2)) (gdb) info locals // 显示变量 t = {tab = 0x487020 &amp;lt;data,main.Ier&amp;gt;, data = 0xc000096000} (gdb) ptype t // 打印t的结构 type = struct runtime.iface {  runtime.itab *tab;  void *data; } (gdb) p *t.tab.inter // 打印t.tab.inter指针指向的数据 $2 = {typ = {size = 16, ptrdata = 16, hash = 2491815843, tflag = 7 &amp;#39;\a&amp;#39;, align = 8 &amp;#39;\b&amp;#39;, fieldAlign = 8 &amp;#39;\b&amp;#39;,  kind = 20 &amp;#39;\024&amp;#39;, equal = {void (void *, void *, bool *)} 0x466ec0,  gcdata = 0x484351 &amp;#34;\002\003\004\005\006\a\b\t\n\f\r\016\017\020\022\025\026\030\033\034\036\037\&amp;#34;&amp;amp;(,-5&amp;lt;BUXx\216\231\330\335\377&amp;#34;, str = 6568, ptrToThis = 23808}, pkgpath = {bytes = 0x4592b4 &amp;#34;&amp;#34;}, mhdr = []runtime.imethod = {{name = 277,  ityp = 48608}, {name = 649, ityp = 48608}}} (gdb) disass // 显示汇编 Dump of assembler code for function main.main:  0x0000000000458210 &amp;lt;&#43;0&amp;gt;: mov %fs:0xfffffffffffffff8,%rcx  0x0000000000458219 &amp;lt;&#43;9&amp;gt;: cmp 0x10(%rcx),%rsp  0x000000000045821d &amp;lt;&#43;13&amp;gt;: jbe 0x458324 &amp;lt;main.main&#43;276&amp;gt;  0x0000000000458223 &amp;lt;&#43;19&amp;gt;: sub $0x50,%rsp  0x0000000000458227 &amp;lt;&#43;23&amp;gt;: mov %rbp,0x48(%rsp)  0x000000000045822c &amp;lt;&#43;28&amp;gt;: lea 0x48(%rsp),%rbp  0x0000000000458231 &amp;lt;&#43;33&amp;gt;: lea 0x10dc8(%rip),%rax # 0x469000  0x0000000000458238 &amp;lt;&#43;40&amp;gt;: mov %rax,(%rsp)  0x000000000045823c &amp;lt;&#43;44&amp;gt;: callq 0x40a5c0 &amp;lt;runtime.newobject&amp;gt; 常用的 gdb 调试命令
 run continue break backtrace 与 frame info break、locals list 命令 print 和 ptype 命令 disass 除了 gdb，另外推荐一款 gdb 的增强版调试工具 cgdb  https://cgdb.github.io/ 效果如下图所示，分两个窗口：上面显示源代码，下面是具体的命令行调试界面(跟 gdb 一样)：
6.2 delve 调试代码 delve 项目地址
https://github.com/go-delve/delve 带图形化界面的 dlv 项目地址
https://github.com/aarzilli/gdlv dlv 的安装使用，这里不再做过多讲解，感兴趣的可以尝试一下。
gdb 作为调试工具自是不用多说，比较老牌、强大，可以支持多种语言。 delve 则是使用 go 语言开发的，用来调试 go 的工具，功能也是十分强大，打印结果可以显示 gdb 支持不了的东西，这里不再做过多讲解，有兴趣的可以查阅相关资料。 7. 总结 对于 Go 汇编基础大致需要熟悉下面几个方面：
通过上面的例子相信已经让你对 Go 的汇编有了一定的理解。当然，对于大部分业务开发人员来说，只要看的懂即可。如果想进一步的了解，可以阅读相关的资料或者书籍。
最后想说的是：鉴于个人能力有限，在阅读过程中你可能会发现存在的一些问题或者缺陷，欢迎各位大佬指正。如果感兴趣的话，也可以一起私下交流。
参考资料  在整理的过程中，部分参考、引用下面链接地址内容。有一些写的还是不错的，感兴趣的同学可以阅读。
[1] https://github.com/cch123/golang-notes/blob/master/assembly.md plan9 assembly
[2] https://segmentfault.com/a/1190000019753885 汇编入门
[3] https://www.davidwong.fr/goasm/ Go Assembly by Example
[4] https://juejin.im/post/6844904005630443533#heading-3
[5] https://github.com/go-internals-cn/go-internals/blob/master/chapter1_assembly_primer/README.md
[6] https://lrita.github.io/2017/12/12/golang-asm/
[7] https://chai2010.cn/advanced-go-programming-book/ch3-asm/ch3-01-basic.html
</content>
    </entry>
    
     <entry>
        <title>深入浅出Go Runtime</title>
        <url>http://shanks.link/blog/2021/04/04/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAgo-runtime/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 以下内容转载自 yifhao
介绍
基于2019.02发布的go 1.12 linux amd64版本, 主要介绍了Runtime一些原理和实现的一些细节, 对大家容易不容易理解或者网络上很多错误的地方做一些梳理:
  Golang Runtime是个什么? Golang Runtime的发展历程, 每个版本的改进
  Go调度: 协程结构体, 上下文切换, 调度队列, 大致调度流程, 同步执行流又不阻塞线程的网络实现等
  Go内存: 内存结构, mspan结构, 全景图及分配策略等
  Go GC: Golang GC停顿大致的一个发展历程, 三色标记实现的一些细节, 写屏障, 三色状态, 扫描及元信息, 1.12版本相对1.5版本的改进点, GC Pacer等
  实践: 观察调度, GC信息, 一些优化的方式, 几点问题排查的思路, 几个有意思的问题排查
  总结: 贯穿Runtime的思想总结
  这个是我今年8月份在深圳Gopher Meetup做的一个关于runtime的分享, 10月份在Go夜读(项目地址 https://reading.developerlearning.cn) 里也分享了一次
视频地址: https://www.bilibili.com/video/av73297683?seid=596154768710832594
一些问题解答: https://github.com/developer-learning/night-reading-go/issues/492
两个分享都是用的精简版, 这里的把完整版的讲一下, 加一些注语, 注语位于PPT页的下面. (ppt地址 https://github.com/yifhao/share).
序 为什么去了解runtime呢?
  可以解决一些棘手的问题: 在写这个PPT的时候, 就有一位朋友在群里发了个pprof图, 说同事写的代码有问题, CPU利用率很高., 找不出来问题在哪, 我看了下pprof图, 说让他找找是不是有这样用select的, 一查的确是的. 平时也帮同事解决了一些和并发, 调度, GC有关的问题
  好奇心: 大家写久了go, 惊叹于它的简洁, 高性能外, 必然对它是怎么实现的有很多好奇. 协程怎么实现, GC怎么能并发, 对象在内存里是怎么存在的? 等等
  技术深度的一种
  本次分享基于2019.02发布的go 1.12 linux amd64版本, 主要介绍了Runtime实现的一点细节. 水平和精力有限, 必然有问题存在, 有问题欢迎大家给我留言.
Runtime简介及发展 Runtime简介
go的runtime代码在go sdk的runtime目录下.
主要有所述的4块功能. 提到runtime, 大家可能会想起java, python的runtime.
不过go和这两者不太一样, java, python的runtime是虚拟机, 而go的runtime和用户代码一起编译到一个可执行文件中.
用户代码和runtime代码除了代码组织上有界限外, 运行的时候并没有明显的界限.
如上所示, 一些常用的关键字被编译成runtime包下的一些函数调用.
Runtime版本历史
左边标粗的是一些更新比较大的版本. 右边的GC STW仅供参考.
调度
调度简述
goroutine实现
我们去看调度的一个进化, 从进程到线程再到协程, 其实是一个不断共享, 不断减少切换成本的过程. go实现的协程为有栈协程, go协程的用法和线程的用法基本类似. 很多人会疑问, 协程到底是个什么东西? 用户态的调度感觉很陌生, 很抽象, 到底是个什么东西?
我觉得要理解调度, 要理解两个概念: 运行和阻塞. 特别是在协程中, 这两个概念不容易被正确理解. 我们理解概念时往往会代入自身感受, 觉得线程或协程运行就是像我们吭哧吭哧的处理事情, 线程或协程阻塞就是做事情时我们需要等待其他人, 然后就在这等着了. 要是其他人搞好了, 那我们就继续做当前的事. 其实主体对象搞错了. 正确的理解应该是我们处理事情时就像CPU, 而不是像线程或者协程. 假如我当前在写某个服务, 发现依赖别人的函数还没有ready, 那就把写服务这件事放一边. 点开企业微信, 我去和产品沟通一些问题了. 我和产品沟通了一会后, 检查一下, 发现别人已经把依赖的函数提交了, 然后我就最小化企业微信, 切到IDE, 继续写服务A了.
对操作系统有过一些了解, 知道linux下的线程其实是task_struct结构, 线程其实并不是真正运行的实体, 线程只是代表一个执行流和其状态. 真正运行驱动流程往前的其实是CPU. CPU在时钟的驱动下, 根据PC寄存器从程序中取指令和操作数, 从RAM中取数据, 进行计算, 处理, 跳转, 驱动执行流往前. CPU并不关注处理的是线程还是协程, 只需要设置PC寄存器, 设置栈指针等(这些称为上下文), 那么CPU就可以欢快的运行这个线程或者这个协程了.
线程的运行, 其实是被运行. 其阻塞, 其实是切换出调度队列, 不再去调度执行这个执行流. 其他执行流满足其条件, 便会把被移出调度队列的执行流重新放回调度队列.
协程同理, 协程其实也是一个数据结构, 记录了要运行什么函数, 运行到哪里了. go在用户态实现调度, 所以go要有代表协程这种执行流的结构体, 也要有保存和恢复上下文的函数, 运行队列. 理解了阻塞的真正含义, 也就知道能够比较容易理解, 为什么go的锁, channel这些不阻塞线程. 对于实现的同步执行流效果, 又不阻塞线程的网络, 接下来也会介绍.
协程结构体和切换函数 我们go一个func时一般这样写
go func1(arg1 type1,arg2 type2){....}(a1,a2) 一个协程代表了一个执行流, 执行流有需要执行的函数(对应上面的func1), 有函数的入参(a1, a2), 有当前执行流的状态和进度(对应CPU的PC寄存器和SP寄存器), 当然也需要有保存状态的地方, 用于执行流恢复. 真正代表协程的是runtime.g结构体. 每个go func都会编译成runtime.newproc函数, 最终有一个runtime.g对象放入调度队列. 上面的func1函数的指针设置在runtime.g的startfunc字段, 参数会在newproc函数里拷贝到stack中, sched用于保存协程切换时的pc位置和栈位置. 协程切换出去和恢复回来需要保存上下文, 恢复上下文, 这些由以下两个汇编函数实现. 以上就能实现协程这种执行流, 并能进行切换和恢复. (下图中的struct和函数都做了精简)
GM模型及GPM模型
有了协程的这种执行流形式, 那待运行的协程放在哪呢? 在Go1.0的时候:
  调度队列schedt是全局的, 对该队列的操作均需要竞争同一把锁, 导致伸缩性不好.
  新生成的协程也会放入全局的队列, 大概率是被其他m(可以理解为底层线程的一个表示)运行了, 内存亲和性不好. 当前协程A新生成了协程B, 然后协程A比较大概率会结束或者阻塞, 这样m直接去执行协程B, 内存的亲和性也会好很多.
  因为mcache与m绑定, 在一些应用中(比如文件操作或其他可能会阻塞线程的系统调用比较多), m的个数可能会远超过活跃的m个数, 导致比较大的内存浪费..
  那是不是可以给m分配一个队列, 把阻塞的m的mcache给执行go代码的m使用? Go 1.1及以后就是这样做的.
在1.1中调度模型更改为GPM模型, 引入逻辑Process的概念, 表示执行Go代码所需要的资源, 同时也是执行Go代码的最大的并行度. 这个概念可能很多人不知道怎么理解. P涉及到几点, 队列和mcache, 还有P的个数的选取. 首先为什么把全局队列打散, 以及mcache为什么跟随P, 这个在GM模型那一页就讲的比较清楚了. 然后为什么P的个数默认是CPU核数: Go尽量提升性能, 那么在一个n核机器上, 如何能够最大利用CPU性能呢? 当然是同时有n个线程在并行运行中, 把CPU喂饱, 即所有核上一直都有代码在运行. 在go里面, 一个协程运行到阻塞系统调用, 那么这个协程和运行它的线程m, 自然是不再需要CPU的, 也不需要分配go层面的内存. 只有一直在并行运行的go代码才需要这些资源, 即同时有n个go协程在并行执行, 那么就能最大的利用CPU, 这个时候需要的P的个数就是CPU核数. (注意并行和并发的区别)
协程状态及流转 协程的状态其实和线程状态类似,状态转换和发生状态转换的时机如图所示. 还是需要注意: 协程只是一个执行流, 并不是运行实体.
调度
并没有一个一直在运行调度的调度器实体. 当一个协程切换出去或新生成的m, go的运行时从stw中恢复等情况时, 那么接下来就需要发生调度. go的调度是通过线程(m)执行runtime.schedule函数来完成的.
sysmon协程
在linux内核中有一些执行定时任务的线程, 比如定时写回脏页的pdflush, 定期回收内存的kswapd0, 以及每个cpu上都有一个负责负载均衡的migration线程等.
在go运行时中也有类似的协程, sysmon. 功能比较多: 定时从netpoll中获取ready的协程, 进行抢占, 定时GC,打印调度信息,归还内存等定时任务
协作式抢占 go目前(1.12)还没有实现非协作的抢占. 基本流程是sysmon协程标记某个协程运行过久, 需要切换出去, 该协程在运行函数时会检查栈标记, 然后进行切换.
同步执行流不阻塞线程的网络的实现 go写后台最舒服的就是能够以同步写代码的方式操作网络, 但是网络操作不阻塞线程.
主要是结合了非阻塞的fd, epoll以及协程的切换和恢复.
linux提供了网络fd的非阻塞模式, 对于没有ready的非阻塞fd执行网络操作时, linux内核不阻塞线程, 会直接返回EAGAIN, 这个时候将协程状态设置为wait, 然后m去调度其他协程.
go在初始化一个网络fd的时候, 就会把这个fd使用epollctl加入到全局的epoll节点中. 同时放入epoll中的还有polldesc的指针.
func netpollopen(fd uintptr, pd *pollDesc) int32 {  var ev epollevent  ev.events = _EPOLLIN | _EPOLLOUT | _EPOLLRDHUP | _EPOLLET  *(**pollDesc)(unsafe.Pointer(&amp;amp;ev.data)) = pd  return-epollctl(epfd, _EPOLL_CTL_ADD, int32(fd), &amp;amp;ev)  } 在sysmon中, schedule函数中, start the world中等情况下, 会执行netpoll 调用epollwait系统调用.
把ready的网络事件从epoll中取出来, 每个网络事件可以通过前面传入的polldesc获取到阻塞在其上的协程, 以此恢复协程为runnable.
调度相关结构体 图片调度综述 内存分配 内存分配简介 Go的分配采用了类似tcmalloc的结构.
特点: 使用一小块一小块的连续内存页, 进行分配某个范围大小的内存需求.
比如某个连续8KB专门用于分配17-24字节,以此减少内存碎片. 线程拥有一定的cache, 可用于无锁分配.
同时Go对于GC后回收的内存页, 并不是马上归还给操作系统, 而是会延迟归还, 用于满足未来的内存需求.
内存空间结构 在1.10以前go的堆地址空间是线性连续扩展的, 比如在1.10(linux amd64)中, 最大可扩展到512GB.
因为go在gc的时候会根据拿到的指针地址来判断是否位于go的heap的, 以及找到其对应的span, 其判断机制需要gc heap是连续的.
但是连续扩展有个问题, cgo中的代码(尤其是32位系统上)可能会占用未来会用于go heap的内存. 这样在扩展go heap时, mmap出现不连续的地址, 导致运行时throw.
在1.11中, 改用了稀疏索引的方式来管理整体的内存. 可以超过512G内存, 也可以允许内存空间扩展时不连续.
在全局的mheap struct中有个arenas二阶数组, 在linux amd64上,一阶只有一个slot, 二阶有4M个slot, 每个slot指向一个heapArena结构, 每个heapArena结构可以管理64M内存, 所以在新的版本中, go可以管理4M*64M=256TB内存, 即目前64位机器中48bit的寻址总线全部256TB内存.
span机制
前面提到了go的内存分配类似于tcmalloc, 采用了span机制来减少内存碎片.
每个span管理8KB整数倍的内存, 用于分配一定范围的内存需求.
内存分配全景
多层次的分配Cache, 每个P上有一个mcache, mcache会为每个size最多缓存一个span, 用于无锁分配.
全局每个size的span都有一个mcentral, 锁的粒度相对于全局的heap小很多, 每个mcentral可以看成是每个size的span的一个全局后备cache.
在gc完成后, 会把P中的span都flush到mcentral中, 用于清扫后再分配. P有需要span时, 从对应size的mcentral获取. 获取不到再上升到全局的heap.
几种特殊的分配器
对于很小的对象分配, go做了个优化, 把小对象合并, 以移动指针的方式分配.
对于栈内存有stackcache分配, 也有多个层次的分配, 同时stack也有多个不同size.
用于分配stack的内存也是位于go gc heap, 用mspan管理, 不过这个span的状态和用于分配对象的mspan状态不太一样, 为mSpanManual.
我们可以思考一个问题, go的对象是分配在go gc heap中, 并由mcache, mspan, mcentral这些结构管理, 那么mcache, mspan, mcentral这些结构又是哪里管理和分配的呢?
肯定不是自己管理自己. 这些都是由特殊的分配fixalloc分配的, 每种类型有一个fixalloc, 大致原理就是通过mmap从进程空间获取一小块内存(百KB的样子), 然后用来分配这个固定大小的结构.
内存分配综合
GC
Golang GC简述
GC简介
GC并不是个新事物, 使得GC大放光彩的是Java语言.
Golang GC发展 上面是几个比较重要的版本. 左图是根据twitter工程师的数据绘制的(堆比较大), 从1.4的百ms级别的停顿到1.8以后的小于1ms.
右图是我对线上服务(Go 1.11编译)测试的一个结果, 是一个批量拉取数据的服务, 大概3000qps, 服务中发起的rpc调用大概在2w/s. 可以看到大部分情况下GC停顿小于1ms, 偶尔超过一点点.
整体来说golang gc用起来是很舒心的, 几乎不用你关心.
三色标记
go采用的是并发三色标记清除法.
图展示的是一个简单的原理.
有几个问题可以思考一下:
并发情况下, 会不会漏标记对象?
对象的三色状态存放在哪?
如何根据一个对象来找到它引用的对象?
写屏障
GC最基本的就是正确性: 不漏标记对象, 程序还在用的对象都被清除了, 那程序就错误了. 有一点浮动垃圾是允许的.
在并发情况下, 如果没有一些措施来保障, 那可能会有什么问题呢?
看左边的代码和图示, 第2步标记完A对象, A又没有引用对象, 那A变成黑色对象.
在第3步的时候, muator(程序)运行, 把对象C从B转到了A,
第4步, GC继续标记, 扫描B, 此时B没有引用对象, 变成了黑色对象. 我们会发现C对象被漏标记了.
如何解决这个问题? go使用了写屏障, 这里的写屏障是指由编译器生成的一小段代码. 在gc时对指针操作前执行的一小段代码, 和CPU中维护内存一致性的写屏障不太一样哈. 所以有了写屏障后, 第3步, A.obj=C时, 会把C加入写屏障buf. 最终还是会被扫描的.
这里感受一下写屏障具体生成的代码.
我们可以看到在写入指针slot时, 对写屏障是否开启做了判断, 如果开启了, 会跳转到写屏障函数, 执行加入写屏障buf的逻辑.
1.8中写屏障由Dijkstra写屏障改成了混合式写屏障, 使得GC停顿达到了1ms以下.
三色状态
并没有这样一个集合把不同状态对象放到对应集合中. 只是一个逻辑上的意义.
扫描和元信息 gc拿到一个指针, 如何把这个指针指向的对象其引用的子对象都加到扫描队列呢? 而且go还允许内部指针, 似乎更麻烦了.
我们分析一下, 要知道对象引用的子对象, 从对象开始到对象结尾, 把对象那一块内存上是指针的放到扫描队列就好了.
那我们是不是得知道对象有多大, 从哪开始到哪结束, 同时要知道内存上的8个字节, 哪里是指针, 哪里是普通的数据.
首先go的对象是mspan管理的, 我们如果能知道对象属于哪个mspan, 就知道对象多大, 从哪开始, 到哪结束了.
前面我们讲到了areans结构, 可以通过指针加上一定的偏移量, 就知道属于哪个heap arean 64M块. 再通过对64M求余, 结合spans数组, 即可知道属于哪个mspan了.
结合heapArean的bitmap和每8个字节在heapArean中的偏移, 就可知道对象每8个字节是指针还是普通数据(这里的bitmap是在分配对象时根据type信息就设置了, type信息来源于编译器生成)
GC流程
1.5和1.12的GC大致流程相同.
上图是golang官方的ppt里的图, 下图是我根据1.12源码绘制的.
从最坏可能会有百ms的gc停顿到能够稳定在1ms以下, 这之间GC做了很多改进.
右边是我根据官方issues整理的一些比较重要的改进. 1.6的分布式检测, 1.7将栈收缩放到了并发扫描阶段, 1.8的混合写屏障, 1.12更改了mark termination检测算法, mcache flush移除出mark termination等等&amp;hellip;
Golang GC Pacer 大家对并发GC除了怎么保证不漏指针有疑问外, 可能还会疑问, 并发GC如何保证能够跟得上应用程序的分配速度? 会不会分配太快了, GC完全跟不上, 然后OOM?
这个就是Golang GC Pacer的作用.
Go的GC是一种比例GC, 下一次GC结束时的堆大小和上一次GC存活堆大小成比例. 由GOGC控制, 默认100, 即2倍的关系, 200就是3倍, 以此类推.
假如上一次GC完成时, 存活对象1000M, 默认GOGC 100, 那么下次GC会在比较接近但小于2000M的时候(比如1900M)开始, 争取在堆大小达到2000M的时候结束.
这之间留有一定的裕度, 会计算待扫描对象大小(根据历史数据计算)与可分配的裕度的比例, 应用程序分配内存根据该比例进行辅助GC, 如果应用程序分配太快了, 导致credit不够, 那么会被阻塞, 直到后台的mark跟上来了,该比例会随着GC进行不断调整.
GC结束后, 会根据这一次GC的情况来进行负反馈计算, 计算下一次GC开始的阈值. 如何保证按时完成GC呢?
GC完了后, 所有的mspan都需要sweep, 类似于GC的比例, 从GC结束到下一次GC开始之间有一定的堆分配裕度, 会根据还有多少的内存需要清扫, 来计算分配内存时需要清扫的span数这样的一个比例.
实践与总结
** 观察调度** 观察一下调度, 加一些请求.
我们可以看到虽然有1000个连接, 但是go只用了几个线程就能处理了, 表明go的网络的确是由epoll管理的.
runqueue表示的是全局队列待运行协程数量, 后面的数字表示每个P上的待运行协程数.
可以看到待处理的任务并没有增加, 表示虽然请求很多, 但完全能hold住.
同时可以看到, 不同P上有的时候可能任务不均衡, 但是一会后, 任务又均衡了, 表示go的work stealing是有效的.
观察GC
其中一些数据的含义, 在分享的时候没有怎么解释, 不过网上的解释几乎没有能完全解释正确.
我这里敲一下. 其实一般关注堆大小和两个stw的wall time即可.
gc 8913(第8913次gc) @2163.341s(在程序运行的第2163s) 1%(gc所有work消耗的历史累计CPU比例, 所以其实这个数据没太大意义) 0.13(第一个stw的wall time)&#43;14(并发mark的wall time)&#43;0.20(第二个stw的wall time) ms clock, 1.1(第一个stw消耗的CPU时间)&#43;21(用户程序辅助扫描消耗的cpu时间)/22(分配用于mark的P消耗的cpu时间)/0(空闲的P用于mark的cpu时间)&#43;1.6ms(第2个stw的cpu时间) cpu, 147(gc开始时的堆大小)-&amp;gt;149(gc结束的堆大小)-&amp;gt;75MB(gc结束时的存活堆大小), 151 MB goal(本次gc预计结束的堆大小), 8P(8个P)
优化 个人建议, 没事不要总想着优化, 好好curd就好.
当然还是有一些优化方法的..
一点实践
我们将pprof的开启集成到模板中, 并自动选择端口, 并集成了gops工具, 方便查询runtime信息, 同时在浏览器上可直接点击生成火焰图, pprof图, 非常的方便, 也不需要使用者关心.
问题排查的一点思路
一次有意思的问题排查
负载, 依赖服务都很正常, CPU利用率也不高, 请求也不多, 就是有很多超时.
该服务在线上打印了debug日志, 因为早期的服务模板开启了gctrace, 框架把stdout重定向到一个文件了. 而输出gctrace时本来是到console的, 输出到文件了, 而磁盘跟不上, 导致gctrace日志被阻塞了.
这里更正一下ppt中的内容, 并不是因为gc没完成而导致其他协程不能运行, 而是后续gc无法开启, 导致实质上的stw. 打印gc trace日志时, 已经start the world了, 其他协程可以开始运行了. 但是在打印gctrace日志时, 还保持着开启gc需要的锁, 所以, 打印gc trace日志一直没完成, 而gc又比较频繁, 比如0.1s一次, 这样会导致下一次gc开始时无法获取锁, 每一个进入gc检查的p阻塞, 实际上就造成了stw.
Runtime的一点个人总结 并行, 纵向多层次, 横向多个class, 缓存, 缓冲, 均衡.
参考文档
</content>
    </entry>
    
     <entry>
        <title>Goroutine 的切换过程涉及了什么</title>
        <url>http://shanks.link/blog/2021/04/04/goroutine-%E7%9A%84%E5%88%87%E6%8D%A2%E8%BF%87%E7%A8%8B%E6%B6%89%E5%8F%8A%E4%BA%86%E4%BB%80%E4%B9%88/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> GCTT:anxk Go语言中文网 
点击上方蓝色“Go语言中文网”关注，每天一起学 Go
Illustration created for “A Journey With Go”, made from the original Go Gopher, created by Renee French.
本文基于 Go 1.13 版本。
Goroutine 很轻，它只需要 2Kb 的内存堆栈即可运行。另外，它们运行起来也很廉价，将一个 Goroutine 切换到另一个的过程不牵涉到很多的操作。在深入 Goroutine 切换过程之前，让我们回顾一下 Goroutine 的切换在更高的层次上是如何进行的。
在继续阅读本文之前，我强烈建议您阅读我的文章 Go：Goroutine、操作系统线程和 CPU 管理[1] 以了解本文中涉及的一些概念。
案例 Go 根据两种断点将 Goroutine 调度到线程上：
  当 Goroutine 因为系统调用、互斥锁或通道而被阻塞时，goroutine 将进入睡眠模式（等待队列），并允许 Go 调度运行另一个处于就绪状态的 goroutine；
  在函数调用时，如果 Goroutine 必须增加其堆栈，这会使 Go 调度另一个 Goroutine 以避免运行中的 Goroutine 独占 CPU 时间片；
  在这两种情况下，运行调度程序的 g0 会替换当前的 goroutine，然后选出下一个将要运行的 Goroutine 替换 g0 并在线程上运行。
有关 g0 的更多信息，建议您阅读我的文章 Go：特殊的 Goroutine g0[2]。
将一个运行中的 Goroutine 切换到另一个的过程涉及到两个切换：
 将运行中的 g 切换到 g0：  !()[https://img-blog.csdnimg.cn/img_convert/8e94cc30b8ff144c738b4d9848091bd9.png]
将 g0 切换到下一个将要运行的 g：
图片
在 Go 中，goroutine 的切换相当轻便，其中需要保存的状态仅仅涉及以下两个：
  Goroutine 在停止运行前执行的指令，程序当前要运行的指令是记录在程序计数器（PC）中的， Goroutine 稍后将在同一指令处恢复运行；
  Goroutine 的堆栈，以便在再次运行时还原局部变量；
  让我们看看实际情况下的切换是怎样进行的。
程序计数器 这里通过基于通道的 生产者/消费者模式 来举例说明，其中一个 Goroutine 产生数据，而另一些则消费数据，代码如下：
消费者仅仅是打印从 0 到 99 的偶数。我们将注意力放在第一个 goroutine（生产者）上，它将数字添加到缓冲区。当缓冲区已满时，它将在发送消息时被阻塞。此时，Go 必须切换到 g0 并调度另一个 Goroutine 来运行。
如前所述，Go 首先需要保存当前执行的指令，以便稍后在同一条指令上恢复 goroutine。程序计数器（PC）保存在 Goroutine 的内部结构中：
可以通过 go tool objdump 命令找到对应的指令及其地址，这是生产者的指令：
程序逐条指令的执行直到在函数 runtime.chansend1 处阻塞在通道上。Go 将当前程序计数器保存到当前 Goroutine 的内部属性中。在我们的示例中，Go 使用运行时的内部地址 0x4268d0 和方法 runtime.chansend1 保存程序计数器：
然后，当 g0 唤醒 Goroutine 时，它将在同一指令处继续执行，继续将数值循环的推入通道。现在，让我们将视线移到 Goroutine 切换期间堆栈的管理。
堆栈 在被阻塞之前，正在运行的 Goroutine 具有其原始堆栈，该堆栈包含临时存储器，例如变量 i：
然后，当它在通道上阻塞时，goroutine 将切换到 g0 及其堆栈（更大的堆栈）：
在切换之前，堆栈将被保存，以便在 Goroutine 再次运行时进行恢复：
现在，我们对 Goroutine 切换中涉及的不同操作有了一个完整的了解，让我们继续看看它是如何影响性能的。
我们应该注意，诸如 arm 等 CPU 架构需要再保存一个寄存器，即 LR 链接寄存器。
性能 我们仍然使用上述的程序来测量一次切换所需的时间。但是，由于切换时间取决于寻找下一个要调度的 Goroutine 所花费的时间，因此无法提供完美的性能视图。在函数调用情况下进行的切换要比阻塞在通道上的切换执行更多的操作，这也会影响到性能。
让我们总结一下我们将要测量的操作：
  当前 g 阻塞在通道上并切换到 g0：
  PC 和堆栈指针一起保存在内部结构中
  将 g0 设置为正在运行的 goroutine
  g0 的堆栈替换当前堆栈
    g0 寻找新的 Goroutine 来运行；
  g0 使用所选的 Goroutine 进行切换：
  PC 和堆栈指针是从其内部结构中获取的
  程序跳转到对应的 PC 地址
    结果如下：
从 g 到 g0 或从 g0 到 g 的切换是相当迅速的，它们只包含少量固定的指令。相反，对于调度阶段，调度程序需要检查许多资源以便确定下一个要运行的 goroutine，根据程序的不同，此阶段可能会花费更多的时间。
该基准测试给出了性能的数量级估计，由于没有标准的工具可以衡量它，所以我们并不能完全依赖于这个结果。此外，性能也取决于 CPU 架构、机器（本文使用的机器是 Mac 2.9 GHz 双核 Intel Core i5）以及正在运行的程序。 via: https://medium.com/a-journey-with-go/go-what-does-a-goroutine-switch-actually-involve-394c202dddb7
作者：Vincent Blanchon[3]译者：anxk[4]校对：polaris1119[5]
本文由 GCTT[6] 原创编译，Go 中文网[7] 荣誉推出
参考资料 Go：Goroutine、操作系统线程和 CPU 管理: https://medium.com/a-journey-with-go/go-goroutine-os-thread-and-cpu-management-2f5a5eaf518a
Go：特殊的 Goroutine g0: https://medium.com/a-journey-with-go/go-g0-special-goroutine-8c778c6704d8
Vincent Blanchon: https://medium.com/@blanchon.vincent
anxk: https://github.com/anxk
polaris1119: https://github.com/polaris1119
GCTT: https://github.com/studygolang/GCTT
Go 中文网: https://studygolang.com/
</content>
    </entry>
    
     <entry>
        <title>Go：Goroutine, OS线程 以及 CPU管理</title>
        <url>http://shanks.link/blog/2021/04/04/gogoroutine-os%E7%BA%BF%E7%A8%8B-%E4%BB%A5%E5%8F%8A-cpu%E7%AE%A1%E7%90%86/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 中文翻译 英文原文
操作系统的线程创建以及切换是需要开销的，会影响程序的性能。Go致力于尽可能地从内核中获取优势，所以从最开始的时候设计就考虑到了并发性。
M，P，G 编排 为了解决这个问题，Go有他自己的调度者，负责在线程上分配goroutines。这个协调者由3个概念组成，如下：
The main concepts are: G - goroutine. M - worker thread, or machine. 工作线程或机器 P - processor, a resource that is required to execute Go code.  M must have an associated P to execute Go code[...].  处理者，负责执行Go代码， 每个M必须有一个关联的P去执行Go代码 三者关系图如下：
每一个goruntine（G）运行在操作系统线程（M）上并分配一个逻辑CPU（P）。我们用一个简单的例子来看看Go是如何管理他们的：
func main() {  var wg sync.WaitGroup  wg.Add(2)   go func() {  println(`hello`)  wg.Done()  }()   go func() {  println(`world`)  wg.Done()  }()   wg.Wait() } Go首先会基于机器逻辑CPUs的数量来创建不同的P，并将他们储存成一个空闲的P的列表
然后，当新的goroutine或者goroutine准备运行的时候会唤醒一个空闲的P，这个P会创建一个关联到操作系统线程的M
然而，当P，M不工作的，假如，没有goruntine在等待被执行的时候，就会返回一个系统调用syscall，或者甚至被垃圾回收强制停止，放回空闲P/M链表中。
在程序运行时候，Go已经创建了一些OS线程以及关联上M。在我们的例子中，第一个负责打印hello的goroutine会使用主goroutine， 而第二个goroutine从空闲列表中获取一个P和M
现在我们已经对goroutines以及线程管理有一个大概了解了，让我们看看在什么时候Go会出现M数量比P多的情况以及goroutines是如何管理这种系统调用的。
系统调用 System calls Go通过在运行时封装系统调用来进行优化，无论阻塞与否。这个封装会自动将P与M的关联切断，然后允许第二个线程M来运行P。我们来看看下面一个读取文件例子：
func main() {  buf := make([]byte, 0, 2)   fd, _ := os.Open(&amp;#34;number.txt&amp;#34;)  fd.Read(buf)  fd.Close()   println(string(buf)) // 42 } 下面是图片演示整个执行过程
P0现在在空闲列表中处于可被使用状态。一旦系统调用退出时，Go遵循下面的规制直到其中一个条件满足
 尝试去获得一个一模一样的P，在我们的例子中就是P0，然后恢复执行 尝试获取空闲列表中的P，然后恢复执行 将goroutine到全局队列中，然后将其关联的M放回到空闲列表中 然而，Go同样需要处理当资源还没准备好的情况，例如HTTP请求这种非阻塞I/O。在这种情况下，第一个系统调用，同样会遵循上述规制但是不会成功，因为资源还没有准备好，这时会强迫Go使用network poller以及暂停goroutine。如下例子：  func main() {  http.Get(`https://httpstat.us/200`) } 当第一个系统调用执行完成并明确地说资源还没准备好的时候，goroutine会暂停直到network poller通知其说资源已经准备好了。在这种情况下，线程M是不会被阻塞的。
当Go协调程序重新查找待完成工作时，goroutine会被重新执行一次。这个协调者在成功获取一个他所等待的消息以后，会问network poller是否有goroutine在等待运行。
如果有多于一个goroutine准备好的时候，其余的goroutine会进入全局的可执行队列中等待被执行。
OS线程的限制 Restriction in term of OS threads 当系统调用时，Go不会限制可以阻塞的OS线程的数量，官方解释：
GOMAXPROCS变量限制了可以同时执行用户级Go代码的操作系统线程的数量。 对于代表Go代码的系统调用中可以阻止的线程数量没有限制； GOMAXPROCS函数可查询并更改限制。
这段代码解释这个情况
func main() {  var wg sync.WaitGroup   for i := 0;i &amp;lt; 100 ;i&#43;&#43; {  wg.Add(1)   go func() {  http.Get(`https://httpstat.us/200?sleep=10000`)   wg.Done()  }()  }   wg.Wait() } 下面是跟踪工具里面展示的线程数量
由于Go将线程的使用进行了优化，当goroutines被阻塞时候可以被重新利用，也就解释了为什么这个数与循环数并不匹配。
</content>
    </entry>
    
     <entry>
        <title>go g0,特殊的Goroutinue</title>
        <url>http://shanks.link/blog/2021/04/04/go-g0%E7%89%B9%E6%AE%8A%E7%9A%84goroutinue/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原文链接
ℹ️ 这篇文章基于 Go 1.13。
在 Go 中创建的所有 Goroutine 都会被一个内部的调度器所管理。Go 调度器尝试为所有的 Goroutine 分配运行时间，并且在当前的 Goroutine 阻塞或者终止的时候，Go 调度器会通过运行 Goroutine 的方式使所有 CPU 保持忙碌状态。这个调度器实际上是作为一个特殊的 Goroutine 运行的。
调度 goroutine Go 使用 GOMAXPROCS 变量限制同时运行的 OS 线程数量，这意味着 Go 必须对每个运行着的线程上的 Goroutine 进行调度和管理。这个调度的功能被委托给了一个叫做 g0 的特殊的 goroutine， g0 是为每个 OS 线程创建的第一个 goroutine：
之后，g0 会把就绪状态的 Goroutine 调度到线程上去运行。
我建议你阅读我的文章“ Go：Goroutine，OS 线程和 CPU 管理”，来了解更多关于 P，M，G 模型的信息。
为了更好的理解 g0 的调度策略，来回顾下 channel 的用法。下面是一个 Goroutine 在向 channel 发送数据是阻塞的例子：
ch := make(chan int) [...] ch &amp;lt;- v 当在 channel 上阻塞时，当前的 Goroutine 会被停放（ parked ），即处于等待状态（ waiting mode ），并且不会被放在任何 Goroutine 队列中：
之后，g0 会替换 Goroutine 并进行一轮调度：
本地队列在调度过程中具有优先级，2 号 Goroutine 会被运行： 我建议你阅读我的文章“ Go: Go 调度器中的工作窃取（Work-Stealing）” 来了解更多关于调度优先级的细节。
一旦有接收者读取 channel 中的数据，7 号 Goroutine 就会解除阻塞状态：
v := &amp;lt;-ch 收到消息的 Goroutine 会切换到 g0，并且通过放入本地队列的方式将该 Goroutine 从停放状态解锁：
虽然这个特殊的 Goroutine 管理调度策略，但这并不是它唯一的工作，它还负责着更多的工作。
职责 与普通 Goroutine 不同的是，g0 有着固定且更大的栈，这使得在需要更大的栈的时候，以及栈不宜增长的时候，Go 可以进行操作。在 g0 的职责中，我们可以列出：
 Goroutine 创建。当调用 go func(){ &amp;hellip; }() 或 go myFunction() 时，Go 会在把它们放入本地队列前，将函数的创建委托给 g0 去做：   新创建的 Goroutine 优先运行，并且被放在本地队列的顶部。
建议阅读我的文章“Go：并发与调度器亲和性（ Go: Concurrency &amp;amp; Scheduler Affinity ）”了解更多关于 Goroutine 优先级的信息。
 defer 函数分配。 垃圾收集操作，比如 STW（ stopping the world ），扫描 Goroutine 的栈，以及一些标记清理操作。 栈增长。当需要的时候，Go 会增加 Goroutine 的大小。这个操作是由 g0 的 prolog 函数完成的。 这个特殊的 Goroutine 涉及许多其他操作（较大空间的对象分配，cgo 等），需要较大的栈来保证我们的程序进行更高效的管理操作，以保持程序的低内存打印效率。  via: https://medium.com/a-journey-with-go/go-g0-special-goroutine-8c778c6704d8
作者：Vincent Blanchon 译者：dust347 校对：polaris1119
本文由 GCTT 原创编译，Go语言中文网 荣誉推出
本文由 GCTT 原创翻译，Go语言中文网 首发。也想加入译者行列，为开源做一些自己的贡献么？欢迎加入 GCTT！ 翻译工作和译文发表仅用于学习和交流目的，翻译工作遵照 CC-BY-NC-SA 协议规定，如果我们的工作有侵犯到您的权益，请及时联系我们。 欢迎遵照 CC-BY-NC-SA 协议规定 转载，敬请在正文中标注并保留原文/译文链接和作者/译者等信息。 文章仅代表作者的知识和看法，如有不同观点，请楼下排队吐槽
</content>
    </entry>
    
     <entry>
        <title>Goroutine 数量控制在多少合适，会影响 GC 和调度？</title>
        <url>http://shanks.link/blog/2021/04/04/goroutine-%E6%95%B0%E9%87%8F%E6%8E%A7%E5%88%B6%E5%9C%A8%E5%A4%9A%E5%B0%91%E5%90%88%E9%80%82%E4%BC%9A%E5%BD%B1%E5%93%8D-gc-%E5%92%8C%E8%B0%83%E5%BA%A6/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 大家好，我是煎鱼。
前几天在读者交流群里看到一位小伙伴，发出了一个致命提问，那就是：“单机的 goroutine 数量控制在多少比较合适？”。
也许你和群内小伙伴第一反应一样，会答复 “控制多少，我觉得没有定论”。
紧接着延伸出了更进一步的疑惑：“goroutine 太多了会影响 gc 和调度吧，主要是怎么预算这个数是合理的呢？”
这是本文要进行探讨的主体，因此本文的结构会是先探索基础知识，再一步步揭开，深入理解这个问题。
Goroutine 是什么 Go 语言作为一个新生编程语言，其令人喜爱的特性之一就是 goroutine。Goroutine 是一个由 Go 运行时管理的轻量级线程，一般称其为 “协程”。
go f(x, y, z) 操作系统本身是无法明确感知到 Goroutine 的存在的，Goroutine 的操作和切换归属于 “用户态” 中。
Goroutine 由特定的调度模式来控制，以 “多路复用” 的形式运行在操作系统为 Go 程序分配的几个系统线程上。
同时创建 Goroutine 的开销很小，初始只需要 2-4k 的栈空间。Goroutine 本身会根据实际使用情况进行自伸缩，非常轻量。
func say(s string) {  for i := 0; i &amp;lt; 9999999; i&#43;&#43; {  time.Sleep(100 * time.Millisecond)  fmt.Println(s)  } }  func main() {  go say(&amp;#34;煎鱼&amp;#34;)  say(&amp;#34;你好&amp;#34;) } 人称可以开几百几千万个的协程小霸王，是 Go 语言的得意之作之一。
调度是什么 既然有了用户态的代表 Goroutine，操作系统又看不到他。必然需要有某个东西去管理他，才能更好的运作起来。
这指的就是 Go 语言中的调度，最常见、面试最爱问的 GMP 模型。因此接下来将会给大家介绍一下 Go 调度的基础知识和流程。
下述内容摘自煎鱼和 p 神写的《Go 语言编程之旅》中的章节内容。
调度基础知识 Go scheduler 的主要功能是针对在处理器上运行的 OS 线程分发可运行的 Goroutine，而我们一提到调度器，就离不开三个经常被提到的缩写，分别是：
  G：Goroutine，实际上我们每次调用 go func 就是生成了一个 G。
  P：Processor，处理器，一般 P 的数量就是处理器的核数，可以通过 GOMAXPROCS 进行修改。
  M：Machine，系统线程。
  这三者交互实际来源于 Go 的 M: N 调度模型。也就是 M 必须与 P 进行绑定，然后不断地在 M 上循环寻找可运行的 G 来执行相应的任务。
调度流程 我们以 GMP 模型的工作流程图进行简单分析，官方图如下:
  当我们执行 go func() 时，实际上就是创建一个全新的 Goroutine，我们称它为 G。
  新创建的 G 会被放入 P 的本地队列（Local Queue）或全局队列（Global Queue）中，准备下一步的动作。需要注意的一点，这里的 P 指的是创建 G 的 P。
  唤醒或创建 M 以便执行 G。
  不断地进行事件循环
  寻找在可用状态下的 G 进行执行任务
  清除后，重新进入事件循环
  在描述中有提到全局和本地这两类队列，其实在功能上来讲都是用于存放正在等待运行的 G，但是不同点在于，本地队列有数量限制，不允许超过 256 个。
并且在新建 G 时，会优先选择 P 的本地队列，如果本地队列满了，则将 P 的本地队列的一半的 G 移动到全局队列。
这可以理解为调度资源的共享和再平衡。
窃取行为 我们可以看到图上有 steal 行为，这是用来做什么的呢，我们都知道当你创建新的 G 或者 G 变成可运行状态时，它会被推送加入到当前 P 的本地队列中。
其实当 P 执行 G 完毕后，它也会 “干活”，它会将其从本地队列中弹出 G，同时会检查当前本地队列是否为空，如果为空会随机的从其他 P 的本地队列中尝试窃取一半可运行的 G 到自己的名下。
官方图如下：
在这个例子中，P2 在本地队列中找不到可以运行的 G，它会执行 work-stealing 调度算法，随机选择其它的处理器 P1，并从 P1 的本地队列中窃取了三个 G 到它自己的本地队列中去。
至此，P1、P2 都拥有了可运行的 G，P1 多余的 G 也不会被浪费，调度资源将会更加平均的在多个处理器中流转。
有没有什么限制 在前面的内容中，我们针对 Go 的调度模型和 Goroutine 做了一个基本介绍和分享。
接下来我们回到主题，思考 “goroutine 太多了，会不会有什么影响”。
在了解 GMP 的基础知识后，我们要知道在协程的运行过程中，真正干活的 GPM 又分别被什么约束？
煎鱼带大家分别从 GMP 来逐步分析。
M 的限制 第一，要知道在协程的执行中，真正干活的是 GPM 中的哪一个？
那势必是 M（系统线程） 了，因为 G 是用户态上的东西，最终执行都是得映射，对应到 M 这一个系统线程上去运行。
那么 M 有没有限制呢？
答案是：有的。在 Go 语言中，**M 的默认数量限制是 10000，**如果超出则会报错：
GO: runtime: program exceeds 10000-thread limit 通常只有在 Goroutine 出现阻塞操作的情况下，才会遇到这种情况。这可能也预示着你的程序有问题。
若确切是需要那么多，还可以通过 debug.SetMaxThreads 方法进行设置。
G 的限制 第二，那 G 呢，Goroutine 的创建数量是否有限制？
答案是：没有。但理论上会受内存的影响，假设一个 Goroutine 创建需要 4k（via @GoWKH）：
  4k * 80,000 = 320,000k ≈ 0.3G内存
  4k * 1,000,000 = 4,000,000k ≈ 4G内存
  以此就可以相对计算出来一台单机在通俗情况下，所能够创建 Goroutine 的大概数量级别。
注：Goroutine 创建所需申请的 2-4k 是需要连续的内存块。
P 的限制 第三，那 P 呢，P 的数量是否有限制，受什么影响？
答案是：有限制。# P 的数量受环境变量 GOMAXPROCS 的直接影响。 #
环境变量 GOMAXPROCS 又是什么？在 Go 语言中，通过设置 GOMAXPROCS，用户可以调整调度中 P（Processor）的数量。
另一个重点在于，与 P 相关联的的 M（系统线程），是需要绑定 P 才能进行具体的任务执行的，因此 P 的多少会影响到 Go 程序的运行表现。
P 的数量基本是受本机的核数影响，没必要太过度纠结他。
那 P 的数量是否会影响 Goroutine 的数量创建呢？
答案是：不影响。且 Goroutine 多了少了，P 也该干嘛干嘛，不会带来灾难性问题。
何为之合理 在介绍完 GMP 各自的限制后，我们回到一个重点，就是 “Goroutine 数量怎么预算，才叫合理？”。
“合理” 这个词，是需要看具体场景来定义的，可结合上述对 GPM 的学习和了解。得出：
M：有限制，默认数量限制是 10000，可调整。
G：没限制，但受内存影响。
P：受本机的核数影响，可大可小，不影响 G 的数量创建。
Goroutine 数量在 MG 的可控限额以下，多个把个、几十个，少几个其实没有什么影响，就可以称其为 “合理”。
真实情况 在真实的应用场景中，没法如此简单的定义。如果你 Goroutine：
在频繁请求 HTTP，MySQL，打开文件等，那假设短时间内有几十万个协程在跑，那肯定就不大合理了（可能会导致 too many files open）。
常见的 Goroutine 泄露所导致的 CPU、Memory 上涨等，还是得看你的 Goroutine 里具体在跑什么东西。
还是得看 Goroutine 里面跑的是什么东西。
总结 在这篇文章中，分别介绍了 Goroutine、GMP、调度模型的基本知识，针对如下问题进行了展开：
单机的 goroutine 数量控制在多少比较合适？
goroutine 太多了会影响 gc 和调度吧，主要是怎么预算这个数是合理的呢？
单机的 goroutine 数量只要控制在限额以下的，都可以认为是 “合理”。
真实场景得看具体里面跑的是什么，跑的如果是 “资源怪兽”，只运行几个 Goroutine 都可以跑死。
因此想定义 “预算”，就得看跑的什么了。
</content>
    </entry>
    
     <entry>
        <title>go高效内存分配</title>
        <url>http://shanks.link/blog/2021/04/04/go%E9%AB%98%E6%95%88%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原文链接
手动内存管理真的很坑爹(如C C&#43;&#43;)，好在我们有强大的自动化系统能够管理内存分配和生命周期，从而解放我们的双手。
但是呢，如果你想通过调整JVM垃圾回收器参数或者是优化go代码的内存分配模式话来解决问题的话，这是远远不够的。自动化的内存管理帮我们规避了大部分的错误，但这只是故事的一半。我们必须要合理有效构建我们的软件，这样垃圾回收系统可以有效工作。
在构建高性能go服务Centrifuge时我们学习到的内存相关的东西，在这里进行分享。Centrifuge每秒钟可以处理成百上千的事件。Centrifuge是Segment公司基础设施的关键部分。一致性、行为可预测是必须的。整洁、高效和精确的使用内存是实现一致性的重要部分。
这篇文章，我们将介绍导致低效率和与内存分配相关的生产意外的常见模式，以及消除这些问题的实用方法。我们会专注于分配器的核心机制，为广大开发人员提供一种处理内存使用的方法。
使用工具 首先我们建议的是避免过早进行优化。Go提供了出色的分析工具，能够直接指向内存分配密集的代码部分。没有必要重新造轮子，我们直接参考Go官方这篇文章即可。它为使用pprof进行CPU和分配分析提供了可靠的demo。我们在Segment中用于查找生产Go代码中的瓶颈的工具就是它，学会使用pprof是基本要求。
另外，使用数据去推动你的优化。
# 逃逸分析 # Go能够自动管理内存分配。这可以防止一大类潜在错误，但是不能说完全不去了解分配的机制。
首先要记住一点：栈分配是很廉价的而堆分配代价是昂贵的。我们来看一下具体含义。
Go在两个地方分配内存：用于动态分配的全局堆，以及用于每个goroutine的局部栈。Go偏向于在栈中分配&amp;mdash;-大多数go程序的分配都是在栈上面的。栈分配很廉价，因为它只需要两个CPU指令：一个是分配入栈，另一个是栈内释放。
但是不幸的是，不是所有数据都能使用栈上分配的内存。栈分配要求可以在编译时确定变量的生存期和内存占用量。然而堆上的动态分配发生在运行时。malloc必须去找一块儿足够大的空闲内存来保存新值。然后垃圾收集器扫描堆以查找不再引用的对象。毫无疑问，它比堆栈分配使用的两条指令要贵得多。
编译器使用逃逸分析技术去选择堆或者栈。基本思想是在编译时期进行垃圾收集工作。编译器追踪代码域变量的作用范围。它使用追踪数据来检查哪些变量的生命周期是完全可知的。如果变量通过这些检查，则可以在栈上进行分配。如果没通过，也就是所说的逃逸，则必须在堆上分配。
go语言里没有明确说明逃逸分析规则。对于Go程序员来说，最直接去了解规则的方式就是去实验。通过构建时候加上go build -gcflags &amp;lsquo;-m&amp;rsquo;，可以看到逃逸分析结果。我们看一个例子。
package main  import &amp;#34;fmt&amp;#34;  func main() {  x := 42  fmt.Println(x) } $ go build -gcflags &amp;#39;-m&amp;#39; ./main.go # command-line-arguments ./main.go:7: x escapes to heap ./main.go:7: main ... argument does not escape 我们这里看到变量x“逃逸到堆上”，因为它是在运行时期动态在堆上分配的。这个例子可能有点困惑。我们肉眼看上去，显然x变量在main()方法上不会逃逸。编译器输出并没有解释为什么它会认为变量逃逸了。为了看到更多细节，再加上一个-m参数，可以看到更多输出
$ go build -gcflags &amp;#39;-m -m&amp;#39; ./main.go # command-line-arguments ./main.go:5: cannot inline main: non-leaf function ./main.go:7: x escapes to heap ./main.go:7: from ... argument (arg to ...) at ./main.go:7 ./main.go:7: from *(... argument) (indirection) at ./main.go:7 ./main.go:7: from ... argument (passed to call[argument content escapes]) at ./main.go:7 ./main.go:7: main ... argument does not escape 这说明，x逃逸是因为它被传入一个方法参数里，这个方法参数自己逃逸了。后面可以看到更多这种情况。
规则可能看上去是随意的，经过工具的尝试，一些规律显现出来。这里列出了一些典型的导致逃逸的情况：
 **发送指针或者是带有指针的值到channel里。**编译时期没有办法知道哪个goroutine会受到channel中的数据。因此编译器无法确定这个数据什么时候不再被引用到。 **在slice中存储指针或者是带有指针的值。**这种情况的一个例子是[]*string。它总会导致slice中的内容逃逸。尽管切片底层的数组还是在堆上，但是引用的数据逃逸到堆上了。 slice底层数组由于append操作超过了它的容量，它会重新分片内存。如果在编译时期知道切片的初始大小，则它会在栈上分配。如果切片的底层存储必须被扩展，数据在运行时才获取到。则它将在堆上分配。 **在接口类型上调用方法。**对接口类型的方法调用是动态调用&amp;ndash;接口的具体实现只有在运行时期才能确定。考虑一个接口类型为io.Reader的变量r。对r.Read(b)的调用将导致r的值和byte slice b的底层数组都逃逸，因此在堆上进行分配。 以我们的经验来讲，这四种情况是Go程序中最常见的动态分配情况。对于这些情况还是有一些解决方案的。接下来，我们将深入探讨如何解决生产软件中内存低效问题的一些具体示例。  # 指针相关 # 经验法则是：指针指向堆上分配的数据。 因此，减少程序中指针的数量会减少堆分配的数量。 这不是公理，但我们发现它是现实世界Go程序中的常见情况。
我们直觉上得出的一个常见的假设是这样的：“复制值代价是昂贵的，所以我会使用指针。”然而在许多情况下，复制值比使用指针的开销要便宜的多。你可能会问这是为什么。
 在解引用一个指针的时候，编译器会生成检查。它的目的是，如果指针是nil的话，通过运行panic()来避免内存损坏。这部分额外代码必须在运行时去运行。如果数据按值传递，它不会是nil。 指针通常具有较差的引用局部性。函数中使用的所有值都在并置在堆栈内存中。引用局部性是代码高效的一个重要方面。它极大增加了变量在CPU caches中变热的可能性，并降低了预取时候未命中风险。 复制缓存行中的对象大致相当于复制单个指针。 CPU在缓存层和主存在常量大小的缓存行上之间移动内存。 在x86上，cache行是64个字节。 此外，Go使用一种名为Duff`s devices的技术，使拷贝等常见内存操作非常高效。 指针应主要用于反映成员所有关系以及可变性。实际中，使用指针避免复制应该是不常见的。不要陷入过早优化陷阱。按值传递数据习惯是好的，只有在必要的时候才去使用指针传递数据。另外，值传递消除了nil从而增加了安全性。  减少程序中指针的数量可以产生另一个有用的结果，因为垃圾收集器将跳过不包含指针的内存区域。例如，根本不扫描返回类型为[]byte 的切片的堆区域。对于不包含任何具有指针类型字段的结构类型数组，也同样适用。
减少指针不仅减少垃圾回收的工作量，还会生存出”cache友好“的代码。读取内存会将数据从主存移到CPU cache中。Caches是优先的，因此必须清掉一些数据来腾出空间。cache清掉的数据可能会和程序的其它部分相关。由此产生的cache抖动可能会导致不可预期行为和突然改变生产服务的行为。
指针深入 减少指针使用通常意需要味着深入研究用于构建程序的类型的源代码。我们的服务Centrifuge保留了一个失败操作队列，来作为重试循环缓冲区去进行重试，它包含一组如下所示的数据结构：
type retryQueue struct {  buckets [][]retryItem // each bucket represents a 1 second interval  currentTime time.Time  currentOffset int }  type retryItem struct {  id ksuid.KSUID // ID of the item to retry  time time.Time // exact time at which the item has to be retried } 数组buckets的外部大小是一个常量值，但是[]retryItem所包含的items会在运行时期改变。重试次数越多，这些slices就变越大。
深入来看一下retryItem细节，我们了解到KSUID是一个[20]byte的同名类型，不包含指针，因此被逃逸规则排除在外。currentOffset是一个int值，是一个固定大小的原始值，也可以排除。下面看一下，time.Time的实现：
type Time struct {  sec int64  nsec int32  loc *Location // pointer to the time zone structure } time.Time结构内部包含一个loc的指针。在retryItem内部使用它导致了在每次变量通过堆区域时候，GC都会去标记struct上的指针。
我们发现这是在不可预期情况下级联效应的典型情况。通常情况下操作失败是很少见的。只有小量的内存去存这个retries的变量。当失败操作激增，retry队列会每秒增加到上千个，这会大大增加垃圾回收器的工作量。
对于这种特殊使用场景，time.Time的time信息其实是不必要的。这些时间戳存在内存中，永远不会被序列化。可以重构这些数据结构以完全避免time类型出现。
type retryItem struct {  id ksuid.KSUID  nsec uint32  sec int64 }  func (item *retryItem) time() time.Time {  return time.Unix(item.sec, int64(item.nsec)) }  func makeRetryItem(id ksuid.KSUID, time time.Time) retryItem {  return retryItem{  id: id,  nsec: uint32(time.Nanosecond()),  sec: time.Unix(), } 现在retryItem不包含任何指针。这样极大的减少了垃圾回收器的工作负载，编译器知道retryItem的整个足迹。
请给我传切片(Slice) slice使用很容易会产生低效分配代码。除非编译器知道slice的大小，否则slice(和maps)的底层数组会分配到堆上。我们来看一下一些方法，让slice在栈上分配而不是在堆上。
Centrifuge集中使用了Mysql。整个程序的效率严重依赖了Mysql driver的效率。在使用pprof去分析了分配行为之后，我们发现Go MySQL driver代码序列化time.Time值的代价十分昂贵。
分析器显示大部分堆分配都在序列化time.Time的代码中。
相关代码在调用time.Time的Format这里，它返回了一个string。等会儿，我们不是在说slices么？好吧，根据Go官方文档，一个string其实就是个只读的bytes类型slices，加上一点额外的语言层面的支持。大多数分配规则都适用！
分析数据告诉我们大量分配，即12.38%都产生在运行的这个Format方法里。这个Format做了些什么？
事实证明，有一种更加有效的方式来做同样的事情。虽然Format()方法方便容易，但是我们使用AppendFormat()在分配器上会更轻松。观察源码库，我们注意到所有内部的使用都是AppendFormat()而非Format()，这是一个重要提示，AppendFormat()的性能更高。
实际上，Format方法仅仅是包装了一下AppendFormat方法：
func (t Time) Format(layout string) string {  const bufSize = 64  var b []byte  max := len(layout) &#43; 10  if max &amp;lt; bufSize {  var buf [bufSize]byte  b = buf[:0]  } else {  b = make([]byte, 0, max)  }  b = t.AppendFormat(b, layout)  return string(b) } 更重要的是，AppendFormat()给程序员提供更多分配控制。传递slice而不是像Format()自己在内部分配。相比Format，直接使用AppendFormat()可以使用固定大小的slice分配，因此内存分配会在栈空间上面。
可以看一下我们给Go MySQL driver提的这个PR
首先注意到var a [64]byte是一个大小固定的数组。编译期间我们知道它的大小，以及它的作用域仅在这个方法里，所以我们知道它会被分配在栈空间里。
但是这个类型不能传给AppendFormat()，该方法只接受[]byte类型。使用a[:0]的表示法将固定大小的数组转换为由此数组所支持的b表示的切片类型。这样可以通过编译器检查，并且会在栈上面分配内存。
更关键的是，AppendFormat()，这个方法本身通过编译器栈分配检查。而之前版本Format()，编译器不能确定需要分配的内存大小，所以不满足栈上分配规则。
这个小的改动大大减少了这部分代码的堆上分配！类似于我们在MySQL驱动里使用的“附加模式”。在这个PR里，KSUID类型使用了Append()方法。在热路径代码中，KSUID使用Append()模式处理大小固定的buffer而不是String()方法，节省了类似的大量动态堆分配。 另外值得注意的是，strconv包使用了相同的append模式，用于将包含数字的字符串转换为数字类型。
接口类型 众所周知，接口类型上进行方法调用比struct类型上进行方法调用要昂贵的多。接口类型的方法调用通过动态调度执行。这严重限制了编译器确定代码在运行时执行方式的能力。到目前为止，我们已经在很大程度上讨论了类型固定的代码，以便编译器能够在编译时最好地理解它的行为。 接口类型抛弃了所有这些规则！
不幸的是接口类型在抽象层面非常有用 &amp;mdash; 它可以让我们写出更加灵活的代码。程序里常用的热路径代码的相关实例就是标准库提供的hash包。hash包定义了一系列常规接口并提供了几个具体实现。我们看一个例子。
package main  import (  &amp;#34;fmt&amp;#34;  &amp;#34;hash/fnv&amp;#34; )  func hashIt(in string) uint64 {  h := fnv.New64a()  h.Write([]byte(in))  out := h.Sum64()  return out }  func main() {  s := &amp;#34;hello&amp;#34;  fmt.Printf(&amp;#34;The FNV64a hash of &amp;#39;%v&amp;#39; is &amp;#39;%v&amp;#39;\n&amp;#34;, s, hashIt(s)) } 构建检查逃逸分析结果：
./foo1.go:9:17: inlining call to fnv.New64a ./foo1.go:10:16: ([]byte)(in) escapes to heap ./foo1.go:9:17: hash.Hash64(&amp;amp;fnv.s·2) escapes to heap ./foo1.go:9:17: &amp;amp;fnv.s·2 escapes to heap ./foo1.go:9:17: moved to heap: fnv.s·2 ./foo1.go:8:24: hashIt in does not escape ./foo1.go:17:13: s escapes to heap ./foo1.go:17:59: hashIt(s) escapes to heap ./foo1.go:17:12: main ... argument does not escape 也就是说，hash对象，输入字符串，以及代表输入的[]byte全都会逃逸到堆上。我们肉眼看上去显然不会逃逸，但是接口类型限制了编译器。不通过hash包的接口就没有办法安全地使用具体的实现。 那么效率相关的开发人员应该做些什么呢？
我们在构建Centrifuge的时候遇到了这个问题，Centrifuge在热代码路径对小字符串进行非加密hash。因此我们建立了fasthash库。构建它很直接，困难工作依旧在标准库里做。fasthash只是在没有使用堆分配的情况下重新打包了标准库。
直接来看一下fasthash版本的代码
package main  import (  &amp;#34;fmt&amp;#34;  &amp;#34;github.com/segmentio/fasthash/fnv1a&amp;#34; )  func hashIt(in string) uint64 {  out := fnv1a.HashString64(in)  return out }  func main() {  s := &amp;#34;hello&amp;#34;  fmt.Printf(&amp;#34;The FNV64a hash of &amp;#39;%v&amp;#39; is &amp;#39;%v&amp;#39;\n&amp;#34;, s, hashIt(s)) } 看一下逃逸分析输出
./foo2.go:9:24: hashIt in does not escape ./foo2.go:16:13: s escapes to heap ./foo2.go:16:59: hashIt(s) escapes to heap ./foo2.go:16:12: main ... argument does not escape 唯一产生的逃逸就是因为fmt.Printf()方法的动态特性。尽管通常我们更喜欢是用标准库，但是在一些情况下需要进行权衡是否要提高分配效率。
一个小窍门 我们最后这个事情，不够实际但是很有趣。它有助我们理解编译器的逃逸分析机制。 在查看所涵盖优化的标准库时，我们遇到了一段相当奇怪的代码。
// noescape hides a pointer from escape analysis. noescape is // the identity function but escape analysis doesn&amp;#39;t think the // output depends on the input. noescape is inlined and currently // compiles down to zero instructions. // USE CAREFULLY! //go:nosplit func noescape(p unsafe.Pointer) unsafe.Pointer {  x := uintptr(p)  return unsafe.Pointer(x ^ 0) } 这个方法会让传递的指针逃过编译器的逃逸分析检查。那么这意味着什么呢？我们来设置个实验看一下。
package main  import (  &amp;#34;unsafe&amp;#34; )  type Foo struct {  S *string }  func (f *Foo) String() string {  return *f.S }  type FooTrick struct {  S unsafe.Pointer }  func (f *FooTrick) String() string {  return *(*string)(f.S) }  func NewFoo(s string) Foo {  return Foo{S: &amp;amp;s} }  func NewFooTrick(s string) FooTrick {  return FooTrick{S: noescape(unsafe.Pointer(&amp;amp;s))} }  func noescape(p unsafe.Pointer) unsafe.Pointer {  x := uintptr(p)  return unsafe.Pointer(x ^ 0) }  func main() {  s := &amp;#34;hello&amp;#34;  f1 := NewFoo(s)  f2 := NewFooTrick(s)  s1 := f1.String()  s2 := f2.String() } 这个代码包含两个相同任务的实现：它们包含一个字符串，并使用String()方法返回所持有的字符串。但是，编译器的逃逸分析说明FooTrick版本根本没有逃逸。
./foo3.go:24:16: &amp;amp;s escapes to heap ./foo3.go:23:23: moved to heap: s ./foo3.go:27:28: NewFooTrick s does not escape ./foo3.go:28:45: NewFooTrick &amp;amp;s does not escape ./foo3.go:31:33: noescape p does not escape ./foo3.go:38:14: main &amp;amp;s does not escape ./foo3.go:39:19: main &amp;amp;s does not escape ./foo3.go:40:17: main f1 does not escape ./foo3.go:41:17: main f2 does not escape 这两行是最相关的
./foo3.go:24:16: &amp;amp;s escapes to heap ./foo3.go:23:23: moved to heap: s 这是编译器认为NewFoo()``方法把拿了一个string类型的引用并把它存到了结构体里，导致了逃逸。但是NewFooTrick()方法并没有这样的输出。如果去掉noescape()，逃逸分析会把FooTrick结构体引用的数据移动到堆上。这里发生了什么?
func noescape(p unsafe.Pointer) unsafe.Pointer {  x := uintptr(p)  return unsafe.Pointer(x ^ 0) } noescape()方法掩盖了输入参数和返回值直接的依赖关系。编译器不认为p会通过x逃逸，因为uintptr()会产生一个对编译器不透明的引用。内置的uintptr类型的名称会让人相信它是一个真正的指针类型，但是从编译器的视角来看，它只是一个恰好大到足以存储指针的整数。最后一行代码构造并返回了一个看似任意整数的unsafe.Pointer值。
一定要清楚，我们并不推荐使用这种技术。这也是为什么它引用的包叫做unsafe，并且注释里写着USE CAREFULLY!
总结 我们来总结一下关键点：
 不要过早优化！使用数据来驱动优化工作 栈分配廉价，堆分配昂贵 了解逃逸分析的规则能够让我们写出更高效的代码 使用指针几乎不会在栈上分配 性能关键的代码段中寻找提供分配控制的API 在热代码路径里谨慎地使用接口类型  </content>
    </entry>
    
     <entry>
        <title>垃圾回收GC浅谈</title>
        <url>http://shanks.link/blog/2021/04/04/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6gc%E6%B5%85%E8%B0%88/</url>
        <categories>
          <category>algorithm</category>
        </categories>
        <tags>
          <tag>algorithm</tag>
        </tags>
        <content type="html"> 原文链接
关于内存 计算机通过两个机制，去实现内存的高效使用。
第一种机制是虚拟内存。硬盘的容量其实是远远大于内存的(RAM)，虚拟内存会在内存不足的时候，把不经常访问的内存的数据写到硬盘里。虽然说硬盘容量比较大，但是它的访问速度却很慢。如果内存和硬盘交换数据过于频繁，处理速度就会下降，计算机就会看上去像卡死了一样，这种现象被叫做抖动(Thrushing)。造成电脑蓝屏的主要原因之一就是抖动。
第二种机制就是垃圾回收(GC)。
虚拟内存的东西在计算机组成原理和操作系统的教科书里有相关的章节去讲。由于内容很多我就不多叙述了。主要来讲一下GC的事情。
GC 之前学习java以及参加java相关的面试，被问到关于相关GC的事情一直很是头疼，看了好多遍还是记不住，脑袋里只有隐隐约约的一些关键字，什么老年代、新生代、full GC什么的。具体流程一被问就GG。
现在想想，其实GC就是计算机帮助你去进行内存的回收。你用不到的数据如果一直占着内存，那么你的程序能用的内存就越来越少，所以需要进行内存的管理。比如你在写C、C&#43;&#43;程序的时候，需要自己去管理内存，在堆上申请的内存最后需要自己手动释放，释放的内存会被操作系统重新利用。如果你认为某些内存空间“可能还会被用到”，或者是干脆忘记释放内存，这些无法访问的内存空间就会一直保留下来，造成内存浪费，最终导致性能下降和产生抖动。管理大量分配的内存空间，对于人来说其实是很困难的。
对于像Java、go这些语言，它们有自己的一套内存管理的机制，内存空间释放的自动化也就是GC，从某种程度上解放了程序员的双手。
术语 垃圾(Garbage)
垃圾(Garbage)就是需要回收的对象。作为编程人员你知道对象什么时候不需要，但是计算机无法判断。因此，如果程序直接或者间接地引用一个对象，那么它就会被计算机标记为“存活”；相反的，没有被引用到的对象就被视为“死亡”。把这些“死亡”的对象找出来，然后作为垃圾进行回收，这就是GC的本质。
根（Root）
根(Root)，就是判断对象是否可被引用的起始点。不同语言和编译器对根有不同规定，但是基本上是将变量和运行栈空间作为根。
GC算法 标记清除方式 标记清除原理非常简单，首先从根开始，将可能被引用的对象用递归的方式进行标记，然后将没有标记上的对象作为垃圾进行回收。
图1.1
图1.1的 (1)显示了随着程序的运行进而分配出的一些对象的状态，一个对象可以对其他的对象进行引用。 (2)部分GC开始执行，从根开始对可能被引用的对象打上标记。大多数情况下，这种标记是通过对象内部的标志(Flag)来实现的。被标记的对象我们将它涂黑。 (3)中，被标记的对象所能够引用的对象也被打上标记。重复这一步骤，可以将从根开始可能被间接引用到的对象全部打上标记。到此为止的操作，称作标记阶段(Mark phase)。标记阶段完成是，被标记的对象就被看做是“存活”对象。 (4)中，将全部对象按顺序扫描一遍，将没有标记的对象进行回收。这一步操作称作清除阶段(Sweep phase)。在扫描的同时，还需要将存活对象的标记清除掉，以便下一次GC去处理。
标记清除算法的处理时间，是和存活对象数与对象总数两者的和相关的。
标记清除方式的优点：可以处理循环引用的对象。缺点：在分配了大量对象，并且其中只有一小部分存活的情况下，由于清除阶段还要对大量“死亡”的对象进行扫描，会导致消耗大量不必要的时间。
复制收集方式 复制收集(Copy and Collection)方式试图解决标记清除的缺点。这种算法中，会从根开始，被引用的对象复制到另外的空间中，然后再将复制的对象所能够引用的对象递归的方式不断复制下去。
图1.2
(1)是GC开始前的状态。 (2)部分中，旧对象空间之外，准备出一块新空间，然后将可能从根被引用的对象复制到新空间中。 (3)部分中，从已经复制的对象开始，再将可以被引用的对象复制到新空间中(串到了后面)，“死亡”对象就被留存在了旧空间中。 (4)中，将旧空间废弃掉，就可以将这部分所占的空间一下子全部释放掉，而没有必要再扫描每个对象。下次GC的时候，现在的新空间就当做了未来的旧空间。
通过图1.2可以发现，复制收集方式，只有类似标记清除的标记阶段，而不存在需要扫描所有对象的情况。但是相比之下，复制收集将对象复制一份所需要的开销会比较大，因此在“存活”对象比例较高的情况下，反而会比较不利。
这种算法的另一个好处就是它具有局部性(Locality)。在复制收集过程中，会按照对象被引用的顺序将对象复制到新空间中。因此关系较近的对象被放在距离较近的内存空间中的可能性会提供，这被称为局部性。局部性高的情况，内存缓存会更容易有效运作，程序的性能也会得到提高。
引用计数方式 引用计数的基本原理是，在每一个对象中保存该对象的引用计数，当引用发生增减时对计数进行更新。这让我想到了C&#43;&#43;里的智能指针(shared_ptr)，曾经被面试手写shared_ptr的场景历历在目啊。
引用计数的增减，一般发生在变量赋值、对象内容更新、函数结束(局部变量不再被引用)等时间点。当一个对象的引用计数变为0的时候，则说明它将来不会再被引用，因此可以释放相应的内存空间。
图1.3
(1)里面，所有对象中都保存着自己被多少其他的对象进行引用的数量(引用计数)。 (2)中，当对象引用发生变化的时候，引用计数也跟着变。这里由于B到D的引用失效了，于是对象D的引用计数变为0，由于D的引用计数为0，因此由D到对象C和E的引用数也分别相应减少。结果，对象E的引用计数变为0，于是E也对应释放掉了。 (3)中，引用计数为0的对象被释放，“存活”的对象保留了下来。能够注意到，在整个GC的过程中，并不需要对所有对象进行扫描。
这种方式最大优点，就是容易实现。它的另外一个优点就是，当对象不再被引用的瞬间就会被释放。其它的GC机制很难预测对象什么时候会被释放，而这种方式是立即被释放的。因此，由GC产生的中断时间(Pause time)就比较短。
当然这种方式也有缺点。最大的缺点就是，无法释放循环引用的对象。图1.4中A、B、C之间互相循环引用，它的引用计数永远不会为0，也就永远不会被释放。
图1.4
它的另外一个缺点就是，如果在必要的增减计数的时候遗漏掉了增减操作，或者是增减计数出错，就会产生内存错误。如果是手动管理计数就很容易产生bug。
它的最后一个缺点就是引用计数管理不适合并行处理。如果多个线程同时对引用计数进行增减，引用数值就会产生不一致的问题从而导致内存错误。因此引用计数必须采用独占的方式。如果引用计数频繁发生，每次需要使用加锁等并发控制机制的话，也会造成很大的额外开销。 ** 改良版GC** GC的基本算法，大体上都是上面的三种方式或者是它们的衍生品。现在通过三种方式进行融合，出现一些其他高级的GC方式，即分代回收、增量回收和并行回收。有些情况也会对这些改良版的gc方式进行组合使用。
分代回收(Generational GC) 分代回收的目的，就是在程序运行期间，将GC所消耗的时间尽量的缩短。
它基于这样一个一般程序的性质，即大部分对象都会在短时间内成为垃圾，经过一定时间依然存活的对象往往有较长的寿命。对于刚分配不久的“年轻”对象进行重点扫描，应该可以更有效的回收大部分垃圾。
分代回收中，按照对象生成时间进行分代。刚刚生成不久的对象划分为新生代(Young generation)，而存活了较长时间的对象划分为旧生代(Old generation)。不同实现可能还会有更多划分。如果上面的对象寿命假说成立的话，只要扫描回收新生代对象，就可以回收掉废弃对象中的很大一部分。
这种只扫描新生代对象的回收操作，被称作小回收(Minor GC)。它的具体步骤如下。
首先从根开始一次常规扫描，找到“存活”对象。可以使用复制收集算法或者标记清除算法，但是大部分使用了复制收集。需要注意的是，在扫描的过程中，如果遇到属于旧生代的对象，则不对该对象进行递归扫描。这样需要扫描的对象就会大量减少。
然后，将第一次扫描后残留下来的对象划分到旧生代。具体来说，如果使用复制收集算法，只要将复制目标空间设置为旧生代就可以了；标记清除方式的话，则采用在对象上设置某种标志的方式。
现在有一个问题，如果有从旧生代到新生代对象的引用怎么办？如果只扫描新生代，那么旧生代对新生代的引用就不会被检测到。这样一来，如果一个年轻的对象只有来自旧生代的引用，就会被误认为“死亡”。因此在分代回收中，会对对象的更新进行监视，将从旧生代对新生代的引用，记录在记录集(remembered set)的表中。在执行小回收过程中，这个记录集也作为一个根(root)来对待。
图1.5
没有引用任何其它对象的旧生代F对象，会通过大回收(Full gc)操作进行回收。保证分代回收正确工作，必须使记录集的内容保持更新。
记录引用的子程序工作方式如下。设有两个对象A、B，当对A内容进行改写，并加入对B的引用时，如果A属于旧生代，B属于新生代，则将该引用添加到记录集中。
这种检查程序需要对所有涉及修改对象内容的地方进行保护，因此也被称为写屏障(Write barrier)。写屏障也用在很多其他GC算法中，比如Go的gc算法也用到了写屏障。
虽然旧生代中的对象寿命一般比较长，但是最终也会“死亡”。随着程序运行，旧生代中“死亡”的对象不断增加。为了避免这些“死亡”的旧生代对象白占内存空间，偶尔需要对包括旧生代在内的全部区域进行一次扫描回收。这种以全部区域为对象的GC操作叫Full GC
分代收集通过减少GC中扫描的对象数量进而缩短GC带来的平均中断时间，但是最终还是需要一次Full GC，因此最大中断时间并没有改善。GC的性能也会被程序行为、分代数量、Full GC的触发条件等因素大幅左右。
增量回收 实时性要求很高的程序中，相比缩短GC平均中断时间，缩短GC的最大中断时间更加重要。
GC最大的中断时间要限定在一个时间范围内，但是一般GC算法没办法保证，因为GC产生的中断时间和对象的数量和状态有关系。因此为了维持程序的实时性，不等到GC全部完成，而是将GC操作细分成多个部分逐一执行。这种方式就是增量回收（Incremental GC）
增量回收过程中程序本身会继续运行，为了避免对象之间的引用关系改变而导致GC回收出错，增量回收也使用了写屏障，来讲新被引用的对象作为扫描的起始点记录下来。
由于增量回收过程式分步渐进式的，可以将中断时间控制在一定长度之内。但是相应的中断操作需要消耗一定时间，GC消耗的总时间会相应增加。
并行回收 现在的计算机基本上都有多个CPU核心。而并行回收方式正是通过最大限度利用多CPU的处理能力来进行GC操作。
并行回收的基本原理是，在原有程序运行的同时进行GC操作，这点和增量回收是相似的。相对于在一个CPU上进行任务分割的增量回收方式，并行回收可以利用多CPU的性能，尽可能让这些GC任务并行（同时）进行。由于程序功能运行和GC操作是同时发生的，就会遇到和前面相同的问题，所以并行回收也需要利用写屏障来对对象当前的状态信息保持更新。
但是让GC完全并行，而不影响原有程序运行时做不到的，在GC的某些特定阶段还是需要暂停原有程序的运行。
总结 目前的GC算法基本上都是上述算法的变体或者是组合，例如java里的分代回收，golang中的三色标记法。有时候因为对象之间的引用状态发生了变化，结果导致了本来是“存活”对象却被回收掉，这时候需要写屏障(Write barrier)来进行记录和保护。当我们理解了上面的事情，其他具体编程语言的GC算法就不难理解了。
参考资料 《代码的未来》&amp;ndash; 作者：松本行弘 译者：周自恒 juejin.im/post/684490… legendtkl.com/2017/04/28/…
</content>
    </entry>
    
     <entry>
        <title>详解Go逃逸分析</title>
        <url>http://shanks.link/blog/2021/04/04/%E8%AF%A6%E8%A7%A3go%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原文链接机器铃砍菜刀
Go是一门带有垃圾回收的现代语言，它抛弃了传统C/C&#43;&#43;的开发者需要手动管理内存的方式，实现了内存的主动申请和释放的管理。Go的垃圾回收，让堆和栈的概念对程序员保持透明，它增加的逃逸分析与GC，使得程序员的双手真正地得到了解放，给了开发者更多的精力去关注软件设计本身。
就像《CPU缓存体系对Go程序的影响》文章中说过的一样，“你不一定需要成为一名硬件工程师，但是你确实需要了解硬件的工作原理”。Go虽然帮我们实现了内存的自动管理，我们仍然需要知道其内在原理。内存管理主要包括两个动作：分配与释放。逃逸分析就是服务于内存分配，为了更好理解逃逸分析，我们先谈一下堆栈。
堆和栈
应用程序的内存载体，我们可以简单地将其分为堆和栈。
在Go中，栈的内存是由编译器自动进行分配和释放，栈区往往存储着函数参数、局部变量和调用函数帧，它们随着函数的创建而分配，函数的退出而销毁。一个goroutine对应一个栈，栈是调用栈（call stack）的简称。一个栈通常又包含了许多栈帧（stack frame），它描述的是函数之间的调用关系，每一帧对应一次尚未返回的函数调用，它本身也是以栈形式存放数据。
举例：在一个goroutine里，函数A()正在调用函数B()，那么这个调用栈的内存布局示意图如下。
与栈不同的是，应用程序在运行时只会存在一个堆。狭隘地说，内存管理只是针对堆内存而言的。程序在运行期间可以主动从堆上申请内存，这些内存通过Go的内存分配器分配，并由垃圾收集器回收。
栈是每个goroutine独有的，这就意味着栈上的内存操作是不需要加锁的。而堆上的内存，有时需要加锁防止多线程冲突（为什么要说有时呢，因为Go的内存分配策略学习了TCMalloc的线程缓存思想，他为每个处理器P分配了一个mcache，从mcache分配内存也是无锁的）。
而且，对于程序堆上的内存回收，还需要通过标记清除阶段，例如Go采用的三色标记法。但是，在栈上的内存而言，它的分配与释放非常廉价。简单地说，它只需要两个CPU指令：一个是分配入栈，另外一个是栈内释放。而这，只需要借助于栈相关寄存器即可完成。
另外还有一点，栈内存能更好地利用CPU的缓存策略。因为它们相较于堆而言是更连续的。
逃逸分析
那么，我们怎么知道一个对象是应该放在堆内存，还是栈内存之上呢？可以官网的FAQ（地址：golang.org/doc/faq）中找到…
如果可以，Go编译器会尽可能将变量分配到到栈上。但是，当编译器无法证明函数返回后，该变量没有被引用，那么编译器就必须在堆上分配该变量，以此避免悬挂指针（dangling pointer）。另外，如果局部变量非常大，也会将其分配在堆上。
那么，Go是如何确定的呢？答案就是：逃逸分析。编译器通过逃逸分析技术去选择堆或者栈，逃逸分析的基本思想如下：检查变量的生命周期是否是完全可知的，如果通过检查，则可以在栈上分配。否则，就是所谓的逃逸，必须在堆上进行分配。
Go语言虽然没有明确说明逃逸分析规则，但是有以下几点准则，是可以参考的。
逃逸分析是在编译器完成的，这是不同于jvm的运行时逃逸分析; 如果变量在函数外部没有引用，则优先放到栈中； 如果变量在函数外部存在引用，则必定放在堆中； 我们可通过go build -gcflags &amp;lsquo;-m -l&amp;rsquo;命令来查看逃逸分析结果，其中-m 打印逃逸分析信息，-l禁止内联优化。下面，我们通过一些案例，来熟悉一些常见的逃逸情况。
情况一：变量类型不确定
package main  import &amp;#34;fmt&amp;#34;  func main() { 	a := 666 	fmt.Println(a) } 逃逸分析结果如下
 $ go build -gcflags &amp;#39;-m -l&amp;#39; main.go # command-line-arguments ./main.go:7:13: ... argument does not escape ./main.go:7:13: a escapes to heap 可以看到，分析结果告诉我们变量a逃逸到了堆上。但是，我们并没有外部引用啊，为啥也会有逃逸呢？为了看到更多细节，可以在语句中再添加一个-m参数。得到信息如下
 $ go build -gcflags &amp;#39;-m -m -l&amp;#39; main.go # command-line-arguments ./main.go:7:13: a escapes to heap: ./main.go:7:13: flow: {storage for ... argument} = &amp;amp;{storage for a}: ./main.go:7:13: from a (spill) at ./main.go:7:13 ./main.go:7:13: from ... argument (slice-literal-element) at ./main.go:7:13 ./main.go:7:13: flow: {heap} = {storage for ... argument}: ./main.go:7:13: from ... argument (spill) at ./main.go:7:13 ./main.go:7:13: from fmt.Println(... argument...) (call parameter) at ./main.go:7:13 ./main.go:7:13: ... argument does not escape ./main.go:7:13: a escapes to heap a逃逸是因为它被传入了fmt.Println的参数中，这个方法参数自己发生了逃逸。
func Println(a ...interface{}) (n int, err error) 因为fmt.Println的函数参数为interface类型，编译期不能确定其参数的具体类型，所以将其分配于堆上。 情况二：暴露给外部指针
package main  func foo() *int { 	a := 666 	return &amp;amp;a }  func main() { 	_ = foo() } 逃逸分析如下，变量a发生了逃逸。
 $ go build -gcflags &amp;#39;-m -m -l&amp;#39; main.go # command-line-arguments ./main.go:4:2: a escapes to heap: ./main.go:4:2: flow: ~r0 = &amp;amp;a: ./main.go:4:2: from &amp;amp;a (address-of) at ./main.go:5:9 ./main.go:4:2: from return &amp;amp;a (return) at ./main.go:5:2 ./main.go:4:2: moved to heap: a 这种情况直接满足我们上述中的原则：变量在函数外部存在引用。这个很好理解，因为当函数执行完毕，对应的栈帧就被销毁，但是引用已经被返回到函数之外。如果这时外部从引用地址取值，虽然地址还在，但是这块内存已经被释放回收了，这就是非法内存，问题可就大了。所以，很明显，这种情况必须分配到堆上。
情况三：变量所占内存较大
func foo() { 	s := make([]int, 10000, 10000) 	for i := 0; i &amp;lt; len(s); i&#43;&#43; { 	s[i] = i 	} }  func main() { 	foo() } 逃逸分析结果
$ go build -gcflags &amp;#39;-m -m -l&amp;#39; main.go # command-line-arguments ./main.go:4:11: make([]int, 10000, 10000) escapes to heap: ./main.go:4:11: flow: {heap} = &amp;amp;{storage for make([]int, 10000, 10000)}: ./main.go:4:11: from make([]int, 10000, 10000) (too large for stack) at ./main.go:4:11 ./main.go:4:11: make([]int, 10000, 10000) escapes to heap 可以看到，当我们创建了一个容量为10000的int类型的底层数组对象时，由于对象过大，它也会被分配到堆上。这里我们不禁要想一个问题，为啥大对象需要分配到堆上。
这里需要注意，在上文中没有说明的是：在Go中，执行用户代码的goroutine是一种用户态线程，其调用栈内存被称为用户栈，它其实也是从堆区分配的，但是我们仍然可以将其看作和系统栈一样的内存空间，它的分配和释放是通过编译器完成的。与其相对应的是系统栈，它的分配和释放是操作系统完成的。在GMP模型中，一个M对应一个系统栈（也称为M的g0栈），M上的多个goroutine会共享该系统栈。
不同平台上的系统栈最大限制不同。
$ ulimit -s 8192 以x86_64架构为例，它的系统栈大小最大可为8Mb。我们常说的goroutine初始大小为2kb，其实说的是用户栈，它的最小和最大可以在runtime/stack.go中找到，分别是2KB和1GB。
// The minimum size of stack used by Go code _StackMin = 2048 &amp;hellip; var maxstacksize uintptr = 1 &amp;laquo; 20 // enough until runtime.main sets it for real 复制代码 而堆则会大很多，从1.11之后，Go采用了稀疏的内存布局，在Linux的x86-64架构上运行时，整个堆区最大可以管理到256TB的内存。所以，为了不造成栈溢出和频繁的扩缩容，大的对象分配在堆上更加合理。那么，多大的对象会被分配到堆上呢。
通过测试，小菜刀发现该大小为64KB（这在Go内存分配中是属于大对象的范围：&amp;gt;32kb），即s :=make([]int, n, n)中，一旦n达到8192，就一定会逃逸。注意，网上有人通过fmt.Println(unsafe.Sizeof(s))得到s的大小为24字节，就误以为只需分配24个字节的内存，这是错误的，因为实际还有底层数组的内存需要分配。
情况四：变量大小不确定
我们将情况三种的示例，简单更改一下。
package main  func foo() { 	n := 1 	s := make([]int, n) 	for i := 0; i &amp;lt; len(s); i&#43;&#43; { 	s[i] = i 	} }  func main() { 	foo() } 得到逃逸分析结果如下
$ go build -gcflags &amp;#39;-m -m -l&amp;#39; main.go # command-line-arguments ./main.go:5:11: make([]int, n) escapes to heap: ./main.go:5:11: flow: {heap} = &amp;amp;{storage for make([]int, n)}: ./main.go:5:11: from make([]int, n) (non-constant size) at ./main.go:5:11 ./main.go:5:11: make([]int, n) escapes to heap 这次，我们在make方法中，没有直接指定大小，而是填入了变量n，这时Go逃逸分析也会将其分配到堆区去。可见，为了保证内存的绝对安全，Go的编译器可能会将一些变量不合时宜地分配到堆上，但是因为这些对象最终也会被垃圾收集器处理，所以也能接受。
总结
本文只列举了逃逸分析的部分例子，实际的情况还有很多，理解思想最重要。这里就不过多列举了。
既然Go的堆栈分配对于开发者来说是透明的，编译器已经通过逃逸分析为对象选择好了分配方式。那么我们还可以从中获益什么？
答案是肯定的，理解逃逸分析一定能帮助我们写出更好的程序。知道变量分配在栈堆之上的差别，那么我们就要尽量写出分配在栈上的代码，堆上的变量变少了，可以减轻内存分配的开销，减小gc的压力，提高程序的运行速度。
所以，你会发现有些Go上线项目，它们在函数传参的时候，并没有传递结构体指针，而是直接传递的结构体。这个做法，虽然它需要值拷贝，但是这是在栈上完成的操作，开销远比变量逃逸后动态地在堆上分配内存少的多。当然该做法不是绝对的，如果结构体较大，传递指针将更合适。
因此，从GC的角度来看，指针传递是个双刃剑，需要谨慎使用，否则线上调优解决GC延时可能会让你崩溃。
 闭包造成的逃逸 返回指向栈变量的指针 申请大对象造成的逃逸 申请可变长空间造成的逃逸 返回局部引用的 slice 造成的逃逸 返回局部引用的 map 造成的逃逸 返回函数造成的逃逸 逃逸是在编译期间完成的，主要是决定是在栈中或者堆中分配内存?  </content>
    </entry>
    
     <entry>
        <title>理解golang调度之三：并发</title>
        <url>http://shanks.link/blog/2021/04/04/%E7%90%86%E8%A7%A3golang%E8%B0%83%E5%BA%A6%E4%B9%8B%E4%B8%89%E5%B9%B6%E5%8F%91/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 简介 当我在解决一个问题尤其是新问题的时候，我开始不会去考虑并发(concurrency)是否合适。我首先会去找一系列的解决方式然后确保它有效。然后在可读性和技术方案评估之后，我会开始去考虑并发是否实际合理。有些时候并发的好处是显而易见的，但是有时候并不是很明显。 第一篇文章，我解释了OS调度器的相关内容，我觉得这部分对于你写多线程代码很重要。第二篇里，我讲解了一些Go调度器的一些内容，这部分对于你理解和写go的并发代码很有帮助。在这篇文章里，我会在OS和Go调度器层面让你去深层次的理解并发到底是什么。 这部分内容的目标是：
你的工作负载(workloads)使用并发是否合适，为此提供一些指导建议 不同工作负载的含义，并针对其作出相应的工程方面的决策。
什么是并发 并发的含义就是无序的执行。给你一系列的指令，去找到一个方式可以无序执行而且和有序执行产生同样的结果。这个问题在你面前，显而易见的是无序执行会增加一些足够的性能增益在计算了复杂性成本之后，但是你可能会觉得无序执行是不可能的甚至是没有意义的。 你也要清楚一点，并发和并行是不一样的。并行是在相同时间内同时执行两个或两个以上的指令，这和并发的概念不一样。 图3.1 图3.1里，你看到主机上有两个逻辑处理器。每个都有他们单独的OS线程(M)依附于一个独立的硬件线程(Core)。你可以看到2个Goroutine(G1和G2) 正在并行在各自的OS/硬件线程上面同时执行它们的指令。在每个逻辑处理器里，有3个Goroutines以轮转的方式共享OS线程。这些Goroutines正在以无序的方式并发地执行它们的指令，并且在OS线程上共享时间片。 这里有一个问题。有些时候利用并发而不采用并行实际上会降低你的吞吐量，有趣的是，有时候利用并发同时加上并行处理也不会为你带来你理想中的性能增益。 工作负载(workloads) 你是如何知道无序执行(并发)是可行的呢？了解你所处理问题的工作负载(workload)是一个起点。有两种类型的工作负载在并发的时候要考虑到。
 CPU密集(CPU-Bound)：这种工作负载情况不会有Goroutines自动切换到waiting状态的情况，也不会有自动从waiting状态切到其他状态的情况。这种情况发生在进行持续计算的时候。线程计算Pi值就是CPU-Bound。 IO密集(IO-Bound)：这种工作负载会导致Goroutines自动进入等待状态。这种工作发生在持续地请求网络资源、或者是进行系统调用、或者是等待事件发生的情况。一个Goroutines需要读文件就是IO-Bound。我把同步事件(mutexes，atomic)类似导致Goroutine等待的情况归到此类。  cpu-bound的工作负载，你需要并行去使用并发。一个单独的OS/硬件线程处理多个Goroutines效率很低，因为Goroutines在这个工作负载里不会主动进入或者是离开等待状态。Goroutines数多于OS/硬件线程数的时候会降低工作负载的执行速度，因为从OS线程换上或者是换下Goroutines会有延迟(切换的时间)。上下文切换会在workload里创建出“一切都停止”事件，因为在切换的时候你的所有workload都不会执行。 在IO-Bound的workloads里，你不需要并行去使用并发。一个单独OS/硬件线程可以有效率地处理多个Goroutines，因为Goroutines作为它自己workload的一部分可以自动进入或者离开等待状态(waiting)。Goroutines数量多于OS/硬件线程数可以加速workload的执行,因为Goroutines在OS线程上切换不会创建“一切都停止”事件。你的workload会自然停止并且这会让一个不同的Goroutine去有效率地使用相同的OS/硬件线程，而不是让OS/硬件线程空闲下来。 你如何知道每个硬件线程设置多少个Goroutines会有最好的吞吐量呢？太少的Goroutines你会有更多空闲时间。太多Goroutines你会有更多上下文切换延迟。这件事情你需要考虑，但是这超出了 本篇文章讲述的范围。 现在，我们需要看一些代码来巩固你去判断什么时候workload可以利用并发，以及什么时候需要利用并行什么时候不需要并行。 整数累加 不需要太复杂的代码，就看一下下面的add函数。它计算了一堆整数的和。 L1
36 func add(numbers []int) int { 37 var v int 38 for _, n := range numbers { 39 v &#43;= n 40 } 41 return v 42 } 在L1的36行，声明了add方法，他接受一个int型的slice，然后返回它们的和。37定义了一个变量v去做数字累加。38行函数遍历这些整数，39行把当前数加上去。最后41行返回它们的和。 Question: add是否适合无序执行？我相信答案肯定是yes。整数集可以被分解成更小的lists，并且这些lists可以并行去处理。一旦所有lists都各自加完，这一系列lists的和可以加到一起，得到上面代码里一样的结果。 但是，另一个问题来了。我们应该分多少个lists去分别单独处理才能得到最好的吞吐量呢？为了回答这个问题，你需要知道add方法运行到底是哪种workload。add方法处理的是CPU-Bound类型的workload因为这是一个纯数学计算的方法，它不会导致goroutines进入自动等待状态。这意味着每个OS/硬件线程一个Goroutine即可获得理想的吞吐量。 下面的L2是add方法的并发版本。 注意：你有多种方式去写add的并发版本，不必去纠结代码本身。
44 func addConcurrent(goroutines int, numbers []int) int { 45 var v int64 46 totalNumbers := len(numbers) 47 lastGoroutine := goroutines - 1 48 stride := totalNumbers / goroutines 49 50 var wg sync.WaitGroup 51 wg.Add(goroutines) 52 53 for g := 0; g &amp;lt; goroutines; g&#43;&#43; { 54 go func(g int) { 55 start := g * stride 56 end := start &#43; stride 57 if g == lastGoroutine { 58 end = totalNumbers 59 } 60 61 var lv int 62 for _, n := range numbers[start:end] { 63 lv &#43;= n 64 } 65 66 atomic.AddInt64(&amp;amp;v, int64(lv)) 67 wg.Done() 68 }(g) 69 } 70 71 wg.Wait() 72 73 return int(v) 74 } 在L2里面，addConcurrent方法是add方法的并发版本。这里有很多代码因此我只讲解重要的代码行 Line 48：每个Goroutine会有它单独的一个小的list去处理。list的size由整数集的size去除以Goroutines的数量得到。 Line 53：创建goroutines线程池去处理加数操作。 Line 57-59：最后一个goroutines会处理剩下的最后一个list，它可能比其他list的size要大。 Line 66：所有lists算出来的sum，加到一起得到最后的一个sum。 并发版本比有序版本更复杂，这种复杂度是否值得呢？回答这个问题最好的方式就是写一个benchmark。这里我用了一个一千万个数大小整数集，并且关掉了垃圾回收。这里对add和addConcurrent进行了对比。 L3
func BenchmarkSequential(b *testing.B) {  for i := 0; i &amp;lt; b.N; i&#43;&#43; {  add(numbers)  } }  func BenchmarkConcurrent(b *testing.B) {  for i := 0; i &amp;lt; b.N; i&#43;&#43; {  addConcurrent(runtime.NumCPU(), numbers)  } } L3展示了benchmark函数。下面是当Goroutines只有一个单独的OS/硬件线程能用的情况。有序版本使用1个Goroutine然后并发版本使用runtime.NumCPU数，我的机器上是8。这个例子下面，并发版本没有使用并行去做并发。 L4
10 Million Numbers using 8 goroutines with 1 core 2.9 GHz Intel 4 Core i7 Concurrency WITHOUT Parallelism ----------------------------------------------------------------------------- $ GOGC=off go test -cpu 1 -run none -bench . -benchtime 3s goos: darwin goarch: amd64 pkg: github.com/ardanlabs/gotraining/topics/go/testing/benchmarks/cpu-bound BenchmarkSequential 1000	5720764 ns/op : ~10% Faster BenchmarkConcurrent 1000	6387344 ns/op BenchmarkSequentialAgain 1000	5614666 ns/op : ~13% Faster BenchmarkConcurrentAgain 1000	6482612 ns/op 注意：在你的本机上跑BenchMark很复杂。有很多因素会导致你的benchmarks不够精确。你的机器尽可能的处于空闲状态这样可以去跑一段时间benchmark，以确保自己看到的结果和上面的大体一致。使用测试工具跑两遍benchmark能够得到更一致的结果。 L4给出的benchmark表明，在仅有一个单独OS/硬件线程时候有序版本比并发版本大约要快%10&amp;ndash;%13。这在我们的意料之中，因为并发版本需要在一个单独的OS线程上频繁进行上下文切换(context switches)以及处理Goroutines。 下面是每个Goroutines有一个单独的OS/硬件线程的情况下的结果。有序版本用一个Goroutine然后并发版本使用runtime.NumCPU，在我本机上是8个。这种情况下利用了并行去处理并发。 L5
10 Million Numbers using 8 goroutines with 8 cores 2.9 GHz Intel 4 Core i7 Concurrency WITH Parallelism ----------------------------------------------------------------------------- $ GOGC=off go test -cpu 8 -run none -bench . -benchtime 3s goos: darwin goarch: amd64 pkg: github.com/ardanlabs/gotraining/topics/go/testing/benchmarks/cpu-bound BenchmarkSequential-8 1000	5910799 ns/op BenchmarkConcurrent-8 2000	3362643 ns/op : ~43% Faster BenchmarkSequentialAgain-8 1000	5933444 ns/op BenchmarkConcurrentAgain-8 2000	3477253 ns/op : ~41% Faster L5中的benchmark表明了,每个Goroutines使用一个OS/硬件线程的时候并发版本比有序版本要快大约41%&amp;ndash;43%。这是我们期望中的事情，因为所有的Goroutines现在都在并行执行，8个Goroutines现在都在同一时间并发执行。 排序 需要明白，不是所有的CPU-bound的workloads都适合并发处理。当把工作拆解或者是把结果合并需要花费很大代价的时候这种说法是正确的。这种情况我们可以看一个算法的例子：冒泡排序。看一下下Go实现的冒泡排序。 L6
01 package main 02 03 import &amp;#34;fmt&amp;#34; 04 05 func bubbleSort(numbers []int) { 06 n := len(numbers) 07 for i := 0; i &amp;lt; n; i&#43;&#43; { 08 if !sweep(numbers, i) { 09 return 10 } 11 } 12 } 13 14 func sweep(numbers []int, currentPass int) bool { 15 var idx int 16 idxNext := idx &#43; 1 17 n := len(numbers) 18 var swap bool 19 20 for idxNext &amp;lt; (n - currentPass) { 21 a := numbers[idx] 22 b := numbers[idxNext] 23 if a &amp;gt; b { 24 numbers[idx] = b 25 numbers[idxNext] = a 26 swap = true 27 } 28 idx&#43;&#43; 29 idxNext = idx &#43; 1 30 } 31 return swap 32 } 33 34 func main() { 35 org := []int{1, 3, 2, 4, 8, 6, 7, 2, 3, 0} 36 fmt.Println(org) 37 38 bubbleSort(org) 39 fmt.Println(org) 40 } 在L6里，给出了Go版本的冒泡排序。排序算法遍历每个值并在整数集上进行数据交替。根据初始顺序不同，排序可能需要多次的遍历。 Question: bubbleSort的workload适合无序执行吗？答案肯定是no。整数集可以分解成更小的lists并且这些lists可以并发地排序。但是所有并发工作完成之后，并没有一个有效的方式再去把这些小的lists排序到一起。这里是一个并发版本的冒泡排序。 L8
01 func bubbleSortConcurrent(goroutines int, numbers []int) { 02 totalNumbers := len(numbers) 03 lastGoroutine := goroutines - 1 04 stride := totalNumbers / goroutines 05 06 var wg sync.WaitGroup 07 wg.Add(goroutines) 08 09 for g := 0; g &amp;lt; goroutines; g&#43;&#43; { 10 go func(g int) { 11 start := g * stride 12 end := start &#43; stride 13 if g == lastGoroutine { 14 end = totalNumbers 15 } 16 17 bubbleSort(numbers[start:end]) 18 wg.Done() 19 }(g) 20 } 21 22 wg.Wait() 23 24 // Ugh, we have to sort the entire list again. 25 bubbleSort(numbers) 26 } L8中，bubbleSortConcurrent方法是bubbleSort的并发版本。它使用多个Goroutines去并发地排序整个整数集的一部分。结果你得到的是各自的排序的list。结果你最终在25行还是要整个list做一次排序。 因为冒泡排序的本质就是遍历整个list。25行调用bubbleSort直接否定了任何并发的潜在收益。冒泡排序里，使用并发并没有性能上的增益。 读取文件 我们给出了2个CPU-Bound类型的workloads，那么IO-Bound类型的workload情况是什么样的？当Goroutines自动进入或者是离开waiting状态，情况会有什么不同么？看一个IO-bound类型的workload，它的工作内容是读取文件并查找文本。 第一个版本是一个有序版本的find方法 L10
42 func find(topic string, docs []string) int { 43 var found int 44 for _, doc := range docs { 45 items, err := read(doc) 46 if err != nil { 47 continue 48 } 49 for _, item := range items { 50 if strings.Contains(item.Description, topic) { 51 found&#43;&#43; 52 } 53 } 54 } 55 return found 56 } 在L10里面，你看到一个有序版本的find函数。line 43定义了一个found变量去存topic在文档里的出现次数。line 44，对所有文档进行遍历，并且在45行上使用read方法对每个doc进行读取。最后从49&amp;ndash;53行，使用strings包的Contains方法去检查topic是否在读取到的items里面。如果发现，found变量就对应加一。 这里是find调用的read方法的实现。 L11
33 func read(doc string) ([]item, error) { 34 time.Sleep(time.Millisecond) // Simulate blocking disk read. 35 var d document 36 if err := xml.Unmarshal([]byte(file), &amp;amp;d); err != nil { 37 return nil, err 38 } 39 return d.Channel.Items, nil 40 } read方法以一个time.Sleep方法开始。这个里模拟了真实从硬盘读取文档的系统调用所产生的延迟。设置这个延迟对我们精确地测试有序版本和并发版本find方法的性能差异十分重要。然后在35&amp;ndash;39行，测试的xml文档存储在fine的全局变量里，它被反序列化成一个要去处理的struct。最后返回了一个items的集合。 下面是一个并发版本代码。 注意：有多种方式去写并发版本代码，不要纠结于这个代码本身实现。 L12
58 func findConcurrent(goroutines int, topic string, docs []string) int { 59 var found int64 60 61 ch := make(chan string, len(docs)) 62 for _, doc := range docs { 63 ch &amp;lt;- doc 64 } 65 close(ch) 66 67 var wg sync.WaitGroup 68 wg.Add(goroutines) 69 70 for g := 0; g &amp;lt; goroutines; g&#43;&#43; { 71 go func() { 72 var lFound int64 73 for doc := range ch { 74 items, err := read(doc) 75 if err != nil { 76 continue 77 } 78 for _, item := range items { 79 if strings.Contains(item.Description, topic) { 80 lFound&#43;&#43; 81 } 82 } 83 } 84 atomic.AddInt64(&amp;amp;found, lFound) 85 wg.Done() 86 }() 87 } 88 89 wg.Wait() 90 91 return int(found) 92 } L12是find方法的并发版本。并发版本有30行代码，而非并发版本代码只有13行。我的目标是处理未知数量的documents时候控制Goroutines的数量。这里我选择在池化模式里使用一个channel去给池子里的goroutines喂数据。 这部分代码比较多，我只讲解重要部分 Line 61-64: 创建一个channel去处理所有的documents。 Line 65 关闭这个channel，来让池子里的goroutines在所有documents处理完成后能自动停止。 Line 70:创建一个goroutines线程池 Line 73&amp;ndash;83:每一个池子里的goroutine从channel接受一个document，读取到内存然后检查内容是否有topic。匹配的话,lfound就加一个。 Line 84:把每个单独goroutines跑出来的数加到一起。 并发版本确实比有序版本代码更加复杂，这个复杂性是否值得？验证的最好方式就是再次写一个benchmark。我用了1000个documents的集合，并且关闭了垃圾回收。一个是顺序版本find，一个是并发版本findConcurrent L13
func BenchmarkSequential(b *testing.B) {  for i := 0; i &amp;lt; b.N; i&#43;&#43; {  find(&amp;#34;test&amp;#34;, docs)  } }  func BenchmarkConcurrent(b *testing.B) {  for i := 0; i &amp;lt; b.N; i&#43;&#43; {  findConcurrent(runtime.NumCPU(), &amp;#34;test&amp;#34;, docs)  } } L13给出了benchmark。下面是当所有goroutines只有一个OS/硬件线程的时候。顺序代码使用1个goroutines，而并发版本是runtime.NumCPU的数，在我本机上是8。这种情况下，我们没用并行去做并发。 L14
10 Thousand Documents using 8 goroutines with 1 core 2.9 GHz Intel 4 Core i7 Concurrency WITHOUT Parallelism ----------------------------------------------------------------------------- $ GOGC=off go test -cpu 1 -run none -bench . -benchtime 3s goos: darwin goarch: amd64 pkg: github.com/ardanlabs/gotraining/topics/go/testing/benchmarks/io-bound BenchmarkSequential 3	1483458120 ns/op BenchmarkConcurrent 20	188941855 ns/op : ~87% Faster BenchmarkSequentialAgain 2	1502682536 ns/op BenchmarkConcurrentAgain 20	184037843 ns/op : ~88% Faster L14里面表明了，在只有一个单独OS/硬件线程的时候，并发版本大概要比顺序版本代码快87%&amp;ndash;%88。这是我们预料到的因为每个Goroutines都能有效的共享这一个OS/硬件线程。在read调用的时候每个goroutines能够自动进行上下文切换，这样OS/硬件线程会一直有事情做。 下面是使用并行去做并发处理。 L15
10 Thousand Documents using 8 goroutines with 1 core 2.9 GHz Intel 4 Core i7 Concurrency WITH Parallelism ----------------------------------------------------------------------------- $ GOGC=off go test -run none -bench . -benchtime 3s goos: darwin goarch: amd64 pkg: github.com/ardanlabs/gotraining/topics/go/testing/benchmarks/io-bound BenchmarkSequential-8 3	1490947198 ns/op BenchmarkConcurrent-8 20	187382200 ns/op : ~88% Faster BenchmarkSequentialAgain-8 3	1416126029 ns/op BenchmarkConcurrentAgain-8 20	185965460 ns/op : ~87% Faster L15的benchmark结果说明，额外的OS/硬件线程并没有提供更好的性能。 结论 这篇文章的目的就是让你知道什么时候你的workload适合使用并发。考虑到不同的场景，我给出了不同的例子。 你可以清楚的看到IO-Bound类型的workload并不需要使用并行处理去获得性能的大幅增加，这正好跟CPU-Bound类型的工作截然相反。像类似冒泡算法这种，使用并发其实会增加代码复杂度，而且不会有任何性能增益。所以，一定要确定你的workload是否适合使用并发场景，这是很重要的事情。
原文链接：www.ardanlabs.com/blog/2018/1…
</content>
    </entry>
    
     <entry>
        <title>理解golang调度之二 ：Go调度器</title>
        <url>http://shanks.link/blog/2021/04/04/%E7%90%86%E8%A7%A3golang%E8%B0%83%E5%BA%A6%E4%B9%8B%E4%BA%8C-go%E8%B0%83%E5%BA%A6%E5%99%A8/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原文链接 简介 第一篇文章解释了关于操作系统层级的调度，这对于理解Go的调度是很重要的。这一部分我会在语义层级解释Go调度器是如何工作的，并且着重关注它的一些高级特性。Go 调度器是一个十分复杂的系统，特别细节的地方不重要，重要的是对于它的工作模式有一个好的理解，这会让你做出更好的工程方面的决定。 从一个程序开始 当你的go程序启动，主机上定义的每一个虚拟内核都会为它分配一个逻辑处理器(P)，如果你的处理器上每个物理内核有多个硬件线程（超线程），每个硬件线程对于你的go程序来说就是一个虚拟内核。为了理解这个事情，看一下我的MacBook Pro的系统配置。 图2.1 你可以看到一个单独处理器有4个物理核心。配置表上没说每个物理核心有多少个硬件线程。Intel Core i7 处理器有自己的超线程，也就是每个物理内核上有两个硬件线程。因此Go程序知道并行执行操作系统线程的时候，会有8个虚拟内核可以用 验证一下，看一下下面的程序 L1
package main  import ( 	&amp;#34;fmt&amp;#34; 	&amp;#34;runtime&amp;#34; )  func main() {   // NumCPU returns the number of logical  // CPUs usable by the current process.  fmt.Println(runtime.NumCPU()) } 我在我的本机上运行这个程序，NumCPU()方法会返回8，我在本机上跑的任何Go程序会分配8个逻辑处理器(P)。 每个P会分配一个OS线程（M）。M代表machine。这个线程是OS来处理的，并且OS还负责把线程放置到一个core上去执行。这意味着当我跑一个Go程序在我的机器上，我有8个可用的线程去执行我的工作，每个线程单独连到一个P上。 每个Go程序同时也会有一个初始的Goroutine（G）。一个Goroutine本质上是一个协程（Coroutine），但是在go里，把字面“C”替换为“G”所以我们叫Goroutine。你可以认为Goroutine是一个用户程序级别的线程而且它跟OS线程很多方面都类似。区别仅仅是OS线程在内核(Core)上进行上下文切换，而Goroutines是在M上。 最后一个让人困惑的就是运行队列。在Go 调度器中有两种不同的运行队列：全局运行队列**（GRQ）和本地运行队列(LRQ)**。每个P会分配一个LRQ去处理P的上下文要执行的Goroutines 。这些Goroutines会在绑定到P的M上进行上下文的切换。GRQ会处理还没有分配到P上的Goroutines 。Goroutines从GRQ挪到LRQ的过程一会我们一会儿会说。 图2.2是包含了所有相关组件的一张图片 图2.2 协作调度 我们在第一部分的内容讲到了，OS调度器是一个抢占式调度器。也就是说你不知道调度器下一步会执行什么。内核所做的决定都是不确定的。运行在OS顶层的应用程序无法控制内核里面的调度，除非你使用同步的原始操作，例如atomic指令和mutex调用 Go调度器是Go runtime的一部分，Go runtime会编译到你应用程序里。这意味着Go调度器运行在内核之上的用户空间(user space) 当前Go调度器采用的不是抢占式调度器，而是协作试调度器。协作试调度器，意味着调度器需要代码中安全点处发生的定义好的用户空间事件去做出调度决策。 Go的协作调度有一个非常棒的地方就是，它看上去像是抢占式的。你没办法预测Go调度器将要做什么，调度决策不是开发人员而是go runtime去做的。将Go调度器看做是一个抢占式调度器是很重要的，因为调度是不确定的，这里不需要再过多延伸。 Goroutine状态 和线程一样。Goroutine有三种相同的高级状态。Goroutine可以是任何一种状态：等待（Waiting）、可执行（Runnable）、运行中（Executing）. 等待：此时Goroutine已经停止并且等待事件发生然后再次执行。这可能是出于等待操作系统（系统调用）或同步调用（原子操作atomic和互斥操作mutex）等原因。 这些类型的延迟是性能不佳的根本原因。 可执行： 此时Goroutine想要在M上执行分配给它的指令。如果有很多Goroutines想要M上的时间片，那么Goroutines必须等待更长时间。而且，随着更多Goroutines争夺时间片，单独Goroutines分配的时间就会缩短，这种类型的调度延时也会导致性能很差。 运行中：这意味着Goroutines已经放置在M上并且执行它的指令。此时应用程序的工作即将完成，这是我们想要的状态。 上下文切换（Context Switching） Go调度程序需要明确定义的用户空间事件，这些事件发生在代码中的安全点以进行上下文切换。这些事件和安全点在函数调用时发生。函数调用对Go调度器的运行状况至关重要。Go 1.11 或者更低版本中，如果你跑一个不做函数调用的死循环，会导致调度器延时和垃圾回收延时。合理的时机使用函数调用十分重要。 注意：相关issue和建议已经被提出来，并且应用到了1.12版本中。应用非协作的抢占式技术，使得在tight loop中进行抢占。 Go程序中有4种类型的事件，允许调度器去做出调度决策。
 使用关键字 go 垃圾回收 系统调用 同步处理  使用关键字 go 使用关键字go来创建Goroutine。一旦一个新的Goroutine创建好，调度器便有机会去做出调度决定 垃圾回收 GC时候会有它自己的Goroutines，这些Goroutines也需要M上的时间片。这会导致GC产生很多调度混乱。但是调度器很聪明，它知道Goroutines在做什么，然后会做出合理的调度决策。一个调度策略就是对那些想要访问堆的Goroutine，以及GC时候不会访问堆的Goroutine进行上下文切换。GC发生的时候有很多调度策略。 系统调用 如果一个Goroutine进行系统调用导致了M的阻塞，调度器有时候会用一个新的Goroutine从M上替换下这个Goroutine。但是有时候会需要一个新的M去执行挂在P队列上的Goroutine，这种情况我会在下一部分讲解。 同步处理 如果atomic、mutex或者是channel操作的调用导致了Goroutine的阻塞，调度器会切换一个新的Goroutine去执行。一旦那个Goroutine又可以重新执行了，他会被挂到队列上并最终在M上会上下文切换回去。 异步系统调用 当OS有能力去处理异步的系统调用时候，使用网络轮询器(network poller)去处理系统调用会更加高效。不同的操作系统分别使用了kqueue (MacOS)、epoll (Linux) 、 iocp (Windows) 对此作了实现。 今天许多操作系统都能处理基于网络(Networking-based)的系统调用。这也是网络轮询器(network poller)这一名字的由来，因为它的主要用途就是处理网络操作。网络系统上通过使用network poller，调度器可以防止Goroutines在系统调用的时候阻塞M。这可以让M能够去执行P的 LRQ上面的其他Goroutines，而不是再去新建一个M。这可以减少OS上的调度加载。 最好的方式就是给一个例子看看这些东西是如何工作的。
图2.3 图2.3展示了基本的调用图例。Goroutine-1正在M上面执行并且有3个Goroutine在LRQ上等待想要获取M的时间片。network poller此时空闲没事做。
图2.4 图2.4中 Goroutine-1想要进行network system调用，因此Goroutine-1移到了network poller上面然后处理异步调用，一旦Goroutine-1从M上移到network poller，M便可以去执行其他LRQ上的Goroutine。此时 Goroutine-2切换到了M上面。
图2.5 图2.5中，network poller的异步网络调用完成并且Goroutine-1回到了P的LRQ上面。一旦Goroutine-1能够切换回M上，Go的相关代码便能够再次执行。很大好处是，在执行network system调用时候，我们不需要其他额外的M。network poller有一个OS线程能够有效的处理事件循环。 同步系统调用 当Goroutine想进行系统调用无法异步进行该怎么办呢？这种情况下，无法使用 network poller并且Goroutine产生的系统调用会阻塞M。很不幸但是我们无法阻止这种情况发生。一个例子就是基于文件的系统调用。如果你使用CGO，当你调用C函数的时候也会有其他情况发生会阻塞M。 注意：Windows操作系统确实有能力去异步进行基于文件的系统调用。从技术上讲，在Windows上运行时可以使用network poller。 我们看一下同步系统调用(比如file I/O)阻塞M的时候会发生什么。
图2.6 图2.6又一次展示了我们的基本调度图例。但是这一次Goroutine-1的同步系统调用会阻塞M1
图2.7 图2.7中，调度器能够确定Goroutine-1已经阻塞了M。这时，调度器会从P上拿下来M1，Goroutine-1依旧在M1上。然后调度器会拿来一个新的M2去服务P。此时LRQ上的Goroutine-2会上下文切换到M2上。如果已经有一个可用的M了，那么直接用它会比新建一个M要更快。
图2.8 图2.8中，Goroutine-1的阻塞系统调用结束了。此时Goroutine-1能够回到LRQ的后面并且能够重新被P执行。M1之后会被放置一边供未来类似的情况使用。 工作窃取（Work Stealing） 从另一个层面看，调度器的工作方式其实是work-stealing的。这种行为在一些情况下能够让调度更有效率。我们最不想看到的事情是一个M进入了等待状态，因为这一旦发生，OS将会把M从core上切换下来。这意味着即使有可执行的Goroutine， P此时也没法干活了，直到M重新切换回core上。Work stealing同时也会平衡P上的所有Goroutines从而能够使工作更好的分配，更有效率。 让我们看一个例子
图2.9 图2.9里，我们有个多线程的Go程序。两个P分别服务4个Goroutines。并且一个单独的Goroutine在GRQ上。那么如果其中一个P很快执行完它所有的Goroutines会怎么样？
图2.10 P1没有更多Goroutine去执行了，但是在GRQ和P2的LRQ中都有可执行的Goroutines。这种情况P1会去窃取工作，Work Stealing的规则如下 L2
runtime.schedule() {  // only 1/61 of the time, check the global runnable queue for a G.  // if not found, check the local queue.  // if not found,  // try to steal from other Ps.  // if not, check the global runnable queue.  // if not found, poll network. } 所以基于L2的规则，P1需要去看P2的LRQ上的Goroutines并且拿走一半。
图2.11 图2.11中，一半的Goroutines从P2上偷走，P1现在可以执行那些Goroutines 如果P2完成了所有Goroutines的执行，并且P1的LRQ上已经空了会怎么样？
图2.12 图2.12中，P2完成了它所有的工作，现在想要偷点什么。首先，它会去看P1的LRQ却发现什么也没有了。接下来他会去看GRQ。他会找到Goroutine-9
图2.13 图2.13中，P2从GRQ上偷走了Goroutine-9并且开始执行它的工作。这种work stealing的很大好处是，它让M一直有事情做而不是闲下来。这种work stealing 可以看做内部的M的轮转，这种轮转的好处在这篇博客里做了很好的解释。 实际例子 为了看一下Go调度器为了在同一时间里做更多事情，了解这一切是如何一块发生的。首先想象这样一个多线程的C语言应用，程序需要处理两个OS线程，他们俩互相进行通信。
图2.14 图2.14中，有两个线程，相互通信。线程1上下文切换到Core1上并且现在正在执行，这允许线程1向线程2发送消息。 注意：通信方式不重要。重要的是这个过程里的线程状态。
图2.15 在图2.15中，一旦线程1完成发送消息，它就需要等待响应。这会导致线程1从Core1切换下来并处于等待状态。一旦线程2收到消息通知，它就会进入可执行的状态。现在OS进行上下文切换然后线程2在一个Core2上面执行。接下来线程2处理消息然后给线程1发送一个新消息。
图2.16 图2.16里。随着线程1收到线程2的消息，又一次发生了上下文切换。现在线程2从执行中的状态切换为等待的状态。并且线程1从等待状态切换到了可执行状态，最终回到运行状态。现在线程1可以处理并发送一个新消息回去。 所有的上下文切换(context switches)和状态的改变都需要花费时间去处理，这就限制了工作速度。每一次上下文切换 会导致50ns的潜在延迟，硬件执行指令的期望时间是每ns 12个指令，你会看到上下文切换的时候就少执行600个指令。因为这些线程在不同的core之前切来切去，cache-line未命中导致的延迟也会增加。 我们来看一下相同例子，使用Goroutines和Go调度器做替换。
图2.17 图2.17中，有两个Goroutines相互传递消息。G1上下文切换到M1上进行工作处理，之前这都是在Core1上发生的事情。现在是G1向G2发送消息。
图2.18 图2.18中，一旦G1发送完消息，它就会等待响应返回。这会让G1从M1上切换下来，并且进入到等到状态。一旦G2收到消息通知，它会进入可执行状态。现在Go调度器会把G2切换到M1上去执行，M1依旧在Core1上跑着。接下来G2处理消息然后给G1发送一个新消息。
图2.19 在图2.19中，随着G1收到G2发送来的消息，又一次发生上下文切换。现在G2从执行中的状态切换到等待状态并且G1从等待中切换到可执行状态，最终回到运行的状态，G1又能够处理并向G2发送新的消息了。 表面上事情并没有什么不同。不论你使用线程还是Goroutines都有上下文切换和状态改变的过程。但是线程和Goroutines之间有一个重要的差别可能不会被明显注意到。 在使用Goroutines的场景，整个过程一直使用的是相同的OS线程和Core。这也就意味着，从OS的视角，OS线程从来没有进入到waiting状态，一次也没有。结果就是我们在线程中上下文切换丢失的指令在Goroutines中不会丢失。 本质上讲，在OS层级go把io/blocking类型的工作转变成了cpu密集型的工作。由于所有上下文切换的过程都发生在应用程序的级别，上下文切换不会像线程一样丢掉600个指令（平均来说）。Go调度器还有助于提高cache-line的效率和NUMA。这也是为什么我们不需要比虚拟内核数更多的线程。在Go里，随着时间推移更多事情会被处理，因为Go调度器会尝试用更少的线程并且每个线程去做更多事情，这有助于减少OS和硬件层级的加载延迟。 结论 Go调度程序的设计在考虑操作系统和硬件工作复杂性方面确实令人惊讶。 在操作系统级别将IO /blocking工作转换为CPU密集型工作，是在利用更多CPU容量的过程中获得巨大成功的地方。 这就是为什么你不需要比虚拟内核数更多的OS线程。 每个虚拟内核一个OS线程情况下，你可以合理的期望你的所有工作(CPU密集、IO密集)都能够完成。对于网络程序和那些不需要系统调用阻塞OS线程的程序，也能够完成。 作为开发人员，你依旧需要理解在处理不同类型工作的时候你的程序正在做什么。你不能为了想要更好性能去无限制创建goroutine。Less is always more，但是通过理解了go调度器，你可以更好的做出决定。下一部分，我会探讨以保守的方式利用并发来提升性能的方法，但是对于代码的复杂性还是要做出平衡。
原文链接：www.ardanlabs.com/blog/2018/0…
</content>
    </entry>
    
     <entry>
        <title>理解golang调度之一 ：操作系统调度</title>
        <url>http://shanks.link/blog/2021/04/04/%E7%90%86%E8%A7%A3golang%E8%B0%83%E5%BA%A6%E4%B9%8B%E4%B8%80-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%B0%83%E5%BA%A6/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原文链接 简介 golang调度器的设计行为能够使你的多线程go程序更有效率、性能更好，这要归功于golang调度器对于操作系统调度器的支持。对于一个golang开发者来说，同时深刻理解操作系统调度和golang调度器工作原理，能够让你的golang程序设计和开发走到正确道路上。 操作系统调度器 操作系统调度器十分复杂，它必须要考虑到底层的硬件结构，包括但不限于处理器数和内核数，cpu cache和NUMA。如果没有这些东西，调度器就没办法尽可能有效的工作。 程序其实就是一系列按顺序执行的机器指令。为了能让其正常干活，操作系统使用了线程的概念。线程会处理和执行分配给它的一系列的机器指令。线程会一直执行这些机器指令，直到没有指令再去执行了。这也是为什么把线程称作&amp;quot;a path of execution&amp;quot;。 每个运行程序都会创建一个进程，每个进程都会有一个初始线程。线程能够创建更多的线程。这些不同的线程独立运行并且调度行为是线程级别决定的，而不是在进程级别。线程能够并发的执行(单独内核上每个线程会轮询占用一段cpu时间),而不是并行执行(在不同内核上同时执行)。线程同时会维持它自己的状态，并且能够在本地安全、独立地执行他自己的指令。这也说明了为什么线程是cpu调度的最小单位。 操作系统调度器，它负责确保在有线程能够运行的时候内核不会空闲下来。它会制造一种假象——所有能够跑的线程此时都在同时执行。为此，调度器需要优先执行高优先级的线程，但是它也必须保证低优先级的线程不会饿死。调度器也必须尽可能将调度延时压倒最少，。 好在许多算法的应用使得调度器更加高效。下面解释一些重要的概念。 执行指令 程序计数器(PC)，有时候也叫做指令指针(IP)，能够让你找到下一个要执行的指令。大部分的处理器里，PC指向下一个指令。 如果你曾经注意到go程序的追踪栈，你会注意到这些每一行末尾的16进制数字。例如Listing 1里的&#43;0x39和&#43;0x72 Listing 1
goroutine 1 [running]:  main.example(0xc000042748, 0x2, 0x4, 0x106abae, 0x5, 0xa)  stack_trace/example1/example1.go:13 &#43;0x39 &amp;lt;- LOOK HERE  main.main()  stack_trace/example1/example1.go:8 &#43;0x72 &amp;lt;- LOOK HERE 这些数字代表了PC值，也就是从各自函数开始的偏移量。&#43;0x39 PC偏移量代表了程序在还未panic的时候，线程在example方法执行的下一条指令。&#43;0x72 PC偏移量代表如果example函数回到main函数里，main里的下一条指令。指向指令的前一个指针告诉了你现正在执行什么指令 看一下导致Listing 1 panic的程序 Listing 2
07 func main() { 08 example(make([]string, 2, 4), &amp;#34;hello&amp;#34;, 10) 09 }  12 func example(slice []string, str string, i int) { 13 panic(&amp;#34;Want stack trace&amp;#34;) 14 } 十六进制数&#43;0x39代表了PC偏移量，在example函数里也就是距离函数开头57(10进制)bytes的位置。下面的Listing 3里，你可以通过二进制文件看到example函数的objdump。找到最下面的第12条指令，注意到是它上面一行的指令导致了panic Listing 3
$ go tool objdump -S -s &amp;#34;main.example&amp;#34; ./example1 TEXT main.example(SB) stack_trace/example1/example1.go func example(slice []string, str string, i int) {  0x104dfa0	65488b0c2530000000	MOVQ GS:0x30, CX  0x104dfa9	483b6110	CMPQ 0x10(CX), SP  0x104dfad	762c	JBE 0x104dfdb  0x104dfaf	4883ec18	SUBQ $0x18, SP  0x104dfb3	48896c2410	MOVQ BP, 0x10(SP)  0x104dfb8	488d6c2410	LEAQ 0x10(SP), BP 	panic(&amp;#34;Want stack trace&amp;#34;)  0x104dfbd	488d059ca20000	LEAQ runtime.types&#43;41504(SB), AX  0x104dfc4	48890424	MOVQ AX, 0(SP)  0x104dfc8	488d05a1870200	LEAQ main.statictmp_0(SB), AX  0x104dfcf	4889442408	MOVQ AX, 0x8(SP)  0x104dfd4	e8c735fdff	CALL runtime.gopanic(SB)  0x104dfd9	0f0b	UD2 &amp;lt;--- LOOK HERE PC(&#43;0x39) 注意: PC始终是下一个指令，不是当前指令。Listing 3很好的说明了amd64下面，go线程是如何执行指令序列的。 线程状态 另一个重要概念就是“线程状态”，线程状态说明了调度器该如何处理此时的线程。线程有三个状态:等待、可运行、执行中。 等待(Waiting)： 此时意味着线程停止并且等待被唤醒。可能发生的原因有，等待硬件(硬盘、网络)，操作系统(系统调用) 或者是同步调用(atomic,mutexes)。这些情况是导致性能问题的根源 可运行(Runnable)： 此时线程想要占用内核上的cpu时间来执行分配给线程的指令。如果你有许多线程想要cpu时间，线程必须要等一段时间才能取到cpu时间。随着更多线程争用cpu时间，线程分配的cpu时间会更短。这种情况下的调度延时也会造成性能问题。 执行中(Executing): 此时线程已经置于内核中，并且正在执行它的机器指令。应用程序的相关内容正在被处理。这种状态是我们所希望的 工作类型 线程有两种工作类型。第一种叫CPU密集型，第二种叫IO密集型 CPU密集型(cpu-bound): 这种工作下，线程永远不会被置换到等待(waiting)状态。这种一般是进行持续性的cpu计算工作。比如计算Pi这种的就是cpu密集型工作 IO密集型(io-bound) 这种工作会让线程进入到等待(waiting)状态。这种情况线程会持续的请求资源（比如网络资源）或者是对操作系统进行系统调用。线程需要访问数据库的情况就是IO密集型工作。同步事件(例如mutexes、atomic)，类似需要线程等待的情况y我也归为此类。 上下文切换(Context Switch) 如果你的程序运行在Linux、Mac或者是Windows上面，你的调度器则是抢占式的。这意味着，第一、调度器不会预先知道此时此刻会运行哪个线程。线程优先级加上事务(例如接受网络数据)让调度器无法确定哪个时间执行哪个线程。 第二、永远不能按照历史经验去看，之前跑出来的代码其实不能保证每次都按你所想去执行。如果你的代码1000次都是按照同样方式执行，你会以为下次也保证按照一样方式执行。如果你的程序需要确定性的话，你一定要控制线程的同步和编排。 在内核上切换线程的物理行为叫做上下文切换(context switch)。上下文切换发生情形如下，调度器从内核换下正在执行的线程，替换上可执行的线程。线程是从运行队列中取出，并设置成执行中(Executing)的状态。从内核上取下来的线程会置成可运行状态,或者是等待状态。 上下文切换的代价是昂贵的，因为需要花时间去交换线程，从内核上拿下来再放上去。上下文切换的延时受到很多因素影响，但是通常情况下，它会有1000&amp;ndash;1500纳秒的延时。考虑到硬件上每个内核上平均每纳秒执行12个指令，一次上下文切换会花费你12k&amp;ndash;18k个指令延时。这本质上来说，你的程序在上下文切换过程中失去了执行大量指令的机会。 如果你的程序集中于IO密集型(cpu-bound)的工作，上下文切换会相对有利。一旦一个线程进入到等待(waiting)状态。另一个处于可运行(Runnable)状态的线程会取代它的位置。这会使得内核始终是处于工作状态。这是调度器调度的一个重要层面，如果有事做(有线程处于可运行状态)就不允许内核闲下来。 如果你的程序集中于cpu密集型(cpu-bound)的工作，那么上下文切换会是性能的噩梦。因为线程要一直做事情，上下文切换会停止正在处理的工作。这种情况和IO密集型形工作成鲜明对比。 少即是多(Less Is More) 在早期时候，处理器仅仅只有一个内核，调度器并不十分复杂。因为你有一个单独的处理器，一个单独的内核，所以任何时间只能跑一个线程。处理方式是定义一个调度期(scheduler period) 然后尝试在一个调度期内去执行所有可运行(Runnable)的线程。这样没问题:把调度期按照需要执行的线程数量去分每一小段。 举例，如果你定义了你的调度期是10ms 并且你有两个线程，那每个线程会分到5ms。5个线程的话，每个线程就是2ms。但是如果你有100个线程会怎么样？每个线程时间片是10us(微秒), 这样就会无法工作，因为你需要大量时间去进行上下文切换(context switches)。 在另外一个场景，如果最小的时间切片是2ms 并且你有100个线程，调度期需要增加到2000ms也就是2s。要是如果你有1000个线程呢，现在调度期需要20s，也就是你要花20s才能跑完所有的线程如果每个线程都能跑满它的时间切片。 上面场景都是显而易见的事情。调度器在做决定的时候还要考虑到更多的因素。你控制了应用程序里的线程数量，当有更多线程的时候，并且是IO密集(IO-Bound)工作，就会有更多的混乱和不确定行为发生，调度和执行就花费更多时间。 这也是为什么说游戏规则就是“少即是多(Less is More)”，可运行线程越少意味着调度时间越少，线程得到的时间越多。更多的线程就意味着每个线程获得的时间就越少，分配的时间内做的事情也就越少。 找到平衡点 你需要在内核数和你的线程数量两者间，找到一个能够让你的程序获得最好吞吐量的平衡点。想要去找到这样的平衡点，线程池是一个很好的选择。 使用go之前，原作者在NT系统上使用C&#43;&#43;和c#。在那个操作系统里，使用IOCP(IO Completion Ports) 线程池对于写多线程软件十分重要。作为一个工程师，你需要计算出你要用多少个线程池，以及每个线程池的最大线程数，从而在确定了内核数的系统里最大化你的吞吐量。 当写web服务时候，你需要和数据库通信。3是一个魔法数字，每个内核设置3个线程似乎在NT上有最好的吞吐量。换句话说，每内核3线程能够最小化上下文切换的延时，最大化在内核上的执行时间。当你创建一个IOPC线程池，我知道我可以在主机上设置每个内核1&amp;ndash;3个线程数量。 如果我使用2个线程每个内核，完成工作的时间会变长，因为本来需要有工作去做的内核会有空闲时间。如果我每个内核用4个线程，也会花更长时间，因为我需要花更多时间进行上下文切换。平衡数字3，不管是什么原因，似乎在NT上都是一个神奇的数字。 当你的服务需要处理许多不同类型的工作会如何呢。那会有不同并且不一致的延迟。可能它会产生许多需要去处理的不同系统级别的事件。这种情况，你不可能去找到一个魔法数字，能让你在所有时间所有不同的工作情况下都有优秀的性能。当你使用线程池的时候，找到一个合适的配置会十分复杂。 缓存行(Cache Lines) 从主存访问数据有很高的延迟（大概100~300个时钟周期），因此处理器和内核会有缓存，能够让线程访问到更近的数据。从缓存访问数据的延迟非常低(大概3~40个时钟周期) 根据不同的缓存访问方式。衡量性能的一个方面就是，处理器通过减少数据访问延时而获取数据的效率。编写多线程的应用程序需要考虑到机器的缓存系统。 处理器和主存使用缓存行(cache lines)进行数据交换。一个缓存行是一个64 byte的内存块，它在内存和缓存系统之间进行交换。每个内核会分配它自己需要的cache副本。这也是为什么多线程中的内存突变会造成严重的性能问题。 当多线程并行运行，正在访问相同数据，甚至是相邻的数据单元，他们会访问相同的缓存行。任何内核上运行的任何线程能够从相同的缓存行获取各自的拷贝。 如果内核上面的线程修改它的cache行副本，在硬件的操作下，同一cache行的所有其他副本都会被标记为无效。当一个线程尝试读写无效cache行，需要重新访问主存去获取新的cache行副本(大约要100~300个时钟周期) 也许在2核的处理器上这不是大问题，但是如果是一个32核处理器并行跑32个线程，并且同时访问和修改一个相同的cache行呢？由于处理器到处理器之间的通信延迟增加，情况会更糟。程序内存会发生颠簸，性能变得很差，而且很可能你也不知道问题的所在。 这就是cache的一致性问题（ cache-coherency problem ）或者是说是共享失败（false sharing）。当编写改变共享状态的多线程应用时，cache系统必须要考虑在内。 调度决策场景 思考一下下面的调度场景。 应用程序启动，主线程已经在core1上启动。当线程正在执行，它为了访问数据需要去检索cache行。主线程现在为了某些并发处理创建一个新的线程。那么问题来了。 一旦线程创建好，并且准备要运行了，那么调度器是否应该:
 从core1上换下主线程？这样做有助于提高性能，因为这个新线程需要的相同数据被缓存的可能性非常大。但是主线程并没有得到它的全部时间片。 线程是否要一直等待直到main主线程完成它的时间后core1可用？线程并没有在运行，但是一旦运行它获取数据的延时将会消除。 线程等待下一个可用的core？这意味着所选择的core的cache行会经历冲刷、检索、复制，从而导致延迟。但是线程会更快的启动，并且主线程会完成它的时间片。  以上都是调度器在做决定时需要考虑到的事情。 结论 这是第一部分，为你提供了一些多线程编程时要考虑到线程和OS调度器的一些理解。这同时也是golang调度器需要考虑的事情。下面一部分，会讲Go调度器的一些相关知识。
原文链接:www.ardanlabs.com/blog/2018/0…
</content>
    </entry>
    
     <entry>
        <title>Golang 中的垃圾回收（三)</title>
        <url>http://shanks.link/blog/2021/04/04/golang-%E4%B8%AD%E7%9A%84%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E4%B8%89/</url>
        <categories>
          <category>[go go内存详解]</category>
        </categories>
        <tags>
          <tag>go</tag><tag>go内存详解</tag>
        </tags>
        <content type="html"> 原文链接 通过前两节的说明，我们得出这样一个结论：如果降低堆内存的分配压力就会相应的减少延迟，从而提升程序性能。这一节来讲一下，给一种类型的工作负载，GC的pacing算法是怎么来确定最佳回收速率的。 并发代码实例 本节给出的代码在这里可以找到： github.com/ardanlabs/g… 程序是做了这样一件事情，给一个特定topic，要确定它在文档集中出现的频率。程序包含了不用版本的寻找算法，它们使用了不同的并发模式。这里我们只看freq，freqConcurrent和freqNumCPU这三种版本的算法。 首先看freq，它是非并发顺序执行的程序版本，代码如下。 L1
01 func freq(topic string, docs []string) int { 02 var found int 03 04 for _, doc := range docs { 05 file := fmt.Sprintf(&amp;#34;%s.xml&amp;#34;, doc[:8]) 06 f, err := os.OpenFile(file, os.O_RDONLY, 0) 07 if err != nil { 08 log.Printf(&amp;#34;Opening Document [%s] : ERROR : %v&amp;#34;, doc, err) 09 return 0 10 } 11 defer f.Close() 12 13 data, err := ioutil.ReadAll(f) 14 if err != nil { 15 log.Printf(&amp;#34;Reading Document [%s] : ERROR : %v&amp;#34;, doc, err) 16 return 0 17 } 18 19 var d document 20 if err := xml.Unmarshal(data, &amp;amp;d); err != nil { 21 log.Printf(&amp;#34;Decoding Document [%s] : ERROR : %v&amp;#34;, doc, err) 22 return 0 23 } 24 25 for _, item := range d.Channel.Items { 26 if strings.Contains(item.Title, topic) { 27 found&#43;&#43; 28 continue 29 } 30 31 if strings.Contains(item.Description, topic) { 32 found&#43;&#43; 33 } 34 } 35 } 36 37 return found 38 } 非并发版本代码会去遍历文件集合，并执行以下4中操作：打开，读文件，解码和search，每次只处理一个文件。 运行freq，得到如下信息。 L2
$ time ./trace 2019/07/02 13:40:49 Searching 4000 files, found president 28000 times. ./trace 2.54s user 0.12s system 105% cpu 2.512 total 复制代码可以看到程序处理4000个文件花费了大约2.5s的时间。如果能够看到gc的实际情况就更好了，你可以使用trace包来生成trace信息。 L3
03 import &amp;#34;runtime/trace&amp;#34; 04 05 func main() { 06 trace.Start(os.Stdout) 07 defer trace.Stop() L3中引入了runtime/trace包。 重新编译运行代码，不要忘记把标准输出重定向到文件里。 L4
$ go build $ time ./trace &amp;gt; t.out Searching 4000 files, found president 28000 times. ./trace &amp;gt; t.out 2.67s user 0.13s system 106% cpu 2.626 total 复制代码正如我们预料的，运行时间增加了大概100ms。trace获取了每一次的方法调用的执行时间，达到微秒的级别。t.out包含了trace的数据。 我们可以使用下面的命令来查看trace信息。
$ go tool trace t.out 运行命令后会自动开一个浏览器窗口，如下图所示 图1.1 图1.1给了9个链接，现在我们只关心View trace。点击链接，看到如下图示： 图1.2 图2是程序运行的trace图。这部分我会主要关注垃圾回收器相关的东西，图中的Heap和GC部分。 图1.3 图1.3更近一些去看前200ms的trace信息。注意Heap信息(绿色和橘黄色区域)，以及GC（底下蓝色的竖线）。Heap信息告诉了你两件事情。橘色区域是当前时间正在使用的堆空间大小。绿色部分代表,触发下次回收，in-used堆内存空间。也就是说，每次橘色区域达到顶峰的时候，便开始进行垃圾回收。蓝色竖线代表了垃圾回收。 这个版本的程序运行中，堆中in-use的内存保持在大约4MB。要看一次单独垃圾回收的统计信息，可以使用选择工具框住蓝线。 图1.4 !()[https://user-gold-cdn.xitu.io/2019/7/30/16c42dd4681fa5d2?imageView2/0/w/1280/h/960/format/webp/ignore-error/1] 图1.4格里的数字，代表了选中区域的时间量。图中大概是316ms，当选中了所有蓝线，会出现下面统计信息 图1.5 图5中代表了图表中所有蓝线都在标记点15.911ms到2.596s之间。一共发生了232次回收，占用了64.524ms，平均每次回收时间是287.121微秒。了解到程序运行时间是2.626s，也就是说，垃圾回收占用了总时间的2%，基本上垃圾回收的代价对程序运行来说是微不足道的。 下面来看一下使用算法的并发版，我们希望可以加速程序运行。 L6
01 func freqConcurrent(topic string, docs []string) int { 02 var found int32 03 04 g := len(docs) 05 var wg sync.WaitGroup 06 wg.Add(g) 07 08 for _, doc := range docs { 09 go func(doc string) { 10 var lFound int32 11 defer func() { 12 atomic.AddInt32(&amp;amp;found, lFound) 13 wg.Done() 14 }() 15 16 file := fmt.Sprintf(&amp;#34;%s.xml&amp;#34;, doc[:8]) 17 f, err := os.OpenFile(file, os.O_RDONLY, 0) 18 if err != nil { 19 log.Printf(&amp;#34;Opening Document [%s] : ERROR : %v&amp;#34;, doc, err) 20 return 21 } 22 defer f.Close() 23 24 data, err := ioutil.ReadAll(f) 25 if err != nil { 26 log.Printf(&amp;#34;Reading Document [%s] : ERROR : %v&amp;#34;, doc, err) 27 return 28 } 29 30 var d document 31 if err := xml.Unmarshal(data, &amp;amp;d); err != nil { 32 log.Printf(&amp;#34;Decoding Document [%s] : ERROR : %v&amp;#34;, doc, err) 33 return 34 } 35 36 for _, item := range d.Channel.Items { 37 if strings.Contains(item.Title, topic) { 38 lFound&#43;&#43; 39 continue 40 } 41 42 if strings.Contains(item.Description, topic) { 43 lFound&#43;&#43; 44 } 45 } 46 }(doc) 47 } 48 49 wg.Wait() 50 return int(found) 51 } L6给出了freq算法的一个并发版。这个程序版本使用了扇出模式。每个一个docs列出的文件，都去创建一个goroutine去出里。如果有4000个文档，那么就要去创建4000个goroutine。这个版本的好处是，最简单的方式使用了并发。每个goroutine处理一个文件。我们可以使用WaitGroup和原子操作来保持计数器的同步处理。 在程序运行早期，所有goroutines都会分配时间去运行，也就是说程序会快速消耗大量的内存。在12行found增加这里，也会产生cache一致性的问题。由于每个虚拟内核共享这个变量的相同cache行，这会导致程序内存抖动，如果文件数或者内核数增加话，这种问题会更加严重。 我们重新编译代码然后再次运行 L7
$ go build $ time ./trace &amp;gt; t.out Searching 4000 files, found president 28000 times. ./trace &amp;gt; t.out 6.49s user 2.46s system 941% cpu 0.951 total L7中可以看到，程序现在处理4000个文件的时间是951ms，大概是64%的性能提升，来看一下trace信息。 图1.6 程序开始的时候，图中会有很多密集的线。这是因为所有goroutines都被创建了，他们运行并且尝试进行堆内存分配。只要第一个4MB内存分配了之后，就会开始GC。在GC期间，每个Goroutine都会去运行，并且当它们在堆上请求内存时，大多数都会进入等待状态。GC结束时，至少有9个goroutines还在继续运行，并且堆内存涨到了大约26MB。 图1.7 图1.7中你可以看到，第一次GC的时候，有一大堆处于Running或者是Runnable状态的goroutines。第一次GC结束之后，后面的GC时间就很快了，而且GC不再像上一个版本代码那样有规律。 如果你选择了图表上所有的回收，你会得到如下统计信息 图1.8 图1.8给出了，从4.828ms到906.939ms内。一共有23次垃圾回收，占用时间284.447ms，平均收集时间为12.367ms。程序运行时间是951ms，这意味着垃圾回收占用了总时间的34%。 可以对比出程序性能和GC时间的不同。运行更多goroutines确实让程序运行速度提升了64%。但是代价就是需要更多的机器资源，如果在同一时间，一下子达到了200MB in-use堆内存这个峰值的话就会很糟糕。 在并发版本的基础上，下面的并发版本，我们来更有效率更合理的来利用资源。 L8
01 func freqNumCPU(topic string, docs []string) int { 02 var found int32 03 04 g := runtime.NumCPU() 05 var wg sync.WaitGroup 06 wg.Add(g) 07 08 ch := make(chan string, g) 09 10 for i := 0; i &amp;lt; g; i&#43;&#43; { 11 go func() { 12 var lFound int32 13 defer func() { 14 atomic.AddInt32(&amp;amp;found, lFound) 15 wg.Done() 16 }() 17 18 for doc := range ch { 19 file := fmt.Sprintf(&amp;#34;%s.xml&amp;#34;, doc[:8]) 20 f, err := os.OpenFile(file, os.O_RDONLY, 0) 21 if err != nil { 22 log.Printf(&amp;#34;Opening Document [%s] : ERROR : %v&amp;#34;, doc, err) 23 return 24 } 25 26 data, err := ioutil.ReadAll(f) 27 if err != nil { 28 f.Close() 29 log.Printf(&amp;#34;Reading Document [%s] : ERROR : %v&amp;#34;, doc, err) 23 return 24 } 25 f.Close() 26 27 var d document 28 if err := xml.Unmarshal(data, &amp;amp;d); err != nil { 29 log.Printf(&amp;#34;Decoding Document [%s] : ERROR : %v&amp;#34;, doc, err) 30 return 31 } 32 33 for _, item := range d.Channel.Items { 34 if strings.Contains(item.Title, topic) { 35 lFound&#43;&#43; 36 continue 37 } 38 39 if strings.Contains(item.Description, topic) { 40 lFound&#43;&#43; 41 } 42 } 43 } 44 }() 45 } 46 47 for _, doc := range docs { 48 ch &amp;lt;- doc 49 } 50 close(ch) 51 52 wg.Wait() 53 return int(found) 54 } L8中给出了freqNumCPU版本的代码。这个设计模式的核心就是使用了池化模式。我们使用基于逻辑处理器数的goroutines池子，去处理所有的文件。如果是12个逻辑处理器，那么就是12个goroutines。这种方式的好处是，它会从开始到结束持续地让资源被使用。在任何时间，只有12个goroutines去申请内存。这也解决了由于cache一致性导致的内存抖动。 重新编译程序，再次运行。 L9
$ go build $ time ./trace &amp;gt; t.out Searching 4000 files, found president 28000 times. ./trace &amp;gt; t.out 6.22s user 0.64s system 909% cpu 0.754 total 可以看到L9中，同样4000个文件，花费了754ms。相比上个程序块了200ms，下面看下trace 图1.9 图1.9里，可以看到全部CPU容量都被使用，仔细观察可以看到，这个版本代码和顺序版本类似，GC比较有规律。 图1.10 图10给出了前20ms的程序trace图。12个goroutines运行，垃圾回收相对顺序版本时间更长一些。内存使用量维持在4MB之内。 框住所有垃圾回收，可以看到下面信息。 图1.11 图1.11，给出了3.055ms到719.928ms之间。产生了467次垃圾回收，占用177.709ms，平均回收时间380.535微秒。程序运行时间754ms，也就是说垃圾回收占了25%的全部时间。相比上一个版本有9%的提升。 如果文件数或者是虚拟核数更多的话，池化版本似乎会有更好的扩展，代码复杂性的代价是值得的。 结论 我们主要关注的就是不同版本代码的GC情况。总的内存分配其实每个版本都是一样的，不同只是如何去分配。 当只有一个goroutine，4MB的内存基本够用了。当程序一次性把所有work都扔过来，GC会让触发GC的in-used堆内存增加，减少GC次数但同时增加了GC时间。当程序控制每次并发处理file的数量的时候，GC会采取使用保持小堆的方式，增加了GC次数但是减少了每次GC时间。每种方式GC都会尽力让其对程序产生的影响最小。
| Algorithm | Program | GC Time | % Of GC | # of GC’s | Avg GC | Max Heap | |------------|---------|----------|---------|-----------|----------|----------| | freq | 2626 ms | 64.5 ms | ~2% | 232 | 278 μs | 4 meg | | concurrent | 951 ms | 284.4 ms | ~34% | 23 | 12.3 ms | 200 meg | | numCPU | 754 ms | 177.7 ms | ~25% | 467 | 380.5 μs | 4 meg | 复制代码freqNumCPU 版本会更好的处理cache一致性上的问题，这很有用。 综上，程序运行时候我们还是可以把一堆work扔过去处理。例如一个web服务使用50k的goroutines，本质上就是类似于第一种并发算法的扇出模式。GC会考虑workload然后找到最优的步调去进行。但是一些情况下也需要考虑相应的代价。 原文链接：www.ardanlabs.com/blog/2019/0…
</content>
    </entry>
    
     <entry>
        <title>Golang 中的垃圾回收（二)</title>
        <url>http://shanks.link/blog/2021/04/03/golang-%E4%B8%AD%E7%9A%84%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E4%BA%8C/</url>
        <categories>
          <category>[go go内存详解]</category>
        </categories>
        <tags>
          <tag>go</tag><tag>go内存详解</tag>
        </tags>
        <content type="html"> 原文链接 第一部分，我花了时间去描述了golang 垃圾收集器的行为，并说明了程序运行时候收集器所产生的延迟。我分享了怎么样去产生以及去解释GC traces。并展示了堆内内存如何改变，并且解释了GC不同阶段对延迟代价的影响。 最后的结论是，如果你减少了堆的压力，你就会减少延迟代价并提高了程序性能。我也指出了，降低收集速率，推迟收集，设法增加两次收集的时间间隔并不是很好的策略。即使是收集速率很快，但是以一致的速度进行，也能保持程序以最佳性能运行。 这部分里，我会带你通过一个实际的web应用并向你展示怎么样生成GC traces和程序状态。然后我会解释这些工具的输出内容，这样你可以找到方法去提高应用程序的性能。 运行应用 看一下go training的web应用程序 图1.1 github.com/ardanlabs/g… 图一是应用程序的样子。这个程序从不同的地方下载三个rss 订阅集合，并且允许用户去进行搜索。build之后，启动程序 L1
$ go build $ GOGC=off ./project &amp;gt; /dev/null 复制代码L1中我们设置了GOGC变量为off，也就是关闭垃圾回收。日志重定向到/dev/null。随着程序运行，我们可以向server中发送请求了。 L2
$ hey -m POST -c 100 -n 10000 &amp;#34;http://localhost:5000/search? term=topic&amp;amp;cnn=on&amp;amp;bbc=on&amp;amp;nyt=on&amp;#34; 复制代码L2展示了通过hey使用100个连接发送了10k的请求。所有请求发送到服务端，这个过程结果产生如下结果 图1.2 图2.2给出了关闭GC处理requests的可视化的过程。10k请求的处理大概花费了4188ms，也就是服务端每秒处理大概2387次请求。 打开GC 如果开启GC的话会怎么样 L3
$ GODEBUG=gctrace=1 ./project &amp;gt; /dev/null 复制代码L3中GOGC移除了，使用了GODEBUG变量，我们可以看到GC traces。 GODEBUG设置之后runtime就会在每次收集的时候生成GC trace。现在我们再次跑同样10k的请求。所有请求发送到服务端，我们可以看到GC traces和hey提供的信息。 L4
$ GODEBUG=gctrace=1 ./project &amp;gt; /dev/null gc 3 @3.182s 0%: 0.015&#43;0.59&#43;0.096 ms clock, 0.19&#43;0.10/1.3/3.0&#43;1.1 ms cpu, 4-&amp;gt;4-&amp;gt;2 MB, 5 MB goal, 12 P . . . gc 2553 @8.452s 14%: 0.004&#43;0.33&#43;0.051 ms clock, 0.056&#43;0.12/0.56/0.94&#43;0.61 ms cpu, 4-&amp;gt;4-&amp;gt;2 MB, 5 MB goal, 12 P 复制代码L4中展示了从程序运行开始的第三次和最后一次的GC trace。我没展示前两次的collection因为在这些收集发生之后，负载信息才会通过服务发送。最后一次collection表明了处理请求一共产生了2551次收集（没算前两个） 下面是我对每次trace进行了拆分 L5
gc 2553 @8.452s 14%: 0.004&#43;0.33&#43;0.051 ms clock, 0.056&#43;0.12/0.56/0.94&#43;0.61 ms cpu, 4-&amp;gt;4-&amp;gt;2 MB, 5 MB goal, 12 P  gc 2553 : The 2553 GC runs since the program started @8.452s : Eight seconds since the program started 14% : Fourteen percent of the available CPU so far has been spent in GC  // wall-clock 0.004ms : STW : Write-Barrier - Wait for all Ps to reach a GC safe-point. 0.33ms : Concurrent : Marking 0.051ms : STW : Mark Term - Write Barrier off and clean up.  // CPU time 0.056ms : STW : Write-Barrier 0.12ms : Concurrent : Mark - Assist Time (GC performed in line with allocation) 0.56ms : Concurrent : Mark - Background GC time 0.94ms : Concurrent : Mark - Idle GC time 0.61ms : STW : Mark Term  4MB : Heap memory in-use before the Marking started 4MB : Heap memory in-use after the Marking finished 2MB : Heap memory marked as live after the Marking finished 5MB : Collection goal for heap memory in-use after Marking finished  // Threads 12P : Number of logical processors or threads used to run Goroutines. 复制代码L5展示了最后一次collection的实际数字。多亏hey,下面是我们看到的运行时的性能结果。 L6
Requests : 10,000 ------------------------------------------------------ Requests/sec : 1,882 r/s - Hey Total Duration : 5,311ms - Hey Percent Time in GC : 14% - GC Trace Total Collections : 2,551 - GC Trace ------------------------------------------------------ Total GC Duration : 744.54ms - (5,311ms * .14) Average Pace of GC : ~2.08ms - (5,311ms / 2,551) Requests/Collection : ~3.98 r/gc - (10,000 / 2,511) L6给出了结果。下面给出了过程的可视化，来看一下发生了什么。 图1.3 图1.3给出了可视化的发生过程。开启回收器之后，相同10k的请求，它必须去处理大概~2.5k次collection。每次collection平均处理速度大概是2ms，处理这些collection增加了额外大概1.1秒的延迟。 图1.4 图1.4对比了两种情况下应用程序的运行情况。 减少分配 我们最好是可以看看堆内存的分配情况，来看看是否有可以去掉的non-productive的分配 L7
go tool pprof http://localhost:5000/debug/pprof/allocs 复制代码L7使用了pprof去调用/debug/pprof/allocs接口，然后取从运行程序里拉取内存分配信息。这个接口的存在是因为用了下面的代码。 L8
import _ &amp;#34;net/http/pprof&amp;#34;  go func() {  http.ListenAndServe(&amp;#34;localhost:5000&amp;#34;, http.DefaultServeMux) }() 导入net/http/pprof去绑定系统的默认服务。然后使用http.ListenAndServer携带http.DefaultServerMux去开启服务。 L9
(pprof) top 6 -cum Showing nodes accounting for 0.56GB, 5.84% of 9.56GB total Dropped 80 nodes (cum &amp;lt;= 0.05GB) Showing top 6 nodes out of 51  flat flat% sum% cum cum%  0 0% 0% 4.96GB 51.90% net/http.(*conn).serve  0.49GB 5.11% 5.11% 4.93GB 51.55% project/service.handler  0 0% 5.11% 4.93GB 51.55% net/http.(*ServeMux).ServeHTTP  0 0% 5.11% 4.93GB 51.55% net/http.HandlerFunc.ServeHTTP  0 0% 5.11% 4.93GB 51.55% net/http.serverHandler.ServeHTTP  0.07GB 0.73% 5.84% 4.55GB 47.63% project/search.rssSearch L9的底下出现了rssSearch的方法。这个方法分配了4.55GB的内存。接下来使用list去看一下这个方法的内部细节 L10
(pprof) list rssSearch Total: 9.56GB ROUTINE ======================== project/search.rssSearch in project/search/rss.go  71.53MB 4.55GB (flat, cum) 47.63% of Total    . . 117:	// Capture the data we need for our results if we find ...  . . 118:	for _, item := range d.Channel.Items {  . 4.48GB 119:	if strings.Contains(strings.ToLower(item.Description), strings.ToLower(term)) {  48.53MB 48.53MB 120:	results = append(results, Result{  . . 121:	Engine: engine,  . . 122:	Title: item.Title,  . . 123:	Link: item.Link,  . . 124:	Content: item.Description,  . . 125:	}) L10列出了代码，第119行出现了大量的内存分配 L11
 . 4.48GB 119:	if strings.Contains(strings.ToLower(item.Description), strings.ToLower(term)) { L11 给出了出现问题的代码。整个函数分配了4.55GB的数据，但这一行就分配了4.48GB。接下来看一下这一行代码做了什么，然后看看有哪里可以优化的地方。 L12
117 // Capture the data we need for our results if we find the search term. 118 for _, item := range d.Channel.Items { 119 if strings.Contains(strings.ToLower(item.Description), strings.ToLower(term)) { 120 results = append(results, Result{ 121 Engine: engine, 122 Title: item.Title, 123 Link: item.Link, 124 Content: item.Description, 125 }) 126 } 127 } 复制代码L12列出了tight loop里的代码。调用strings.ToLower会产生内存分配，因为需要创造新的strings，而且它们需要分配到堆内存上。在循环里调用strings.ToLower根本没有必要，因为完全可以在循环外面进行处理。 119行代码可以做一下调整来去掉不必要的内存分配。 L13
// Before the code change. if strings.Contains(strings.ToLower(item.Description), strings.ToLower(term)) {  // After the code change. if strings.Contains(item.Description, term) { 注意：在把item塞进缓存之前已经把item.Description进行lower处理了，这部分代码没列出来。新塞进来item会每15分钟缓存一次。把term进行lower处理直接在循环外面进行就可以了 L13里给出了我们是怎么把strings.ToLower从tight loop中拿掉的。重新编译项目然后运行，然后再次拿10k个requests去请求。 L14
$ go build $ GODEBUG=gctrace=1 ./project &amp;gt; /dev/null gc 3 @6.156s 0%: 0.011&#43;0.72&#43;0.068 ms clock, 0.13&#43;0.21/1.5/3.2&#43;0.82 ms cpu, 4-&amp;gt;4-&amp;gt;2 MB, 5 MB goal, 12 P . . . gc 1404 @8.808s 7%: 0.005&#43;0.54&#43;0.059 ms clock, 0.060&#43;0.47/0.79/0.25&#43;0.71 ms cpu, 4-&amp;gt;5-&amp;gt;2 MB, 5 MB goal, 12 P L14中，在调整了代码之后，相同10K请求下，现在只有1402次的collections次数了。 L15
With Extra Allocations Without Extra Allocations ====================================================================== Requests : 10,000 Requests : 10,000 ---------------------------------------------------------------------- Requests/sec : 1,882 r/s Requests/sec : 3,631 r/s Total Duration : 5,311ms Total Duration : 2,753 ms Percent Time in GC : 14% Percent Time in GC : 7% Total Collections : 2,551 Total Collections : 1,402 ---------------------------------------------------------------------- Total GC Duration : 744.54ms Total GC Duration : 192.71 ms Average Pace of GC : ~2.08ms Average Pace of GC : ~1.96ms Requests/Collection : ~3.98 r/gc Requests/Collection : 7.13 r/gc L15展示了和上一次结果的对比。下面提供更加清晰的可视化图例来看看发生了什么。 图1.5 图1.5展示了对比图。这一次收集器运行少了1149次（1402 vs 2551）在相同10k请求情况下。GC的时间比率从14%降到了7%。collection节省了%74的时间，这让应用程序处理速度提高了48%。 图1.6 图1.6展示了4中不同情况的对比图。我加上了优化版本关闭gc的情况 学习到什么 在上一篇文章中提到，提升收集器的效率在于减少堆内存的压力。记住，压力可以定义为：在给定时间内，应用程序在可用堆内存上的分配有多快。当压力减少，收集器产生的延时就会减少。这些延迟会拖慢你的应用程序。 L16
With Extra Allocations Without Extra Allocations ====================================================================== Requests : 10,000 Requests : 10,000 ---------------------------------------------------------------------- Requests/sec : 1,882 r/s Requests/sec : 3,631 r/s Total Duration : 5,311ms Total Duration : 2,753 ms Percent Time in GC : 14% Percent Time in GC : 7% Total Collections : 2,551 Total Collections : 1,402 ---------------------------------------------------------------------- Total GC Duration : 744.54ms Total GC Duration : 192.71 ms Average Pace of GC : ~2.08ms Average Pace of GC : ~1.96ms Requests/Collection : ~3.98 r/gc Requests/Collection : 7.13 r/gc L16是上面两个带GC版本的程序运行对比。很明显移除了4.48GB的不必要分配使程序运行更快。有趣的事情是，两个版本里，每次垃圾收集的平均速度时间几乎是相同的，大概都是在2ms左右。我们改变的事情是在于每次收集之间做了更多的work处理。应用程序从3.98r/gc提升到7.13r/gc(请求次数/gc)。工作量提高了79.1%。 在两次收集之间处理更多work会帮助减少收集的次数，可以看到gc次数从2551减少到了1402，大概45%的降低。应用程序的gc时间减少了74%，从745ms减少到193ms，也就是总时间的14%减少到7%。如果你运行关闭gc的优化版本代码，性能差异只有13%，应用程序处理时间从2753ms降到2398ms。 结论 如果你花时间专注于减少分配，作为go开发者的你也就是在提高gc的效率。你无法写出0分配的程序，因此区分生产性的分配（利于程序运行）和非生产性的内存分配(损害性能)是很重要的事情。之后你就可以完全相信gc去帮你处理内存管理的事情了。 gc是一个好的折衷方式。我花一点时间去进行gc处理，得到的是我不需要再去关系内存的管理了。go会让开发者更有效率而且应用程序依旧可以足够快的运行，这一切都归功于golang的garbage collector 原文链接：www.ardanlabs.com/blog/2019/0…
</content>
    </entry>
    
     <entry>
        <title>Golang 中的垃圾回收（一）</title>
        <url>http://shanks.link/blog/2021/04/03/golang-%E4%B8%AD%E7%9A%84%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E4%B8%80/</url>
        <categories>
          <category>[go go内存详解]</category>
        </categories>
        <tags>
          <tag>go</tag><tag>go内存详解</tag>
        </tags>
        <content type="html"> 原文链接 垃圾回收器负责追踪堆内存的分配，释放掉不需要的空间，追踪那些还在使用的分配空间。不同编程语言对这个机制的实现都很复杂，但是开发人员开发软件时候并不需要了解垃圾回收太细节的东西就能进行构建。另外，不同发布版本编程语言的VM和runtime也总是在改变和进化。对于应用开发人员来说，重要的是保持一个良好的work模型，了解编程语言里垃圾回收器的行为并且它们是怎么样支持这种行为的。 对于go 1.12版本来说，go语言使用了非分代，并发的三色标记和清扫的回收器。如果想了解如何进行标记和清扫的工作，请参考这篇文章。golang的垃圾回收器的实现每个版本都在更新和进化。因此一旦下个版本发布，讲任何细节的实现都不再准确。 总而言之，这篇文章不会去讲实际的实现细节。我会为你分享回收器的一些行为并且去解释怎样面对这些行为，不考虑实现细节以及未来的改变。这将会使你成为一个更好的golang开发者 堆不是一个容器 我不会把堆看做是一个可以存储或者是释放值的容器。理解这件事情很重要，内存里并没有明确定义了“堆”的一个分界线。任何应用程序预留的内存空间，在堆内存分配上是可用的。给定任何堆内存分配空间，它实际在虚拟内存还是物理内存上的存储位置和我们的模型并没有关联。理解这件事情会帮助你更好的理解垃圾回收模型的工作方式。 回收器行为 当回收开始，回收器会完成三个阶段的工作。这其中两个阶段会产生Stop The World(STW) 延迟，并且另一个阶段也会产生延迟，并且会导致降低应用程序的吞吐量。这三个阶段是：
 Mark Setup - STW Marking - Concurrent Mark Termination -STW  下面看各个阶段的详细说明。 Mark Setup -STW 当回收开始，首先要做的肯定是开启写屏障(Write Barrier)。写屏障的目的是在collector和应用程序goroutines并发时候，允许回收器去维持数据在堆中的完整性。 为了开启写屏障，每个运行中的应用程序goroutine必须要停下来。这个活动通常非常快，平均在10~30微妙之间。前提是在你的应用程序goroutines行为合理的情况下。 注意：为了更好的理解下面的调度图解，最好先看过之前写的golang调度文章 图1.1 图1给出了4个应用程序goroutines，在开始垃圾回收之前它们都在运行中。为了进行回收，4个goroutines中每一个都必须被停下来，这么做的唯一方式就是让回收器去检查并等待goroutine去做方法调用。方法调用确保了goroutines在安全的点停下来。如果其中一个goroutine没有进行方法调用但是其它的做了方法调用，会发生什么？ 图1.2 图1.2给出了一个问题的实际案例。如果P4的goroutine不停下来的话，垃圾回收就无法启动。但是P4正在执行一个tight loop去做一些math处理，这导致回收根本无法开始。 L1：
01 func add(numbers []int) int { 02 var v int 03 for _, n := range numbers { 04 v &#43;= n 05 } 06 return v 07 } L1给出了P4 goroutine正在执行的代码。取决于slice的大小，goroutine可能会执行很长很长的时间，导致了根本没有机会停下来。这种代码会阻止垃圾回收开始。更糟糕的是，其他的P无法为其他goroutine服务，因为collector处于等待状态。所以goroutine在合理的实际范围内进行方法调用是至关重要的。 注意：这部分是golang团队将在1.14版本中要改进的内容，通过加入调度器的抢占式调度技术 Marking -Concurrent 一旦写屏障开启，回收器就会开始进入都标记阶段。回收器第一件做的事情就是拿走25%的可用CPU给自己使用。collector使用Goroutines去进行回收工作，也就是它会从应用程序抢过来对应数量的P和M。这意味着，4个线程的go程序里，会有一个P被拿去处理回收工作。 图1.3 图1.3给出了collector是怎样拿走P1的在进行回收工作的时候。现在回收器可以开始Marking过程了。标记阶段就是标记处理堆内存中的in-use的值。它会去检查栈中所有存在的goroutines，去找到指向堆内存的根指针。之后回收器必须从根指针开始，遍历堆内存的树图。当P1上进行处理Marking工作，应用程序可以在P2、P3和P4上继续并发执行。这意味着回收器减少了当前CPU容量的25%。 我希望事情到此就结束了，但是并不是。如果P1上GC的goroutine在in-use的堆内存达到上限时候没完成Marking会怎么样？如果其他3个应用程序的goroutine导致了collector无法按时完成工作会怎么样？如果发生这种情况，新的内存分配就必须慢下来，尤其是在对应的goroutine上。 如果回收器确定它必须要减慢内存分配速度，它就会招募应用程序的goroutines去协助（Assist）进行标记工作。这叫做Mark Assist。任何应用程序goroutine被置入Mark Assist的时间和它将要在堆内存中加的数据量是成比例的。Mark Assist的一个正面功能就是它帮助提高了回收速度。 图1.4 图1.4展示了，之前P3上应用程序运行的goroutine，现在正在进行Mark Assist来帮助进行回收工作。希望其他goroutines不要参与其中。应用程序有分配内存压力的时候会看到大部分正在运行的goroutines在垃圾回收的时候去处理小量的Mark Assist工作。 Mark Termination -STW 一旦标记工作完成，下一个过程就是Mark Termination。这个时候写屏障关闭，各种清理工作会进行，并且计算出下一次的回收目标。在标记过程中那些发现自己处理tight loop的goroutines也会导致Mark Termination STW的延时增加。 图1.5 图1.5展示了，Mark Termination阶段完成，所有Goroutines都会停止。这个活动通常会在60~90微妙内完成。这个阶段完成可以没有STW，但是通过STW，会使得代码更加简单，并且增加的代码复杂度并不值得这点小增益。 一旦回收完成了，每个P可以再次被应用程序goroutines去使用，程序又回到了全力运行的状态。 图1.6 图1.6展示了回收完成后，全部可用的P现在正在处理应用程序的工作。 Sweeping - Concurrent 在回收完成之后，会有另外一个活动，叫做清扫（Sweeping）。Sweeping就是清理内存中有值但是没有被标记为in-use的堆内存。这个活动发生在当应用程序goroutines尝试去在堆中分配新的值的时候。Sweeping延迟增加到了堆内存分配的开销中，并且和任何垃圾回收的延迟都没有关联。 下面是在我的机器上进行trace的样本，我的机器上有12个hardware thread去执行goroutines。 图1.7 图1.7展示了trace的部分快照。你可以看到在回收中（注意上面蓝色GC行），12个P中的3个被拿去处理GC。你可以看到goroutine 2450，1978和2696在这时间正在进行Mark Assist而不是它自己的程序work。在回收的最后，只有一个P去处理GC并且最终进行STW(Mark Termination)工作. 在回收完成后，程序又回到了全力运行的状态。你可以看到在这些goroutine下面的许多玫瑰色的竖线。 图1.8 图1.8展示了那些玫瑰色的线代表了goroutine进行Sweeping工作而不是它自己的程序工作的时候。这些时刻goroutine会尝试在堆中分配新的值。 图1.9 图1.9展示了一个goroutine在Sweeping活动最后的追踪数据。runtime.mallocgc的调用会去在堆中分配新的值。runtime.(*mcache).nextFree调用会导致Sweeping。一旦堆中不再有分配的内存需要回收，nextFree就不会再看见。 上面描述的回收行为仅仅发生在当回收已经启动并正在处理的过程中。在确定什么时候开始回收中，GC配置选项扮演了重要的角色。 GC percentage runtime中有一个配置选项叫做 GC Percentage，默认值是100。这个值代表了下一次回收开始之前，有多少新的堆内存可以分配。GC Percentage设置为100意味着，基于回收完成之后被标记为生存的堆内存数量，下一次回收的开始必须在有100%以上的新内存分配到堆内存时启动。 作为例子，想象回收完成了并标记了2MB的in-use堆内存。 注意：图表中的堆内存不代表实际情况。go中的堆内存通常都是凌乱的碎片化的，你不会有图表中那种清晰的区分。这些图表提供了一个方便的可视化的堆内存模型来方便理解。 图1.10 图1.10展示了，在上一次的回收完成后，有2MB的in-use堆内存。由于GC Percentage设置了100%，下一次回收启动需要在堆内存增加了2MB或者更多内存时候或者之前启动。 图1.11 图1.11展示了2MB或者更多内存处于in-use。这会触发回收。一种方式去看到这些行为的方法，就是为每次GC生成一个GC trace。 L2
GODEBUG=gctrace=1 ./app  gc 1405 @6.068s 11%: 0.058&#43;1.2&#43;0.083 ms clock, 0.70&#43;2.5/1.5/0&#43;0.99 ms cpu, 7-&amp;gt;11-&amp;gt;6 MB, 10 MB goal, 12 P  gc 1406 @6.070s 11%: 0.051&#43;1.8&#43;0.076 ms clock, 0.61&#43;2.0/2.5/0&#43;0.91 ms cpu, 8-&amp;gt;11-&amp;gt;6 MB, 13 MB goal, 12 P  gc 1407 @6.073s 11%: 0.052&#43;1.8&#43;0.20 ms clock, 0.62&#43;1.5/2.2/0&#43;2.4 ms cpu, 8-&amp;gt;14-&amp;gt;8 MB, 13 MB goal, 12 P L2展示了如何使用GODEBUG变量去生成GC trace。下面的L3展示了程序生成的gc traces。 L3
gc 1405 @6.068s 11%: 0.058&#43;1.2&#43;0.083 ms clock, 0.70&#43;2.5/1.5/0&#43;0.99 ms cpu, 7-&amp;gt;11-&amp;gt;6 MB, 10 MB goal, 12 P  // General gc 1404 : The 1404 GC run since the program started @6.068s : Six seconds since the program started 11% : Eleven percent of the available CPU so far has been spent in GC  // Wall-Clock 0.058ms : STW : Mark Start - Write Barrier on 1.2ms : Concurrent : Marking 0.083ms : STW : Mark Termination - Write Barrier off and clean up  // CPU Time 0.70ms : STW : Mark Start 2.5ms : Concurrent : Mark - Assist Time (GC performed in line with allocation) 1.5ms : Concurrent : Mark - Background GC time 0ms : Concurrent : Mark - Idle GC time 0.99ms : STW : Mark Term  // Memory 7MB : Heap memory in-use before the Marking started 11MB : Heap memory in-use after the Marking finished 6MB : Heap memory marked as live after the Marking finished 10MB : Collection goal for heap memory in-use after Marking finished  // Threads 12P : Number of logical processors or threads used to run Goroutines L3展示了GC中的实际数值和它的含义。我最后会讲到这些值，但是现在注意1405 GC trace的内存片段。 图1.12 L4
// Memory 7MB : Heap memory in-use before the Marking started 11MB : Heap memory in-use after the Marking finished 6MB : Heap memory marked as live after the Marking finished 10MB : Collection goal for heap memory in-use after Marking finished 复制代码GC trace行给出了如下的信息：Marking Work开始之前堆内存中in-use大小是7MB。当Marking Work完成后，堆内存中in-use的大小是11MB。这意味着回收中额外增加了4MB的内存分配。Marking Work完成之后堆内存中存活空间的大小是6MB。这意味着下次回收开始之前，in-use堆内存可以增加到12MB（100%*生存堆内存大小=6MB） 你可以看到回收器超过了它设定的目标1MB，Marking Work完成之后的in-use堆内存是11MB而不是10MB。但是没关系，因为目标是根据当前in-use的堆内存计算得到的，也就是堆内存中标记为生存的空间，当回收进行的时候会有额外随时间计算增加的内存分配。在这个案例里，应用程序做了一些事情，导致在Marking之后，需要比预期更多去使用的堆内存。 如果你看下一个GC Trace 行（1406），你开会看到在2ms内事情是如何改变的。 图1.13 L5
gc 1406 @6.070s 11%: 0.051&#43;1.8&#43;0.076 ms clock, 0.61&#43;2.0/2.5/0&#43;0.91 ms cpu, 8-&amp;gt;11-&amp;gt;6 MB, 13 MB goal, 12 P  // Memory 8MB : Heap memory in-use before the Marking started 11MB : Heap memory in-use after the Marking finished 6MB : Heap memory marked as live after the Marking finished 13MB : Collection goal for heap memory in-use after Marking finished 复制代码L5展示了在之前的回收工作开始之后（6.068s vs 6.070s）这个回收工作开始了2ms的状态，尽管in-use的堆内存在允许的12MB中仅仅达到8MB。需要注意到，如果回收器决定最好要早一点开始进行回收的话，它就会那么做。这个案例下，它可能提前开始回收了，因为应用程序的分配压力很大并且collector想要降低在这次回收工作中Mark Assist的延迟。 还有两个事情要注意，回收器在它设定的目标内完成了。在Marking 完成之后in-use的堆内存空间是11MB而不是13MB，少了2MB。在Marking完成之后堆内存中标记为存活的空间同样是6MB。 另外，你可以获得更多GC的细节通过增加gcpacertrace=1的标记。这会让回收器打印concurrent pacer的内部状态。 L6
$ export GODEBUG=gctrace=1,gcpacertrace=1 ./app  Sample output: gc 5 @0.071s 0%: 0.018&#43;0.46&#43;0.071 ms clock, 0.14&#43;0/0.38/0.14&#43;0.56 ms cpu, 29-&amp;gt;29-&amp;gt;29 MB, 30 MB goal, 8 P  pacer: sweep done at heap size 29MB; allocated 0MB of spans; swept 3752 pages at &#43;6.183550e-004 pages/byte  pacer: assist ratio=&#43;1.232155e&#43;000 (scan 1 MB in 70-&amp;gt;71 MB) workers=2&#43;0  pacer: H_m_prev=30488736 h_t=&#43;2.334071e-001 H_T=37605024 h_a=&#43;1.409842e&#43;000 H_a=73473040 h_g=&#43;1.000000e&#43;000 H_g=60977472 u_a=&#43;2.500000e-001 u_g=&#43;2.500000e-001 W_a=308200 goalΔ=&#43;7.665929e-001 actualΔ=&#43;1.176435e&#43;000 u_a/u_g=&#43;1.000000e&#43;000 复制代码运行GC trace可以告诉你很多应用程序的健康状态以及回收器的速度。 Pacing 回收器有一个pacing算法，它会去确定什么时候回收去开始。算法依靠一个反馈循环，回收器会使用这种算法收集应用程序运行时候的信息，以及应用程序给堆造成的压力。压力可以定义为在给定的时间内应用程序在堆上的分配有多快。压力确定了回收器运行的速度。 在回收器开始回收之前，它会计算它认为完成回收所需的时间。 一旦回收运行，会造成正在运行的应用程序上的延迟，这将减慢应用程序的工作。 每次回收都会增加应用程序的整体延迟。 有一个错误观念就是认为降低回收器的速度是一种提高性能的方式。如果你可以推迟下一次的回收，你就会推迟它产生的延时。 但其实提升性能并不在于降低回收器的速度。 你可以决定改变GC Percentage的值，设置大于100。这会增加下次回收开始之前可以分配的内存大小。这会降低回收器的速度。但是不要考虑这么做。 图1.14 图1.14展示了改变GC percentage并改变了在下次回收之前可以分配的堆内存。你可以预想到回收器是怎么被降速的，因为它要等待堆内存in-use。 尝试直接影响回收速度并不能提升回收器性能。重要的事情是在于在每次回收的之间或者是回收的时候做更多事情，这个你可以通过减少work的堆内存的分配量来进行影响。 注意：也可以尽量使用最小的堆来实现所需要的吞吐量。记住，在云环境中，最小化堆内存的使用很重要。 图1.15 图1.15展示了go程序内部的一些统计。蓝色版本的统计展示了没有任何优化的情况下，应用程序处理10k请求情况。绿色版本表明了相同10k请求下，4.48GB的非生产性的内存分配产生而被发现后，从应用程序中移除之后的统计情况(降低堆内存分配压力)。 看一下两个版本的平均回收速度（2.08ms vs 1.96ms）。它们几乎差不太多，大概是2ms。不同的地方在于两个版本在每一次回收之间的work的量。应用程序每次回收之间，处理requests次数从3.98次变为 7.13次。可以看几乎相同的时间内有79.1%的工作量提升。可以看到，回收工作没有随着分配内存的减少而降速，而是保持了原来速度。成功点在于每次回收之间做了更多的事情。 调整回收器的回收速度，推迟延迟代价不是你提升应用程序的性能的方法，它只是减少了回收器需要运行的时间，这反过来会减少造成的延迟成本。回收器产生的延迟代价已经解释过了，但是这里再进行一个简单的总结说明。 Collector 延迟代价 每次回收工作，会带来两种类型的延迟。第一种是窃取CPU，在回收的时候这种窃取CPU的行为意味着你的应用程序没有以满CPU的状态运行。应用程序goroutines现在和回收器goroutine共享P，或者是进行Mark Assist。 图1.16 图1.16表明了只有75%的CPU在进行应用程序工作。因为回收器占用了一个P。 图1.17 图1.17中，只有一半的CPU在处理应用程序work。因为P3正在进行Mark Assist，P1被collector占用。 注意：Marking通常需要4 CPU-millsecondes/MB 的生存堆（举例，为了评估Marking阶段运行多少millseconds，这个值会设置为生存堆MB大小去除以0.25*CPU数目的值）。Marking实际运行大概是1MB/ms，但是只有1/4的CPU去处理。 第二种类型的延迟就是在回收中产生的STW。STW就是没有任何goroutine进行工作的情况。整个应用程序本质上是停止状态。 图1.18 图1.18展示了，STW时候所有goroutine都停止了。每次回收会发生两次STW。如果你的应用程序处于健康状态，那么回收器会让STW时间保持在100微秒以内。 降低GC延迟 减少GC延迟的方式是识别哪些是应用程序中不必要的内存分配并移除它们，这会在几个方面帮助提高collector。 帮助回收器:
 维持了最小堆 找到最优的一致速度 每次回收保持在目标（goal）之内 最小化回收的时间，STW和Mark Assist  这些事情都会帮助减少回收器产生的延迟，从而增加应用程序的吞吐量和性能。改变回收速度并没有什么用。你可以通过做出正确的工程方面决策，降低堆内存的分配压力来提升性能。 理解应用程序正在运行的workload 关于性能，还需要清楚你的workload的类型。理解你的workload意味着，确定你使用合理数量的goroutines来处理你的工作。CPU vs IO bound 的workloads是不同的，需要做出不同抉择。相关内容可以参考这里 结论 如果你花时间去专注于减少内存分配，你会得到性能上的提升。但是你不可能写出0分配的程序来，所以了解和确认productive（对程序有帮助的）的内存分配和not productive（损害性能）的分配是很重要的。之后你就可以信任垃圾回收器帮你维持好内存的健康和稳定，然后让你的程序持续的运行下去。 垃圾回收器是一个很好的折衷方式。花一点代价去进行垃圾回收，这样就不需要考虑内存管理的问题。Go 垃圾回收器能够让程序员更加高效和多产，可以让你写出足够快的程序。 原文链接：www.ardanlabs.com/blog/2018/1…
</content>
    </entry>
    
     <entry>
        <title>go 垃圾回收：三色算法</title>
        <url>http://shanks.link/blog/2021/04/03/go-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E4%B8%89%E8%89%B2%E7%AE%97%E6%B3%95/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原文链接 三色算法 go垃圾回收器的操作都是基于三色算法，这篇文章主要来说明此算法。
注意：三色算法并不是go独有的，它也会在其它编程语言中使用到
严格来说，在Go中这个算法的官方名称是叫做三色标记清除算法（tricolor mark-and-sweep algorithm）。它可以和程序一起并发工作并且使用写屏障（write barrier）。这就意味着，当Go程序员运行起来，go调度器去负责应用程序的调度，而垃圾回收器会像调度器处理常规应用程序一样，去使用多个goroutines去进行工作。
这个算法背后的核心思想是由Edsger W. Dijkstra，Leslie Lamport，A.J.Martin，C.S.Scholten和E.F.M.Steffens这些大佬提出的。算法首先发表在论文On-the-fly Garbage Collection：An Exercise in Cooperation上面。三色标记清除算法背后的首要原则就是它把堆中的对象根据它们的颜色分到不同集合里面。
现在让我们来谈谈每种颜色集合代表的含义。黑色集合是为了确保没有任何指针指向白色集合。但是白色集合中的对象允许有指针指向黑色集合，因为这不会对垃圾回收器的操作产生影响。灰色集合可能会有指针指向白色集合里的对象。白色集合中的对象就是垃圾回收的候选对象。
注意到没有任何对象可以从黑色集合进到白色集合，这允许算法能够去操作并且清除白色集合里的对象。此外，没有任何黑色集合里的指针对象能够直接指向白色集合中的对象。
当垃圾回收开始，全部对象标记为白色，然后垃圾回收器会遍历所有根对象并把它们标记为灰色。根对象就是程序能直接访问到的对象，包括全局变量以及栈里面的东西。这些对象大多数取决于特定程序的go代码。在这之后，垃圾回收器选取一个灰色的对象，把它变为黑色，然后开始寻找去确定这个对象是否有指针指向白色集合的对象。这意味着当一个灰色对象由于被其它对象的指针所指而扫描到的时候，这个灰色对象会被标记为黑色。如果扫描发现这个灰色对象有一个或者更多指针指向白色对象时，会把所指向的白色对象放到灰色集合里。只要有灰色集合对象存在，这个过程就会一直进行下去。之后，白色集合里的对象就是没人访问的对象，并且它们所占用的内存可以被回收重用。因此，在这个点上，我们说白色集合里的元素被垃圾回收了。
如果垃圾回收过程中，一个灰色对象在某些情况变为不可达状态，它在那次垃圾回收中就不会被回收了，但是不是说下次也不会回收！
在这个过程中，运行应用程序被叫做修改器（mutator）。mutator去运行一个小的方法叫做写屏障（write barrier），每次堆中的指针被修改写屏障都会去执行。如果堆中对象的指针被修改，就意味着那个对象现在是可触达的，写屏障会把它标记为灰色并把它放到灰色集合中。
mutator负责保持黑色集合中没有任何元素的指针去指向白色集合中的元素。这是在写屏障方法的帮助下完成的。如果维持这个不变状态失败的话，会毁坏垃圾回收过程，并且很可能会以一种丑陋和非预期的方式破坏你的程序。
堆可以看成许多连接对象的图，如下所示，展示了单独一个垃圾回收的过程。
我们有三种不同颜色：黑色、白色和黑色。当算法开始的时候，所有对象标记为白色。随着算法继续进行，白色对象移到了其它两种颜色集合的一种里面。最后留在白色集合里面的对象会在将来某个时间点被清理掉。
在前面的图里，你可以看到白色对象E，它是在白色集合里而且可以访问对象F，E不会被任何其它的对象访问到因为没有其它指向E的指针，这使得E成为了垃圾回收的最佳候选人！另外，对象A、B和C是根对象而且总是可达的，因此它们不会被垃圾回收掉。
接下来，算法会去处理留下的灰色集合元素，这意味着对象A和F会进入到黑色集合里。对象A会进入到黑色集合是因为它是一个根元素，而F会进入黑色集合是因为它没有指向任何其它对象但是是在灰色集合里。在对象A被垃圾回收之后，对象F会变成不可达状态并且会在下一次垃圾回收器的处理循环中被回收掉。
Go允许你通过在你的Go代码里放一个runtime.GC()的声明来手动去开启一次垃圾回收。但是，要记住一点，runtime.GC()会阻塞调用器，并且它可能会阻塞整个程序，尤其是如果你想运行一个非常繁忙的而且有很多对象的go程序。这种情况发生，主要是因为你不能在其他任何事都在频繁变化的时候去处理垃圾回收，因为这种情况不会给垃圾回收器机会，去清楚地确定白色、黑色和灰色集合里的成员。这种垃圾回收状态也被称作是垃圾回收安全点(garbage collection safe-point)。
你可以在https://github.com/golang/go/blob/master/src/runtime/mgc.go里找到垃圾回收器相关的高级go代码。你可以学习这个如果你想了解更多关于垃圾回收操作的东西。
</content>
    </entry>
    
     <entry>
        <title>深入 Go Golang 内存分配超级棒的文章：Go 内存分配器可视化指南</title>
        <url>http://shanks.link/blog/2021/04/03/%E6%B7%B1%E5%85%A5-go-golang-%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E8%B6%85%E7%BA%A7%E6%A3%92%E7%9A%84%E6%96%87%E7%AB%A0go-%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%99%A8%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 翻译地址 原文链接
当我第一次开始尝试理解 Go 语言的内存分配器时，整个过程让我抓狂。一切看起来都像一个神秘的黑盒子。因为几乎所有技术魔法（technical wizardry）都隐藏在抽象之下，所以你需要一层一层的剥离才能去理解它。
我们将通过这篇文章来一层层的剥离这些细节。如果你想学习所有关于 Go 内存分配器的知识，那么这篇文章正适合你。
物理内存和虚拟内存 每一个内存分配器都需要运行在由底层操作系统管理的虚拟内存空间（Virtual Memory Space）之上。
下图是一个物理内存单元（Physical Memory Cell）的简要说明（非精准） A simple illustration of a Physical Memory Cell
一个内存单元的概述经过大大简化之后描述如下：
 地址线（Address line）（晶体管做的开关）用于访问电容器（数据到数据线（Data Lines））。 如果地址线有电流流动（显式为红色），数据线可以写入到电容器，所以电容器带电，逻辑值表示 “1”。 如果地址线没有电流流动（显式为绿色），数据线不可以写入到电容器，所以电容器不带电，逻辑值表示 “0” 当 CPU 需要从 RAM 中“读取”值，则顺着“地址线（ADDRESS LINE）”（关闭开关）发送一个电流。如果电容器带电，则电流流向“数据线（DATA LINE）”（值为 1）；否则没有电流流向数据线，所以电容器保持不带电（值为 0）。 下图简单的描述 CPU 和物理内存单元如何交互  Simple Illustration of how a Physical Memory Cell interacts with CPU
数据总线（Data Bus）：用于在 CPU 和内存中间传输数据。
还有一点关于地址线（Address line）和按字节寻址（Addressable bytes）。
下图是 CPU 和物理内存之间地址线的说明
Illustrative Representation of an Address Line between CPU and Physical Memory.
 DRAM 中的每一个字节都分配了一个唯一的数字标识符（地址）。“物理字节 != 地址线的数量（Physical bytes present != Number of address line）”（e.g. 16 位 Intel 8088、PAE） 每一个“地址线”可以发送 1-bit 的值，用于表示给定字节地址中的“一个位（SINGLE BIT）” 在我们的上面给出的图中，我们有 32 个地址线。所以每个 字节（BYTE） 都有“32 位”作为地址。 [ 00000000000000000000000000000000 ] — 低内存地址 [ 11111111111111111111111111111111 ] — 高内存地址 由于我们每字节都有一个 32 位的地址，所以我们的地址空间包含 2 的 32 次方个可寻址字节（bytes）（4GB）。 综上所述，可寻址的字节数量取决于地址总线的数量，所以对于 64 个地址线最大可寻址 2 的 64 次方个字节数（16 EB），但是由于大部分架构实际上仅使用 48-bit 地址线（AMD）和 42-bit 地址线（Intel）作为 64-bit 指针，所以理论上允许 256TB 物理内存（Linux 在 x86-64 下通过 with 4 level page tables 允许每个处理器 128TB 地址空间，Windows 192TB）。  由于物理内存的大小是受限制的，所以进程运行在自身的内存沙盒内 &amp;ndash; “虚拟内存地址（virtual address space）”，称作 虚拟内存（Virtual Memory）。
**字节的地址在这个虚拟地址空间内不再和处理器放在地址总线上的地址相同。**因此必须建立转换数据结构和系统将虚拟地址空间中的字节映射到物理字节。
虚拟地址表示参见下图（/proc/$PID/maps）：
Virtual Address Space Representation
综上所述当 CPU 执行一个指令需要引用内存地址时。首先将在 VMA（Virtual Memory Areas）中的逻辑地址转换为线性地址。这个转换通过 MMU 完成。
This is not a physical diagram, only a depiction. address translation process not included for simpl
由于逻辑地址太大几乎很难独立的管理，所以引入术语 页（pages） 进行管理。当必要的分页操作被激活后，虚拟地址空间被分成更小的称作页的区域（大部分操作系统下是 4KB，可以修改）。页是虚拟内存中数据内存管理的最小单元。虚拟内存不存储任何内容，只是简单的将程序地址空间映射到底层物理内存之上。
独立的进程只能使用 VMA 作为他们的地址。所以当我们的程序需要更多 “堆内存（heap memory）时发生了什么？
下图是简单的汇编代码用于分配更多的堆内存
A simple assembly code asking for more heap memory.
下图描述堆内存的增长
heap memory increment
应用程序通过系统调用 brk[1]（sbrk/mmap 等）获得内存。内核仅更新堆 VMA 并调用它。
当前时间点实际上不分配页帧且新页在物理内存中并不存在。这也是 VSZ 和 RSS 大小的不同点。
内存分配器 通过对“虚拟地址空间”基本了解和它对在堆分配的意义，内存分配器现在变得更加容易解释。
如果堆上有足够的空间的满足我们代码的内存申请，内存分配器可以完成内存申请无需内核参与，否则将通过操作系统调用（brk）进行扩展堆，通常是申请一大块内存。（对于 malloc 大默认指的是大于 MMAP_THRESHOLD 个字节 - 128KB）。
但是，内存分配器除了更新 brk address 还有其他职责。其中主要的一项就是如何减少 内部（internal）和外部（external）碎片和如何快速分配当前块。考虑我们的程序以串行的方式（p1 到 p4）通过 malloc(size) 函数申请一块连续的内存然后通过 free(pointer)函数进行释放。
An external fragmentation demonstration
在 p4 阶段由于内存碎片化即使我们有足够的内存块依然无法满足申请的 6 个连续的内存块。
所以我们该如何减少内存碎片化呢 ？答案取决是使用哪种内存分配算法，也就是使用哪个底层库。
我们将简单看一下一个和 Go 内存分配器建模相近的内存分配器：TCMalloc。
TCMalloc TCMalloc 的核心思想是将内存分为多个级别缩小锁的粒度。在 TCMalloc 内存管理内部分为两个部分：线程内存（thread memory)和页堆（page heap）。
线程内存 每一个内存页都被分为多个固定分配大小规格的空闲列表（free list） 用于减少碎片化。这样每一个线程都可以获得一个用于无锁分配小对象的缓存，这样可以让并行程序分配小对象（&amp;lt;=32KB）非常高效。
Thread Cache (Each Thread gets this Thread Local Thread Cache)
页堆 TCMalloc 管理的堆由一组页组成，一组连续的页面被表示为 span。当分配的对象大于 32KB，将使用页堆（Page Heap）进行内存分配。
Page Heap (for span management)
当没有足够的空间分配小对象则会到页堆获取内存。如果页堆页没有足够的内存，则页堆会向操作系统申请更多的内存。
Note: 即使 Go 的内存分配器最初是基于 TCMalloc，但是现在已经有很大的不同。
Go 内存分配器 我们知道 Go 运行时（Go Runtime）调度器在调度时会将 Goroutines(G) 绑定到 逻辑处理器（P）(Logical Processors） 运行。类似的，Go 实现的 TCMalloc 将内存页（Memory Pages）分为 67 种不同大小规格的块。
如果你不熟悉 Go 的调度器可以先参见《Go scheduler: Ms, Ps &amp;amp; Gs》,然后继续阅读。
Size Classes in Go
如果页的规格大小为 1KB 那么 Go 管理粒度为 8192B 内存将被切分为 8 个像下图这样的块。
8 KB page divided into a size class of 1KB (In Go pages are maintained at the granularity of 8KB)
Go 中这些页通过 mspan 结构体进行管理。
mspan 简单的说，mspan 是一个包含页起始地址、页的 span 规格和页的数量的双端链表。
Illustrative Representation of a mspan in Go memory allocator
mcache
Go 像 TCMalloc 一样为每一个 逻辑处理器（P）（Logical Processors） 提供一个本地线程缓存（Local Thread Cache）称作 mcache，所以如果 Goroutine 需要内存可以直接从 mcache中获取，由于在同一时间只有一个 Goroutine 运行在 逻辑处理器（P）（Logical Processors）上，所以中间不需要任何锁的参与。
mcache 包含所有大小规格的 mspan 作为缓存。
Illustrative Representation of a Relationship between P, mcache, and mspan in Go.
由于每个 P 都拥有各自的 mcache，所以从 mcache 分配内存无需持有锁。
对于每一种大小规格都有两个类型：
scan &amp;ndash; 包含指针的对象。 noscan &amp;ndash; 不包含指针的对象。 采用这种方法的好处之一就是进行垃圾回收时 noscan 对象无需进一步扫描是否引用其他活跃的对象。
mcache 的作用是什么？
&amp;lt;=32K 字节的对象直接使用相应大小规格的 mspan 通过 mcache 分配
当 mcache 没有可用空间时会发生什么？
从 mcentral 的 mspans 列表获取一个新的所需大小规格的 mspan。
mcentral mcentral 对象收集所有给定规格大小的 span。每一个 mcentral 都包含两个 mspan 的列表：
empty mspanList &amp;ndash; 没有空闲对象或 span 已经被 mcache 缓存的 span 列表 nonempty mspanList &amp;ndash; 有空闲对象的 span 列表 Illustrative Representation of a mcentral
每一个 mcentral 结构体都维护在 mheap 结构体内。
mheap Go 使用 mheap 对象管理堆，只有一个全局变量。持有虚拟地址空间。
Illustrative Representation of a mheap.
就上我们从上图看到的：mheap 存储了 mcentral 的数组。这个数组包含了各个的 span 的 mcentral。
central [numSpanClasses]struct { mcentral mcentral pad [sys.CacheLineSize unsafe.Sizeof(mcentral{})%sys.CacheLineSize]byte } 由于我们有各个规格的 span 的 mcentral，当一个 mcache 从 mcentral 申请 mspan 时，只需要在独立的 mcentral 级别中使用锁，所以其它任何 mcache 在同一时间申请不同大小规格的 mspan 将互不受影响可以正常申请。
对齐填充（Padding）用于确保 mcentrals 以 CacheLineSize 个字节数分隔，所以每一个 MCentral.lock 都可以获取自己的缓存行（cache line），以避免伪共享（false sharing）[2]问题。
当 mcentral 列表空的时候会发生什么？mcentral 从 mheap 获取一系列页用于需要的大小规格的 span。
free[_MaxMHeapList]mSpanList：一个 spanList 数组。每一个 spanList 中的 mspan 包含 1 ~ 127（_MaxMHeapList - 1）个页。例如，free[3] 是一个包含 3 个页的 mspan 链表。free 表示 free list，表示未分配。对应 busy list。 freelarge mSpanList：一个 mspan 的列表。每一个元素(mspan)的页数大于 127。通过 mtreap 结构体管理。对应 busylarge。 大于 32K 的对象被定义为大对象，直接通过 mheap 分配。这些大对象的申请是以一个全局锁为代价的，因此任何给定的时间点只能同时供一个 P 申请。
对象分配流程
 大于 32K 的大对象直接从 mheap 分配。 小于 16B 的使用 mcache 的微型分配器分配 对象大小在 16B ~ 32K 之间的的，首先通过计算使用的大小规格，然后使用 mcache 中对应大小规格的块分配 如果对应的大小规格在 mcache 中没有可用的块，则向 mcentral 申请 如果 mcentral 中没有可用的块，则向 mheap 申请，并根据 BestFit 算法找到最合适的 mspan。如果申请到的 mspan 超出申请大小，将会根据需求进行切分，以返回用户所需的页数。剩余的页构成一个新的 mspan 放回 mheap 的空闲列表。 如果 mheap 中没有可用 span，则向操作系统申请一系列新的页（最小 1MB）。但是 Go 会在操作系统分配超大的页（称作 arena）。分配一大批页会减少和操作系统通信的成本。 所有在堆上的内存申请都来自 arena。让我们看看 arena 是什么。  Go 虚拟内存 让我们看一个简单的 Go 程序的内存情况
func main() { for {} } process stats for a program
从上面可以即使是一个简单的程序虚拟空间占用页大概 ~100MB 左右，但是 RSS 仅仅占用 696KB。让我们先搞清楚这之间的差异。
map and smap stats.
这里有一块内存区域大小在 ~ 2MB、64MB 和 32MB。这些是什么？
Arena 事实证明 Go 的虚拟内存布局中包含一系列 arenas。初始的堆映射是一个 arena，如 64MB（基于 go 1.11.5）。
current incremental arena size on a different system.
所以当前内存根据我们的程序需要以小增量映射，并且初始于一个 arena（~64MB）。
请首先记住这些数字。主题开始改变。早期 Go 需要预先保留一个连续的虚拟地址，在一个 64-bit 的系统 arena 的大小是 512GB。（如果分配的足够大且 被 mmap 拒绝 会发生什么？）
这些 arenas 就是我们所说的堆。在 Go 中每一个 arena 都以 8192B 的粒度的页进行管理。
下图表示一个 64MB 的 arena
Single arena ( 64 MB ).
Go 同时存在其他两个块：span 和 bitmap。两者都在堆外分配并且包含每个 arena 的元数据。大多用于垃圾回收期间（所以我们就讨论到这）。
在我们刚刚讨论的 Go 的内存分配策略种类里，只涉及到内存分配奇妙且多样性的冰山一角。
然而，Go 内存管理的一般思想是使用不同的内存结构为不同大小的对象使用不同的内存缓存级别来分配内存。将一个从操作系统接收的连续地址的块切分到多级缓存来减少锁的使用，同时根据指定的大小分配内存减少内存碎片以提高内存分配的效率和在内存释放之后加快 GC 运行的速度。
现在我们将通过下图结束 Go 内存分配可视化指南。
Visual Overview of Runtime Memory Allocator.
</content>
    </entry>
    
     <entry>
        <title>go 定时器 ticker和timer</title>
        <url>http://shanks.link/blog/2021/04/03/go-%E5%AE%9A%E6%97%B6%E5%99%A8-ticker%E5%92%8Ctimer/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原文链接
两种类型的定时器：ticker和timer。两者有什么区别呢？请看如下代码：
ticker
package main  import (  &amp;#34;fmt&amp;#34;  &amp;#34;time&amp;#34; )  func main() {  d := time.Duration(time.Second*2)  t := time.NewTicker(d)  defer t.Stop()   for {  &amp;lt;- t.C  fmt.Println(&amp;#34;timeout...&amp;#34;)  } } timeout… timeout… timeout…
解析
ticker只要定义完成，从此刻开始计时，不需要任何其他的操作，每隔固定时间都会触发。
timer
package main  import (  &amp;#34;fmt&amp;#34;  &amp;#34;time&amp;#34; )   func main() {   d := time.Duration(time.Second*2)  t := time.NewTimer(d)  defer t.Stop()   for {  &amp;lt;- t.C  fmt.Println(&amp;#34;timeout...&amp;#34;)  // need reset  t.Reset(time.Second*2)  } } output:
timeout… timeout… timeout…
解析
使用timer定时器，超时后需要重置，才能继续触发。
 如果callback中有sleep操作，那么ticker也不会在sleep期间发送多个timeout_signal，可以认为用了一个容量为1的channel
实操如下
d := time.Duration(time.Second * 1) t := time.NewTicker(d) defer t.Stop() log.Println(&amp;#34;timeout...&amp;#34;) time.Sleep(10 * time.Second)  for { 	&amp;lt;-t.C 	log.Println(&amp;#34;timeout...&amp;#34;) } 15:12:44 timeout&amp;hellip; 15:12:54 timeout&amp;hellip; 15:12:55 timeout&amp;hellip;
</content>
    </entry>
    
     <entry>
        <title>go 使用protobuf</title>
        <url>http://shanks.link/blog/2021/04/03/go-%E4%BD%BF%E7%94%A8protobuf/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原文链接发布于 2017-05-03
为什么要使用protobuf 最近的项目中，一直使用Json做数据传输。Json用起来的确很方便。但相对于protobuf数据量更大些。做一个移动端应用，为用户省点流量还是很有必要的。正好也可以学习一下protobuf的使用
  跟Json相比protobuf性能更高，更加规范
  编解码速度快，数据体积小
  使用统一的规范，不用再担心大小写不同导致解析失败等蛋疼的问题了
  但也失去了一些便利性
  改动协议字段，需要重新生成文件。
  数据没有可读性
安装 在go中使用protobuf，有两个可选用的包goprotobuf（go官方出品）和gogoprotobuf。 gogoprotobuf完全兼容google protobuf，它生成的代码质量和编解码性能均比goprotobuf高一些
安装protoc 首先去https://github.com/google/pro&amp;hellip; 上下载protobuf的编译器protoc，windows上可以直接下到exe文件(linux则需要编译)，最后将下载好的可执行文件拷贝到GOPATH的bin目录下(GOPATH的bin目录下(GOPATH/bin目录最好添加到系统环境变量里)
安装protobuf库文件 go get github.com/golang/protobuf/proto goprotobuf 安装插件
go get github.com/golang/protobuf/protoc-gen-go 生成go文件
protoc &amp;ndash;go_out=. *.proto gogoprotobuf 安装插件
gogoprotobuf有两个插件可以使用
protoc-gen-gogo：和protoc-gen-go生成的文件差不多，性能也几乎一样(稍微快一点点)
protoc-gen-gofast：生成的文件更复杂，性能也更高(快5-7倍)
//gogo go get github.com/gogo/protobuf/protoc-gen-gogo  //gofast go get github.com/gogo/protobuf/protoc-gen-gofast 安装gogoprotobuf库文件
go get github.com/gogo/protobuf/proto go get github.com/gogo/protobuf/gogoproto //这个不装也没关系 生成go文件
//gogo protoc --gogo_out=. *.proto  //gofast protoc --gofast_out=. *.proto 性能测试 这里只是简单的用go test测试了一下
//goprotobuf &amp;#34;编码&amp;#34;：447ns/op &amp;#34;解码&amp;#34;：422ns/op  //gogoprotobuf-go &amp;#34;编码&amp;#34;：433ns/op &amp;#34;解码&amp;#34;：427ns/op  //gogoprotobuf-fast &amp;#34;编码&amp;#34;：112ns/op &amp;#34;解码&amp;#34;：112ns/op go_protobuf的简单使用 test.proto
syntax = &amp;#34;proto3&amp;#34;; //指定版本，必须要写（proto3、proto2） package proto;  enum FOO {  X = 0; };  //message是固定的。UserInfo是类名，可以随意指定，符合规范即可 message UserInfo{  string message = 1; //消息  int32 length = 2; //消息大小  int32 cnt = 3; //消息计数 } client_protobuf.go
package main  import (  &amp;#34;bufio&amp;#34;  &amp;#34;fmt&amp;#34;  &amp;#34;net&amp;#34;  &amp;#34;os&amp;#34;  stProto &amp;#34;proto&amp;#34;  &amp;#34;time&amp;#34;   //protobuf编解码库,下面两个库是相互兼容的，可以使用其中任意一个  &amp;#34;github.com/golang/protobuf/proto&amp;#34;  //&amp;#34;github.com/gogo/protobuf/proto&amp;#34; )  func main() {  strIP := &amp;#34;localhost:6600&amp;#34;  var conn net.Conn  var err error   //连接服务器  for conn, err = net.Dial(&amp;#34;tcp&amp;#34;, strIP); err != nil; conn, err = net.Dial(&amp;#34;tcp&amp;#34;, strIP) {  fmt.Println(&amp;#34;connect&amp;#34;, strIP, &amp;#34;fail&amp;#34;)  time.Sleep(time.Second)  fmt.Println(&amp;#34;reconnect...&amp;#34;)  }  fmt.Println(&amp;#34;connect&amp;#34;, strIP, &amp;#34;success&amp;#34;)  defer conn.Close()   //发送消息  cnt := 0  sender := bufio.NewScanner(os.Stdin)  for sender.Scan() {  cnt&#43;&#43;  stSend := &amp;amp;stProto.UserInfo{  Message: sender.Text(),  Length: *proto.Int(len(sender.Text())),  Cnt: *proto.Int(cnt),  }   //protobuf编码  pData, err := proto.Marshal(stSend)  if err != nil {  panic(err)  }   //发送  conn.Write(pData)  if sender.Text() == &amp;#34;stop&amp;#34; {  return  }  } } server_protobuf.go
package main  import (  &amp;#34;fmt&amp;#34;  &amp;#34;net&amp;#34;  &amp;#34;os&amp;#34;  stProto &amp;#34;proto&amp;#34;   //protobuf编解码库,下面两个库是相互兼容的，可以使用其中任意一个  &amp;#34;github.com/golang/protobuf/proto&amp;#34;  //&amp;#34;github.com/gogo/protobuf/proto&amp;#34; )  func main() {  //监听  listener, err := net.Listen(&amp;#34;tcp&amp;#34;, &amp;#34;localhost:6600&amp;#34;)  if err != nil {  panic(err)  }   for {  conn, err := listener.Accept()  if err != nil {  panic(err)  }  fmt.Println(&amp;#34;new connect&amp;#34;, conn.RemoteAddr())  go readMessage(conn)  } }  //接收消息 func readMessage(conn net.Conn) {  defer conn.Close()  buf := make([]byte, 4096, 4096)  for {  //读消息  cnt, err := conn.Read(buf)  if err != nil {  panic(err)  }   stReceive := &amp;amp;stProto.UserInfo{}  pData := buf[:cnt]   //protobuf解码  err = proto.Unmarshal(pData, stReceive)  if err != nil {  panic(err)  }   fmt.Println(&amp;#34;receive&amp;#34;, conn.RemoteAddr(), stReceive)  if stReceive.Message == &amp;#34;stop&amp;#34; {  os.Exit(1)  }  } } </content>
    </entry>
    
     <entry>
        <title>How to Use Websockets in go</title>
        <url>http://shanks.link/blog/2021/04/03/how-to-use-websockets-in-go/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原文链接
Sending a message and getting an instant response without refreshing the page is something we take for granted. But in the past, enabling real-time functionality was a real challenge for developers. The developer community has come a long way from HTTP long polling and AJAX and has finally found a solution for building truly real-time apps.
This solution comes in the form of WebSockets, which make it possible to open an interactive session between a user’s browser and a server. WebSockets allow a browser to send messages to a server and receive event-driven responses without having to poll the server for a reply.
For now, WebSockets are the number one solution for building real-time applications: online games, instant messengers, tracking apps, and so on. This guide explains how WebSockets operate and shows how we can build WebSocket applications in Go programming language. We also compare the most popular WebSocket libraries so you can choose the best one for your needs.
Read also: Best Practices for Speeding Up JSON Encoding and Decoding in Go
Network sockets vs WebSockets Getting started with WebSockets in go, let’s draw the line between network sockets and WebSockets.
Network socket A network socket, or simply a socket, serves as an internal endpoint for exchanging data between applications running on the same computer or on different computers on the same network.
Sockets are a key part of Unix and Windows-based operating systems, and they make it easier for developers to create network-enabled software. Instead of constructing network connections from scratch, app developers can include sockets in their programs. Since network sockets are used for a number of different network protocols (HTTP, FTP, etc.), several sockets can be used simultaneously.
Sockets are created and used with a set of function calls, which are sometimes referred to as a socket’s application programming interface (API). Thanks to function calls, sockets can be opened just like regular files.
There are several types of network sockets:
Datagram sockets (SOCK_DGRAM), also known as connectionless sockets, use the User Datagram Protocol (UDP). Datagram sockets support a bidirectional flow of messages and preserve record boundaries.
Stream sockets (SOCK_STREAM), also known as connection-oriented sockets, use the Transmission Control Protocol (TCP), Stream Control Transmission Protocol (SCTP), or Datagram Congestion Control Protocol (DCCP). These sockets provide a bidirectional, reliable, sequenced, and unduplicated flow of data with no record boundaries.
Raw sockets (or raw IP sockets) are typically available in routers and other networking equipment. These sockets are normally datagram-oriented, although their exact characteristics depend on the interface provided by the protocol. Raw sockets are not used by most applications. They’re provided to support the development of new communication protocols and to provide access to more esoteric facilities of existing protocols.
Socket communication
First, let’s figure out how to ensure that every socket is unique. If they’re not, you can’t establish a reliable communication channel.
Giving every process a unique PID helps to deal with the problem locally. But such an approach doesn’t work over a network. To create a unique socket, we recommend using the TCP/IP protocol. With TCP/IP, the IP addresses of the network layer are unique within a given network, and the protocol and port are unique among host applications.
TCP and UDP are two major protocols for communicating between hosts. Let’s see how your app can connect to TCP and UDP sockets.
Connecting to a TCP socket
To establish a TCP connection, a Go client uses the DialTCP function in the net package. DialTCP returns a TCPConn object. When a connection is established, the client and server begin exchanging data: the client sends a request to the server through a TCPConn, the server parses the request and sends a response, and the TCPConn receives the response from the server. tcp socket
This connection remains valid until the client or server closes it. The functions for creating a connection are as follows:
Client side:
 // init  tcpAddr, err := net.ResolveTCPAddr(resolver, serverAddr)  if err != nil {  // handle error  }  conn, err := net.DialTCP(network, nil, tcpAddr)  if err != nil {  // handle error  }   // send message  _, err = conn.Write({message})  if err != nil {  // handle error  }   // receive message  var buf [{buffSize}]byte  _, err := conn.Read(buf[0:])  if err != nil {  // handle error  } Server side:
// init  tcpAddr, err := net.ResolveTCPAddr(resolver, serverAddr)  if err != nil {  // handle error  }   listener, err := net.ListenTCP(&amp;#34;tcp&amp;#34;, tcpAddr)  if err != nil {  // handle error  }   // listen for an incoming connection  conn, err := listener.Accept()  if err != nil {  // handle error  }   // send message  if _, err := conn.Write({message}); err != nil {  // handle error  }  // receive message  buf := make([]byte, 512)  n, err := conn.Read(buf[0:])  if err != nil {  // handle error  } Connecting to a UDP socket
In contrast to a TCP socket, with a UDP socket, the client just sends a datagram to the server. There’s no Accept function, since the server doesn’t need to accept a connection and just waits for datagrams to arrive. udp socket
Other TCP functions have UDP counterparts; just replace TCP with UDP in the functions above.
Client side:
// init  raddr, err := net.ResolveUDPAddr(&amp;#34;udp&amp;#34;, address)  if err != nil {  // handle error  }   conn, err := net.DialUDP(&amp;#34;udp&amp;#34;, nil, raddr)  if err != nil {  // handle error  }  .......  // send message  buffer := make([]byte, maxBufferSize)  n, addr, err := conn.ReadFrom(buffer)  if err != nil {  // handle error  }  .......  // receive message  buffer := make([]byte, maxBufferSize)  n, err = conn.WriteTo(buffer[:n], addr)  if err != nil {  // handle error  } Server side:
 // init  udpAddr, err := net.ResolveUDPAddr(resolver, serverAddr)  if err != nil {  // handle error  }   conn, err := net.ListenUDP(&amp;#34;udp&amp;#34;, udpAddr)  if err != nil {  // handle error  }  .......  // send message  buffer := make([]byte, maxBufferSize)  n, addr, err := conn.ReadFromUDP(buffer)  if err != nil {  // handle error  }  .......  // receive message  buffer := make([]byte, maxBufferSize)  n, err = conn.WriteToUDP(buffer[:n], addr)  if err != nil {  // handle error  } What WebSockets are The WebSocket communication protocol provides a full-duplex communication channel over a single TCP connection. In contrast to HTTPs, WebSockets don’t require you to send a request in order to get a response. They allow for bidirectional data flows, so you can just wait for the server to respond. It will send you a message when it’s available.
WebSockets are a good solution for services that require continuous data exchange – for instance, instant messengers, online games, and real-time trading systems. You can find complete information about the WebSocket protocol in the RFC 6455 specification.
WebSocket connections are requested by browsers and are responded to by servers, after which a connection is established. This process is often called a handshake. The special kind of header in WebSockets requires only one handshake between a browser and server for establishing a connection that will remain active throughout its lifetime.
WebSockets solve many of the headaches of real-time web development and have several benefits over traditional HTTP:
The lightweight header reduces data transmission overhead.
Only one TCP connection is required for a single web client.
WebSocket servers can push data to web clients. how websockets work
The WebSocket protocol is relatively simple to implement. It uses the HTTP protocol for the initial handshake. After a successful handshake, a connection is established and the WebSocket essentially uses raw TCP to read/write data.
This is what a client request looks like:
 GET /chat HTTP/1.1  Host: server.example.com  Upgrade: websocket  Connection: Upgrade  Sec-WebSocket-Key: x3JJHMbDL1EzLkh9GBhXDw==  Sec-WebSocket-Protocol: chat, superchat  Sec-WebSocket-Version: 13  Origin: http://example.com And here’s the server response:
 HTTP/1.1 101 Switching Protocols  Upgrade: websocket  Connection: Upgrade  Sec-WebSocket-Accept: HSmrc0sMlYUkAGmm5OPpG2HaGWk=  Sec-WebSocket-Protocol: chat How to create WebSocket app in Go To write a simple WebSocket echo server based on the net/http library, you need to:
Initiate a handshake
Receive data frames from the client
Send data frames to the client
Close the handshake
First, let’s create an HTTP handler with a WebSocket endpoint:
// HTTP server with WebSocket endpoint  func Server() {  http.HandleFunc(&amp;#34;/&amp;#34;, func(w http.ResponseWriter, r *http.Request) {  ws, err := NewHandler(w, r)  if err != nil {  // handle error  }  if err = ws.Handshake(); err != nil {  // handle error  }  … Then initialize the WebSocket structure.
The initial handshake request always comes from the client. Once the server has defined a WebSocket request, it needs to reply with a handshake response.
Bear in mind that you can’t write the response using the http.ResponseWriter, since it will close the underlying TCP connection once you start sending the response.
So you need to use HTTP Hijacking. Hijacking allows you to take over the underlying TCP connection handler and bufio.Writer. This gives you the possibility to read and write data without closing the TCP connection.
// NewHandler initializes a new handler func NewHandler(w http.ResponseWriter, req *http.Request) (*WS, error) { hj, ok := w.(http.Hijacker) if !ok { // handle error } &amp;hellip;.. } To complete the handshake, the server must respond with the appropriate headers.
// Handshake creates a handshake header func (ws *WS) Handshake() error {
 hash := func(key string) string { h := sha1.New() h.Write([]byte(key)) h.Write([]byte(&amp;quot;258EAFA5-E914-47DA-95CA-C5AB0DC85B11&amp;quot;)) return base64.StdEncoding.EncodeToString(h.Sum(nil)) }(ws.header.Get(&amp;quot;Sec-WebSocket-Key&amp;quot;)) .....  }
“Sec-WebSocket-key” is generated randomly and is Base64-encoded. The server needs to append this key to a fixed string after accepting a request. Assume your have the x3JJHMbDL1EzLkh9GBhXDw== key. In this case, you can use SHA-1 to compute the binary value and use Base64 to encode it. You’ll get HSmrc0sMlYUkAGmm5OPpG2HaGWk=. Use this as the value of the Sec-WebSocket-Accept response header.
Transferring the data frame When the handshake has been successfully completed, your app can read and write data from and to the client. The WebSocket specification defines a specific frame format that’s used between a client and server. Here is a bit pattern of the frame: The bit pattern of the frame
Use the following code to decode the client payload:
// Recv receives data and returns a Frame  func (ws *WS) Recv() (frame Frame, _ error) {  frame = Frame{}  head, err := ws.read(2)  if err != nil {  // handle error  } In turn, these lines of code allow for encoding data:
// Send sends a Frame  func (ws *WS) Send(fr Frame) error {  // make a slice of bytes of length 2  data := make([]byte, 2)   // Save fragmentation &amp;amp; opcode information in the first byte  data[0] = 0x80 | fr.Opcode  if fr.IsFragment {  data[0] &amp;amp;= 0x7F  }  ..... Closing a handshake A handshake is closed when one of the parties sends a close frame with a close status as the payload. Optionally, the party sending the close frame can send a close reason in the payload. If closing is initiated by the client, the server should send a corresponding close frame in response.
// Close sends a close frame and closes the TCP connection func (ws *Ws) Close() error {  f := Frame{}  f.Opcode = 8  f.Length = 2  f.Payload = make([]byte, 2)  binary.BigEndian.PutUint16(f.Payload, ws.status)  if err := ws.Send(f); err != nil {  return err  }  return ws.conn.Close() } List of WebSocket libraries There are several third-party libraries that ease developers’ lives and greatly facilitate working with WebSockets.
STDLIB ( x/net/websocket )
This WebSocket library is part of the standard library. It implements a client and server for the WebSocket protocol, as described in the RFC 6455 specification. It doesn’t need to be installed and has good official documentation. But on the other hand, it still lacks some features that can be found in other WebSocket libraries. Golang WebSocket implementations in the /x/net/websocket package do not allow users to reuse I/O buffers between connections in a clear way.
Let’s check how the STDLIB package works. Here’s an example of code for performing basic functions like creating a connection and sending and receiving messages.
First of all, to install and use this library, you should add this line of code to your:
import &amp;ldquo;golang.org/x/net/websocket&amp;rdquo;
Client side:
 // create connection  // schema can be ws:// or wss://  // host, port – WebSocket server  conn, err := websocket.Dial(&amp;#34;{schema}://{host}:{port}&amp;#34;, &amp;#34;&amp;#34;, op.Origin)  if err != nil {  // handle error  }  defer conn.Close()  .......  // send message  if err = websocket.JSON.Send(conn, {message}); err != nil {  // handle error  }  .......  // receive message  // messageType initializes some type of message  message := messageType{}  if err := websocket.JSON.Receive(conn, &amp;amp;message); err != nil {  // handle error  }  ....... Server side:
 // Initialize WebSocket handler &#43; server  mux := http.NewServeMux()  mux.Handle(&amp;#34;/&amp;#34;, websocket.Handler(func(conn *websocket.Conn) {  func() {  for {   // do something, receive, send, etc.  }  }  .......  // receive message  // messageType initializes some type of message  message := messageType{}  if err := websocket.JSON.Receive(conn, &amp;amp;message); err != nil {  // handle error  }  .......  // send message  if err := websocket.JSON.Send(conn, message); err != nil {  // handle error  }  ........ GORILLA
The WebSocket package in the Gorilla web toolkit boasts a complete and tested implementation of the WebSocket protocol as well as a stable package API. The WebSocket package is well-documented and easy to use. You can find documentation on the official Gorilla website.
Installation
go get github.com/gorilla/websocket Examples of code Client side:
 // init  // schema – can be ws:// or wss://  // host, port – WebSocket server  u := url.URL{  Scheme: {schema},  Host: {host}:{port},  Path: &amp;#34;/&amp;#34;,  }  c, _, err := websocket.DefaultDialer.Dial(u.String(), nil)  if err != nil {  // handle error  }  .......  // send message  err := c.WriteMessage(websocket.TextMessage, {message})  if err != nil {  // handle error  }  .......  // receive message  _, message, err := c.ReadMessage()  if err != nil {  // handle error  }  ....... Server side:
 // init  u := websocket.Upgrader{}  c, err := u.Upgrade(w, r, nil)  if err != nil {  // handle error  }  .......  // receive message  messageType, message, err := c.ReadMessage()  if err != nil {  // handle error  }  .......  // send message  err = c.WriteMessage(messageType, {message})  if err != nil {  // handle error  }  ....... Read also: What projects should you use Go for?
GOBWAS
This tiny WebSocket packahe has a powerful list of features, such as a zero-copy upgrade and a low-level API that allows for building custom packet handling logic. GOBWAS requires no intermediate allocations during I/O. It also boasts high-level wrappers and helpers around the API in the wsutil package, allowing developers to start fast without digging into the internals of the protocol. This library has a flexible API, but that comes at the cost of usability and clarity.
You can check the GoDoc website for the available documentation. The installation is provided by including the following line of code:
go get github.com/gobwas/ws
Client side:
 // init  // schema – can be ws or wss  // host, port – ws server  conn, _, _, err := ws.DefaultDialer.Dial(ctx, {schema}://{host}:{port})  if err != nil {  // handle error  }  .......  // send message  err = wsutil.WriteClientMessage(conn, ws.OpText, {message})  if err != nil {  // handle error  }   .......  // receive message  msg, _, err := wsutil.ReadServerData(conn)  if err != nil {  // handle error  }  ....... Server side:
 // init  listener, err := net.Listen(&amp;#34;tcp&amp;#34;, op.Port)  if err != nil {  // handle error  }  conn, err := listener.Accept()  if err != nil {  // handle error  }  upgrader := ws.Upgrader{}  if _, err = upgrader.Upgrade(conn); err != nil {  // handle error  }  .......  // receive message  for {  reader := wsutil.NewReader(conn, ws.StateServerSide)  _, err := reader.NextFrame()  if err != nil {  // handle error  }  data, err := ioutil.ReadAll(reader)  if err != nil {  // handle error  }  .......  }  .......  // send message  msg := &amp;#34;new server message&amp;#34;  if err := wsutil.WriteServerText(conn, {message}); err != nil {  // handle error  }  ....... GOWebsockets
This tool offers a wide range of easy-to-use features. It allows for concurrency control, data compression, and setting request headers. GoWebsockets supports proxies and subprotocols for emitting and receiving text and binary data. Developers can also enable or disable SSL verification. You can find documentation for and examples of how to use GOWebsockets on the GoDoc website and on the project’s GitHub page. Install the package by adding the following line of code:
go get github.com/sacOO7/gowebsocket
Client side:
 // init  // schema – can be ws or wss  // host, port – ws server  socket := gowebsocket.New({schema}://{host}:{port})  socket.Connect()  .......  // send message  socket.SendText({message})  or  socket.SendBinary({message})  .......  // receive message  socket.OnTextMessage = func(message string, socket gowebsocket.Socket) {  // hande received message  };  or  socket.OnBinaryMessage = func(data [] byte, socket gowebsocket.Socket) {  // hande received message  };  ....... Server side:
 // init  // schema – can be ws or wss  // host, port – ws server  conn, _, _, err := ws.DefaultDialer.Dial(ctx, {schema}://{host}:{port})  if err != nil {  // handle error  }  .......  // send message  err = wsutil.WriteClientMessage(conn, ws.OpText, {message})  if err != nil {  // handle error  }  .......  // receive message  msg, _, err := wsutil.ReadServerData(conn)  if err != nil {  // handle error  } Comparing existing solutions We’ve described four of the most widely used WebSocket libraries for Golang. The table below contains a detailed comparison of these tools. websocket libraries
To better analyze their performance, we also conducted a couple of benchmarks.
Read also: Monitoring the Performance of Your Go Application: Why and How You Should Do It
The results are the following: Benchmark tests
As you can see, GOBWAS has a significant advantage over others libraries. It has fewer allocations per operation and uses less memory and time per allocation. Plus, it has zero I/O allocation. Besides, GOBWAS has all the methods you need to create WebSocket client–server interactions and receive message fragments. You can also use it to easily work with TCP sockets.
If you really don’t like GOBWAS, you can use Gorilla. It’s quite simple and has almost all the same features. You can also use STDLIB, but it’s not as good in production because it lacks many necessary features and, as you can see in the benchmarks, offers weaker performance. GOWebsocket is about the same as STDLIB. But if you need to quickly build a prototype or MVP, it can be a reasonable choice.
Besides these tools, there are also several alternative implementations that allow you to build powerful steaming solutions. Among them there are:
go-socket.io
Apache Thrift
gRPC
Package rpc
The constant development of streaming technologies and the availability of well-documented tools such as WebSockets make it easy for developers to create truly real-time applications. Write us if you need advice on or help with creating a real-time app using WebSockets. We hope, this tutorial helped you a lot.
</content>
    </entry>
    
     <entry>
        <title>go系统学习推荐书籍</title>
        <url>http://shanks.link/blog/2021/04/03/go%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E4%B9%A6%E7%B1%8D/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Tony Bai
一个程序员的心路历程
 Go语言的发展现状 如果从2007年9月20日那个下午三个“程序员大佬”在谷歌总部的一间办公室里进行的一次有关设计一门新编程语言的讨论算起，那么Go语言已经度过了自己的13个年头了。  Robert Griesemer、Rob Pike和Ken Thompson
如果从2009年11月10日Go语言正式开源发布算起，Go语言也即将迎来自己的第11个生日。
2020年，Go联合创始人Rob Pike在专访中也认可了Go确实已成为云基础架构的语言。在Go即将迎来自己的11个生日的时候，Hacker News有人发起了“Go已超过10岁了，你觉得这门语言如何？”的提问，收到了广泛的关注和回答。国内媒体将这些问答整理后得到的结论是：“人生苦短，我要换Go”。
Stackoverflow官博11月2日发表的《Go语言有哪些优点？探讨导致Go语言日益流行的特征 》一文对Go语言的发展趋势描述的贴切：Go语言就像爬行的藤蔓，虽缓慢，但却逐渐占据了开发世界。它正以一种郁郁葱葱的并且在许多方面都很优越的编程能力覆盖着在它之前出现的所有事物。 不管你是否承认，Go在IT就业市场已经成为事实上的“香饽饽”之一，就像一贯不激进的慕课网也在今年双11打出了下面的专题：
上车，任何时间都不晚！ 那么怎么才能踏上Go这一强大且稳健前行的车呢？和其他主流编程语言一样，上车的必经之路：看书！
市面上的Go书籍为何这么少 和C、C&#43;&#43;、Java、Python等编程语言在市面上的书籍数量相比，Go流行于市面（大陆）上的图书似乎少了很多。其原因笔者觉得有如下几点：   年轻  我们来看看上述几门主流编程语言的诞生时间：
java 1995
c 1972
c&#43;&#43; 1983
python 1991
对于很多IT从业者来说，这些语言诞生的时候他们还没出生呢。而2009年末才正式发布的Go和“最年轻”的java之间还有14年的“年龄差”。
Go在国内真正开始快速流行起来大致在2015年第一届GopherChina大会(2015.4月)之后，当时的Go是1.4版本)。同一年下半年发布的Go 1.5实现自举并让GC延迟大幅下降，这引爆了Go在国内的流行。一批又一批程序员成为Gopher，在大厂、初创实践着Go语言。但知识和技能的沉淀和总结需要时间，相信再有5年，国内作者出版的Go语言相关书籍会像雨后春笋版出现在大家的书架上。
2）以品类代名词的身份占据的“领域”还少
提到Web，人们想到的是Java spring；提到深度学习、机器学习、人工智能，人们想到的是python和tensorflow；提到比特币，嵌入式，人们想到的是C；提到游戏，人们想到的是C&#43;&#43;；提到前端，人们想到的是Javascript。这些语言在这些垂直领域早早以杀手级框架入场，使得它们成为了这一领域的“品类代名词”，因此与该垂直领域相关的技术书籍都会采用作为该领域“品类代名词”的编程语言编写书中示例等，这样的书也就会被归类为这类语言方面的书籍。
Go语言诞生晚，入场也较晚。Go虽然通过缓慢的“爬行”，覆盖了一些领域并占据优势地位，但还不能说已经成为了该领域的“品类代名词”，比如：云原生、API、微服务、区块链等，因此被垂直领域书籍关联的机会也不像上面那几门语言多。
同时，由于Go“自带电池”，基于Go标准库我们可以实现大部分功能特性，无需依赖过多框架。即便依赖框架，框架本身也不复杂，很少以“某某框架”为主题编写一本技术书籍，这方面远远无法媲美Java和Spring这对“黄金组合”。
引进国外优秀作品需要时间  相对于国内，国外关于Go语言的作品要多不少，但引进国外图书资料需要时机以及时间(找译者翻译)。
系统学习Go语言的书籍列表TOP 5 笔者接触Go语言较早，Go语言相关的中外文书籍几乎都通读过一遍（经典好书读过可不止一遍哦）。Go语言比较简单，如果单单从系统掌握这门语言的角度来看，阅读下面基本书籍就足够了。如果你要学习某些垂直领域的Go应用和技巧，那么期待我后续对垂直领域Go书籍/资料的推荐吧^_^。  这里参考“天下足球”TOP10栏目的方式推荐我心目中掌握Go语言必读的五大好书（每项满分为5分）！
第五名：The Way To Go – Go语言百科全书
《The Way To Go》是我早期学习Go语言时最喜欢翻看的一本书。该书成书于2012年3月，恰逢Go 1.0版本刚刚发布，作者承诺书中代码均可在Go 1.0版本上编译通过并运行。该书分为4个部分：
为什么学习Go以及Go环境安装入门
Go语言核心语法
Go高级用法（读写、错误处理、单元测试、并发编程、socket与web编程等)
Go应用(常见陷阱、语言应用模式、从性能考量的代码编写建议、现实中的Go应用等)
每部分的每个章节都很精彩，这本书也是目前见到的最全面详实的讲解Go语言的书籍了，我称之为Gopher们的第一本“Go百科全书”。
该书作者Ivo Balbaert想必大多数人都不曾耳闻。为了写本文，我特地研究了一下他的作品以及出版时间，发现这个技术作者是很会“抢先机”并且眼光独到。他总是能发现市面刚出现不久但却很有潜力的编程语言并在其他人了解该门语言之前，就编写出类似“The way to Go”这样的为早期语言接纳者提供的详实资料，包括Julia，Rust等。在很多人还不知道这些语言名字的时候，他就已经开始学习这些语言，并为这些语言编写出质量很高的“百科全书”式的书籍。
很遗憾，这本书没有中文版。这可能是由于本书出版太早，等国内出版社意识到要引进Go语言方面的书籍时，这本书使用的Go版本又太老了，虽然本书中绝大部分例子依然可以在今天最新的Go编译器下通过编译并运行起来。不过无闻在github上发起了这本书的中译版项目：https://github.com/Unknwon/the-way-to-go_ZH_CN，感兴趣的gopher可以去在线或下载阅读。 此书虽棒，但毕竟年头“久远”，我只能委屈它一下了，将它列在第五位，下面是其各个指数的评分：
作者名气指数：3
关注度指数：3
内容实用指数：4
经典指数：4
总分：14
第四名：Go 101 – Go语言规范全方位解读
这是一本在国外人气和关注度比在国内高的中国人编写的英文书，当然也是有中文版的。
如果仅从书名中的101去判断，你很大可能会认为这仅仅是一本讲解Go入门基础的书，但这本书的内容可远远不止入门这么简单。这本书可大致分为三个部分：
Go语法基础
Go类型系统与运行时实现
以专题(topic)形式阐述的Go特性、技巧与实践模式
除了第一部分算是101范畴，其余两个部分都是Go语言的高级话题，也是要精通Go必须要掌握的“知识点”。并且，结合Go语言规范，作者对每个知识点的阐述都细致入微并结合大量示例辅助说明。我们知道有关C和C&#43;&#43;语言，市面上有一些由语言作者或标准规范委员会成员编写的annotated或rationale书籍（语言参考手册或标准解读），Go 101这本书也可以理解为Go语言的标准解读或参考手册。
Go 101这本书是开源电子书，其作者也在国外一些支持自出版的服务商那里做了付费数字出版。这使得这本书相对于其他纸板书有着另外一个优势：与时俱进。在作者的不断努力下，该书的知识点更新基本保持与Go的演化同步，目前其内容已经覆盖了最新的Go 1.15版本。
该书作者为国内资深工程师老貘，他花费三年时间“呕心沥血”完成此书并免费奉献给Go社区，值得大家为其大大的点赞！ 下面是本书推荐指数的评分：
作者名气指数：3
关注度指数：4
内容实用指数：4
经典指数：4
总分：15
第三名：Go语言学习笔记 – Go源码剖析与实现原理探索
这是一本在国内影响力很大和关注度较高的作品。一来其作者雨痕老师是国内资深工程师，也是2015年第一届GopherChina大会讲师；二来，该作品的前期版本是以开源电子书的形式风险给国内Go社区的；三来，作者在Go源码剖析方便可谓之条理清晰，细致入微。
2016年《Go语言学习笔记》纸版书出版，该书覆盖了当时最新的Go 1.5版本，Go 1.5版本在Go语言演化历史中的分量极高，它不仅实现了Go自举，还让Go GC的延迟下降到绝大多数应用可以将其应用到生产的程度。本书整体上分为两大部分：
Go语言详解：以短平快、捞干的来的风格对Go语言语法做了说明，能用示例说明的，绝不用文字做过多修饰。
Go源码剖析：这是本书精华，也是最受Gopher关注的部分。这部分对Go运行时神秘的内存分配、垃圾回收、并发调度、channel和defer的实现原理、syn.Pool的实现原理做了细致的源码剖析与原理总结。
随着Go语言演化，其语言和运行时实现一直在变化，但Go 1.5版本的实现是后续版本的基础，因此这本书的剖析非常值得每位Gopher阅读。从雨痕老师的github上最新消息来看，他似乎在编写新版Go语言学习笔记，基于Go 1.12版本，剖析源码是枯燥繁琐的，期待新版Go学习笔记早日与Gopher们见面。 下面是本书各个指数的评分：
作者名气指数：4
关注度指数：4
内容实用指数：4
经典指数：4
总分：16
第二名：Go语言实战 – 实战系列(in action)经典之作，紧扣Go语言的精华
Manning出版社出版的“实战系列(xx in action)”一直是程序员心中高质量和经典的代名词。在出版Go语言实战方面，该出版社也是丝毫不敢怠慢，邀请了Go社区知名的三名明星级作者联合撰写了该书的内容。这三位作者分别是：
威廉·肯尼迪 (William Kennedy) – 知名Go培训师，培训机构Ardan Labs的联合创始人，”Ultimate Go”培训的策划实施者。
布赖恩·克特森 (Brian Ketelsen) – 世界上最知名的Go技术大会 – GopherCon大会的联合发起人和组织者，GopherAcademy创立者，现微软Azure工程师
埃里克·圣马丁 (Erik St.Martin) – 世界上最知名的Go技术大会 – GopherCon大会的联合发起人和组织者
本书并不是大部头，而是薄薄的一本（中文版才200多页），因此你不要期望从本书得到百科全书一样的阅读感。本书的作者们显然也没有想将其写成面面俱到的作品，而是直击要点，即挑出Go语言和其他语言相比与众不同的特点进行着重讲解，这些特点构成了本书的结构框架：
入门：快速上手搭建、编写、运行一个go程序
语法：数组(作为一个类型而存在)、切片和map
Go类型系统的与众不同：方法、接口、嵌入类型
Go的拿手好戏：并发及并发模式
标准库常用包：log、marshal/unmarshal、io(Reader和Writer)
原生支持的测试
读完这本书，你就掌握了Go语言的精髓之处，这迎合了多数gopher的内心需求。本书中文版译者Googol Lee也是Go圈子里的资深gopher，翻译质量上乘。
下面对本书各个指数的评分：
作者名气指数：5
关注度指数：5
内容实用指数：4
经典指数：4
总分：18
第一名：Go程序设计语言 – 人手一本的Go语言“圣经”
如果说由Brian W. Kernighan和Dennis M. Ritchie联合编写的《The C Programming Language》(也称K&amp;amp;R C)是C程序员(甚至是所有程序员)心目中的“圣经”的话，
那么同样由Brian W. Kernighan(K)参与编写的The Go Programming Language（也称tgpl）就是Go程序员心目中的“圣经”。 本书模仿并致敬“The C Programming Language”的经典结构，从一个”hello, world”示例开始带领大家开启Go语言之旅。第二章程序结构是Go语言这个“游乐园”的向导图，了解它之后，我们就会迫不及待地奔向各个“景点”细致参观。Go语言规范中的所有“景点”在本书中都被覆盖到了，并且由浅入深，循序渐进：从基础数据类型到复合数据类型、从函数、方法到接口、从创新的并发goroutine到传统的基于共享变量的并发，从包、工具链到测试，从反射到低级编程(unsafe包)。作者行文十分精炼，字字珠玑，这与《The C Programming Language》的风格保持了高度的一致。书中的示例在浅显易懂的同时，又极具实用性并突出Go语言的特点（比如：并发web爬虫、并发非阻塞缓存等）。
读完本书后，你会有一种爱不释手，马上还要从头再读一遍的感觉，也许这就是“圣经”的魅力！
本书出版于2015年10月26日，也是既当年中旬Go 1.5这个里程碑版本发布后，Go社区的又一重大历史事件！并且Brian W. Kernighan老爷子的影响力让更多程序员加入到Go阵营，这也或多或少促成了Go成为下一个年度，即2016年年度TIOBE最佳编程语言。能得到Brian W. Kernighan老爷子青睐的编程语言只有C和Go，这也是Go的幸运。当然了如果老爷子是被Rob Pike或Ken Thompson通过私人关系邀请写书的，那就另当别论了，当然这纯属臆测，别当真^_^。
这本书的另一名作者Alan A. A. Donovan也并非等闲之辈，他是Go核心开发团队的成员，专注于Go工具链方面的开发。
现在唯一遗憾的是Brian W. Kernighan老爷子年事已高，不知道Go加入泛型后老爷子是否还有精力更新这本圣经。
该书中文版由七牛团队翻译，总体质量是不错的。建议Gopher们人手购置一本圣经“供奉”起来！^_^
下面对本书各个指数的评分：
作者名气指数：5
关注度指数：5
内容实用指数：5
经典指数：5
总分：20
小结 Go书籍绝非“汗牛充栋”，预计Go增加泛型表达力增强后，市面上会有更多的技术书籍出炉。上面的某些经典也许还会出新版。而市面上Go书籍不多从另外一角度也可以理解成Go语言在国内还有巨大的发展空间与潜力。  努力吧，Gopher们！
只有写书者，才能体会到写者的艰辛！Go专栏：改善Go语言编程质量的50个有效实践也是我努力了一年多才打磨雕琢出来的心血之作。自从上线后，收到大家的热烈关注和好评！现在恰逢双11慕课大促，欢迎有意愿在Go这条技术路线上进阶的朋友们订阅，在学习过程中欢迎随时反馈和交流！
</content>
    </entry>
    
     <entry>
        <title>go post请求常用的几种方式</title>
        <url>http://shanks.link/blog/2021/04/03/go-post%E8%AF%B7%E6%B1%82%E5%B8%B8%E7%94%A8%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原文链接
post请求常用的几种方式，记录一下
func httpPost() {  resp, err := http.Post(&amp;#34;https://www.abcd123.top/api/v1/login&amp;#34;,  &amp;#34;application/x-www-form-urlencoded&amp;#34;,  strings.NewReader(&amp;#34;username=test&amp;amp;password=ab123123&amp;#34;))  if err != nil {  fmt.Println(err)  }   defer resp.Body.Close()  body, err := ioutil.ReadAll(resp.Body)  if err != nil {  // handle error  }   fmt.Println(string(body)) }  func httpPostForm() {  resp, err := http.PostForm(&amp;#34;https://www.denlery.top/api/v1/login&amp;#34;,  url.Values{&amp;#34;username&amp;#34;: {&amp;#34;auto&amp;#34;}, &amp;#34;password&amp;#34;: {&amp;#34;auto123123&amp;#34;}})  if err != nil {  // handle error  }  defer resp.Body.Close()  body, err := ioutil.ReadAll(resp.Body)  if err != nil {  // handle error  }  fmt.Println(string(body))  }  func httpPostJson() {  jsonStr :=[]byte(`{ &amp;#34;username&amp;#34;: &amp;#34;auto&amp;#34;, &amp;#34;password&amp;#34;: &amp;#34;auto123123&amp;#34; }`)  url:= &amp;#34;https://www.denlery.top/api/v1/login&amp;#34;  req, err := http.NewRequest(&amp;#34;POST&amp;#34;, url, bytes.NewBuffer(jsonStr))  req.Header.Set(&amp;#34;Content-Type&amp;#34;, &amp;#34;application/json&amp;#34;)   client := &amp;amp;http.Client{}  resp, err := client.Do(req)  if err != nil {  // handle error  }  defer resp.Body.Close()   statuscode := resp.StatusCode  hea := resp.Header  body, _ := ioutil.ReadAll(resp.Body)  fmt.Println(string(body))  fmt.Println(statuscode)  fmt.Println(hea)  } </content>
    </entry>
    
     <entry>
        <title>go中的init函数以及main函数</title>
        <url>http://shanks.link/blog/2021/04/03/go%E4%B8%AD%E7%9A%84init%E5%87%BD%E6%95%B0%E4%BB%A5%E5%8F%8Amain%E5%87%BD%E6%95%B0/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原文链接
首先我们看一个例子：init函数：
init 函数可在package main中，可在其他package中，可在同一个package中出现多次。
main函数
main 函数只能在package main中。
执行顺序
golang里面有两个保留的函数：init函数（能够应用于所有的package）和main函数（只能应用于package main）。这两个函数在定义时不能有任何的参数和返回值。
虽然一个package里面可以写任意多个init函数，但这无论是对于可读性还是以后的可维护性来说，我们都强烈建议用户在一个package中每个文件只写一个init函数。
go程序会自动调用init()和main()，所以你不需要在任何地方调用这两个函数。每个package中的init函数都是可选的，但package main就必须包含一个main函数。
程序的初始化和执行都起始于main包。
如果main包还导入了其它的包，那么就会在编译时将它们依次导入。有时一个包会被多个包同时导入，那么它只会被导入一次（例如很多包可能都会用到fmt包，但它只会被导入一次，因为没有必要导入多次）。
当一个包被导入时，如果该包还导入了其它的包，那么会先将其它包导入进来，然后再对这些包中的包级常量和变量进行初始化，接着执行init函数（如果有的话），依次类推。
等所有被导入的包都加载完毕了，就会开始对main包中的包级常量和变量进行初始化，然后执行main包中的init函数（如果存在的话），最后执行main函数。下图详细地解释了整个执行过程： 首先我们看一个例子：
代码结构： Lib1.go  复制代码  package InitLib1 import &amp;#34;fmt&amp;#34; func init() {  fmt.Println(&amp;#34;lib1&amp;#34;) }  Lib2.go package InitLib2  import &amp;#34;fmt&amp;#34;  func init() {  fmt.Println(&amp;#34;lib2&amp;#34;) } main.go  package main  import (  &amp;#34;fmt&amp;#34;  _ &amp;#34;GolangTraining/InitLib1&amp;#34;  _ &amp;#34;GolangTraining/InitLib2&amp;#34; )  func init() {  fmt.Println(&amp;#34;libmain init&amp;#34;) }  func main() {  fmt.Println(&amp;#34;libmian main&amp;#34;) }  代码很简单，只是一些简单的输出
lib1 lib2 libmain init libmian main 输出的顺序与我们上面图给出的顺序是一致的
那我们现在就改动一个地方，Lib1包导入Lib2，main包不管
Lib1  package InitLib1  import (  &amp;#34;fmt&amp;#34;  _ &amp;#34;GolangTraining/InitLib2&amp;#34; )  func init() {  fmt.Println(&amp;#34;lib1&amp;#34;) } 输出：
lib2 lib1 libmain init libmian main main包以及Lib1包都导入了Lib2，但是只出现一次，并且最先输出，
说明如果一个包会被多个包同时导入，那么它只会被导入一次，而先输出lib2是因为main包中导入Lib1时，Lib1又导入了Lib2，会首先初始化Lib2包的东西
</content>
    </entry>
    
     <entry>
        <title>go 语言中关于包导入必学的8个知识点</title>
        <url>http://shanks.link/blog/2021/04/03/go-%E8%AF%AD%E8%A8%80%E4%B8%AD%E5%85%B3%E4%BA%8E%E5%8C%85%E5%AF%BC%E5%85%A5%E5%BF%85%E5%AD%A6%E7%9A%848%E4%B8%AA%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Hi，大家好，我是明哥。
在自己学习 Golang 的这段时间里，我写了详细的学习笔记放在我的个人微信公众号 《Go编程时光》，对于 Go 语言，我也算是个初学者，因此写的东西应该会比较适合刚接触的同学，如果你也是刚学习 Go 语言，不防关注一下，一起学习，一起成长。
我的在线博客：golang.iswbm.com 我的 Github：github.com/iswbm/GolangCodingTime
 单行导入与多行导入 在 Go 语言中，一个包可包含多个 .go 文件（这些文件必须得在同一级文件夹中），只要这些 .go 文件的头部都使用 package 关键字声明了同一个包。  导入包主要可分为两种方式：
单行导入 import &amp;ldquo;fmt&amp;rdquo; import &amp;ldquo;sync&amp;rdquo; 复制代码 多行导入 import( &amp;ldquo;fmt&amp;rdquo; &amp;ldquo;sync&amp;rdquo; )复制代码 如你所见，Go 语言中 导入的包，必须得用双引号包含，在这里吐槽一下。
使用别名 在一些场景下，我们可能需要对导入的包进行重新命名，比如  我们导入了两个具有同一包名的包时产生冲突，此时这里为其中一个包定义别名 import ( &amp;ldquo;crypto/rand&amp;rdquo; mrand &amp;ldquo;math/rand&amp;rdquo; // 将名称替换为mrand避免冲突 )复制代码 我们导入了一个名字很长的包，为了避免后面都写这么长串的包名，可以这样定义别名 import hw &amp;ldquo;helloworldtestmodule&amp;quot;复制代码 防止导入的包名和本地的变量发生冲突，比如 path 这个很常用的变量名和导入的标准包冲突。 import pathpkg &amp;ldquo;path&amp;quot;复制代码 3. 使用点操作 如里在我们程序内部里频繁使用了一个工具包，比如 fmt，那每次使用它的打印函数打印时，都要 包名&#43;方法名。
对于这种使用高频的包，可以在导入的时，就把它定义会 &amp;ldquo;自己人&amp;rdquo;（方法是使用一个 . ），自己人的话，不分彼此，它的方法，就是我们的方法。
从此，我们打印再也不用加 fmt 了。
import . &amp;ldquo;fmt&amp;rdquo;
func main() { Println(&amp;ldquo;hello, world&amp;rdquo;) }复制代码 但这种用法，会有一定的隐患，就是导入的包里可能有函数，会和我们自己的函数发生冲突。
包的初始化 每个包都允许有一个 init 函数，当这个包被导入时，会执行该包的这个 init 函数，做一些初始化任务。  对于 init 函数的执行有两点需要注意
init 函数优先于 main 函数执行
在一个包引用链中，包的初始化是深度优先的。比如，有这样一个包引用关系：main→A→B→C，那么初始化顺序为
C.init→B.init→A.init→main复制代码 5. 包的匿名导入 当我们导入一个包时，如果这个包没有被使用到，在编译时，是会报错的。
但是有些情况下，我们导入一个包，只想执行包里的 init 函数，来运行一些初始化任务，此时怎么办呢？
可以使用匿名导入，用法如下，其中下划线为空白标识符，并不能被访问
// 注册一个PNG decoder import _ &amp;ldquo;image/png&amp;quot;复制代码 由于导入时，会执行 init 函数，所以编译时，仍然会将这个包编译到可执行文件中。
导入的是路径还是包？ 当我们使用 import 导入 testmodule/foo 时，初学者，经常会问，这个 foo 到底是一个包呢，还是只是包所在目录名？  import &amp;ldquo;testmodule/foo&amp;quot;复制代码 为了得出这个结论，专门做了个试验（请看「第七点里的代码示例」），最后得出的结论是：
导入时，是按照目录导入。导入目录后，可以使用这个目录下的所有包。 出于习惯，包名和目录名通常会设置成一样，所以会让你有一种你导入的是包的错觉。 7. 相对导入和绝对导入 据我了解在 Go 1.10 之前，好像是不支持相对导入的，在 Go 1.10 之后才可以。
绝对导入：从 $GOPATH/src 或 $GOROOT 或者 $GOPATH/pkg/mod 目录下搜索包并导入
相对导入：从当前目录中搜索包并开始导入。就像下面这样
import (  &amp;#34;./module1&amp;#34;  &amp;#34;../module2&amp;#34;  &amp;#34;../../module3&amp;#34;  &amp;#34;../module4/module5&amp;#34; ) 分别举个例子吧
一、使用绝对导入
有如下这样的目录结构（注意确保当前目录在 GOPATH 下）
其中 main.go 是这样的
package main import (  &amp;#34;app/utilset&amp;#34; // 这种使用的就是绝对路径导入 )  func main() {  utils.PrintHello() } 而在 main.go 的同级目录下，还有另外一个文件夹 utilset ，为了让你理解 「第六点：import 导入的是路径而不是包」，我在 utilset 目录下定义了一个 hello.go 文件，这个go文件定义所属包为 utils。
package utils  import &amp;#34;fmt&amp;#34;  func PrintHello(){  fmt.Println(&amp;#34;Hello, 我在 utilset 目录下的 utils 包里&amp;#34;) } 运行结果如下
二、使用相对导入
还是上面的代码，将绝对导入改为相对导入后
将 GOPATH 路径设置回去（请对比上面使用绝对路径的 GOPATH）
然后再次运行
总结一下，使用相对导入，有两点需要注意
项目不要放在 $GOPATH/src 下，否则会报错（比如我修改当前项目目录为GOPATH后，运行就会报错）
Go Modules 不支持相对导入，在你开启 GO111MODULE 后，无法使用相对导入。
最后，不得不说的是：使用相对导入的方式，项目可读性会大打折扣，不利用开发者理清整个引用关系。
所以一般更推荐使用绝对引用的方式。使用绝对引用的话，又要谈及优先级了
包导入路径优先级 前面一节，介绍了三种不同的包依赖管理方案，不同的管理模式，存放包的路径可能都不一样，有的可以将包放在 GOPATH 下，有的可以将包放在 vendor 下，还有些包是内置包放在 GOROOT 下。  那么问题就来了，如果在这三个不同的路径下，有一个相同包名但是版本不同的包，我们导入的时候，是选择哪个进行导入呢？
这就需要我们搞懂，在 Golang 中包搜索路径优先级是怎样的？
这时候就需要区分，是使用哪种模式进行包的管理的。
如果使用 govendor
当我们导入一个包时，它会：
先从项目根目录的 vendor 目录中查找 最后从 $GOROOT/src 目录下查找 然后从 $GOPATH/src 目录下查找 都找不到的话，就报错。 为了验证这个过程，我在创建中创建一个 vendor 目录后，就开启了 vendor 模式了，我在 main.go 中随便导入一个包 pkg，由于这个包是我随便指定的，当然会找不到，找不到就会报错， Golang 会在报错信息中打印中搜索的过程，从这个信息中，就可以看到 Golang 的包查找优先级了。
如果使用 go modules
你导入的包如果有域名，都会先在 $GOPATH/pkg/mod 下查找，找不到就连网去该网站上寻找，找不到或者找到的不是一个包，则报错。
而如果你导入的包没有域名（比如 &amp;ldquo;fmt&amp;quot;这种），就只会到 $GOROOT 里查找。
还有一点很重要，当你的项目下有 vendor 目录时，不管你的包有没有域名，都只会在 vendor 目录中想找。
通常vendor 目录是通过 go mod vendor 命令生成的，这个命令会将项目依赖全部打包到你的项目目录下的 verdor 文件夹中。
</content>
    </entry>
    
     <entry>
        <title>go struct详解</title>
        <url>http://shanks.link/blog/2021/04/03/go-struct%E8%AF%A6%E8%A7%A3/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Go Struct超详细讲解 原创作者，程序员读书
Go语言中提供了对struct的支持,struct,中文翻译称为结构体，与数组一样，属于复合类型，并非引用类型。
Go语言的struct，与C语言中的struct或其他面向对象编程语言中的类(class)类似，可以定义字段(属性)和方法，但也有很不同的地方，需要深入学习，才能区分他们之间的区别。
注意复合类型与引用类型之间的区别，这应该也是值传递和引用传递的区别吧。
定义 使用struct关键字可以定义一个结构体,结构体中的成员，称为结构体的字段或属性。
type Member struct {  id int  name, email string  gender, age int } 上面的代码中，我们定义了一个包含5个字段的结构体，可以看到，相同类型name和email、gender和age在同一行中定义，但比较好的编程习惯是每一行只定义一个字段,如：
type Member struct {  id int  name string  email string  gender int  age int } 当然，结构体也可以不包含任何字段，称为空结构体，struct{}表示一个空的结构体，注意，直接定义一个空的结构体并没有意义，但在并发编程中，channel之间的通讯，可以使用一个struct{}作为信号量。
ch := make(chan struct{}) ch &amp;lt;- struct{}{} 使用 上面的例子中，我们定义了Member结构体类型，接下就可以这个自定义的类型创建变量了。
直接定义变量，这个使用方式并没有为字段赋初始值，因此所有字段都会被自动赋予自已类型的零值，比如name的值为空字符串&amp;quot;&amp;quot;，age的值为0。
var m1 Member//所有字段均为空值 复制代码 使用字面量创建变量，这种使用方式，可以在大括号中为结构体的成员赋初始值，有两种赋初始值的方式，一种是按字段在结构体中的顺序赋值，下面代码中m2就是使用这种方式，这种方式要求所有的字段都必须赋值，因此如果字段太多，每个字段都要赋值，会很繁琐，另一种则使用字段名为指定字段赋值，如下面代码中变量m3的创建，使用这种方式，对于其他没有指定的字段，则使用该字段类型的零值作为初始化值。
var m2 = Member{1,&amp;#34;小明&amp;#34;,&amp;#34;xiaoming@163.com&amp;#34;,1,18} // 简短变量声明方式：m2 := Member{1,&amp;#34;小明&amp;#34;,&amp;#34;xiaoming@163.com&amp;#34;,1,18} var m3 = Member{id:2,&amp;#34;name&amp;#34;:&amp;#34;小红&amp;#34;}// 简短变量声明方式：m3 := Member{id:2,&amp;#34;name&amp;#34;:&amp;#34;小红&amp;#34;} 访问字段
通过变量名，使用逗号(.)，可以访问结构体类型中的字段，或为字段赋值，也可以对字段进行取址(&amp;amp;)操作。
fmt.Println(m2.name)//输出：小明 m3.name = &amp;#34;小花&amp;#34; fmt.Println(m3.name)//输出：小花 age := &amp;amp;m3.age *age = 20 fmt.Println(m3.age)//20 指针结构体
结构体与数组一样，都是值传递，比如当把数组或结构体作为实参传给函数的形参时，会复制一个副本，所以为了提高性能，一般不会把数组直接传递给函数，而是使用切片(引用类型)代替，而把结构体传给函数时，可以使用指针结构体。
指针结构体，即一个指向结构体的指针,声明结构体变量时，在结构体类型前加*号，便声明一个指向结构体的指针，如：
注意，指针类型为引用类型，声明结构体指针时，如果未初始化，则初始值为nil,只有初始化后，才能访问字段或为字段赋值。
var m1 *Member m1.name = &amp;#34;小明&amp;#34;//错误用法，未初始化,m1为nil m1 = &amp;amp;Member{} m1.name = &amp;#34;小明&amp;#34;//初始化后，结构体指针指向某个结构体地址，才能访问字段，为字段赋值。 另外，使用Go内置new()函数，可以分配内存来初始化结构休，并返回分配的内存指针，因为已经初始化了，所以可以直接访问字段。
var m2 = new(Member) m2.name = &amp;#34;小红&amp;#34; 我们知道，如果将结构体转给函数，只是复制结构体的副本，如果在函数内修改结构体字段值，外面的结构体并不会受影响，而如果将结构体指针传给函数，则在函数中使用指针对结构体所做的修改，都会影响到指针指向的结构体。
func main() {  m1 := Member{}  m2 := new(Member)  Change(m1,m2)  fmt.Println(m1,m2) }  func Change(m1 Member,m2 *Member){  m1.Name = &amp;#34;小明&amp;#34;  m2.Name = &amp;#34;小红&amp;#34; } 可见性 上面的例子中，我们定义结构体字段名首字母是小写的，这意味着这些字段在包外不可见,因而无法在其他包中被访问，只允许包内访问。
下面的例子中，我们将Member声明在member包中，而后在main包中创建一个变量，但由于结构体的字段包外不可见，因此无法为字段赋初始值，无法按字段还是按索引赋值，都会引发panic错误。
package member type Member struct {  id int  name string  email string  gender int  age int }  package main  fun main(){  var m = member.Member{1,&amp;#34;小明&amp;#34;,&amp;#34;xiaoming@163.com&amp;#34;,1,18}//会引发panic错误 } 因此，如果想在一个包中访问另一个包中结构体的字段，则必须是大写字母开头的变量，即可导出的变量，如：
type Member struct {  Id int  Name string  Email string  Gender int  Age int } Tags 在定义结构体字段时，除字段名称和数据类型外，还可以使用反引号为结构体字段声明元信息，这种元信息称为Tag，用于编译阶段关联到字段当中,如我们将上面例子中的结构体修改为：
type Member struct {  Id int `json:&amp;#34;id,-&amp;#34;`  Name string `json:&amp;#34;name&amp;#34;`  Email string `json:&amp;#34;email&amp;#34;`  Gender int `json:&amp;#34;gender,&amp;#34;`  Age int `json:&amp;#34;age&amp;#34;` } 上面例子演示的是使用encoding/json包编码或解码结构体时使用的Tag信息。
Tag由反引号括起来的一系列用空格分隔的key:&amp;ldquo;value&amp;quot;键值对组成，如：
Id int `json:&amp;#34;id&amp;#34; gorm:&amp;#34;AUTO_INCREMENT&amp;#34;` 特性 下面总结几点结构体的相关特性：
值传递
结构体与数组一样，是复合类型，无论是作为实参传递给函数时，还是赋值给其他变量，都是值传递，即复一个副本。
没有继承
Go语言是支持面向对象编程的，但却没有继承的概念，在结构体中，可以通过组合其他结构体来构建更复杂的结构体。
结构体不能包含自己
一个结构体，并没有包含自身，比如Member中的字段不能是Member类型，但却可能是*Member。
方法 在Go语言中，将函数绑定到具体的类型中，则称该函数是该类型的方法，其定义的方式是在func与函数名称之间加上具体类型变量，这个类型变量称为方法接收器，如：
注意，并不是只有结构体才能绑定方法，任何类型都可以绑定方法，只是我们这里介绍将方法绑定到结构体中。
func setName(m Member,name string){//普通函数 m.Name = name }
func (m Member)setName(name string){//绑定到Member结构体的方法 m.Name = name } 复制代码 从上面的例子中，我们可以看出，通过方法接收器可以访问结构体的字段，这类似其他编程语言中的this关键词，但在Go语言中，只是一个变量名而已，我们可以任意命名方法接收器。
调用结构体的方法，与调用字段一样：
m := Member{} m.setName(&amp;#34;小明&amp;#34;) fmt.Println(m.Name)//输出为空 上面的代码中，我们会很奇怪，不是调用setName()方法设置了字段Name的值了吗？为什么还是输出为空呢？
这是因为，结构体是值传递，当我们调用setName时，方法接收器接收到是只是结构体变量的一个副本，通过副本对值进行修复，并不会影响调用者，因此，我们可以将方法接收器定义为指针变量，就可达到修改结构体的目的了。
func (m *Member)setName(name string){/将Member改为*Member  m.Name = name }  m := Member{} m.setName(&amp;#34;小明&amp;#34;) fmt.Println(m.Name)//小明 方法和字段一样，如果首字母为小写，则只允许在包内可见，在其他包中是无法访问的，因此，如果要在其他包中访问setName,则应该将方法名改为SetName。
组合 我们知道，结构体中并没有继承的概念，其实，在Go语言中也没有继承的概念，Go语言的编程哲学里，推荐使用组合的方式来达到代码复用效果。
什么是组合
组合，可以理解为定义一个结构体中，其字段可以是其他的结构体，这样，不同的结构体就可以共用相同的字段。
注意，在记得我们前面提过的，结构体不能包含自身，但可能包含指向自身的结构体指针。
例如，我们定义了一个名为Animal表示动物，如果我们想定义一个结构体表示猫，如：
type Animal struct {  Name string //名称  Color string //颜色  Height float32 //身高  Weight float32 //体重  Age int //年龄 } //奔跑 func (a Animal)Run() {  fmt.Println(a.Name &#43; &amp;#34;is running&amp;#34;) } //吃东西 func (a Animal)Eat() {  fmt.Println(a.Name &#43; &amp;#34;is eating&amp;#34;) }  type Cat struct {  a Animal }  func main() {  var c = Cat{ 	a: Animal{  Name: &amp;#34;猫猫&amp;#34;,  Color: &amp;#34;橙色&amp;#34;,  Weight: 10,  Height: 30,  Age: 5,  },  }  fmt.Println(c.a.Name)  c.a.Run() }  可以看到，我们定义Cat结构体时，可以把Animal结构体作为Cat的字段。
匿名字段
上面的例子，我们看到，把Animal结构体作为Cat的字段时，其变量名为a，所以我们访问Animal的方法时，语法为c.a.Run(),这种通过叶子属性访问某个字段类型所带的方法和字段用法非常繁琐。
Go语言支持直接将类型作为结构体的字段，而不需要取变量名，这种字段叫匿名字段，如：
type Lion struct { 	Animal //匿名字段 }  func main(){  var lion = Lion{  Animal{  Name: &amp;#34;小狮子&amp;#34;,  Color: &amp;#34;灰色&amp;#34;,  },  }  lion.Run()  fmt.Println(lion.Name) } 通过上面例子，可以看到，通过匿名字段组合其他类型，而后访问匿名字段类型所带的方法和字段时，不需要使用叶子属性，非常方便。
小结 在Go语言编程中，结构体大概算是使用得最多的数据类型了，通过定义不同字段和方法的结构体，抽象组合不同的结构体，这大概便是Go语言中对面向对象编程了。
</content>
    </entry>
    
     <entry>
        <title>go语言panic,recover的实现</title>
        <url>http://shanks.link/blog/2021/04/03/go%E8%AF%AD%E8%A8%80panicrecover%E7%9A%84%E5%AE%9E%E7%8E%B0/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 爱写程序的阿波张 源码游记 2019-07-02
本文主要分析Go语言的panic/recover在AMD64 Linux平台下的实现，包括：
主动调用 panic() 函数所引发的panic的处理流程，比如go代码中直接调用panic()函数或编译器插入的对panic()的调用；
非法操作所导致的panic的处理流程，这主要跟信号处理流程有关。
阅读本文所必需的预备知识：
defer/panic/recover 的基本用法；
defer 的实现机制；
mcall/gogo 函数的实现。
panic/recover例子
先来热一下身，大家可以先想想下面几个例子的输出会是什么，检测一下自己对panic/recover的理解。
例1:
func f() {  defer catch(&amp;#34;f&amp;#34;)   g() }  func g() {  defer m()   panic(&amp;#34;g panic&amp;#34;) }  func m() {  panic(&amp;#34;m panic&amp;#34;) }  func catch(funcname string) {  if r := recover(); r != nil {  fmt.Println(funcname, &amp;#34;recover:&amp;#34;, r)  } } 例2:  func f() {  defer catch(&amp;#34;f&amp;#34;)   g() }  func g() {  defer m()   panic(&amp;#34;g panic&amp;#34;) }  func m() {  defer catch(&amp;#34;m&amp;#34;) }  func catch(funcname string) {  if r := recover(); r != nil {  fmt.Println(funcname, &amp;#34;recover:&amp;#34;, r)  } } 例3:  func f() {  defer catch(&amp;#34;f&amp;#34;)   g() }  func catch(funcname string) {  if r := recover(); r != nil {  fmt.Println(funcname, &amp;#34;recover:&amp;#34;, r)  } }  func g() {  defer m()   panic(&amp;#34;g panic&amp;#34;) }  func m() {  defer catch(&amp;#34;m&amp;#34;)   panic(&amp;#34;m panic&amp;#34;) } panic/recover要点简介
为了更好的理解panic/recover的实现代码，我们首先需要了解几个与之有关的要点：
当panic发生之后，程序从正常的执行流程跳转到执行panic发生之前通过defer语句注册的defered函数，直到某个defered函数通过recover函数捕获了panic后再恢复正常的执行流程，如果没有recover则当所有的defered函数被执行完成之后结束程序；
defer语句会被编译器翻译成对runtime包中deferproc()函数的调用，该函数会把defered函数打包成一个_defer结构体对象挂入goroutine对应的g结构体对象的_defer链表中，_defer对象除了保存有defered函数的地址以及该函数需要的参数外，还会分别把call deferproc指令的下一条指令的地址以及此时函数调用栈顶指针保存在_defer.pc和_defer.sp成员之中，用于recover时恢复程序的正常执行流程；
当某个defered函数通过recover()函数捕获到一个panic之后，程序将从该defered函数对应的_defer结构体对象的pc成员所保存的指令地址处开始执行；
panic可以嵌套，当发生panic之后在执行defer函数时又发生了panic即为嵌套。每个还未被recover的panic都会对应着一个_panic结构体对象，它们会被依次挂入g结构体的_panic链表之中，最近一次发生的panic位于_panic链表表头，最早发生的panic位于链表尾。
下面对第2点和第3点做个简单的说明。假设有如下程序片段：
例4
package main  import &amp;#34;fmt&amp;#34;  func main() {  f()  fmt.Println(&amp;#34;main&amp;#34;) }  func f() {  defer catch(&amp;#34;f&amp;#34;) // 1   panic(&amp;#34;f panic&amp;#34;)   fmt.Println(&amp;#34;f continue&amp;#34;) }  func catch(funcname string) {  if r := recover(); r != nil {  fmt.Println(funcname, &amp;#34;recover:&amp;#34;, r)  } } f()函数运行时会发生panic，但该panic会被它通过defer注册的catch函数所捕获从而恢复程序的正常执行流程，上一篇文章我们提到过deferproc函数有个隐含的返回值与panic/recover有关，下面我们通过f()函数再来看一下相关的汇编指令片段：
 ......  # 对应defer catch(&amp;#34;f&amp;#34;)  0x0000000000487245 &amp;lt;&#43;69&amp;gt;: callq 0x426c00 &amp;lt;runtime.deferproc&amp;gt;  0x000000000048724a &amp;lt;&#43;74&amp;gt;: test %eax,%eax  0x000000000048724c &amp;lt;&#43;76&amp;gt;: jne 0x48726c &amp;lt;main.f&#43;108&amp;gt;  ......  # 对应panic(&amp;#34;f panic&amp;#34;)  0x0000000000487265 &amp;lt;&#43;101&amp;gt;: callq 0x427880 &amp;lt;runtime.gopanic&amp;gt;  ......  0x000000000048726c &amp;lt;&#43;108&amp;gt;: nop  0x000000000048726d &amp;lt;&#43;109&amp;gt;: callq 0x427490 &amp;lt;runtime.deferreturn&amp;gt;  ...... 该代码片段前3条指令对应着f()函数中注释1处的一行go代码，最后两条指令通过调用deferreturn函数去执行defered函数，如果f函数不发生panic，其执行流程我们在上一篇文章中已经详细介绍过，但此处的f函数会发生panic，其流程稍有不同：
当f函数执行到callq 0x426c00 &amp;lt;runtime.deferproc&amp;gt;指令时，deferproc函数将会把catch函数的地址及其参数&amp;quot;f&amp;quot;、下一条指令的地址0x000000000048724a以及当前的栈顶指针打包成一个_defer结构体对象挂入当前goroutine的_defer链表，然后通过eax寄存器隐形的返回一个0值；
因为从deferproc函数返回时，eax寄存器的值为0，所以0x000000000048724a &amp;lt;&#43;74&amp;gt;: test %eax,%eax这条指令不会导致下一条jne指令发生跳转，于是程序会继续执行到0x0000000000487265 &amp;lt;&#43;101&amp;gt;处的callq 0x427880 &amp;lt;runtime.gopanic&amp;gt;指令；
gopanic函数内部会去调用defered函数即catch(&amp;ldquo;f&amp;rdquo;)，因为catch()函数调用了recover，这将导致CPU跳转到f()函数的0x000000000048724a &amp;lt;&#43;74&amp;gt;: test %eax,%eax指令处继续执行，这看起来就像deferproc函数再一次返回了，但这次eax寄存器的值却会被设置成1，所以执行这条test指令将导致下一条jne指令跳转到0x000000000048726c &amp;lt;&#43;108&amp;gt;: nop处继续执行，此时已经恢复了程序的正常执行流程；
调用deferreturn函数，因为例4程序只有一个defered函数，而且已经被gopanic调用了，所以这里的deferreturn函数并不会调用任何defered函数就直接返回到了f()函数，然后从f函数返回到main函数继续执行main函数的fmt.Println(&amp;ldquo;main&amp;rdquo;)语句。
主动调用panic()函数
一般来说，Go程序在两种情况下会发生panic：
主动调用panic()函数，这包括go代码中直接调用以及由编译器插入的调用，比如编译器会插入代码检查访问数组/slice是否越界，同时还会插入调用panic()的代码，运行时如果越界就会去调用panic()函数；
非法操作，比如向只读内存写入数据，访问非法内存等也会发生panic。这种情况在Linux平台（其它平台不熟悉）下是通过信号(signal)机制来实现对panic()函数的调用。
我们先来看主动调用panic函数时panic/recover的流程。
通过反汇编可以得知go代码中对panic()/recover()函数的调用会被编译器翻译成对runtime包中的gopanic()以及gorecover()函数的调用。
runtime/panic.go : 453  // The implementation of the predeclared function panic. func gopanic(e interface{}) {  gp := getg()  ......   //panic可以嵌套，比如发生了panic之后运行defered函数又发生了panic，如上面的例3。  //最新的panic会被挂入goroutine对应的g结构体对象的_panic链表的表头  var p _panic //创建_panic结构体对象  p.arg = e //panic的参数  p.link = gp._panic  gp._panic = (*_panic)(noescape(unsafe.Pointer(&amp;amp;p)))   atomic.Xadd(&amp;amp;runningPanicDefers, 1)   for {  d := gp._defer //取出_defer链表头的defered函数  if d == nil {  break //没有defer函数将会跳出循环，然后打印栈信息然后结束程序  }   // If defer was started by earlier panic or Goexit (and, since we&amp;#39;re back here, that triggered a new panic),  // take defer off list. The earlier panic or Goexit will not continue running.  if d.started {  //到这里一定发生了panic嵌套，即在defered函数中又发生了panic，请参考本文开头的例1  //d.started = true是panic嵌套的充分条件，但并不是必要条件，也就是说  //即使d.started为false也是可能发生嵌套的，请结合defer的处理流程并参考本文开头的例3  //最近发生的一次panic并没有被recover所以取消上一次发生的panic  if d._panic != nil {  d._panic.aborted = true  }  d._panic = nil  d.fn = nil  gp._defer = d.link  freedefer(d)  continue  }   // Mark defer as started, but keep on list, so that traceback  // can find and update the defer&amp;#39;s argument frame if stack growth  // or a garbage collection happens before reflectcall starts executing d.fn.  d.started = true //用于判断是否发生了嵌套panic   // Record the panic that is running the defer.  // If there is a new panic during the deferred call, that panic  // will find d in the list and will mark d._panic (this panic) aborted.  //把panic和defer函数关联起来  d._panic = (*_panic)(noescape(unsafe.Pointer(&amp;amp;p)))   //在panic中记录当前panic的栈顶位置，用于recover判断  p.argp = unsafe.Pointer(getargp(0))  //通过reflectcall函数调用defered函数  //如果defered函数再次发生panic而且并未被该defered函数recover，则reflectcall永远不会返回，参考例2。  //如果defered函数并没有发生过panic或者发生了panic但该defered函数成功recover了新发生的panic，  //则此函数会返回继续执行后面的代码。  reflectcall(nil, unsafe.Pointer(d.fn), deferArgs(d), uint32(d.siz), uint32(d.siz))  p.argp = nil   // reflectcall did not panic. Remove d.  if gp._defer != d {  throw(&amp;#34;bad defer entry in panic&amp;#34;)  }  //defer函数已经被执行，脱链  d._panic = nil  d.fn = nil  gp._defer = d.link   // trigger shrinkage to test stack copy. See stack_test.go:TestStackPanic  //GC()   pc := d.pc //call deferproc的下一条指令的地址，下一条指令为 test rax, rax，在defer实现机制一文中有详细说明  //call deferproc指令执行前的栈顶指针  sp := unsafe.Pointer(d.sp) // must be pointer so it gets adjusted during stack copy  freedefer(d)  if p.recovered {  //defered函数调用recover成功捕获了panic会设置p.recovered = true  atomic.Xadd(&amp;amp;runningPanicDefers, -1)   gp._panic = p.link  // Aborted panics are marked but remain on the g.panic list.  // Remove them from the list.  for gp._panic != nil &amp;amp;&amp;amp; gp._panic.aborted {  gp._panic = gp._panic.link  }  if gp._panic == nil { // must be done with signal  gp.sig = 0  }  // Pass information about recovering frame to recovery.  gp.sigcode0 = uintptr(sp)  gp.sigcode1 = pc  //mcall函数永远不会返回，mcall函数的实现可以参考公众号内的其它文章，有详细分析  //调用recovery函数跳转到pc位置继续执行  mcall(recovery)  throw(&amp;#34;recovery failed&amp;#34;) // mcall should not return  }  }   // ran out of deferred calls - old-school panic now  // Because it is unsafe to call arbitrary user code after freezing  // the world, we call preprintpanics to invoke all necessary Error  // and String methods to prepare the panic strings before startpanic.  preprintpanics(gp._panic)   //打印函数调用链，然后挂死程序  fatalpanic(gp._panic) // should not return  *(*int)(nil) = 0 // not reached }  // runtime/panic.go : 578  // The implementation of the predeclared function recover. // Cannot split the stack because it needs to reliably // find the stack segment of its caller. // // TODO(rsc): Once we commit to CopyStackAlways, // this doesn&amp;#39;t need to be nosplit. //go:nosplit func gorecover(argp uintptr) interface{} {  // Must be in a function running as part of a deferred call during the panic.  // Must be called from the topmost function of the call  // (the function used in the defer statement).  // p.argp is the argument pointer of that topmost deferred function call.  // Compare against argp reported by caller.  // If they match, the caller is the one who can recover.  gp := getg()  p := gp._panic  //条件argp == uintptr(p.argp)在判断panic和recover是否匹配，内层recover不能捕获外层的panic  //比如本文开头的例2中m函数中的defer catch(&amp;#34;m&amp;#34;)不能捕获g函数中的panic  if p != nil &amp;amp;&amp;amp; !p.recovered &amp;amp;&amp;amp; argp == uintptr(p.argp) {  p.recovered = true //通过设置p.recovered = true告诉gopanic函数panic已经被recover了  return p.arg  }  return nil }  // runtime/panic.go : 634 // Unwind the stack after a deferred function calls recover // after a panic. Then arrange to continue running as though // the caller of the deferred function returned normally. func recovery(gp *g) {  // Info about defer passed in G struct.  sp := gp.sigcode0 //call deferproc时的栈顶指针  pc := gp.sigcode1 //call deferproc下一条指令的地址   // d&amp;#39;s arguments need to be in the stack.  if sp != 0 &amp;amp;&amp;amp; (sp &amp;lt; gp.stack.lo || gp.stack.hi &amp;lt; sp) {  print(&amp;#34;recover: &amp;#34;, hex(sp), &amp;#34; not in [&amp;#34;, hex(gp.stack.lo), &amp;#34;, &amp;#34;, hex(gp.stack.hi), &amp;#34;]\n&amp;#34;)  throw(&amp;#34;bad recovery&amp;#34;)  }   // Make the deferproc for this d return again,  // this time returning 1. The calling function will  // jump to the standard return epilogue.  gp.sched.sp = sp  gp.sched.pc = pc  gp.sched.lr = 0  gp.sched.ret = 1 //该值（1）会被gogo函数放入eax寄存器  gogo(&amp;amp;gp.sched) //跳转到pc所指的指令处继续执行，gogo函数的实现请参考公众号内的其它文章，有详细分析 } 从代码可以看出，如果不考虑嵌套，主动 panic/recover 的流程比较清晰：遍历当前 goroutine 所注册的 defered 函数并通过 reflectcall 调用遍历到的函数，如果某个 defered 函数调用了recover（对应到runtime的gorecover函数）则使用 mcall(recovery) 恢复程序的正常流程，否则执行完所有的 defered 函数之后打印出 panic 的栈信息然后退出程序。这里需要说明一下为什么需要通过 reflectcall 来调用 defered 函数而不是直接调用 defered 函数。原因在于直接调用 defered 函数就得在当前栈帧中为它准备参数，而不同的 defered 函数的参数大小可能会有很大差异，比如有的defered函数没有参数而有些defered函数可能又需要成千上万字节的参数，然而gopanic 函数的栈帧大小固定而且很小，所以很有可能没有足够的空间来存放 defered 函数的参数，而reflectcall函数可以处理这种情况，具体是怎么处理的这里就不介绍了，有兴趣的话大家可以去看一下reflectcall函数的代码。
对于panic的嵌套，也就是defered函数再次发生了panic，这会导致gopanic函数再次被调用，也就是说gopanic函数会存在递归调用，其调用链为 gopanic()-&amp;gt;reflectcall()-&amp;gt;defered函数-&amp;gt;gopanic() ，这时有两种情况：
defered函数通过defer再次注册了defered函数而且recover了最新的panic，则上面的调用链将原路从reflect call()返回到gopanic函数继续执行；
defered函数没有recover它自己的panic，则reflectcall()不会返回。要么第二次gopanic执行完所有defered函数之后退出程序，要么新发生的panic代替了前一次panic然后由外层的defered函数recover。
对于上述两种情况，大家可以结合前面代码中的注释以及例2和例3加以理解。
非法操作引起的panic
最常见的非法操作主要是非法访问内存，我们来看一个例子：
package main  import (  &amp;#34;fmt&amp;#34; )  func f() {  var p *int   *p = 100 // crash   fmt.Println(&amp;#34;not reached&amp;#34;) }  func main() {  f() } 这个程序运行时会发生panic，原因是f()函数企图向p所指的内存写入100，但指针变量p却是nil。来看看f函数的汇编代码片段：
 0x0000000000487200 &amp;lt;&#43;0&amp;gt;: mov %fs:0xfffffffffffffff8,%rcx  0x0000000000487209 &amp;lt;&#43;9&amp;gt;: cmp 0x10(%rcx),%rsp  0x000000000048720d &amp;lt;&#43;13&amp;gt;: jbe 0x4872a1 &amp;lt;main.f&#43;161&amp;gt;  0x0000000000487213 &amp;lt;&#43;19&amp;gt;: sub $0x70,%rsp  0x0000000000487217 &amp;lt;&#43;23&amp;gt;: mov %rbp,0x68(%rsp)  0x000000000048721c &amp;lt;&#43;28&amp;gt;: lea 0x68(%rsp),%rbp  0x0000000000487221 &amp;lt;&#43;33&amp;gt;: movq $0x0,0x30(%rsp)  0x000000000048722a &amp;lt;&#43;42&amp;gt;: xor %eax,%eax  0x000000000048722c &amp;lt;&#43;44&amp;gt;: test %al,(%rax)  0x000000000048722e &amp;lt;&#43;46&amp;gt;: movq $0x64,(%rax) # *p = 100  0x0000000000487235 &amp;lt;&#43;53&amp;gt;: xorps %xmm0,%xmm0  0x0000000000487238 &amp;lt;&#43;56&amp;gt;: movups %xmm0,0x40(%rsp)  0x000000000048723d &amp;lt;&#43;61&amp;gt;: lea 0x40(%rsp),%rax  ...... 通过汇编代码我们可以确定编译器并未插入对gopanic函数的调用，但这个程序运行起来发生panic时与在go代码中直接调用gopanic函数时的表现是一样的，都会输出panic时栈的信息，所以这种非法操作最终应该也会调用到gopanic函数，但具体是怎么调用到它的呢？我们可以使用调试工具dlv给gopanic下一个断点，等断下来之后使用bt可以看到其函数调用链为：
f()-&amp;gt;runtime.sigpanic()-&amp;gt;runtime.panicmem()-&amp;gt;runtime.gopanic() 可以看到f()调用了runtime.sigpanic()函数，但从上面的汇编代码可以得知f()其实并没有直接调用runtime.sigpanic()函数，是不是有些奇怪？
事实上，当CPU在执行
0x000000000048722e &amp;lt;&#43;46&amp;gt;: movq $0x64,(%rax) # *p = 100 这一条指令时，CPU会发生异常，异常发生后将依次执行如下流程：
CPU在内存中保存发生异常的指令的地址（这里是0x000000000048722e）。为了方便描述，我们称这个地址为异常返回地址；
陷入内核执行由操作系统在系统启动时提供的异常处理程序，该异常处理程序会负责把CPU的所有相关寄存器的值保存在内存之中；
向引起异常的当前线程发送一个SIGSEGV信号；
从内核返回，在返回过程中发现有信号需要处理；
从内核返回到用户态执行信号处理程序（go程序启动时向内核注册的信号处理函数），该信号处理程序将会把第1步中由CPU保存的异常返回地址修改为runtime.sigpanic函数的地址；
信号处理程序执行完成后再次进入内核；
从内核返回开始执行runtime.sigpanic函数；
上述整个流程与Linux系统的信号处理有关，了解即可，如果有兴趣可以参考相关的内核资料，这里我们只需要关注第5步和第7步。从该流程可以看出，当go程序发生异常之后之所以能够最终执行到gopanic函数，关键在于上述流程的第5步修改了异常之后的执行流程，而第5步中的信号处理程序是由go语言的runtime提供的，所以下面我们直接从信号处理程序开始大致看一下其流程。
SIGSEGV信号处理流程
对于SIGSEGV信号，信号处理程序的函数调用链为
内核返回-&amp;gt; runtime.sigtramp() -&amp;gt;runtime.sigtrampgo()-&amp;gt;runtime.sighandler()-&amp;gt;sigctxt.preparePanic()修改异常返回地址 这个调用链中的函数由大家自己去挖掘细节，这里只说两点：
runtime.sigtramp是go程序启动时向内核注册的信号处理函数，所以当线程收到SIGSEGV信号后内核会负责让CPU进入这个函数运行；
内核在返回用户态执行信号处理程序runtime.sigtramp()函数之前，内核会把异常返回地址等数据保存在信号处理程序的函数调用栈之中，等信号处理程序执行完成之后再次进入内核时，内核会把它之前保存在信号处理程序函数栈上的异常返回地址等数据拷贝回内核，然后再返回到用户态继续执行异常返回地址处的指令。这个流程给信号处理程序提供了一个可以修改CPU执行流程的机会，我们来看看sigctxt.preparePanic()函数是怎么修改异常返回地址的：
// preparePanic sets up the stack to look like a call to sigpanic. func (c *sigctxt) preparePanic(sig uint32, gp *g) {  if GOOS == &amp;#34;darwin&amp;#34; {  ......  }   //指针c所指的内存即执行信号处理程序之前由内核保存在栈上的数据  //c.rip即为异常返回地址，也就是异常发生时CPU正在执行的指令的地址  pc := uintptr(c.rip())  sp := uintptr(c.rsp())   if shouldPushSigpanic(gp, pc, *(*uintptr)(unsafe.Pointer(sp))) {  // Make it look the like faulting PC called sigpanic.  if sys.RegSize &amp;gt; sys.PtrSize {  sp -= sys.PtrSize  *(*uintptr)(unsafe.Pointer(sp)) = 0  }  sp -= sys.PtrSize  *(*uintptr)(unsafe.Pointer(sp)) = pc  c.set_rsp(uint64(sp))  }  c.set_rip(uint64(funcPC(sigpanic))) //修改异常返回地址为sigpanic函数的地址 } 这个函数的最后一行把异常返回地址修改成了runtime.sigpanic函数的地址，等信号处理完成进入内核后再次返回用户态时CPU将会从runtime.sigpanic函数开始执行，最终执行到前面已经分析过的gopanic函数，这部分代码很清晰，大家有兴趣的话可以自己看看。
最后，如果你觉得本文对你有帮助的话，麻烦帮忙点一下文末右下角的 在看 或转发到朋友圈，非常感谢！
</content>
    </entry>
    
     <entry>
        <title>go深入理解defer（下）defer实现机制</title>
        <url>http://shanks.link/blog/2021/04/03/go%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3defer%E4%B8%8Bdefer%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6/</url>
        <categories>
          <category>[go]</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 爱写程序的阿波张 源码游记 2019-06-17
上一篇文章我们主要从使用的角度介绍了 defer 的基础知识，本文我们来分析一下 defer 的实现机制。
还是从一个例子程序开始。
package main  import &amp;#34;fmt&amp;#34;  func sum(a, b int) {  c := a &#43; b  fmt.Println(&amp;#34;sum:&amp;#34; , c) }  func f(a, b int) {  defer sum(a, b)   fmt.Printf(&amp;#34;a: %d, b: %d\n&amp;#34;, a, b) }  func main() {  a, b := 1, 2  f(a, b) } 从前一篇文章我们得知，编译器会把 defer 语句翻译成对 deferproc 函数的调用，同时，编译器也会在使用了 defer 语句的 go 函数的末尾插入对 deferreturn 函数的调用，下面我们来看一下这两个函数的实现代码。
deferproc 函数
先来看看 deferproc 的函数原型：
runtime/panic.go : 89  // Create a new deferred function fn with siz bytes of arguments. // The compiler turns a defer statement into a call to this. //go:nosplit func deferproc(siz int32, fn *funcval) deferproc 函数的第一个参数 siz 是 defered 函数（比如本例中的 sum 函数）的参数以字节为单位的大小，第二个参数 funcval 是一个变长结构体：  proc/runtime2.go : 139  type funcval struct {  fn uintptr  // variable-size, fn-specific data here } 于是，在64位系统中本文例子中的 defer sum(a, b) 大致等价于
deferproc(16, &amp;amp;funcval{sum}) 因为 sum 函数有 2 个 int 型的参数共 16 字节，所以在调用 deferproc 函数时第一个参数为16，第二个参数 funcval 结构体对象的 fn 成员为 sum 函数的地址。我们可以先想一下为什么需要把 sum 函数的参数大小传递给 deferproc() 函数？另外为什么没看到 sum 函数需要的两个参数呢？
为了搞清楚编译器到底会怎么翻译 defer 关键字，我们需要看一下 f() 函数的汇编代码：
0x0000000000488de0 &amp;lt;&#43;0&amp;gt;: mov %fs:0xfffffffffffffff8,%rcx 0x0000000000488de9 &amp;lt;&#43;9&amp;gt;: cmp 0x10(%rcx),%rsp 0x0000000000488ded &amp;lt;&#43;13&amp;gt;: jbe 0x488f10 &amp;lt;main.f&#43;304&amp;gt; 0x0000000000488df3 &amp;lt;&#43;19&amp;gt;: sub $0x80,%rsp 0x0000000000488dfa &amp;lt;&#43;26&amp;gt;: mov %rbp,0x78(%rsp) 0x0000000000488dff &amp;lt;&#43;31&amp;gt;: lea 0x78(%rsp),%rbp # 这一条指令以及前面几条指令是函数序言，跟defer无关 0x0000000000488e04 &amp;lt;&#43;36&amp;gt;: movl $0x10,(%rsp) # deferproc的第一个参数siz 0x0000000000488e0b &amp;lt;&#43;43&amp;gt;: lea 0x39076(%rip),%rax 0x0000000000488e12 &amp;lt;&#43;50&amp;gt;: mov %rax,0x8(%rsp) # 第二个参数funcval结构体对象的地址 0x0000000000488e17 &amp;lt;&#43;55&amp;gt;: mov 0x88(%rsp),%rax 0x0000000000488e1f &amp;lt;&#43;63&amp;gt;: mov %rax,0x10(%rsp) # f()函数的第一个参数a，a = 1 0x0000000000488e24 &amp;lt;&#43;68&amp;gt;: mov 0x90(%rsp),%rcx 0x0000000000488e2c &amp;lt;&#43;76&amp;gt;: mov %rcx,0x18(%rsp) # f()函数的第二个参数b, b = 2 0x0000000000488e31 &amp;lt;&#43;81&amp;gt;: callq 0x426c00 &amp;lt;runtime.deferproc&amp;gt; # 调用deferproc函数 # 注意deferproc函数本来是没有返回值的，下面的test指令在检查deferproc的隐性返回值 # 这条指令是编译器专门针对deferproc函数而插入的，对其它go函数调用时编译器不会插入该指令 0x0000000000488e36 &amp;lt;&#43;86&amp;gt;: test %eax,%eax # 如果deferproc返回不为0则直接跳转到函数结尾去执行deferreturn函数 0x0000000000488e38 &amp;lt;&#43;88&amp;gt;: jne 0x488efd &amp;lt;main.f&#43;285&amp;gt; 0x0000000000488e3e &amp;lt;&#43;94&amp;gt;: mov 0x88(%rsp),%rax ...... 0x0000000000488ee5 &amp;lt;&#43;261&amp;gt;: callq 0x480b20 &amp;lt;fmt.Fprintf&amp;gt; #输出a b的值 0x0000000000488eea &amp;lt;&#43;266&amp;gt;: nop #调用deferreturn函数完成对sum函数的延迟调用 0x0000000000488eeb &amp;lt;&#43;267&amp;gt;: callq 0x427490 &amp;lt;runtime.deferreturn&amp;gt; 0x0000000000488ef0 &amp;lt;&#43;272&amp;gt;: mov 0x78(%rsp),%rbp 0x0000000000488ef5 &amp;lt;&#43;277&amp;gt;: add $0x80,%rsp 0x0000000000488efc &amp;lt;&#43;284&amp;gt;: retq 0x0000000000488efd &amp;lt;&#43;285&amp;gt;: nop 0x0000000000488efe &amp;lt;&#43;286&amp;gt;: callq 0x427490 &amp;lt;runtime.deferreturn&amp;gt; 0x0000000000488f03 &amp;lt;&#43;291&amp;gt;: mov 0x78(%rsp),%rbp 0x0000000000488f08 &amp;lt;&#43;296&amp;gt;: add $0x80,%rsp 0x0000000000488f0f &amp;lt;&#43;303&amp;gt;: retq 0x0000000000488f10 &amp;lt;&#43;304&amp;gt;: callq 0x44f300 &amp;lt;runtime.morestack_noctxt&amp;gt; #扩栈处理 0x0000000000488f15 &amp;lt;&#43;309&amp;gt;: jmpq 0x488de0 &amp;lt;main.f&amp;gt; 从 f() 函数的汇编代码可以看出，在调用 runtime.deferproc 时，栈上除了保存了 deferproc 函数需要的两个参数之外，还保存了 defered 函数所需要的参数（我们这个例子中 defered 函数是 sum 函数，它的2个参数 a 和 b 也都保存在了栈上，它们紧邻 deferproc 函数的第二个参数），也就是说，在执行 defer 语句时，defer 后面的函数的参数已经确定了。
另外需要注意的是，从 deferproc 函数的原型可以知道它并没有返回值，但上面的汇编代码在调用了 deferproc 函数之后却检查了 rax 寄存器的值是否为0(0x0000000000488e36 &amp;lt;&#43;86&amp;gt;: test %eax,%eax)，也就是说 deferproc 函数实际上会通过 rax 寄存器返回一个隐性的返回值！
接着我们继续看 deferproc 函数的实现:
proc/panic.go : 89  // Create a new deferred function fn with siz bytes of arguments. // The compiler turns a defer statement into a call to this. //go:nosplit func deferproc(siz int32, fn *funcval) { // arguments of fn follow fn  if getg().m.curg != getg() { //用户goroutine才能使用defer  // go code on the system stack can&amp;#39;t defer  throw(&amp;#34;defer on system stack&amp;#34;)  }   // the arguments of fn are in a perilous state. The stack map  // for deferproc does not describe them. So we can&amp;#39;t let garbage  // collection or stack copying trigger until we&amp;#39;ve copied them out  // to somewhere safe. The memmove below does that.  // Until the copy completes, we can only call nosplit routines.   // 对getcallersp()和getcallerpc() 函数的分析可以参考本公众号的其它文章  sp := getcallersp() //sp = 调用deferproc之前的rsp寄存器的值  // argp指向defer函数的第一个参数，本例为sum函数的参数a  argp := uintptr(unsafe.Pointer(&amp;amp;fn)) &#43; unsafe.Sizeof(fn)  callerpc := getcallerpc() // deferproc函数的返回地址   d := newdefer(siz)  if d._panic != nil {  throw(&amp;#34;deferproc: d.panic != nil after newdefer&amp;#34;)  }  d.fn = fn //需要延迟执行的函数  d.pc = callerpc //记录deferproc函数的返回地址，主要用于panic/recover  d.sp = sp //调用deferproc之前rsp寄存器的值   //把defer函数需要用到的参数拷贝到d结构体后面，下面的deferrArgs返回的是一个地址  //deferArgs(d) = d &#43; sizeof(d) ，newdefer返回的内存空间 &amp;gt;= deferArgs(d)  switch siz {  case 0:  // Do nothing.  case sys.PtrSize: //如果defered函数的参数只有指针大小则直接通过赋值来拷贝参数  *(*uintptr)(deferArgs(d)) = *(*uintptr)(unsafe.Pointer(argp))  default: //通过memmove拷贝defered函数的参数  memmove(deferArgs(d), unsafe.Pointer(argp), uintptr(siz))  }   // deferproc returns 0 normally.  // a deferred func that stops a panic  // makes the deferproc return 1.  // the code the compiler generates always  // checks the return value and jumps to the  // end of the function if deferproc returns != 0.  return0() //通过汇编指令设置rax = 0  // No code can go here - the C return register has  // been set and must not be clobbered. } deferproc 函数流程很清晰，它首先通过 newdefer 函数分配一个 _defer 结构体对象，然后把需要延迟执行的函数以及该函数需要用到的参数、调用 deferproc 函数时的 rsp 寄存器的值以及 deferproc 函数的返回地址保存在 _defer 结构体对象之中，最后通过 return0() 设置 rax 寄存器的值为 0 隐性的给调用者返回一个 0 值。
不知道大家是否会觉得很奇怪，deferproc 明明只会隐性的返回 0 值，但为什么上面的 f() 函数在调用了 deferproc 之后还用了一条指令来判断返回值是否是 0 呢，这不多此一举吗？事实上这里主要与 panic 和 recover 的实现机制有关，当程序发生 panic 之后，程序会“再次从 deferproc 函数返回”，这种情况下返回值就不是 0 了，因为 panic/recover 机制这一块比较复杂，所以我们以后会专门写一篇文章来分析，现在略过。
回到主题，_defer 结构体的定义为：
runtime/runtime2.go : 727  // A _defer holds an entry on the list of deferred calls. // If you add a field here, add code to clear it in freedefer. type _defer struct {  siz int32 //defer函数的参数大小  started bool  sp uintptr // sp at time of defer  pc uintptr // defer语句下一条语句的地址  fn *funcval //需要被延迟执行的函数  _panic *_panic // panic that is running defer  link *_defer //同一个goroutine所有被延迟执行的函数通过该成员链在一起形成一个链表 } 该结构中的 sp、pc以及 _panic 成员主要与 panic/recover 有关，这里我们无需过多关注（ sp 成员还会被用来判断 _defer 结构体对象中保存的延迟执行函数是否应该在当前函数结束时执行，后面我们会分析到）。
对于本文的例子，初始化完成后的 _defer 结构体对象各成员的值大致如下：
d.siz = 16 d.started = false d.sp = 调用deferproc函数之前的rsp寄存器的值 d.pc = 0x0000000000488e36 d.fn = &amp;amp;funcval{sum} d._panic = nil d._defer = nil sum函数的参数a sum函数的参数b 注意，defered 函数的参数并未在 _defer 结构体中定义，它所需要的参数在内存中紧跟在 _defer 结构体对象的后面。
我们接着看 newdefer 是如何分配 _defer 结构体对象的：
proc/panic.go : 205  // Allocate a Defer, usually using per-P pool. // Each defer must be released with freedefer. // // This must not grow the stack because there may be a frame without // stack map information when this is called. // //go:nosplit func newdefer(siz int32) *_defer {  var d *_defer  sc := deferclass(uintptr(siz))  gp := getg() //获取当前goroutine的g结构体对象  if sc &amp;lt; uintptr(len(p{}.deferpool)) {  pp := gp.m.p.ptr() //与当前工作线程绑定的p  if len(pp.deferpool[sc]) == 0 &amp;amp;&amp;amp; sched.deferpool[sc] != nil {  // Take the slow path on the system stack so  // we don&amp;#39;t grow newdefer&amp;#39;s stack.  systemstack(func() { //切换到系统栈  lock(&amp;amp;sched.deferlock)  //从全局_defer对象池拿一些到p的本地_defer对象池  for len(pp.deferpool[sc]) &amp;lt; cap(pp.deferpool[sc])/2 &amp;amp;&amp;amp; sched.deferpool[sc] != nil {  d := sched.deferpool[sc]  sched.deferpool[sc] = d.link  d.link = nil  pp.deferpool[sc] = append(pp.deferpool[sc], d)  }  unlock(&amp;amp;sched.deferlock)  })  }  if n := len(pp.deferpool[sc]); n &amp;gt; 0 {  d = pp.deferpool[sc][n-1]  pp.deferpool[sc][n-1] = nil  pp.deferpool[sc] = pp.deferpool[sc][:n-1]  }  }  if d == nil { //如果p的缓存中没有可用的_defer结构体对象则从堆上分配  // Allocate new defer&#43;args.  //因为roundupsize以及mallocgc函数都不会处理扩栈，所以需要切换到系统栈执行  systemstack(func() {  total := roundupsize(totaldefersize(uintptr(siz)))  d = (*_defer)(mallocgc(total, deferType, true))  })  if debugCachedWork {  // Duplicate the tail below so if there&amp;#39;s a  // crash in checkPut we can tell if d was just  // allocated or came from the pool.  d.siz = siz  //把新分配出来的d放入当前goroutine的_defer链表头  d.link = gp._defer  gp._defer = d  return d  }  }  d.siz = siz  //把新分配出来的d放入当前goroutine的_defer链表头  d.link = gp._defer  gp._defer = d //把新分配出来的d放入当前goroutine的_defer链表头  return d } newdefer 函数比较长，大家可以参考上面的代码和注释加以理解。newdefer 函数首先会尝试从与当前工作线程绑定的 p 的 _defer 对象池和全局对象池中获取一个满足大小要求(sizeof(_defer) &#43; siz向上取整至16的倍数)的 _defer 结构体对象，如果没有能够满足要求的空闲 _defer 对象则从堆上分一个，最后把分配到的对象链入当前 goroutine 的 _defer 链表的表头。
到此 defer 语句中被延迟执行的函数已经挂入当前 goroutine 的 _defer 链表，我们来简单的总结一下这个过程：
编译器会把 go 代码中 defer 语句翻译成对 deferproc 函数的调用；
deferproc 函数通过 newdefer 函数分配一个 _defer 结构体对象并放入当前 goroutine 的 _defer 链表的表头；
在 _defer 结构体对象中保存被延迟执行的函数 fn 的地址以及 fn 所需的参数；
返回到调用 deferproc 的函数继续执行后面的代码。
deferreturn 函数
分析完 deferproc，我们接着分析 deferreturn：
runtime/panic.go : 331  // Run a deferred function if there is one. // The compiler inserts a call to this at the end of any // function which calls defer. // If there is a deferred function, this will call runtime·jmpdefer, // which will jump to the deferred function such that it appears // to have been called by the caller of deferreturn at the point // just before deferreturn was called. The effect is that deferreturn // is called again and again until there are no more deferred functions. // Cannot split the stack because we reuse the caller&amp;#39;s frame to // call the deferred function.  // The single argument isn&amp;#39;t actually used - it just has its address // taken so it can be matched against pending defers. //go:nosplit func deferreturn(arg0 uintptr) {  gp := getg() //获取当前goroutine对应的g结构体对象  d := gp._defer //defer函数链表  if d == nil {  //没有需要执行的函数直接返回，deferreturn和deferproc是配对使用的  //为什么这里d可能为nil？因为deferreturn其实是一个递归调用，这个是递归结束条件之一  return  }  sp := getcallersp() //获取调用deferreturn时的栈顶位置  if d.sp != sp { //递归结束条件之二  //如果保存在_defer对象中的sp值与调用deferretuen时的栈顶位置不一样，直接返回  //因为sp不一样表示d代表的是在其他函数中通过defer注册的延迟调用函数，比如:  //a()-&amp;gt;b()-&amp;gt;c()它们都通过defer注册了延迟函数，那么当c()执行完时只能执行在c中注册的函数  return  }   // Moving arguments around.  //  // Everything called after this point must be recursively  // nosplit because the garbage collector won&amp;#39;t know the form  // of the arguments until the jmpdefer can flip the PC over to  // fn.  //把保存在_defer对象中的fn函数需要用到的参数拷贝到栈上，准备调用fn  //注意fn的参数放在了调用调用者的栈帧中，而不是此函数的栈帧中  switch d.siz {  case 0:  // Do nothing.  case sys.PtrSize:  *(*uintptr)(unsafe.Pointer(&amp;amp;arg0)) = *(*uintptr)(deferArgs(d))  default:  memmove(unsafe.Pointer(&amp;amp;arg0), deferArgs(d), uintptr(d.siz))  }  fn := d.fn  d.fn = nil  gp._defer = d.link //使gp._defer指向下一个_defer结构体对象  //因为需要调用的函数d.fn已经保存在了fn变量中，它的参数也已经拷贝到了栈上，所以释放_defer结构体对象  freedefer(d)  jmpdefer(fn, uintptr(unsafe.Pointer(&amp;amp;arg0))) //调用fn } deferreturn 函数主要流程为：
通过当前 goroutine 对应的 g 结构体对象的 _defer 链表判断是否有需要执行的 defered 函数，如果没有（g._defer == nil 或则 defered 函数不是在 deferreturn 的 caller 函数中注册的函数）则直接返回；
从 _defer 对象中把 defered 函数需要的参数拷贝到栈上；
释放 _defer 结构体对象；
通过 jmpdefer 函数调用 defered 函数（比如本文的sum函数）。
deferreturn 函数虽然比较简单，但有2点需要注意：
代码中的两个提前return的条件：d == nil 和 d.sp != sp。其中 d == nil 在判断是否有 defered 函数需要执行，可能有些读者会有疑问，deferreturn 明明是与 deferproc 配套使用的，这里怎么会是nil呢？这个是因为deferreturn 函数其实是被递归调用的，每次调用它只会执行一个 defered 函数，比如本文使用的例子在 f() 函数中注册了一个 defered 函数(sum函数)，所以 deferreturn 函数会被调用两次，第一次进入时会去执行 sum 函数，第二次进入时 d 为 nil 就直接返回了；另外一个条件 d.sp != sp 在判断 d 对象所包装的 defered 函数现在是否应该被执行，比如有函数调用链a()-&amp;gt;b()-&amp;gt;c()，即 a 函数调用了 b 函数，b 函数又调用了 c 函数，它们都通过 defer 注册了延迟函数，那么当 c() 执行完时只能执行在 c 中注册的函数，而不能执行 a 函数和 b 函数注册的 defered 函数；
defered 函数的参数并不是放在 deferreturn 函数的栈帧中的，比如前面的例子，f() 调用 deferreturn 函数，所以 deferreturn 函数通过 memmove 把 sum 函数的两个参数 copy 到了 f() 函数的栈中，结合前面 f() 函数的汇编代码，可知在调用 jmpdefer 函数之前，f() 以及 deferreturn() 函数的栈帧大致如下：
jmpdefer 函数
下面我们来看 jmpdefer 函数，该函数使用了些技巧实现了一个对 deferreturn 函数的递归调用：
runtime/asm_amd64.s : 560  // func jmpdefer(fv *funcval, argp uintptr) // argp is a caller SP. // called from deferreturn. // 1. pop the caller // 2. sub 5 bytes from the callers return // 3. jmp to the argument TEXT runtime·jmpdefer(SB), NOSPLIT, $0-16  MOVQ fv&#43;0(FP), DX # fn，fn.fn = sum函数的地址  MOVQ argp&#43;8(FP), BX # caller sp  LEAQ -8(BX), SP # caller sp after CALL  MOVQ -8(SP), BP # restore BP as if deferreturn returned (harmless if framepointers not in use)  SUBQ $5, (SP) # return to CALL again  MOVQ 0(DX), BX  JMP BX # but first run the deferred function 要理解这个函数的功能，需要对函数调用栈及函数调用过程有比较清晰的认识，如果对这部分不熟悉，可以先去看一下网上的资料或本公众号之前写的文章。
下面我们结合本文前面的例子程序来逐条分析 jmpdefer 函数的 7 条汇编指令。
第1条指令：
MOVQ fv&#43;0(FP), DX # fn，fn.fn = sum函数的地址 把jmpdefer的第一个参数也就是结构体对象fn的地址放入DX寄存器，之后的代码就可以通过DX寄存器访问到fn.fn从而拿到 sum 函数的地址。
第2条指令：
MOVQ argp&#43;8(FP), BX # caller sp 把jmpdefer的第二个参数放入 BX 寄存器，该参数是一个指针，它指向 sum 函数的第一个参数，见上图的箭头。
第3条指令：
LEAQ -8(BX), SP # caller sp after CALL 从第二条指令得知 BX 存放的是一个指针，BX - 8所指的位置是 deferreturn 函数执行完后的返回地址 0x488ef0，所以这条指令的作用是让 SP 寄存器指向 deferreturn 函数的返回地址所在的栈内存单元，执行完这条指令后 SP 寄存器与栈之间的关系如下图：
第4条指令：
MOVQ -8(SP), BP # restore BP as if deferreturn returned (harmless if framepointers not in use) 调整 BP 寄存器的值，因为此时 SP - 8 的位置存放的是 f() 函数的 rbp 寄存器的值，所以这条指令在调整 rbp 寄存器的值使其指向 f() 函数的栈帧的适当位置，执行完这条指令后 rbp 寄存器与栈之间的关系如下图：
经过第3条和第4条指令之后，deferreturn 函数的栈帧被抛弃了，因为 jmpdefer 函数并不会直接返回到 deferreturn 之中，所以这里抛弃 deferreturn 函数的栈帧没有问题。
第5条指令：
SUBQ $5, (SP) # return to CALL again CPU 在执行这条指令是，rsp 寄存器指向的是 deferreturn 函数的返回地址，也就是 f() 函数中的 0x0000000000488ef0 &amp;lt;&#43;272&amp;gt;: mov 0x78(%rsp),%rbp 这一条指令的地址，即0x488ef0，所以这条指令把 rsp 寄存器所指的内存中的值 0x488ef0 减了 5 得到 0x488eeb，对照前面f函数的汇编代码可知，这个地址指向的是 0x0000000000488eeb &amp;lt;&#43;267&amp;gt;: callq 0x427490 &amp;lt;runtime.deferreturn&amp;gt; 这条指令。注意看下图中rsp寄存器所指的内存单元中的值的变化：
到此，sum 函数的参数以及 sum 函数执行完的返回地址在栈上已经构造完成，下面开始调用 sum 函数。
第6～7条指令
MOVQ 0(DX), BX # BX = fn.fn JMP BX # but first run the deferred function 会跳转到 sum 函数去执行，完成对 sum 函数的调用，在 sum 函数的执行过程中，栈如下图所示：
因为 sum 函数的返回地址被上面的第5条指令设置成了 0x488eeb，所以等 sum 函数执行完成之后它会直接返回到 f() 函数的
0x0000000000488eeb &amp;lt;&#43;267&amp;gt;: callq 0x427490 &amp;lt;runtime.deferreturn&amp;gt; 指令处继续执行，而这条指令又调用了 deferreturn 函数。回忆一下sum函数的调用路径 f()-&amp;gt;deferreturn()-&amp;gt;jmpdefer()-&amp;gt;sum()，sum函数返回到 f() 时又再一次调用了 deferreturn ，这个过程从形式上看起来就是一个递归，只不过每次“递归”时并没有增加栈空间！
因为 f 函数只使用了一次 defer 语句，所以这里的第二次进入 deferreturn 函数会因为 d == nil 这个条件结束递归，然后返回到 f() 函数中继续执行后面的指令。
总结
最后我们来总结一下 defer 的实现机制。
对于如下所示的 defer 语句
func x() { &amp;hellip;&amp;hellip;. defer y(&amp;hellip;&amp;hellip;) &amp;hellip;&amp;hellip;. } 首先，编译器会把 defer 语句翻译成对 deferproc 函数的调用，deferproc 负责构造一个用来保存 y 函数的地址以及 y 函数需要用到的参数的 _defer 结构体对象，并把该对象加入当前 goroutine 对应的 g 结构体对象的 _defer 链表表头；
然后，编译器会在 x 函数的结尾处插入对 deferreturn 的调用，deferreturn 负责递归的调用 x 函数通过 defer 语句注册的函数。
总体说来，在不考虑 panic/recover 的情况下，go语言对 defer 的实现机制还是比较简单，但其具体实现细节还是有很多地方值得我们仔细思考和学习的。
最后，如果你觉得本文对你有帮助的话，麻烦帮忙点一下文末右下角的 在看 或转发到朋友圈，非常感谢！
</content>
    </entry>
    
     <entry>
        <title>go深入理解defer（上）defer基础</title>
        <url>http://shanks.link/blog/2021/04/03/go%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3defer%E4%B8%8Adefer%E5%9F%BA%E7%A1%80/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 爱写程序的阿波张 源码游记 2019-06-11
深入理解 defer 分上下两篇文章，本文为上篇，主要介绍如下内容：
为什么需要 defer；
defer 语法及语义；
defer 使用要点；
defer 语句中的函数到底是在 return 语句之后被调用还是 return 语句之前被调用。
为什么需要 defer
先来看一段没有使用 defer 的代码：
func f() {  r := getResource() //0，获取资源  ......  if ... {  r.release() //1，释放资源  return  }  ......  if ... {  r.release() //2，释放资源  return  }  ......  if ... {  r.release() //3，释放资源  return  }  ......  r.release() //4，释放资源  return } f() 函数首先通过调用 getResource() 获取了某种资源（比如打开文件，加锁等），然后进行了一些我们不太关心的操作，但这些操作可能会导致 f() 函数提前返回，为了避免资源泄露，所以每个 return 之前都调用了 r.release() 函数对资源进行释放。这段代码看起来并不糟糕，但有两个小问题：代码臃肿和可维护性比较差。臃肿倒是其次，主要问题在于代码的可维护性差，因为随着开发和维护的进行，修改代码在所难免，一旦对 f() 函数进行修改添加某个提前返回的分支，就很有可能在提前 return 时忘记调用 r.release() 释放资源，从而导致资源泄漏。
那么我们如何改善上述两个问题呢？一个不错的方案就是通过 defer 调用 r.release() 来释放资源：
func f() {  r := getResource() //0，获取资源  defer r.release() //1，注册延迟调用函数，f()函数返回时才会调用r.release函数释放资源  ......  if ... {  return  }  ......  if ... {  return  }  ......  if ... {  return  }  ......  return } 可以看到通过使用 defer 调用 r.release()，我们不需要在每个 return 之前都去手动调用 r.release() 函数，代码确实精简了一点，重要的是不管以后加多少提前 return 的代码，都不会出现资源泄露的问题，因为不管在什么地方 return ，r.release() 函数始终都会被调用。
defer 语法及语义
defer语法很简单，直接在普通写法的函数调用之前加 defer 关键字即可：
defer xxx(arg0, arg1, arg2, &amp;hellip;&amp;hellip;) defer 表示对紧跟其后的 xxx() 函数延迟到 defer 语句所在的当前函数返回时再进行调用。比如前文代码中注释 1 处的 defer r.release() 表示等 f() 函数返回时再调用 r.release() 。下文我们称 defer 语句中的函数叫 defer函数。
defer 使用要点
对 defer 的使用需要注意如下几个要点：
延迟对函数进行调用；
即时对函数的参数进行求值；
根据 defer 顺序反序调用；
下面我们用例子来简单的看一下这几个要点。
defer 函数延迟调用
func f() {  defer fmt.Println(&amp;#34;defer&amp;#34;)  fmt.Println(&amp;#34;begin&amp;#34;)  fmt.Println(&amp;#34;end&amp;#34;)  return } 这段代码首先会输出 begin 字符串，然后是 end ，最后才输出 defer 字符串。
defer 函数参数即时求值
func g(i int) {  fmt.Println(&amp;#34;g i:&amp;#34;, i) } func f() {  i := 100  defer g(i) //1  fmt.Println(&amp;#34;begin i:&amp;#34;, i)  i = 200  fmt.Println(&amp;#34;end i:&amp;#34;, i)  return } 这段代码首先输出 begin i: 100，然后输出 end i: 200，最后输出 g i: 100 ，可以看到 g() 函数虽然在f函数返回时才被调用，但传递给 g() 函数的参数还是100，因为代码 1 处的 defer g(i) 这条语句执行时 i 的值是100。也就是说 defer 函数会被延迟调用，但传递给 defer 函数的参数会在 defer 语句处就被准备好。
反序调用
func f() {  defer fmt.Println(&amp;#34;defer01&amp;#34;)  fmt.Println(&amp;#34;begin&amp;#34;)  defer fmt.Println(&amp;#34;defer02&amp;#34;)  fmt.Println(&amp;#34;----&amp;#34;)  defer fmt.Println(&amp;#34;defer03&amp;#34;)  fmt.Println(&amp;#34;end&amp;#34;)  return } 这段程序的输出如下：
begin end defer03 defer02 defer01 可以看出f函数返回时，第一个 defer 函数最后被执行，而最后一个 defer 函数却第一个被执行。
defer 函数的执行与 return 语句之间的关系
到目前为止，defer 看起来都还比较好理解。下面我们开始把问题复杂化
package main  import &amp;#34;fmt&amp;#34;  var g = 100  func f() (r int) {  defer func() {  g = 200  }()   fmt.Printf(&amp;#34;f: g = %d\n&amp;#34;, g)   return g }  func main() {  i := f()  fmt.Printf(&amp;#34;main: i = %d, g = %d\n&amp;#34;, i, g) } 输出：
$ ./defer f: g = 100 main: i = 100, g = 200 这个输出还是比较容易理解，f() 函数在执行 return g 之前 g 的值还是100，所以 main() 函数获得的 f() 函数的返回值是100，因为 g 已经被 defer 函数修改成了200，所以在 main 中输出的 g 的值为200，看起来 defer 函数在 return g 之后才运行。下面稍微修改一下上面的程序：
package main  import &amp;#34;fmt&amp;#34;  var g = 100  func f() (r int) {  r = g  defer func() {  r = 200  }()   fmt.Printf(&amp;#34;f: r = %d\n&amp;#34;, r)   r = 0  return r }  func main() {  i := f()  fmt.Printf(&amp;#34;main: i = %d, g = %d\n&amp;#34;, i, g) } 输出：
$ ./defer f: r = 100 main: i = 200, g = 100 从这个输出可以看出，defer 函数修改了 f() 函数的返回值，从这里看起来 defer 函数的执行发生在 return r 之前，然而上一个例子我们得出的结论是 defer 函数在 return 语句之后才被调用执行，这两个结论很矛盾，到底是怎么回事呢？
仅仅从go语言的角度来说确实不太好理解，我们需要深入到汇编来分析一下。
老套路，使用 gdb 反汇编一下 f() 函数：
 0x0000000000488a30 &amp;lt;&#43;0&amp;gt;: mov %fs:0xfffffffffffffff8,%rcx  0x0000000000488a39 &amp;lt;&#43;9&amp;gt;: cmp 0x10(%rcx),%rsp  0x0000000000488a3d &amp;lt;&#43;13&amp;gt;: jbe 0x488b33 &amp;lt;main.f&#43;259&amp;gt;  0x0000000000488a43 &amp;lt;&#43;19&amp;gt;: sub $0x68,%rsp  0x0000000000488a47 &amp;lt;&#43;23&amp;gt;: mov %rbp,0x60(%rsp)  0x0000000000488a4c &amp;lt;&#43;28&amp;gt;: lea 0x60(%rsp),%rbp  0x0000000000488a51 &amp;lt;&#43;33&amp;gt;: movq $0x0,0x70(%rsp) # 初始化返回值r为0  0x0000000000488a5a &amp;lt;&#43;42&amp;gt;: mov 0xbd66f(%rip),%rax # 0x5460d0 &amp;lt;main.g&amp;gt;  0x0000000000488a61 &amp;lt;&#43;49&amp;gt;: mov %rax,0x70(%rsp) # r = g  0x0000000000488a66 &amp;lt;&#43;54&amp;gt;: movl $0x8,(%rsp)  0x0000000000488a6d &amp;lt;&#43;61&amp;gt;: lea 0x384a4(%rip),%rax # 0x4c0f18  0x0000000000488a74 &amp;lt;&#43;68&amp;gt;: mov %rax,0x8(%rsp)  0x0000000000488a79 &amp;lt;&#43;73&amp;gt;: lea 0x70(%rsp),%rax  0x0000000000488a7e &amp;lt;&#43;78&amp;gt;: mov %rax,0x10(%rsp)  0x0000000000488a83 &amp;lt;&#43;83&amp;gt;: callq 0x426c00 &amp;lt;runtime.deferproc&amp;gt;  0x0000000000488a88 &amp;lt;&#43;88&amp;gt;: test %eax,%eax  0x0000000000488a8a &amp;lt;&#43;90&amp;gt;: jne 0x488b23 &amp;lt;main.f&#43;243&amp;gt;  0x0000000000488a90 &amp;lt;&#43;96&amp;gt;: mov 0x70(%rsp),%rax  0x0000000000488a95 &amp;lt;&#43;101&amp;gt;: mov %rax,(%rsp)  0x0000000000488a99 &amp;lt;&#43;105&amp;gt;: callq 0x408950 &amp;lt;runtime.convT64&amp;gt;  0x0000000000488a9e &amp;lt;&#43;110&amp;gt;: mov 0x8(%rsp),%rax  0x0000000000488aa3 &amp;lt;&#43;115&amp;gt;: xorps %xmm0,%xmm0  0x0000000000488aa6 &amp;lt;&#43;118&amp;gt;: movups %xmm0,0x50(%rsp)  0x0000000000488aab &amp;lt;&#43;123&amp;gt;: lea 0x101ee(%rip),%rcx # 0x498ca0  0x0000000000488ab2 &amp;lt;&#43;130&amp;gt;: mov %rcx,0x50(%rsp)  0x0000000000488ab7 &amp;lt;&#43;135&amp;gt;: mov %rax,0x58(%rsp)  0x0000000000488abc &amp;lt;&#43;140&amp;gt;: nop  0x0000000000488abd &amp;lt;&#43;141&amp;gt;: mov 0xd0d2c(%rip),%rax # 0x5597f0 &amp;lt;os.Stdout&amp;gt;  0x0000000000488ac4 &amp;lt;&#43;148&amp;gt;: lea 0x495f5(%rip),%rcx # 0x4d20c0 &amp;lt;go.itab.*os.File,io.Writer&amp;gt;  0x0000000000488acb &amp;lt;&#43;155&amp;gt;: mov %rcx,(%rsp)  0x0000000000488acf &amp;lt;&#43;159&amp;gt;: mov %rax,0x8(%rsp)  0x0000000000488ad4 &amp;lt;&#43;164&amp;gt;: lea 0x31ddb(%rip),%rax # 0x4ba8b6  0x0000000000488adb &amp;lt;&#43;171&amp;gt;: mov %rax,0x10(%rsp)  0x0000000000488ae0 &amp;lt;&#43;176&amp;gt;: movq $0xa,0x18(%rsp)  0x0000000000488ae9 &amp;lt;&#43;185&amp;gt;: lea 0x50(%rsp),%rax  0x0000000000488aee &amp;lt;&#43;190&amp;gt;: mov %rax,0x20(%rsp)  0x0000000000488af3 &amp;lt;&#43;195&amp;gt;: movq $0x1,0x28(%rsp)  0x0000000000488afc &amp;lt;&#43;204&amp;gt;: movq $0x1,0x30(%rsp)  0x0000000000488b05 &amp;lt;&#43;213&amp;gt;: callq 0x480b20 &amp;lt;fmt.Fprintf&amp;gt;  0x0000000000488b0a &amp;lt;&#43;218&amp;gt;: movq $0x0,0x70(%rsp) # r = 0  # ---- 下面5条指令对应着go代码中的 return r  0x0000000000488b13 &amp;lt;&#43;227&amp;gt;: nop  0x0000000000488b14 &amp;lt;&#43;228&amp;gt;: callq 0x427490 &amp;lt;runtime.deferreturn&amp;gt;  0x0000000000488b19 &amp;lt;&#43;233&amp;gt;: mov 0x60(%rsp),%rbp  0x0000000000488b1e &amp;lt;&#43;238&amp;gt;: add $0x68,%rsp  0x0000000000488b22 &amp;lt;&#43;242&amp;gt;: retq  # ---------------------------  0x0000000000488b23 &amp;lt;&#43;243&amp;gt;: nop  0x0000000000488b24 &amp;lt;&#43;244&amp;gt;: callq 0x427490 &amp;lt;runtime.deferreturn&amp;gt;  0x0000000000488b29 &amp;lt;&#43;249&amp;gt;: mov 0x60(%rsp),%rbp  0x0000000000488b2e &amp;lt;&#43;254&amp;gt;: add $0x68,%rsp  0x0000000000488b32 &amp;lt;&#43;258&amp;gt;: retq  0x0000000000488b33 &amp;lt;&#43;259&amp;gt;: callq 0x44f300 &amp;lt;runtime.morestack_noctxt&amp;gt;  0x0000000000488b38 &amp;lt;&#43;264&amp;gt;: jmpq 0x488a30 &amp;lt;main.f&amp;gt; f() 函数本来很简单，但里面使用了闭包和 Printf，所以汇编代码看起来比较复杂，这里我们只挑重点出来说。f() 函数最后 2 条语句被编译器翻译成了如下6条汇编指令：
 0x0000000000488b0a &amp;lt;&#43;218&amp;gt;: movq $0x0,0x70(%rsp) # r = 0  # ---- 下面5条指令对应着go代码中的 return r  0x0000000000488b13 &amp;lt;&#43;227&amp;gt;: nop  0x0000000000488b14 &amp;lt;&#43;228&amp;gt;: callq 0x427490 &amp;lt;runtime.deferreturn&amp;gt; # deferreturn会调用defer注册的函数  0x0000000000488b19 &amp;lt;&#43;233&amp;gt;: mov 0x60(%rsp),%rbp # 调整栈  0x0000000000488b1e &amp;lt;&#43;238&amp;gt;: add $0x68,%rsp # 调整栈  0x0000000000488b22 &amp;lt;&#43;242&amp;gt;: retq # 从f()函数返回  # --------------------------- 这6条指令中的第一条指令对应到的go语句是 r = 0，因为 r = 0 之后的下一行语句是 return r ，所以这条指令相当于把 f() 函数的返回值保存到了栈上，然后第三条指令调用了 runtime.deferreturn 函数，该函数会去调用我们在 f() 函数开始处使用 defer 注册的函数修改 r 的值为200，所以我们在main函数拿到的返回值是200，后面三条指令完成函数调用栈的调整及返回。
从这几条指令可以得出，准确的说，defer 函数的执行既不是在 return 之后也不是在 return 之前，而是一条go语言的 return 语句包含了对 defer 函数的调用，即 return 会被翻译成如下几条伪指令
保存返回值到栈上 调用defer函数 调整函数栈 retq指令返回 到此我们已经知道，前面说的矛盾其实并非矛盾，只是从Go语言层面来理解不好理解而已，一旦我们深入到汇编层面，一切都会显得那么自然，正所谓汇编之下了无秘密。
总结
defer 主要用于简化编程（以及实现 panic/recover ，后面会专门写一篇相关文章来介绍）
defer 实现了函数的延迟调用；
defer 使用要点：延迟调用，即时求值和反序调用；
go 语言的 return 会被编译器翻译成多条指令，其中包括保存返回值，调用defer注册的函数以及实现函数返回。
本文我们主要从使用的角度介绍了defer 的基础知识，下一篇文章我们将会深入 runtime.deferproc 和 runtime.deferreturn 这两个函数分析 defer 的实现机制。
最后，如果你觉得本文对你有帮助的话，麻烦帮忙点一下文末右下角的 在看 或转发到朋友圈，非常感谢！
</content>
    </entry>
    
     <entry>
        <title>抢占系统调用执行时间过长的goroutine（22）</title>
        <url>http://shanks.link/blog/2021/04/03/%E6%8A%A2%E5%8D%A0%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%E6%89%A7%E8%A1%8C%E6%97%B6%E9%97%B4%E8%BF%87%E9%95%BF%E7%9A%84goroutine22/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> ​​​​​​​​​原创 爱写程序的阿波张 源码游记 2019-06-01
本文是《Go语言调度器源代码情景分析》系列的第22篇，也是第六章《抢占调度》的第2小节。
上一节我们分析了因运行时间过长而导致的抢占调度，这一节我们来分析因进入系统调用时间过长而发生的抢占调度。
剥夺工作线程的p
现在重新回到sysmon监控线程定期调用的retake函数:
runtime/proc.go : 4380  func retake(now int64) uint32 {  ......  for i := 0; i &amp;lt; len(allp); i&#43;&#43; { //遍历所有p，然后根据p的状态进行抢占  _p_ := allp[i]  if _p_ == nil {  // This can happen if procresize has grown  // allp but not yet created new Ps.  continue  }   //_p_.sysmontick用于sysmon监控线程监控p时记录系统调用时间和运行时间，由sysmon监控线程记录  pd := &amp;amp;_p_.sysmontick  s := _p_.status  if s == _Psyscall { //系统调用抢占处理  // Retake P from syscall if it&amp;#39;s there for more than 1 sysmon tick (at least 20us).  //_p_.syscalltick用于记录系统调用的次数，主要由工作线程在完成系统调用之后&#43;&#43;  t := int64(_p_.syscalltick)  if int64(pd.syscalltick) != t {  //pd.syscalltick != _p_.syscalltick，说明已经不是上次观察到的系统调用了，  //而是另外一次系统调用，所以需要重新记录tick和when值  pd.syscalltick = uint32(t)  pd.syscallwhen = now  continue  }   //pd.syscalltick == _p_.syscalltick，说明还是之前观察到的那次系统调用，  //计算这次系统调用至少过了多长时间了   // On the one hand we don&amp;#39;t want to retake Ps if there is no other work to do,  // but on the other hand we want to retake them eventually  // because they can prevent the sysmon thread from deep sleep.  // 只要满足下面三个条件中的任意一个，则抢占该p，否则不抢占  // 1. p的运行队列里面有等待运行的goroutine  // 2. 没有无所事事的p  // 3. 从上一次监控线程观察到p对应的m处于系统调用之中到现在已经超过10了毫秒  if runqempty(_p_) &amp;amp;&amp;amp; atomic.Load(&amp;amp;sched.nmspinning)&#43;atomic.Load(&amp;amp;sched.npidle)&amp;gt; 0 &amp;amp;&amp;amp; pd.syscallwhen&#43;10*1000*1000 &amp;gt; now {  continue  }  // Drop allpLock so we can take sched.lock.  unlock(&amp;amp;allpLock)  // Need to decrement number of idle locked M&amp;#39;s  // (pretending that one more is running) before the CAS.  // Otherwise the M from which we retake can exit the syscall,  // increment nmidle and report deadlock.  incidlelocked(-1)  if atomic.Cas(&amp;amp;_p_.status, s, _Pidle) {  ......  _p_.syscalltick&#43;&#43;  handoffp(_p_) //寻找一个新的m出来接管P  }  incidlelocked(1)  lock(&amp;amp;allpLock)  } else if s == _Prunning { //运行时间太长，抢占处理，前面已经分析  ......  }  }  ...... } retake函数所做的主要事情就在遍历所有的p，并根据每个p的状态以及处于该状态的时长来决定是否需要发起抢占。从代码可以看出只有当p处于 _Prunning 或 _Psyscall 状态时才会进行抢占，而因p处于_Prunning状态的时间过长而发生的抢占调度我们在上一节已经分析过了，现在我们来看看如何对处于系统调用之中的p（对应的goroutine）进行抢占。
根据retake函数的代码，只要满足下面三个条件中的任意一个就需要对处于_Psyscall 状态的p进行抢占：
p的运行队列里面有等待运行的goroutine。这用来保证当前p的本地运行队列中的goroutine得到及时的调度，因为该p对应的工作线程正处于系统调用之中，无法调度队列中goroutine，所以需要寻找另外一个工作线程来接管这个p从而达到调度这些goroutine的目的；
没有空闲的p。表示其它所有的p都已经与工作线程绑定且正忙于执行go代码，这说明系统比较繁忙，所以需要抢占当前正处于系统调用之中而实际上系统调用并不需要的这个p并把它分配给其它工作线程去调度其它goroutine。
从上一次监控线程观察到p对应的m处于系统调用之中到现在已经超过10了毫秒。这表示只要系统调用超时，就对其抢占，而不管是否真的有goroutine需要调度，这样保证sysmon线程不至于觉得无事可做（sysmon线程会判断retake函数的返回值，如果为0，表示retake并未做任何抢占，所以会觉得没啥事情做）而休眠太长时间最终会降低sysmon监控的实时性。至于如何计算某一次系统调用时长可以参考上面代码及注释。
retake函数发现如果需要抢占，则通过使用cas修改p的状态来获取p的使用权（为什么需要使用cas呢？从后面的分析我们将知道，工作线程此时此刻可能正好从系统调用返回了，也正在获取p的使用权），如果使用权获取成功则调用handoffp寻找新的工作线程来接管这个p。
runtime/proc.go : 1995  // Hands off P from syscall or locked M. // Always runs without a P, so write barriers are not allowed. //go:nowritebarrierrec func handoffp(_p_ *p) {  // handoffp must start an M in any situation where  // findrunnable would return a G to run on _p_.   // if it has local work, start it straight away  //运行队列不为空，需要启动m来接管  if !runqempty(_p_) || sched.runqsize != 0 {  startm(_p_, false)  return  }  // if it has GC work, start it straight away  //有垃圾回收工作需要做，也需要启动m来接管  if gcBlackenEnabled != 0 &amp;amp;&amp;amp; gcMarkWorkAvailable(_p_) {  startm(_p_, false)  return  }  // no local work, check that there are no spinning/idle M&amp;#39;s,  // otherwise our help is not required  //所有其它p都在运行goroutine，说明系统比较忙，需要启动m  if atomic.Load(&amp;amp;sched.nmspinning)&#43;atomic.Load(&amp;amp;sched.npidle) == 0 &amp;amp;&amp;amp; atomic.Cas(&amp;amp;sched.nmspinning, 0, 1) { // TODO: fast atomic  startm(_p_, true)  return  }  lock(&amp;amp;sched.lock)  if sched.gcwaiting != 0 { //如果gc正在等待Stop The World  _p_.status = _Pgcstop  sched.stopwait--  if sched.stopwait == 0 {  notewakeup(&amp;amp;sched.stopnote)  }  unlock(&amp;amp;sched.lock)  return  }  ......  if sched.runqsize != 0 { //全局运行队列有工作要做  unlock(&amp;amp;sched.lock)  startm(_p_, false)  return  }  // If this is the last running P and nobody is polling network,  // need to wakeup another M to poll network.  //不能让所有的p都空闲下来，因为需要监控网络连接读写事件  if sched.npidle == uint32(gomaxprocs-1) &amp;amp;&amp;amp; atomic.Load64(&amp;amp;sched.lastpoll) != 0 {  unlock(&amp;amp;sched.lock)  startm(_p_, false)  return  }  pidleput(_p_) //无事可做，把p放入全局空闲队列  unlock(&amp;amp;sched.lock) } handoffp函数流程比较简单，它的主要任务是通过各种条件判断是否需要启动工作线程来接管_p_，如果不需要则把_p_放入P的全局空闲队列。
从handoffp的代码可以看出，在如下几种情况下则需要调用我们已经分析过的startm函数启动新的工作线程出来接管_p_：
_p_的本地运行队列或全局运行队列里面有待运行的goroutine；
需要帮助gc完成标记工作；
系统比较忙，所有其它_p_都在运行goroutine，需要帮忙；
所有其它P都已经处于空闲状态，如果需要监控网络连接读写事件，则需要启动新的m来poll网络连接。
到此，sysmon监控线程对处于系统调用之中的p的抢占就已经完成。
系统调用
从上面的分析可以看出，这里对正在进行系统调用的goroutine的抢占实质上是剥夺与其对应的工作线程所绑定的p，虽然说处于系统调用之中的工作线程并不需要p，但一旦从操作系统内核返回到用户空间之后就必须绑定一个p才能运行go代码，那么，工作线程从系统调用返回之后如果发现它进入系统调用之前所使用的p被监控线程拿走了，该怎么办呢？接下来我们就来分析这个问题。
为了搞清楚工作线程从系统调用返回之后需要做哪些事情，我们需要找到相关的代码，怎么找代码呢？这里我们通过对一个使用了系统调用的程序的调试来寻找。
package main  import (  &amp;#34;fmt&amp;#34;  &amp;#34;os&amp;#34; )  func main() {  fd, err := os.Open(&amp;#34;./syscall.go&amp;#34;) //一定会执行系统调用  if err != nil {  fmt.Println(err)  }   fd.Close() } 使用gdb跟踪调试上面这个程序可以发现，main函数调用的os.Open函数最终会调用到Syscall6函数，因为中间调用过程与我们分析目标没关系，所以我们直接从Syscall6函数开始分析。
syscall/asm_linux_amd64.s : 42  // func Syscall6(trap, a1, a2, a3, a4, a5, a6 uintptr) (r1, r2, err uintptr) TEXT ·Syscall6(SB), NOSPLIT, $0-80  CALL runtime·entersyscall(SB)   #按照linux系统约定复制参数到寄存器并调用syscall指令进入内核  MOVQ a1&#43;8(FP), DI  MOVQ a2&#43;16(FP), SI  MOVQ a3&#43;24(FP), DX  MOVQ a4&#43;32(FP), R10  MOVQ a5&#43;40(FP), R8  MOVQ a6&#43;48(FP), R9  MOVQ trap&#43;0(FP), AX#syscall entry，系统调用编号放入AX  SYSCALL #进入内核   #从内核返回，判断返回值，linux使用 -1 ~ -4095 作为错误码  CMPQ AX, $0xfffffffffffff001  JLS ok6   #系统调用返回错误，为Syscall6函数准备返回值  MOVQ $-1, r1&#43;56(FP)  MOVQ $0, r2&#43;64(FP)  NEGQ AX  MOVQ AX, err&#43;72(FP)  CALL runtime·exitsyscall(SB)  RET ok6: #系统调用返回错误  MOVQ AX, r1&#43;56(FP)  MOVQ DX, r2&#43;64(FP)  MOVQ $0, err&#43;72(FP)  CALL runtime·exitsyscall(SB)  RET Syscall6函数主要依次干了如下3件事：
调用runtime.entersyscall函数；
使用SYSCALL指令进入系统调用；
调用runtime.exitsyscall函数。
根据前面的分析和这段代码我们可以猜测，exitsyscall函数将会处理当前工作线程进入系统调用之前所拥有的p被监控线程抢占剥夺的情况。但这里怎么会有个entersyscall呢，它是干啥的？我们先来看看。
entersyscall函数  runtime/proc.go : 2847  // Standard syscall entry used by the go syscall library and normal cgo calls. //go:nosplit func entersyscall() {  reentersyscall(getcallerpc(), getcallersp()) }  func reentersyscall(pc, sp uintptr) {  _g_ := getg() //执行系统调用的goroutine   // Disable preemption because during this function g is in Gsyscall status,  // but can have inconsistent g-&amp;gt;sched, do not let GC observe it.  _g_.m.locks&#43;&#43;   // Entersyscall must not call any function that might split/grow the stack.  // (See details in comment above.)  // Catch calls that might, by replacing the stack guard with something that  // will trip any stack check and leaving a flag to tell newstack to die.  _g_.stackguard0 = stackPreempt  _g_.throwsplit = true   // Leave SP around for GC and traceback.  save(pc, sp) //save函数分析过，用来保存g的现场信息，rsp, rbp, rip等等  _g_.syscallsp = sp  _g_.syscallpc = pc  casgstatus(_g_, _Grunning, _Gsyscall)  ......  _g_.m.syscalltick = _g_.m.p.ptr().syscalltick  _g_.sysblocktraced = true  _g_.m.mcache = nil  pp := _g_.m.p.ptr()  pp.m = 0 //p解除与m之间的绑定  _g_.m.oldp.set(pp) //把p记录在oldp中，等从系统调用返回时，优先绑定这个p  _g_.m.p = 0 //m解除与p之间的绑定  atomic.Store(&amp;amp;pp.status, _Psyscall) //修改当前p的状态，sysmon线程依赖状态实施抢占  .....  _g_.m.locks-- } entersyscall函数直接调用了reentersyscall函数，reentersyscall首先把现场信息保存在当前g的sched成员中，然后解除m和p的绑定关系并设置p的状态为_Psyscall，前面我们已经看到sysmon监控线程需要依赖该状态实施抢占。
这里有几个问题需要澄清一下：
有sysmon监控线程来抢占剥夺，为什么这里还需要主动解除m和p之间的绑定关系呢？原因主要在于这里主动解除m和p的绑定关系之后，sysmon线程就不需要通过加锁或cas操作来修改m.p成员从而解除m和p之间的关系；
为什么要记录工作线程进入系统调用之前所绑定的p呢？因为记录下来可以让工作线程从系统调用返回之后快速找到一个可能可用的p，而不需要加锁从sched的pidle全局队列中去寻找空闲的p。
为什么要把进入系统调用之前所绑定的p搬到m的oldp中，而不是直接使用m的p成员？笔者第一次看到这里也有疑惑，于是翻看了github上的提交记录，从代码作者的提交注释来看，这里主要是从保持m的p成员清晰的语义方面考虑的，因为处于系统调用的m事实上并没有绑定p，所以如果记录在p成员中，p的语义并不够清晰明了。
看完进入系统调用之前调用的entersyscall函数后，我们再来看系统调用返回之后需要调用的exitsyscall函数。
exitsyscall函数  runtime/proc.go : 2931  // The goroutine g exited its system call. // Arrange for it to run on a cpu again. // This is called only from the go syscall library, not // from the low-level system calls used by the runtime. // // Write barriers are not allowed because our P may have been stolen. // //go:nosplit //go:nowritebarrierrec func exitsyscall() {  _g_ := getg()  ......  oldp := _g_.m.oldp.ptr() //进入系统调用之前所绑定的p  _g_.m.oldp = 0  if exitsyscallfast(oldp) {//因为在进入系统调用之前已经解除了m和p之间的绑定，所以现在需要绑定p  //绑定成功，设置一些状态  ......   // There&amp;#39;s a cpu for us, so we can run.  _g_.m.p.ptr().syscalltick&#43;&#43; //系统调用完成，增加syscalltick计数，sysmon线程依靠它判断是否是同一次系统调用  // We need to cas the status and scan before resuming...  //casgstatus函数会处理一些垃圾回收相关的事情，我们只需知道该函数重新把g设置成_Grunning状态即可  casgstatus(_g_, _Gsyscall, _Grunning)  ......  return  }  ......  _g_.m.locks--   // Call the scheduler.  //没有绑定到p，调用mcall切换到g0栈执行exitsyscall0函数  mcall(exitsyscall0)  ...... } 因为在进入系统调用之前，工作线程调用entersyscall解除了m和p之间的绑定，现在已经从系统调用返回需要重新绑定一个p才能继续运行go代码，所以exitsyscall函数首先就调用exitsyscallfast去尝试绑定一个空闲的p，如果绑定成功则结束exitsyscall函数按函数调用链原路返回去执行其它用户代码，否则则调用mcall函数切换到g0栈执行exitsyscall0函数。下面先来看exitsyscallfast如何尝试绑定一个p，然后再去分析exitsyscall0函数。
exitsyscallfast首先尝试绑定进入系统调用之前所使用的p，如果绑定失败就需要调用exitsyscallfast_pidle去获取空闲的p来绑定。
runtime/proc.go : 3020  //go:nosplit func exitsyscallfast(oldp *p) bool {  _g_ := getg()  ......  // Try to re-acquire the last P.  //尝试快速绑定进入系统调用之前所使用的p  if oldp != nil &amp;amp;&amp;amp; oldp.status == _Psyscall &amp;amp;&amp;amp; atomic.Cas(&amp;amp;oldp.status, _Psyscall, _Pidle) {  //使用cas操作获取到p的使用权，所以之后的代码不需要使用锁就可以直接操作p  // There&amp;#39;s a cpu for us, so we can run.  wirep(oldp) //绑定p  exitsyscallfast_reacquired()  return true  }   // Try to get any other idle P.  if sched.pidle != 0 {  var ok bool  systemstack(func() {  ok = exitsyscallfast_pidle() //从全局队列中寻找空闲的p，需要加锁，比较慢  ......  })  if ok {  return true  }  }  return false } exitsyscallfast首先尝试快速绑定进入系统调用之前所使用的p，因为该p的状态目前还是_Psyscall，监控线程此时可能也正好准备操作这个p的状态，所以这里需要使用cas原子操作来修改状态，保证只有一个线程的cas能够成功，一旦cas操作成功，就表示当前线程获取到了p的使用权，这样当前线程的后续代码就可以直接操作该p了。具体到exitsyscallfast函数，一旦我们拿到p的使用权，就调用wirep把工作线程m和p关联起来，完成绑定工作。所谓的绑定其实就是设置m的p成员指向p和p的m成员指向m。
runtime/proc.go : 4099  // wirep is the first step of acquirep, which actually associates the // current M to _p_. This is broken out so we can disallow write // barriers for this part, since we don&amp;#39;t yet have a P. // //go:nowritebarrierrec //go:nosplit func wirep(_p_ *p) {  _g_ := getg()  ......  //相互赋值，绑定m和p  _g_.m.mcache = _p_.mcache  _g_.m.p.set(_p_)  _p_.m.set(_g_.m)  _p_.status = _Prunning } exitsyscallfast函数如果绑定进入系统调用之前所使用的p失败，则调用exitsyscallfast_pidle从p的全局空闲队列中获取一个p出来绑定，注意这里使用了systemstack(func())函数来调用exitsyscallfast_pidle，systemstack(func())函数有一个func()类型的参数，该函数首先会把栈切换到g0栈，然后调用通过参数传递进来的函数(这里是一个闭包，包含了对exitsyscallfast_pidle函数的调用)，最后再切换回原来的栈并返回，为什么这些代码需要在系统栈也就是g0的栈上执行呢？原则上来说，只要调用链上某个函数有nosplit这个编译器指示就需要在g0栈上去执行，因为有nosplit指示的话编译器就不会插入检查溢出的代码，这样在非g0栈上执行这些nosplit函数就有可能导致栈溢出，g0栈其实就是操作系统线程所使用的栈，它的空间比较大，不需要对runtime代码中的每个函数都做栈溢出检查，否则会严重影响效率。
为什么绑定进入系统调用之前所使用的p会失败呢？原因就在于这个p可能被sysmon监控线程拿走并绑定到其它工作线程，这部分内容我们已经在前面分析过了。
现在继续看exitsyscallfast_pidle函数，从代码可以看到从全局空闲队列获取p需要加锁，如果锁冲突比较严重的话，这个过程就很慢了，这也是为什么exitsyscallfast函数首先会去尝试绑定之前使用的p的原因。
runtime/proc.go : 3083  func exitsyscallfast_pidle() bool {  lock(&amp;amp;sched.lock)  _p_ := pidleget()//从全局空闲队列中获取p  if _p_ != nil &amp;amp;&amp;amp; atomic.Load(&amp;amp;sched.sysmonwait) != 0 {  atomic.Store(&amp;amp;sched.sysmonwait, 0)  notewakeup(&amp;amp;sched.sysmonnote)  }  unlock(&amp;amp;sched.lock)  if _p_ != nil {  acquirep(_p_)  return true  }  return false } 回到exitsyscall函数，如果exitsyscallfast绑定p失败，则调用mcall执行exitsyscall0函数，mcall我们已经见到过多次，所以这里只分析exitsyscall0函数。
runtime/proc.go : 3098  // exitsyscall slow path on g0. // Failed to acquire P, enqueue gp as runnable. // //go:nowritebarrierrec func exitsyscall0(gp *g) {  _g_ := getg()   casgstatus(gp, _Gsyscall, _Grunnable)   //当前工作线程没有绑定到p,所以需要解除m和g的关系  dropg()  lock(&amp;amp;sched.lock)  var _p_ *p  if schedEnabled(_g_) {  _p_ = pidleget() //再次尝试获取空闲的p  }  if _p_ == nil { //还是没有空闲的p  globrunqput(gp) //把g放入全局运行队列  } else if atomic.Load(&amp;amp;sched.sysmonwait) != 0 {  atomic.Store(&amp;amp;sched.sysmonwait, 0)  notewakeup(&amp;amp;sched.sysmonnote)  }  unlock(&amp;amp;sched.lock)  if _p_ != nil {//获取到了p  acquirep(_p_) //绑定p  //继续运行g  execute(gp, false) // Never returns.  }  if _g_.m.lockedg != 0 {  // Wait until another thread schedules gp and so m again.  stoplockedm()  execute(gp, false) // Never returns.  }  stopm() //当前工作线程进入睡眠，等待被其它线程唤醒   //从睡眠中被其它线程唤醒，执行schedule调度循环重新开始工作  schedule() // Never returns. } 因为工作线程没有绑定p是不能运行goroutine的，所以这里会再次尝试从全局空闲队列找一个p出来绑定，找到了就通过execute函数继续执行当前这个goroutine，如果找不到则把当前goroutine放入全局运行队列，由其它工作线程负责把它调度起来运行，自己则调用stopm函数进入睡眠状态。execute和stopm函数我们已经分析过，所以这里就不再重复。
至此，我们已经分析完工作线程从系统调用返回需要做到，
小结
从上一节和本小节的分析我们可以看出，因运行时间过长与因系统调用时间过长而导致的抢占是有差别的：
对于运行时间过长的goroutine，系统监控线程首先会提出抢占请求，然后工作线程在适当的时候会去响应这个请求并暂停被抢占goroutine的运行，最后工作线程再调用schedule函数继续去调度其它goroutine；
而对于系统调用执行时间过长的goroutine，调度器并没有暂停其执行，只是剥夺了正在执行系统调用的工作线程所绑定的p，要等到工作线程从系统调用返回之后绑定p失败的情况下该goroutine才会真正被暂停运行。
思考
最后，我们用一个思考题来结束本专题，读者朋友可以思考一下当GOMAXPROCS等于1时，下面这个程序会输出什么？
package main  import (  &amp;#34;fmt&amp;#34;  &amp;#34;runtime&amp;#34; )  func g2() {  sum := 0  for {  sum&#43;&#43;  } }  func main() {  go g2()   for {  runtime.Gosched()  fmt.Println(&amp;#34;main is scheduled!&amp;#34;)  } } 最后，如果你觉得本文对你有帮助的话，麻烦帮忙点一下文末右下角的 在看 或转发到朋友圈，非常感谢！ ​​​​
</content>
    </entry>
    
     <entry>
        <title>因goroutine运行时间过长而发生的抢占调度（21）</title>
        <url>http://shanks.link/blog/2021/04/03/%E5%9B%A0goroutine%E8%BF%90%E8%A1%8C%E6%97%B6%E9%97%B4%E8%BF%87%E9%95%BF%E8%80%8C%E5%8F%91%E7%94%9F%E7%9A%84%E6%8A%A2%E5%8D%A0%E8%B0%83%E5%BA%A621/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 爱写程序的阿波张 源码游记 2019-05-28
本文是《Go语言调度器源代码情景分析》系列的第21篇，也是第六章《抢占调度》的第1小节。
前面几节我们分析了Goroutine因读写channel等阻塞而导致的被动调度以及通过调用Gosched函数发起的主动调度，现在还剩下最后一种调度方式即抢占调度未讨论，从本节开始，我们就来对它进行分析。
本小节我们需要重点关注：
什么情况下会发生抢占调度；
因运行时间过长而发生的抢占调度有什么特点。
retake函数
在分析调度器初始化的时候我们说过，sysmon系统监控线程会定期（10毫秒）通过retake函数对goroutine发起抢占，下面我们直接从retake函数开始。
runtime/proc.go : 4376  // forcePreemptNS is the time slice given to a G before it is // preempted. const forcePreemptNS = 10 * 1000 * 1000 // 10ms  func retake(now int64) uint32 {  n := 0  // Prevent allp slice changes. This lock will be completely  // uncontended unless we&amp;#39;re already stopping the world.  lock(&amp;amp;allpLock)  // We can&amp;#39;t use a range loop over allp because we may  // temporarily drop the allpLock. Hence, we need to re-fetch  // allp each time around the loop.  for i := 0; i &amp;lt; len(allp); i&#43;&#43; { //遍历所有的P  _p_ := allp[i]  if _p_ == nil {  // This can happen if procresize has grown  // allp but not yet created new Ps.  continue  }   //_p_.sysmontick用于sysmon线程记录被监控p的系统调用时间和运行时间  pd := &amp;amp;_p_.sysmontick  s := _p_.status  if s == _Psyscall { //P处于系统调用之中，需要检查是否需要抢占  // Retake P from syscall if it&amp;#39;s there for more than 1 sysmon tick (at least 20us).  t := int64(_p_.syscalltick)  if int64(pd.syscalltick) != t {  pd.syscalltick = uint32(t)  pd.syscallwhen = now  continue  }  // On the one hand we don&amp;#39;t want to retake Ps if there is no other work to do,  // but on the other hand we want to retake them eventually  // because they can prevent the sysmon thread from deep sleep.  if runqempty(_p_) &amp;amp;&amp;amp; atomic.Load(&amp;amp;sched.nmspinning)&#43;atomic.Load(&amp;amp;sched.npidle)&amp;gt; 0 &amp;amp;&amp;amp; pd.syscallwhen&#43;10*1000*1000 &amp;gt; now {  continue  }  // Drop allpLock so we can take sched.lock.  unlock(&amp;amp;allpLock)  // Need to decrement number of idle locked M&amp;#39;s  // (pretending that one more is running) before the CAS.  // Otherwise the M from which we retake can exit the syscall,  // increment nmidle and report deadlock.  incidlelocked(-1)  if atomic.Cas(&amp;amp;_p_.status, s, _Pidle) {  if trace.enabled {  traceGoSysBlock(_p_)  traceProcStop(_p_)  }  n&#43;&#43;  _p_.syscalltick&#43;&#43;  handoffp(_p_)  }  incidlelocked(1)  lock(&amp;amp;allpLock)  } else if s == _Prunning { //P处于运行状态，需要检查其是否运行得太久了  // Preempt G if it&amp;#39;s running for too long.  //_p_.schedtick：每发生一次调度，调度器&#43;&#43;该值  t := int64(_p_.schedtick)  if int64(pd.schedtick) != t {  //监控线程监控到一次新的调度，所以重置跟sysmon相关的schedtick和schedwhen变量  pd.schedtick = uint32(t)  pd.schedwhen = now  continue  }   //pd.schedtick == t说明(pd.schedwhen ～ now)这段时间未发生过调度，  //所以这段时间是同一个goroutine一直在运行，下面检查一直运行是否超过了10毫秒  if pd.schedwhen&#43;forcePreemptNS &amp;gt; now {  //从某goroutine第一次被sysmon线程监控到正在运行一直运行到现在还未超过10毫秒  continue  }  //连续运行超过10毫秒了，设置抢占请求  preemptone(_p_)  }  }  unlock(&amp;amp;allpLock)  return uint32(n) } 从代码可以看出，retake函数会根据p的两种不同状态检查是否需要抢占：
_Prunning，表示对应的goroutine正在运行，如果其运行时间超过了10毫秒则对需要抢占；
_Psyscall，表示对应的goroutine正在内核执行系统调用，此时需要根据多个条件来判断是否需要抢占。这些判断我们会在后面进行详细描述。
我们首先来分析由于goroutine运行时间过长而导致的抢占，然后分析goroutine进入系统调用之后发生的抢占。
监控线程提出抢占请求
sysmon线程如果监控到某个goroutine连续运行超过了10毫秒（具体是如何监控到的可以看上面代码中笔者的注释），则会调用preemptone函数向该goroutine发出抢占请求。
runtime/proc.go : 4465  // Tell the goroutine running on processor P to stop. // This function is purely best-effort. It can incorrectly fail to inform the // goroutine. It can send inform the wrong goroutine. Even if it informs the // correct goroutine, that goroutine might ignore the request if it is // simultaneously executing newstack. // No lock needs to be held. // Returns true if preemption request was issued. // The actual preemption will happen at some point in the future // and will be indicated by the gp-&amp;gt;status no longer being // Grunning func preemptone(_p_ *p) bool {  mp := _p_.m.ptr()  if mp == nil || mp == getg().m {  return false  }  //gp是被抢占的goroutine  gp := mp.curg  if gp == nil || gp == mp.g0 {  return false  }   gp.preempt = true //设置抢占标志   // Every call in a go routine checks for stack overflow by  // comparing the current stack pointer to gp-&amp;gt;stackguard0.  // Setting gp-&amp;gt;stackguard0 to StackPreempt folds  // preemption into the normal stack overflow check.  //stackPreempt是一个常量0xfffffffffffffade，是非常大的一个数  gp.stackguard0 = stackPreempt //设置stackguard0使被抢占的goroutine去处理抢占请求  return true } 可以看出，preemptone函数只是简单的设置了被抢占goroutine对应的g结构体中的 preempt成员为true和stackguard0成员为stackPreempt（stackPreempt是一个常量0xfffffffffffffade，是非常大的一个数）就返回了，并未真正强制被抢占的goroutine暂停下来。
既然设置了一些抢占标志，那么就一定需要对这些标志进行处理，下面我们就来分析被抢占的goroutine如何处理这些标志去响应监控线程提出的抢占请求。
响应抢占请求
因为我们并不知道什么地方会对抢占标志进行处理，所以我们首先使用文本搜索工具在源代码中查找&amp;quot;stackPreempt&amp;quot;、&amp;ldquo;stackguard0&amp;quot;以及&amp;quot;preempt&amp;quot;这3个字符串，可以找到处理抢占请求的函数为newstack()，在该函数中如果发现自己被抢占，则会暂停当前goroutine的执行。然后再查找哪些函数会调用newstack函数，顺藤摸瓜便可以找到相关的函数调用链为
morestack_noctxt()-&amp;gt;morestack()-&amp;gt;newstack() 从源代码中morestack函数的注释可以知道，该函数会被编译器自动插入到函数序言(prologue)中。我们以下面这个程序为例来做进一步的说明。
package main  import &amp;#34;fmt&amp;#34;  func sum(a, b int) int {  a2 := a * a  b2 := b * b  c := a2 &#43; b2   fmt.Println(c)   return c }  func main() {  sum(1, 2) } 为了看清楚编译器会把对morestack函数的调用插入到什么地方，我们用gdb来反汇编一下main函数：
=&amp;gt; 0x0000000000486a80 &amp;lt;&#43;0&amp;gt;: mov %fs:0xfffffffffffffff8,%rcx  0x0000000000486a89 &amp;lt;&#43;9&amp;gt;: cmp 0x10(%rcx),%rsp  0x0000000000486a8d &amp;lt;&#43;13&amp;gt;: jbe 0x486abd &amp;lt;main.main&#43;61&amp;gt;  0x0000000000486a8f &amp;lt;&#43;15&amp;gt;: sub $0x20,%rsp  0x0000000000486a93 &amp;lt;&#43;19&amp;gt;: mov %rbp,0x18(%rsp)  0x0000000000486a98 &amp;lt;&#43;24&amp;gt;: lea 0x18(%rsp),%rbp  0x0000000000486a9d &amp;lt;&#43;29&amp;gt;: movq $0x1,(%rsp)  0x0000000000486aa5 &amp;lt;&#43;37&amp;gt;: movq $0x2,0x8(%rsp)  0x0000000000486aae &amp;lt;&#43;46&amp;gt;: callq 0x4869c0 &amp;lt;main.sum&amp;gt;  0x0000000000486ab3 &amp;lt;&#43;51&amp;gt;: mov 0x18(%rsp),%rbp  0x0000000000486ab8 &amp;lt;&#43;56&amp;gt;: add $0x20,%rsp  0x0000000000486abc &amp;lt;&#43;60&amp;gt;: retq  0x0000000000486abd &amp;lt;&#43;61&amp;gt;: callq 0x44ece0 &amp;lt;runtime.morestack_noctxt&amp;gt;  0x0000000000486ac2 &amp;lt;&#43;66&amp;gt;: jmp 0x486a80 &amp;lt;main.main&amp;gt; 在main函数的尾部我们看到了对runtime.morestack_noctxt函数的调用，往前我们可以看到，对runtime.morestack_noctxt的调用是通过main函数的第三条jbe指令跳转过来的。
0x0000000000486a8d &amp;lt;&#43;13&amp;gt;: jbe 0x486abd &amp;lt;main.main&#43;61&amp;gt; &amp;hellip;&amp;hellip; 0x0000000000486abd &amp;lt;&#43;61&amp;gt;: callq 0x44ece0 &amp;lt;runtime.morestack_noctxt&amp;gt; jbe是条件跳转指令，它依靠上一条指令的执行结果来判断是否需要跳转。这里的上一条指令是main函数的第二条指令，为了看清楚这里到底在干什么，我们把main函数的前三条指令都列出来：
0x0000000000486a80 &amp;lt;&#43;0&amp;gt;: mov %fs:0xfffffffffffffff8,%rcx #main函数第一条指令，rcx = g 0x0000000000486a89 &amp;lt;&#43;9&amp;gt;: cmp 0x10(%rcx),%rsp 0x0000000000486a8d &amp;lt;&#43;13&amp;gt;: jbe 0x486abd &amp;lt;main.main&#43;61&amp;gt; 第二章我们已经介绍过，go语言使用fs寄存器实现系统线程的本地存储（TLS），main函数的第一条指令就是从TLS中读取当前正在运行的g的指针并放入rcx寄存器，第二条指令的源操作数是间接寻址，从内存中读取相对于g偏移16这个地址中的内容到rsp寄存器，我们来看看g偏移16的地址是放的什么东西，首先再来回顾一下g结构体的定义：
type g struct {  stack stack  stackguard0 uintptr  stackguard1 uintptr  ...... }  type stack struct {  lo uintptr //8 bytes  hi uintptr //8 bytes } 可以看到结构体g的第一个成员stack占16个字节（lo和hi各占8字节），所以g结构体变量的起始位置加偏移16就应该对应到stackguard0字段。因此main函数的第二条指令相当于在比较栈顶寄存器rsp的值是否比stackguard0的值小，如果rsp的值更小，说明当前g的栈要用完了，有溢出风险，需要扩栈，假设main goroutine被设置了抢占标志，那么rsp的值就会远远小于stackguard0，因为从上一节的分析我们知道sysmon监控线程在设置抢占标志时把需要被抢占的goroutine的stackguard0成员设置成了0xfffffffffffffade，而对于goroutine来说其rsp栈顶不可能这么大。因此stackguard0一旦被设置为抢占标记，代码将会跳转到 0x0000000000486abd 处执行call指令调用morestack_noctxt函数，该call指令会把紧跟call后面的一条指令的地址 0x0000000000486ac2 先压入堆栈，然后再跳转到morestack_noctxt函数去执行。下图展示了这一条call指令执行后g，rsp寄存器与main函数栈之间的关系：
morestack_noctxt函数使用JMP指令直接跳转到morestack继续执行，注意这里没有使用CALL指令调用morestack函数，所以rsp栈顶寄存器并没有发生发生变化，与上图一样还是指向存放返回地址的内存处。
morestack函数执行的流程类似于前面我们分析过的mcall函数，首先保存调用morestack函数的goroutine（我们这个场景是main goroutine）的调度信息到对应的g结构的sched成员之中，然后切换到当前工作线程的g0栈继续执行newstack函数。morestack代码如下，跟mcall一样都是使用go汇编语言编写的，这些代码跟mcall和gogo的代码非常类似，所以这里就不再对其进行详细分析了，读者可以自行参考下面的注释理解morestack函数的实现机制。
runtime/asm_amd64.s : 433  // morestack but not preserving ctxt. TEXT runtime·morestack_noctxt(SB),NOSPLIT,$0  MOVL $0, DX  JMP runtime·morestack(SB)   // Called during function prolog when more stack is needed. // // The traceback routines see morestack on a g0 as being // the top of a stack (for example, morestack calling newstack // calling the scheduler calling newm calling gc), so we must // record an argument size. For that purpose, it has no arguments. TEXT runtime·morestack(SB),NOSPLIT,$0-0  ......  get_tls(CX)  MOVQ g(CX), SI # SI = g(main goroutine对应的g结构体变量)  ......  #SP栈顶寄存器现在指向的是morestack_noctxt函数的返回地址，  #所以下面这一条指令执行完成后AX = 0x0000000000486ac2  MOVQ 0(SP), AX   #下面两条指令给g.sched.PC和g.sched.g赋值，我们这个例子g.sched.PC被赋值为0x0000000000486ac2，  #也就是执行完morestack_noctxt函数之后应该返回去继续执行指令的地址。  MOVQ AX, (g_sched&#43;gobuf_pc)(SI) #g.sched.pc = 0x0000000000486ac2  MOVQ SI, (g_sched&#43;gobuf_g)(SI) #g.sched.g = g   LEAQ 8(SP), AX #main函数在调用morestack_noctxt之前的rsp寄存器   #下面三条指令给g.sched.sp，g.sched.bp和g.sched.ctxt赋值  MOVQ AX, (g_sched&#43;gobuf_sp)(SI)  MOVQ BP, (g_sched&#43;gobuf_bp)(SI)  MOVQ DX, (g_sched&#43;gobuf_ctxt)(SI)  #上面几条指令把g的现场保存了起来，下面开始切换到g0运行   #切换到g0栈，并设置tls的g为g0  #Call newstack on m-&amp;gt;g0&amp;#39;s stack.  MOVQ m_g0(BX), BX  MOVQ BX, g(CX) #设置TLS中的g为g0  #把g0栈的栈顶寄存器的值恢复到CPU的寄存器，达到切换栈的目的，下面这一条指令执行之前，  #CPU还是使用的调用此函数的g的栈，执行之后CPU就开始使用g0的栈了  MOVQ (g_sched&#43;gobuf_sp)(BX), SP  CALL runtime·newstack(SB)  CALL runtime·abort(SB)// crash if newstack returns  RET 在切换到g0运行之前，当前goroutine的现场信息被保存到了对应的g结构体变量的sched成员之中（见下图）。这样我们这个场景中的main goroutine下次被调度起来运行时，调度器就可以把g.sched.sp恢复到CPU的rsp寄存器完成栈的切换，然后把g.sched.PC恢复到rip寄存器，于是CPU继续执行callq后面的
0x0000000000486ac2 &amp;lt;&#43;66&amp;gt;: jmp 0x486a80 &amp;lt;main.main&amp;gt; 这条指令，就好像是从morestack_noctxt函数返回的一样，虽然实际上并不是从morestack_noctxt函数返回的，但效果一样。
接下来我们继续看newstack函数，该函数主要有两个职责，一个是扩栈，另一个是响应sysmon提出的抢占请求，扩栈部分我们不关注，所以这里只看抢占相关的代码。
runtime/stack.go : 899  // Called from runtime·morestack when more stack is needed. // Allocate larger stack and relocate to new stack. // Stack growth is multiplicative, for constant amortized cost. // // g-&amp;gt;atomicstatus will be Grunning or Gscanrunning upon entry. // If the GC is trying to stop this g then it will set preemptscan to true. // // This must be nowritebarrierrec because it can be called as part of // stack growth from other nowritebarrierrec functions, but the // compiler doesn&amp;#39;t check this. // //go:nowritebarrierrec func newstack() {  thisg := getg() // thisg = g0  ......  // 这行代码获取g0.m.curg，也就是需要扩栈或响应抢占的goroutine  // 对于我们这个例子gp = main goroutine  gp := thisg.m.curg  ......  // NOTE: stackguard0 may change underfoot, if another thread  // is about to try to preempt gp. Read it just once and use that same  // value now and below.  //检查g.stackguard0是否被设置为stackPreempt  preempt := atomic.Loaduintptr(&amp;amp;gp.stackguard0) == stackPreempt   // Be conservative about where we preempt.  // We are interested in preempting user Go code, not runtime code.  // If we&amp;#39;re holding locks, mallocing, or preemption is disabled, don&amp;#39;t  // preempt.  // This check is very early in newstack so that even the status change  // from Grunning to Gwaiting and back doesn&amp;#39;t happen in this case.  // That status change by itself can be viewed as a small preemption,  // because the GC might change Gwaiting to Gscanwaiting, and then  // this goroutine has to wait for the GC to finish before continuing.  // If the GC is in some way dependent on this goroutine (for example,  // it needs a lock held by the goroutine), that small preemption turns  // into a real deadlock.  if preempt {  //检查被抢占goroutine的状态  if thisg.m.locks != 0 || thisg.m.mallocing != 0 || thisg.m.preemptoff != &amp;#34;&amp;#34; || thisg.m.p.ptr().status != _Prunning {  // Let the goroutine keep running for now.  // gp-&amp;gt;preempt is set, so it will be preempted next time.  //还原stackguard0为正常值，表示我们已经处理过抢占请求了  gp.stackguard0 = gp.stack.lo &#43; _StackGuard   //不抢占，调用gogo继续运行当前这个g，不需要调用schedule函数去挑选另一个goroutine  gogo(&amp;amp;gp.sched) // never return  }  }   //省略的代码做了些其它检查所以这里才有两个同样的判断   if preempt {  if gp == thisg.m.g0 {  throw(&amp;#34;runtime: preempt g0&amp;#34;)  }  if thisg.m.p == 0 &amp;amp;&amp;amp; thisg.m.locks == 0 {  throw(&amp;#34;runtime: g is running but p is not&amp;#34;)  }  ......  //下面开始响应抢占请求  // Act like goroutine called runtime.Gosched.  //设置gp的状态，省略的代码在处理gc时把gp的状态修改成了_Gwaiting  casgstatus(gp, _Gwaiting, _Grunning)   //调用gopreempt_m把gp切换出去  gopreempt_m(gp) // never return  }  ...... } newstack函数首先检查g.stackguard0是否被设置为stackPreempt，如果是则表示sysmon已经发现我们运行得太久了并对我们发起了抢占请求。在做了一些基本的检查后如果当前goroutine可以被抢占则调用gopreempt_m函数完成调度。
runtime/proc.go : 2644  func gopreempt_m(gp *g) {  if trace.enabled {  traceGoPreempt()  }  goschedImpl(gp) } gopreempt_m通过调用goschedImpl函数完成实际的调度切换工作，我们在前面主动调度一节已经详细分析过goschedImpl函数，该函数首先把gp的状态从_Grunning设置成_Grunnable，并通过dropg函数解除当前工作线程m和gp之间的关系，然后把gp放入全局队列等待被调度器调度，最后调用schedule()函数进入新一轮调度。
小结
上面我们分析了由于运行时间过长导致的抢占调度，可以看到go的抢占调度机制并非无条件的抢占。需要抢占时，监控线程负责给被抢占的goroutine设置抢占标记，被抢占的goroutine再在函数的的入口处检查g的stackguard0成员决定是否需要调用morestack_noctxt函数，从而最终调用到newstack函数处理抢占请求。
下一节我们再来看因系统调用而发生的抢占调度。
最后，如果你觉得本文对你有帮助的话，麻烦帮忙点一下文末右下角的 在看 或转发到朋友圈，非常感谢！
</content>
    </entry>
    
     <entry>
        <title>go语言调度器之主动调度(20)</title>
        <url>http://shanks.link/blog/2021/04/03/go%E8%AF%AD%E8%A8%80%E8%B0%83%E5%BA%A6%E5%99%A8%E4%B9%8B%E4%B8%BB%E5%8A%A8%E8%B0%83%E5%BA%A620/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 爱写程序的阿波张 源码游记 2019-05-24
本文是《Go语言调度器源代码情景分析》系列的第20篇，也是第五章《主动调度》的第1小节。
Goroutine的主动调度是指当前正在运行的goroutine通过直接调用runtime.Gosched()函数暂时放弃运行而发生的调度。
主动调度完全是用户代码自己控制的，我们根据代码就可以预见什么地方一定会发生调度。比如下面的程序，在main goroutine中创建了一个新的我们称之为g2的goroutine去执行start函数，g2在start函数的循环中反复调用Gosched()函数放弃自己的执行权，主动把CPU让给调度器去执行调度。
package main  import (  &amp;#34;runtime&amp;#34;  &amp;#34;sync&amp;#34; )  const N = 1  func main() {  var wg sync.WaitGroup   wg.Add(N)  for i := 0; i &amp;lt; N; i&#43;&#43; {  go start(&amp;amp;wg)  }  wg.Wait() } func start(wg *sync.WaitGroup) {  for i := 0; i &amp;lt; 1000 * 1000 * 1000; i&#43;&#43; {  runtime.Gosched()  }  wg.Done() } 下面我们就从这个程序开始分析主动调度是如何实现的。
首先从主动调度的入口函数Gosched()开始分析。
runtime/proc.go : 262  // Gosched yields the processor, allowing other goroutines to run. It does not // suspend the current goroutine, so execution resumes automatically. func Gosched() {  checkTimeouts() //amd64 linux平台空函数   //切换到当前m的g0栈执行gosched_m函数  mcall(gosched_m)  //再次被调度起来则从这里开始继续运行 } 因为我们需要关注程序运行起来之后g2 goroutine的状态，所以这里用gdb配合源代码一起来进行调试和分析，首先使用b proc.go:266在Gosched函数的mcall(gosched_m)这一行设置一个断点，然后运行程序，等程序被断下来之后，反汇编一下程序当前正在执行的函数
(gdb) disass Dump of assembler code for function main.start:  0x000000000044fc90 &amp;lt;&#43;0&amp;gt;:mov %fs:0xfffffffffffffff8,%rcx  0x000000000044fc99 &amp;lt;&#43;9&amp;gt;:cmp 0x10(%rcx),%rsp  0x000000000044fc9d &amp;lt;&#43;13&amp;gt;:jbe 0x44fcfa &amp;lt;main.start&#43;106&amp;gt;  0x000000000044fc9f &amp;lt;&#43;15&amp;gt;:sub $0x20,%rsp  0x000000000044fca3 &amp;lt;&#43;19&amp;gt;:mov %rbp,0x18(%rsp)  0x000000000044fca8 &amp;lt;&#43;24&amp;gt;:lea 0x18(%rsp),%rbp  0x000000000044fcad &amp;lt;&#43;29&amp;gt;:xor %eax,%eax  0x000000000044fcaf &amp;lt;&#43;31&amp;gt;:jmp 0x44fcd0 &amp;lt;main.start&#43;64&amp;gt;  0x000000000044fcb1 &amp;lt;&#43;33&amp;gt;:mov %rax,0x10(%rsp)  0x000000000044fcb6 &amp;lt;&#43;38&amp;gt;:nop  0x000000000044fcb7 &amp;lt;&#43;39&amp;gt;:nop =&amp;gt; 0x000000000044fcb8 &amp;lt;&#43;40&amp;gt;:lea 0x241e1(%rip),%rax # 0x473ea0  0x000000000044fcbf &amp;lt;&#43;47&amp;gt;:mov %rax,(%rsp)  0x000000000044fcc3 &amp;lt;&#43;51&amp;gt;:callq 0x447380 &amp;lt;runtime.mcall&amp;gt;  0x000000000044fcc8 &amp;lt;&#43;56&amp;gt;:mov 0x10(%rsp),%rax  0x000000000044fccd &amp;lt;&#43;61&amp;gt;:inc %rax  0x000000000044fcd0 &amp;lt;&#43;64&amp;gt;:cmp $0x3b9aca00,%rax  0x000000000044fcd6 &amp;lt;&#43;70&amp;gt;:jl 0x44fcb1 &amp;lt;main.start&#43;33&amp;gt;  0x000000000044fcd8 &amp;lt;&#43;72&amp;gt;:nop  0x000000000044fcd9 &amp;lt;&#43;73&amp;gt;:mov 0x28(%rsp),%rax  0x000000000044fcde &amp;lt;&#43;78&amp;gt;:mov %rax,(%rsp)  0x000000000044fce2 &amp;lt;&#43;82&amp;gt;:movq $0xffffffffffffffff,0x8(%rsp)  0x000000000044fceb &amp;lt;&#43;91&amp;gt;:callq 0x44f8f0 &amp;lt;sync.(*WaitGroup).Add&amp;gt;  0x000000000044fcf0 &amp;lt;&#43;96&amp;gt;:mov 0x18(%rsp),%rbp  0x000000000044fcf5 &amp;lt;&#43;101&amp;gt;:add $0x20,%rsp  0x000000000044fcf9 &amp;lt;&#43;105&amp;gt;:retq  0x000000000044fcfa &amp;lt;&#43;106&amp;gt;:callq 0x447550 &amp;lt;runtime.morestack_noctxt&amp;gt;  0x000000000044fcff &amp;lt;&#43;111&amp;gt;:jmp 0x44fc90 &amp;lt;main.start&amp;gt; 可以看到当前正在执行的函数是main.start而不是runtime.Gosched，在整个start函数中都找不到Gosched函数的身影，原来它被编译器优化了。程序现在停在了0x000000000044fcb8 &amp;lt;&#43;40&amp;gt;: lea 0x241e1(%rip),%rax 这一指令处，该指令下面的第二条callq指令在调用runtime.mcall，我们首先使用si 2来执行2条汇编指令让程序停在下面这条指令处：
=&amp;gt; 0x000000000044fcc3 &amp;lt;&#43;51&amp;gt;: callq 0x447380 &amp;lt;runtime.mcall&amp;gt; 然后使用i r rsp rbp rip记录一下CPU的rsp、rbp和rip寄存器的值备用：
(gdb) i r rsp rbp rip rsp 0xc000031fb0 0xc000031fb0 rbp 0xc000031fc8 0xc000031fc8 rip 0x44fcc3 0x44fcc3 &amp;lt;main.start&#43;51&amp;gt; 继续看0x000000000044fcc3位置的callq指令，它首先会把紧挨其后的下一条指令的地址0x000000000044fcc8放入g2的栈，然后跳转到mcall函数的第一条指令开始执行。回忆一下第二章我们详细分析过的mcall函数的执行流程，结合现在这个场景，mcall将依次完成下面几件事：
把上面call指令压栈的返回地址0x000000000044fcc8取出来保存在g2的sched.pc字段，把上面我们查看到的rsp(0xc000031fb0)和rbp(0xc000031fc8)分别保存在g2的sched.sp和sched.bp字段，这几个寄存器代表了g2的调度现场信息；
把保存在g0的sched.sp和sched.bp字段中的值分别恢复到CPU的rsp和rbp寄存器，这样完成从g2的栈到g0的栈的切换；
在g0栈执行gosched_m函数（gosched_m函数是runtime.Gosched函数调用mcall时传递给mcall的参数）。
继续看gosched_m函数
runtime/proc.go : 2623  // Gosched continuation on g0. func gosched_m(gp *g) {  if trace.enabled { //traceback 不关注  traceGoSched()  }  goschedImpl(gp) //我们这个场景：gp = g2 } gosched_m函数只是简单的在调用goschedImpl：
runtime/proc.go : 2608  func goschedImpl(gp *g) {  ......  casgstatus(gp, _Grunning, _Grunnable)  dropg() //设置当前m.curg = nil, gp.m = nil  lock(&amp;amp;sched.lock)  globrunqput(gp) //把gp放入sched的全局运行队列runq  unlock(&amp;amp;sched.lock)   schedule() //进入新一轮调度 } goschedImpl函数有一个g指针类型的形参，我们这个场景传递给它的实参是g2，goschedImpl函数首先把g2的状态从_Grunning设置为_Grunnable，并通过dropg函数解除当前工作线程m和g2之间的关系（把m.curg设置成nil，把g2.m设置成nil），然后通过调用我们已经分析过的globrunqput函数把g2放入全局运行队列之中。
g2被挂入全局运行队列之后，g2以及其它一些相关部分的状态和关系如下图所示：
从上图我们可以清晰的看到，g2被挂在了sched的全局运行队列里面，该队列有一个head头指针指向队列中的第一个g对象，还有一个tail尾指针指向队列中的最后一个g对象，队列中各个g对象通过g的schedlink指针成员相互链接起在一起；g2的sched结构体成员中保存了调度所需的所有现场信息（比如栈寄存器sp和bp的值，pc指令寄存器的值等等），这样当g2下次被schedule函数调度时，gogo函数会负责把这些信息恢复到CPU的rsp, rbp和rip寄存器中，从而使g2又得以从0x44fcc8地址处开始在g2的栈中执行g2的代码。
把g2挂入全局运行队列之后，goschedImpl函数继续调用schedule()进入下一轮调度循环，至此g2通过自己主动调用Gosched()函数自愿放弃了执行权，达到了调度的目的。
最后，如果你觉得本文对你有帮助的话，麻烦帮忙点一下文末右下角的 在看 或转发到朋友圈，非常感谢！
</content>
    </entry>
    
     <entry>
        <title>工作线程的唤醒及创建(19)</title>
        <url>http://shanks.link/blog/2021/04/03/%E5%B7%A5%E4%BD%9C%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%94%A4%E9%86%92%E5%8F%8A%E5%88%9B%E5%BB%BA19/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 爱写程序的阿波张 源码游记 2019-05-23
本文是《Go语言调度器源代码情景分析》系列的第19篇，也是第四章《Goroutine被动调度》的第2小节。
本文需要重点关注：
如何唤醒睡眠中的工作线程
如何创建新的工作线程
上一篇文章我们分析到了ready函数通过把需要唤醒的goroutine放入运行队列来唤醒它，本文接着上文继续分析。
唤醒空闲的P
为了充分利用CPU，ready函数在唤醒goroutine之后会去判断是否需要启动新工作线程出来工作，判断规则是，如果当前有空闲的p而且没有工作线程正在尝试从各个工作线程的本地运行队列偷取goroutine的话（没有处于spinning状态的工作线程），那么就需要把空闲的p唤醒起来工作，详见下面的ready函数：
runtime/proc.go : 639  // Mark gp ready to run. func ready(gp *g, traceskip int, next bool) {  ......  // Mark runnable.  _g_ := getg()  ......  // status is Gwaiting or Gscanwaiting, make Grunnable and put on runq  casgstatus(gp, _Gwaiting, _Grunnable)  runqput(_g_.m.p.ptr(), gp, next) //放入运行队列  if atomic.Load(&amp;amp;sched.npidle) != 0 &amp;amp;&amp;amp; atomic.Load(&amp;amp;sched.nmspinning) == 0 {  //有空闲的p而且没有正在偷取goroutine的工作线程，则需要唤醒p出来工作  wakep()  }  ...... } 而唤醒空闲的p是由wakep函数完成的。
runtime/proc.go : 2051  // Tries to add one more P to execute G&amp;#39;s. // Called when a G is made runnable (newproc, ready). func wakep() {  // be conservative about spinning threads  if !atomic.Cas(&amp;amp;sched.nmspinning, 0, 1) {  return  }  startm(nil, true) } wakep首先通过cas操作再次确认是否有其它工作线程正处于spinning状态，这里之所以需要使用cas操作再次进行确认，原因在于，在当前工作线程通过如下条件
atomic.Load(&amp;amp;sched.npidle) != 0 &amp;amp;&amp;amp; atomic.Load(&amp;amp;sched.nmspinning) == 0 判断到需要启动工作线程之后到真正启动工作线程之前的这一段时间之内，如果已经有工作线程进入了spinning状态而在四处寻找需要运行的goroutine，这样的话我们就没有必要再启动一个多余的工作线程出来了。
如果cas操作成功，则继续调用startm创建一个新的或唤醒一个处于睡眠状态的工作线程出来工作。
runtime/proc.go : 1947  // Schedules some M to run the p (creates an M if necessary). // If p==nil, tries to get an idle P, if no idle P&amp;#39;s does nothing. // May run with m.p==nil, so write barriers are not allowed. // If spinning is set, the caller has incremented nmspinning and startm will // either decrement nmspinning or set m.spinning in the newly started M. //go:nowritebarrierrec func startm(_p_ *p, spinning bool) {  lock(&amp;amp;sched.lock)  if _p_ == nil { //没有指定p的话需要从p的空闲队列中获取一个p  _p_ = pidleget() //从p的空闲队列中获取空闲p  if _p_ == nil {  unlock(&amp;amp;sched.lock)  if spinning {  // The caller incremented nmspinning, but there are no idle Ps,  // so it&amp;#39;s okay to just undo the increment and give up.  //spinning为true表示进入这个函数之前已经对sched.nmspinning加了1，需要还原  if int32(atomic.Xadd(&amp;amp;sched.nmspinning, -1)) &amp;lt; 0 {  throw(&amp;#34;startm: negative nmspinning&amp;#34;)  }  }  return //没有空闲的p，直接返回  }  }  mp := mget() //从m空闲队列中获取正处于睡眠之中的工作线程，所有处于睡眠状态的m都在此队列中  unlock(&amp;amp;sched.lock)  if mp == nil {  //没有处于睡眠状态的工作线程  var fn func()  if spinning {  // The caller incremented nmspinning, so set m.spinning in the new M.  fn = mspinning  }  newm(fn, _p_) //创建新的工作线程  return  }  if mp.spinning {  throw(&amp;#34;startm: m is spinning&amp;#34;)  }  if mp.nextp != 0 {  throw(&amp;#34;startm: m has p&amp;#34;)  }  if spinning &amp;amp;&amp;amp; !runqempty(_p_) {  throw(&amp;#34;startm: p has runnable gs&amp;#34;)  }  // The caller incremented nmspinning, so set m.spinning in the new M.  mp.spinning = spinning  mp.nextp.set(_p_)   //唤醒处于休眠状态的工作线程  notewakeup(&amp;amp;mp.park) } startm函数首先判断是否有空闲的p结构体对象，如果没有则直接返回，如果有则需要创建或唤醒一个工作线程出来与之绑定，从这里可以看出所谓的唤醒p，其实就是把空闲的p利用起来。
在确保有可以绑定的p对象之后，startm函数首先尝试从m的空闲队列中查找正处于休眠状态的工作线程，如果找到则通过notewakeup函数唤醒它，否则调用newm函数创建一个新的工作线程出来。
下面我们首先分析notewakeup函数是如何唤醒工作线程的，然后再讨论newm函数创建工作线程的流程。
唤醒睡眠中的工作线程
在第三章我们讨论过，当找不到需要运行的goroutine时，工作线程会通过notesleep函数睡眠在m.park成员上，所以这里使用m.park成员作为参数调用notewakeup把睡眠在该成员之上的工作线程唤醒。
runtime/lock_futex.go : 130  func notewakeup(n *note) {  //设置n.key = 1, 被唤醒的线程通过查看该值是否等于1来确定是被其它线程唤醒还是意外从睡眠中苏醒  old := atomic.Xchg(key32(&amp;amp;n.key), 1)  if old != 0 {  print(&amp;#34;notewakeup - double wakeup (&amp;#34;, old, &amp;#34;)\n&amp;#34;)  throw(&amp;#34;notewakeup - double wakeup&amp;#34;)  }  //调用futexwakeup唤醒  futexwakeup(key32(&amp;amp;n.key), 1) } notewakeup函数首先使用atomic.Xchg设置note.key值为1，这是为了使被唤醒的线程可以通过查看该值是否等于1来确定是被其它线程唤醒还是意外从睡眠中苏醒了过来，如果该值为1则表示是被唤醒的，可以继续工作了，但如果该值为0则表示是意外苏醒，需要再次进入睡眠，工作线程苏醒之后的处理逻辑我们已经在notesleep函数中见过，所以这里略过。
把note.key的值设置为1后，notewakeup函数继续调用futexwakeup函数
runtime/os_linux.go : 66  // If any procs are sleeping on addr, wake up at most cnt. //go:nosplit func futexwakeup(addr *uint32, cnt uint32) {  //调用futex函数唤醒工作线程  ret := futex(unsafe.Pointer(addr), _FUTEX_WAKE_PRIVATE, cnt, nil, nil, 0)  if ret &amp;gt;= 0 {  return  }   // I don&amp;#39;t know that futex wakeup can return  // EAGAIN or EINTR, but if it does, it would be  // safe to loop and call futex again.  systemstack(func() {  print(&amp;#34;futexwakeup addr=&amp;#34;, addr, &amp;#34; returned &amp;#34;, ret, &amp;#34;\n&amp;#34;)  })   *(*int32)(unsafe.Pointer(uintptr(0x1006))) = 0x1006 } 对于Linux平台来说，工作线程通过note睡眠其实是通过futex系统调用睡眠在内核之中，所以唤醒处于睡眠状态的线程也需要通过futex系统调用进入内核来唤醒，所以这里的futexwakeup又继续调用包装了futex系统调用的futex函数来实现唤醒睡眠在内核中的工作线程。
runtime/sys_linux_amd64.s : 525  // int64 futex(int32 *uaddr, int32 op, int32 val, //struct timespec *timeout, int32 *uaddr2, int32 val2); TEXT runtime·futex(SB),NOSPLIT,$0  MOVQ addr&#43;0(FP), DI #这6条指令在为futex系统调用准备参数  MOVL op&#43;8(FP), SI  MOVL val&#43;12(FP), DX  MOVQ ts&#43;16(FP), R10  MOVQ addr2&#43;24(FP), R8  MOVL val3&#43;32(FP), R9  MOVL $SYS_futex, AX #futex系统调用编号放入AX寄存器  SYSCALL #系统调用，进入内核  MOVL AX, ret&#43;40(FP) #系统调用通过AX寄存器返回返回值，这里把返回值保存到内存之中  RET futex函数由汇编代码写成，前面的几条指令都在为futex系统调用准备参数，参数准备完成之后则通过SYSCALL指令进入操作系统内核完成线程的唤醒功能，内核在完成唤醒工作之后当前工作线程则从内核返回到futex函数继续执行SYSCALL指令之后的代码并按函数调用链原路返回，继续执行其它代码，而被唤醒的工作线程则由内核负责在适当的时候调度到CPU上运行。
看完唤醒流程，下面我们来分析工作线程的创建。
创建工作线程
回到startm函数，如果没有正处于休眠状态的工作线程，则需要调用newm函数新建一个工作线程。
runtime/proc.go : 1807  // Create a new m. It will start off with a call to fn, or else the scheduler. // fn needs to be static and not a heap allocated closure. // May run with m.p==nil, so write barriers are not allowed. //go:nowritebarrierrec func newm(fn func(), _p_ *p) {  mp := allocm(_p_, fn)  mp.nextp.set(_p_)  ......  newm1(mp) } newm首先调用allocm函数从堆上分配一个m结构体对象，然后调用newm1函数。
runtime/proc.go : 1843  func newm1(mp *m) {  //省略cgo相关代码.......  execLock.rlock() // Prevent process clone.  newosproc(mp)  execLock.runlock() } newm1继续调用newosproc函数，newosproc的主要任务是调用clone函数创建一个系统线程，而新建的这个系统线程将从mstart函数开始运行。
runtime/os_linux.go : 143  // May run with m.p==nil, so write barriers are not allowed. //go:nowritebarrier func newosproc(mp *m) {  stk := unsafe.Pointer(mp.g0.stack.hi)  ......  ret := clone(cloneFlags, stk, unsafe.Pointer(mp), unsafe.Pointer(mp.g0), unsafe.Pointer(funcPC(mstart)))  ...... } //clone系统调用的Flags选项 cloneFlags = _CLONE_VM | /* share memory */ //指定父子线程共享进程地址空间  _CLONE_FS | /* share cwd, etc */  _CLONE_FILES | /* share fd table */  _CLONE_SIGHAND | /* share sig handler table */  _CLONE_SYSVSEM | /* share SysV semaphore undo lists (see issue #20763) */  _CLONE_THREAD /* revisit - okay for now */ //创建子线程而不是子进程 clone函数是由汇编语言实现的，该函数使用clone系统调用完成创建系统线程的核心功能。我们分段来看  runtime/sys_linux_amd64.s : 539  // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void)); TEXT runtime·clone(SB),NOSPLIT,$0  MOVL flags&#43;0(FP), DI //系统调用的第一个参数  MOVQ stk&#43;8(FP), SI //系统调用的第二个参数  MOVQ $0, DX //第三个参数  MOVQ $0, R10 //第四个参数   // Copy mp, gp, fn off parent stack for use by child.  // Careful: Linux system call clobbers CX and R11.  MOVQ mp&#43;16(FP), R8  MOVQ gp&#43;24(FP), R9  MOVQ fn&#43;32(FP), R12   MOVL $SYS_clone, AX  SYSCALL clone函数首先用了4条指令为clone系统调用准备参数，该系统调用一共需要四个参数，根据Linux系统调用约定，这四个参数需要分别放入rdi， rsi，rdx和r10寄存器中，这里最重要的是第一个参数和第二个参数，分别用来指定内核创建线程时需要的选项和新线程应该使用的栈。因为即将被创建的线程与当前线程共享同一个进程地址空间，所以这里必须为子线程指定其使用的栈，否则父子线程会共享同一个栈从而造成混乱，从上面的newosproc函数可以看出，新线程使用的栈为m.g0.stack.lo～m.g0.stack.hi这段内存，而这段内存是newm函数在创建m结构体对象时从进程的堆上分配而来的。
准备好系统调用的参数之后，还有另外一件很重的事情需要做，那就是把clone函数的其它几个参数（mp, gp和线程入口函数）保存到寄存器中，之所以需要在系统调用之前保存这几个参数，原因在于这几个参数目前还位于父线程的栈之中，而一旦通过系统调用把子线程创建出来之后，子线程将会使用我们在clone系统调用时给它指定的栈，所以这里需要把这几个参数先保存到寄存器，等子线程从系统调用返回后直接在寄存器中获取这几个参数。这里要注意的是虽然这个几个参数值保存在了父线程的寄存器之中，但创建子线程时，操作系统内核会把父线程的所有寄存器帮我们复制一份给子线程，所以当子线程开始运行时就能拿到父线程保存在寄存器中的值，从而拿到这几个参数。这些准备工作完成之后代码调用syscall指令进入内核，由内核帮助我们创建系统线程。
clone系统调用完成后实际上就多了一个操作系统线程，新创建的子线程和当前线程都得从系统调用返回然后继续执行后面的代码，那么从系统调用返回之后我们怎么知道哪个是父线程哪个是子线程，从而来决定它们的执行流程？使用过fork系统调用的读者应该知道，我们需要通过返回值来判断父子线程，系统调用的返回值如果是0则表示这是子线程，不为0则表示这个是父线程。用c代码来描述大概就是这个样子：
if (clone(&amp;hellip;) == 0) { //子线程 子线程代码 } else { //父线程 父线程代码 } 虽然这里只有一次clone调用，但它却返回了2次，一次返回到父线程，一次返回到子线程，然后2个线程各自执行自己的代码流程。
回到clone函数，下面代码的第一条指令就在判断系统调用的返回值，如果是子线程则跳转到后面的代码继续执行，如果是父线程，它创建子线程的任务已经完成，所以这里把返回值保存在栈上之后就直接执行ret指令返回到newosproc函数了。
runtime/sys_linux_amd64.s : 555   // In parent, return.  CMPQ AX, $0 #判断clone系统调用的返回值  JEQ 3(PC) / #跳转到子线程部分  MOVL AX, ret&#43;40(FP) #父线程需要执行的指令  RET #父线程需要执行的指令 而对于子线程来说，还有很多初始化工作要做，下面是子线程需要继续执行的指令。
runtime/sys_linux_amd64.s : 561   # In child, on new stack.  #子线程需要继续执行的指令  MOVQ SI, SP #设置CPU栈顶寄存器指向子线程的栈顶，这条指令看起来是多余的？内核应该已经把SP设置好了   # If g or m are nil, skip Go-related setup.  CMPQ R8, $0 # m，新创建的m结构体对象的地址，由父线程保存在R8寄存器中的值被复制到了子线程  JEQ nog  CMPQ R9, $0 # g，m.g0的地址，由父线程保存在R9寄存器中的值被复制到了子线程  JEQ nog   # Initialize m-&amp;gt;procid to Linux tid  MOVL $SYS_gettid, AX #通过gettid系统调用获取线程ID（tid）  SYSCALL  MOVQ AX, m_procid(R8) #m.procid = tid   #Set FS to point at m-&amp;gt;tls.  #新线程刚刚创建出来，还未设置线程本地存储，即m结构体对象还未与工作线程关联起来，  #下面的指令负责设置新线程的TLS，把m对象和工作线程关联起来  LEAQ m_tls(R8), DI #取m.tls字段的地址  CALL runtime·settls(SB)   #In child, set up new stack  get_tls(CX)  MOVQ R8, g_m(R9) # g.m = m  MOVQ R9, g(CX) # tls.g = &amp;amp;m.g0  CALL runtime·stackcheck(SB)  nog:  # Call fn  CALL R12 #这里调用mstart函数  ...... 这段代码的第一条指令把CPU寄存器的栈顶指针设置为新线程的的栈顶，这条指令看起来是多余的，因为我们在clone系统调用时已经把栈信息告诉操作系统了，操作系统在把新线程调度起来运行时已经帮我们把CPU的rsp寄存器设置好了，这里应该没必要自己去设置。接下来的4条指令判断m和g是否为nil，如果是则直接去执行fn函数，对于我们这个流程来说，因为现在正在创建工作线程，所以m和g（其实是m.g0）都不为空，因而需要继续对m进行初始化。
对新创建出来的工作线程的初始化过程从上面代码片段的第6条指令开始，它首先通过系统调用获取到子线程的线程id，并赋值给m.procid，然后调用settls设置线程本地存储并通过把m.g0的地址放入线程本地存储之中，从而实现了m结构体对象与工作线程之间的关联，settls函数我们已经在第二章详细分析过，所以这里直接跳过。
新工作线程的初始化完成之后，便开始执行mstart函数，我们在第二章也见过该函数，主线程初始化完成之后也是调用的它。回忆一下，mstart函数首先会去设置m.g0的stackguard成员，然后调用mstart1()函数把当前工作线程的g0的调度信息保存在m.g0.sched成员之中，最后通过调用schedule函数进入调度循环。
总结
本章仅以读写channel为例分析了goroutine因操作被阻塞而发生的被动调度，其实发生被动调度的情况还比较多，比如因读写网络连接而阻塞、加锁被阻塞或select操作阻塞等等都会发生被动调度，读者可以自行阅读相关源代码。
本章还分析了睡眠中的工作线程是如何被唤起起来工作的以及新工作线程的创建和初始化流程。
最后，如果你觉得本文对你有帮助的话，麻烦帮忙点一下文末右下角的 在看 或转发到朋友圈，非常感谢！
</content>
    </entry>
    
     <entry>
        <title>goroutine被动调度之一（18）</title>
        <url>http://shanks.link/blog/2021/04/03/goroutine%E8%A2%AB%E5%8A%A8%E8%B0%83%E5%BA%A6%E4%B9%8B%E4%B8%8018/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 爱写程序的阿波张 源码游记 2019-05-22
本文是《Go语言调度器源代码情景分析》系列的第18篇，也是第四章《Goroutine被动调度》的第1小节。
前一章我们详细分析了调度器的调度策略，即调度器如何选取下一个进入运行的goroutine，但我们还不清楚什么时候以及什么情况下会发生调度，从这一章开始我们就来讨论这个问题。
总体说来，go语言的调度器会在以下三种情况下对goroutine进行调度：
goroutine执行某个操作因条件不满足需要等待而发生的调度；
goroutine主动调用Gosched()函数让出CPU而发生的调度；
goroutine运行时间太长或长时间处于系统调用之中而被调度器剥夺运行权而发生的调度。
本章主要分析我们称之为被动调度的第1种调度，剩下的两种调度将在后面两章分别进行讨论。
Demo例子
我们以一个demo程序为例来分析因阻塞而发生的被动调度。
package main  func start(c chan int) {  c &amp;lt;- 100 } func main() {  c := make(chan int)  go start(c)  &amp;lt;-c } 该程序启动时，main goroutine首先会创建一个无缓存的channel，然后启动一个goroutine(为了方便讨论我们称它为g2)向channel发送数据，而main自己则去读取这个channel。
这两个goroutine读写channel时一定会发生一次阻塞，不是main goroutine读取channel时发生阻塞就是g2写入channel时发生阻塞。
创建g2 goroutine
首先用gdb反汇编一下main函数，看看汇编代码。
0x44f4d0 &amp;lt;&#43;0&amp;gt;: mov %fs:0xfffffffffffffff8,%rcx 0x44f4d9 &amp;lt;&#43;9&amp;gt;: cmp 0x10(%rcx),%rsp 0x44f4dd &amp;lt;&#43;13&amp;gt;: jbe 0x44f549 &amp;lt;main.main&#43;121&amp;gt; 0x44f4df &amp;lt;&#43;15&amp;gt;: sub $0x28,%rsp 0x44f4e3 &amp;lt;&#43;19&amp;gt;: mov %rbp,0x20(%rsp) 0x44f4e8 &amp;lt;&#43;24&amp;gt;: lea 0x20(%rsp),%rbp 0x44f4ed &amp;lt;&#43;29&amp;gt;: lea 0xb36c(%rip),%rax 0x44f4f4 &amp;lt;&#43;36&amp;gt;: mov %rax,(%rsp) 0x44f4f8 &amp;lt;&#43;40&amp;gt;: movq $0x0,0x8(%rsp) 0x44f501 &amp;lt;&#43;49&amp;gt;: callq 0x404330 &amp;lt;runtime.makechan&amp;gt; #创建channel 0x44f506 &amp;lt;&#43;54&amp;gt;: mov 0x10(%rsp),%rax 0x44f50b &amp;lt;&#43;59&amp;gt;: mov %rax,0x18(%rsp) 0x44f510 &amp;lt;&#43;64&amp;gt;: movl $0x8,(%rsp) 0x44f517 &amp;lt;&#43;71&amp;gt;: lea 0x240f2(%rip),%rcx 0x44f51e &amp;lt;&#43;78&amp;gt;: mov %rcx,0x8(%rsp) 0x44f523 &amp;lt;&#43;83&amp;gt;: callq 0x42c1b0 &amp;lt;runtime.newproc&amp;gt; #创建goroutine 0x44f528 &amp;lt;&#43;88&amp;gt;: mov 0x18(%rsp),%rax 0x44f52d &amp;lt;&#43;93&amp;gt;: mov %rax,(%rsp) 0x44f531 &amp;lt;&#43;97&amp;gt;: movq $0x0,0x8(%rsp) 0x44f53a &amp;lt;&#43;106&amp;gt;: callq 0x405080 &amp;lt;runtime.chanrecv1&amp;gt; #从channel读取数据 0x44f53f &amp;lt;&#43;111&amp;gt;: mov 0x20(%rsp),%rbp 0x44f544 &amp;lt;&#43;116&amp;gt;: add $0x28,%rsp 0x44f548 &amp;lt;&#43;120&amp;gt;: retq 0x44f549 &amp;lt;&#43;121&amp;gt;: callq 0x447390 &amp;lt;runtime.morestack_noctxt&amp;gt; 0x44f54e &amp;lt;&#43;126&amp;gt;: jmp 0x44f4d0 &amp;lt;main.main&amp;gt; 从main函数的汇编代码我们可以看到，创建goroutine的go关键字被编译器翻译成了对runtime.newproc函数的调用，第二章我们对这个函数的主要流程做过详细分析，这里简单的回顾一下：
切换到g0栈；
分配g结构体对象；
初始化g对应的栈信息，并把参数拷贝到新g的栈上；
设置好g的sched成员，该成员包括调度g时所必须pc, sp, bp等调度信息；
调用runqput函数把g放入运行队列；
返回
因为当时我们的主要目标是调度器的初始化部分，所以并没有详细分析上述流程中的第5步，也就是runqput是如何把goroutine放入运行队列的，现在就回头分析一下这个过程，下面我们直接从runqput函数开始。
通过runqput函数把goroutine挂入运行队列
runtime/proc.go : 4746  // runqput tries to put g on the local runnable queue. // If next is false, runqput adds g to the tail of the runnable queue. // If next is true, runqput puts g in the _p_.runnext slot. // If the run queue is full, runnext puts g on the global queue. // Executed only by the owner P. func runqput(_p_ *p, gp *g, next bool) {  if randomizeScheduler &amp;amp;&amp;amp; next &amp;amp;&amp;amp; fastrand() % 2 == 0 {  next = false  }   if next {  //把gp放在_p_.runnext成员里，  //runnext成员中的goroutine会被优先调度起来运行  retryNext:  oldnext := _p_.runnext  if !_p_.runnext.cas(oldnext, guintptr(unsafe.Pointer(gp))) {  //有其它线程在操作runnext成员，需要重试  goto retryNext  }  if oldnext == 0 { //原本runnext为nil，所以没任何事情可做了，直接返回  return  }  // Kick the old runnext out to the regular run queue.  gp = oldnext.ptr() //原本存放在runnext的gp需要放入runq的尾部  }  retry:  //可能有其它线程正在并发修改runqhead成员，所以需要跟其它线程同步  h := atomic.LoadAcq(&amp;amp;_p_.runqhead) // load-acquire, synchronize with consumers  t := _p_.runqtail  if t - h &amp;lt; uint32(len(_p_.runq)) { //判断队列是否满了  //队列还没有满，可以放入  _p_.runq[t % uint32(len(_p_.runq))].set(gp)   // store-release, makes it available for consumption  //虽然没有其它线程并发修改这个runqtail，但其它线程会并发读取该值以及p的runq成员  //这里使用StoreRel是为了：  //1，原子写入runqtail  //2，防止编译器和CPU乱序，保证上一行代码对runq的修改发生在修改runqtail之前  //3，可见行屏障，保证当前线程对运行队列的修改对其它线程立马可见  atomic.StoreRel(&amp;amp;_p_.runqtail, t &#43; 1)  return  }  //p的本地运行队列已满，需要放入全局运行队列  if runqputslow(_p_, gp, h, t) {  return  }  // the queue is not full, now the put above must succeed  goto retry } runqput函数流程很清晰，它首先尝试把gp放入_p_的本地运行队列，如果本地队列满了，则通过runqputslow函数把gp放入全局运行队列。
runtime/proc.go : 4784  // Put g and a batch of work from local runnable queue on global queue. // Executed only by the owner P. func runqputslow(_p_ *p, gp *g, h, t uint32) bool {  var batch [len(_p_.runq) / 2 &#43; 1]*g //gp加上_p_本地队列的一半   // First, grab a batch from local queue.  n := t - h  n = n / 2  if n != uint32(len(_p_.runq) / 2) {  throw(&amp;#34;runqputslow: queue is not full&amp;#34;)  }  for i := uint32(0); i &amp;lt; n; i&#43;&#43; { //取出p本地队列的一半  batch[i] = _p_.runq[(h&#43;i) % uint32(len(_p_.runq))].ptr()  }  if !atomic.CasRel(&amp;amp;_p_.runqhead, h, h &#43; n) { // cas-release, commits consume  //如果cas操作失败，说明已经有其它工作线程从_p_的本地运行队列偷走了一些goroutine，所以直接返回  return false  }  batch[n] = gp  if randomizeScheduler {  for i := uint32(1); i &amp;lt;= n; i&#43;&#43; {  j := fastrandn(i &#43; 1)  batch[i], batch[j] = batch[j], batch[i]  }  }  // Link the goroutines.  //全局运行队列是一个链表，这里首先把所有需要放入全局运行队列的g链接起来，  //减少后面对全局链表的锁住时间，从而降低锁冲突  for i := uint32(0); i &amp;lt; n; i&#43;&#43; {  batch[i].schedlink.set(batch[i&#43;1])  }  var q gQueue  q.head.set(batch[0])  q.tail.set(batch[n])  // Now put the batch on global queue.  lock(&amp;amp;sched.lock)  globrunqputbatch(&amp;amp;q, int32(n&#43;1))  unlock(&amp;amp;sched.lock)  return true } runqputslow函数首先使用链表把从_p_的本地队列中取出的一半连同gp一起串联起来，然后在加锁成功之后通过globrunqputbatch函数把该链表链入全局运行队列（全局运行队列是使用链表实现的）。值的一提的是runqputslow函数并没有一开始就把全局运行队列锁住，而是等所有的准备工作做完之后才锁住全局运行队列，这是并发编程加锁的基本原则，需要尽量减小锁的粒度，降低锁冲突的概率。
分析完runqput函数是如何把goroutine放入运行队列之后，接下来我们继续分析main goroutine因读取channel而发生的阻塞流程。
因读取channel阻塞而发生的被动调度
从代码逻辑的角度来说，我们不能确定main goroutine和新创建出来的g2谁先运行，但对于我们分析来说我们可以假定某个goroutine先运行，因为不管谁先运行，都会阻塞在channel的读或则写上，所以这里我们假设main创建好g2后首先阻塞在了对channel的读操作上。下面我们看看读取channel的过程。
从前面的反汇编代码我们知道读取channel是通过调用runtime.chanrecv1函数来完成的，我们就从它开始分析，不过在分析过程中我们不会把精力放在对channel的操作上，而是分析这个过程中跟调度有关的细节。
runtime/chan.go : 403  // entry points for &amp;lt;- c from compiled code //go:nosplit func chanrecv1(c *hchan, elem unsafe.Pointer) {  chanrecv(c, elem, true) } // runtime/chan.go : 415 func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) {  ......  //省略部分的代码逻辑主要在判断读取操作是否可以立即完成，如果不能立即完成  //就需要把g挂在channel c的读取队列上，然后调用goparkunlock函数阻塞此goroutine  goparkunlock(&amp;amp;c.lock, waitReasonChanReceive, traceEvGoBlockRecv, 3)  ...... } chanrecv1直接调用chanrecv函数实现读取操作，chanrecv首先会判断channel是否有数据可读，如果有数据则直接读取并返回，但如果没有数据，则需要把当前goroutine挂入channel的读取队列之中并调用goparkunlock函数阻塞该goroutine.
runtime/proc.go : 304  // Puts the current goroutine into a waiting state and unlocks the lock. // The goroutine can be made runnable again by calling goready(gp). func goparkunlock(lock *mutex, reason waitReason, traceEv byte, traceskip int) {  gopark(parkunlock_c, unsafe.Pointer(lock), reason, traceEv, traceskip) }  // runtime/proc.go : 276 // Puts the current goroutine into a waiting state and calls unlockf. // If unlockf returns false, the goroutine is resumed. // unlockf must not access this G&amp;#39;s stack, as it may be moved between // the call to gopark and the call to unlockf. // Reason explains why the goroutine has been parked. // It is displayed in stack traces and heap dumps. // Reasons should be unique and descriptive. // Do not re-use reasons, add new ones. func gopark(unlockf func(*g, unsafe.Pointer) bool, lock unsafe.Pointer, reason waitReason,traceEv byte, traceskip int) {  ......  // can&amp;#39;t do anything that might move the G between Ms here.  mcall(park_m) //切换到g0栈执行park_m函数 } goparkunlock函数直接调用gopark函数，gopark则调用mcall从当前main goroutine切换到g0去执行park_m函数（mcall前面我们分析过，其主要作用就是保存当前goroutine的现场，然后切换到g0栈去调用作为参数传递给它的函数）
runtime/proc.go : 2581  // park continuation on g0. func park_m(gp *g) {  _g_ := getg()   if trace.enabled {  traceGoPark(_g_.m.waittraceev, _g_.m.waittraceskip)  }   casgstatus(gp, _Grunning, _Gwaiting)  dropg() //解除g和m之间的关系   ......   schedule() } park_m首先把当前goroutine的状态设置为_Gwaiting（因为它正在等待其它goroutine往channel里面写数据），然后调用dropg函数解除g和m之间的关系，最后通过调用schedule函数进入调度循环，schedule函数我们也详细分析过，它首先会从运行队列中挑选出一个goroutine，然后调用gogo函数切换到被挑选出来的goroutine去运行。因为main goroutine在读取channel被阻塞之前已经把创建好的g2放入了运行队列，所以在这里schedule会把g2调度起来运行，这里完成了一次从main goroutine到g2调度（我们假设只有一个工作线程在进行调度）。
唤醒阻塞在channel上的goroutine
g2 goroutine的入口是start函数，下面我们就从该函数开始分析g2写channel的流程，看它如何唤醒正在等待着读取channel的main goroutine。还是先来反汇编一下start函数的代码：
0x44f480 &amp;lt;&#43;0&amp;gt;:mov %fs:0xfffffffffffffff8,%rcx 0x44f489 &amp;lt;&#43;9&amp;gt;:cmp 0x10(%rcx),%rsp 0x44f48d &amp;lt;&#43;13&amp;gt;:jbe 0x44f4c1 &amp;lt;main.start&#43;65&amp;gt; 0x44f48f &amp;lt;&#43;15&amp;gt;:sub $0x18,%rsp 0x44f493 &amp;lt;&#43;19&amp;gt;:mov %rbp,0x10(%rsp) 0x44f498 &amp;lt;&#43;24&amp;gt;:lea 0x10(%rsp),%rbp 0x44f49d &amp;lt;&#43;29&amp;gt;:mov 0x20(%rsp),%rax 0x44f4a2 &amp;lt;&#43;34&amp;gt;:mov %rax,(%rsp) 0x44f4a6 &amp;lt;&#43;38&amp;gt;:lea 0x2d71b(%rip),%rax 0x44f4ad &amp;lt;&#43;45&amp;gt;:mov %rax,0x8(%rsp) 0x44f4b2 &amp;lt;&#43;50&amp;gt;:callq 0x404560 &amp;lt;runtime.chansend1&amp;gt; #写channel 0x44f4b7 &amp;lt;&#43;55&amp;gt;:mov 0x10(%rsp),%rbp 0x44f4bc &amp;lt;&#43;60&amp;gt;:add $0x18,%rsp 0x44f4c0 &amp;lt;&#43;64&amp;gt;:retq 0x44f4c1 &amp;lt;&#43;65&amp;gt;:callq 0x447390 &amp;lt;runtime.morestack_noctxt&amp;gt; 0x44f4c6 &amp;lt;&#43;70&amp;gt;:jmp 0x44f480 &amp;lt;main.start&amp;gt; 可以看到，编译器把对channel的发送操作翻译成了对runtime.chansend1函数的调用
runtime/chan.go : 124  // entry point for c &amp;lt;- x from compiled code //go:nosplit func chansend1(c *hchan, elem unsafe.Pointer) {  chansend(c, elem, true, getcallerpc()) } // runtime/chan.go : 142 func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool {  ......  if sg := c.recvq.dequeue(); sg != nil {  // Found a waiting receiver. We pass the value we want to send  // directly to the receiver, bypassing the channel buffer (if any).  //可以直接发送数据给sg  send(c, sg, ep, func() { unlock(&amp;amp;c.lock) }, 3)  return true  }  ...... } // runtime/chan.go : 269 func send(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) {  ......  goready(gp, skip&#43;1) } // runtime/proc.go : 310 func goready(gp *g, traceskip int) {  systemstack(func() {  ready(gp, traceskip, true)  }) } channel发送和读取的流程类似，如果能够立即发送则立即发送并返回，如果不能立即发送则需要阻塞，在我们这个场景中，因为main goroutine此时此刻正挂在channel的读取队列上等待数据，所以这里直接调用send函数发送给main goroutine，send函数则调用goready函数切换到g0栈并调用ready函数来唤醒sg对应的goroutine，即正在等待读channel的main goroutine。
runtime/proc.go : 639  // Mark gp ready to run. func ready(gp *g, traceskip int, next bool) {  ......  // Mark runnable.  _g_ := getg()  ......  // status is Gwaiting or Gscanwaiting, make Grunnable and put on runq  casgstatus(gp, _Gwaiting, _Grunnable)  runqput(_g_.m.p.ptr(), gp, next) //放入运行队列  if atomic.Load(&amp;amp;sched.npidle) != 0 &amp;amp;&amp;amp; atomic.Load(&amp;amp;sched.nmspinning) == 0 {  //有空闲的p而且没有正在偷取goroutine的工作线程，则需要唤醒p出来工作  wakep()  }  ...... } ready函数首先把需要唤醒的goroutine的状态设置为_Grunnable，然后把其放入运行队列之中等待调度器的调度。
对于本章我们分析的场景，执行到这里main goroutine已经被放入了运行队列，但还未被调度起来运行，而g2 goroutine在向channel写完数据之后就从这里的ready函数返回并退出了，从第二章我们对goroutine的退出流程的分析可以得知，在g2的退出过程中将会在goexit0函数中调用schedule函数进入下一轮调度，从而把刚刚放入运行队列的main goroutine调度起来运行。
在上面分析ready函数时我们略过了一种情况：如果当前有空闲的p而且没有工作线程正在尝试从各个工作线程的本地运行队列偷取goroutine的话（没有处于spinning状态的工作线程），那么就需要通过wakep函数把空闲的p唤醒起来工作。为了不让篇幅过长，下一节我们再来分析wakep如何去唤醒和创建新的工作线程。
最后，如果你觉得本文对你有帮助的话，麻烦帮忙点一下文末右下角的 在看 或转发到朋友圈，非常感谢！
</content>
    </entry>
    
     <entry>
        <title>go语言调度器之盗取goroutine(17)</title>
        <url>http://shanks.link/blog/2021/04/03/go%E8%AF%AD%E8%A8%80%E8%B0%83%E5%BA%A6%E5%99%A8%E4%B9%8B%E7%9B%97%E5%8F%96goroutine17/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 爱写程序的阿波张 源码游记 2019-05-17
本文是《Go语言调度器源代码情景分析》系列的第17篇，也是第三章《Goroutine调度策略》的第2小节。
上一小节我们分析了从全局运行队列与工作线程的本地运行队列获取goroutine的过程，这一小节我们继续分析因无法从上述两个队列中拿到需要运行的goroutine而导致的从其它工作线程的本地运行队列中盗取goroutine的过程。
findrunnable() 函数负责处理与盗取相关的逻辑，该函数代码很繁杂，因为它还做了与gc和netpoll等相关的事情，为了不影响我们的分析思路，这里我们仍然把不相关的代码删掉了，不过代码还是比较多，但总结起来就一句话：尽力去各个运行队列中寻找goroutine，如果实在找不到则进入睡眠状态。下面是代码细节：
runtime/proc.go : 2176  // Finds a runnable goroutine to execute. // Tries to steal from other P&amp;#39;s, get g from global queue, poll network. func findrunnable() (gp *g, inheritTime bool) {  _g_ := getg()   // The conditions here and in handoffp must agree: if  // findrunnable would return a G to run, handoffp must start  // an M.  top:  _p_ := _g_.m.p.ptr()   ......   // local runq  //再次看一下本地运行队列是否有需要运行的goroutine  if gp, inheritTime := runqget(_p_); gp != nil {  return gp, inheritTime  }   // global runq  //再看看全局运行队列是否有需要运行的goroutine  if sched.runqsize != 0 {  lock(&amp;amp;sched.lock)  gp := globrunqget(_p_, 0)  unlock(&amp;amp;sched.lock)  if gp != nil {  return gp, false  }  }   ......   // Steal work from other P&amp;#39;s.  //如果除了当前工作线程还在运行外，其它工作线程已经处于休眠中，那么也就不用去偷了，肯定没有  procs := uint32(gomaxprocs)  if atomic.Load(&amp;amp;sched.npidle) == procs-1 {  // Either GOMAXPROCS=1 or everybody, except for us, is idle already.  // New work can appear from returning syscall/cgocall, network or timers.  // Neither of that submits to local run queues, so no point in stealing.  goto stop  }  // If number of spinning M&amp;#39;s &amp;gt;= number of busy P&amp;#39;s, block.  // This is necessary to prevent excessive CPU consumption  // when GOMAXPROCS&amp;gt;&amp;gt;1 but the program parallelism is low.  // 这个判断主要是为了防止因为寻找可运行的goroutine而消耗太多的CPU。  // 因为已经有足够多的工作线程正在寻找可运行的goroutine，让他们去找就好了，自己偷个懒去睡觉  if !_g_.m.spinning &amp;amp;&amp;amp; 2*atomic.Load(&amp;amp;sched.nmspinning) &amp;gt;= procs-atomic.Load(&amp;amp;sched.npidle) {  goto stop  }  if !_g_.m.spinning {  //设置m的状态为spinning  _g_.m.spinning = true  //处于spinning状态的m数量加一  atomic.Xadd(&amp;amp;sched.nmspinning, 1)  }   //从其它p的本地运行队列盗取goroutine  for i := 0; i &amp;lt; 4; i&#43;&#43; {  for enum := stealOrder.start(fastrand()); !enum.done(); enum.next() {  if sched.gcwaiting != 0 {  goto top  }  stealRunNextG := i &amp;gt; 2 // first look for ready queues with more than 1 g  if gp := runqsteal(_p_, allp[enum.position()], stealRunNextG); gp != nil {  return gp, false  }  }  }  stop:   ......   // Before we drop our P, make a snapshot of the allp slice,  // which can change underfoot once we no longer block  // safe-points. We don&amp;#39;t need to snapshot the contents because  // everything up to cap(allp) is immutable.  allpSnapshot := allp   // return P and block  lock(&amp;amp;sched.lock)   ......   if sched.runqsize != 0 {  gp := globrunqget(_p_, 0)  unlock(&amp;amp;sched.lock)  return gp, false  }   // 当前工作线程解除与p之间的绑定，准备去休眠  if releasep() != _p_ {  throw(&amp;#34;findrunnable: wrong p&amp;#34;)  }  //把p放入空闲队列  pidleput(_p_)  unlock(&amp;amp;sched.lock)  // Delicate dance: thread transitions from spinning to non-spinning state, // potentially concurrently with submission of new goroutines. We must // drop nmspinning first and then check all per-P queues again (with // #StoreLoad memory barrier in between). If we do it the other way around, // another thread can submit a goroutine after we&amp;#39;ve checked all run queues // but before we drop nmspinning; as the result nobody will unpark a thread // to run the goroutine. // If we discover new work below, we need to restore m.spinning as a signal // for resetspinning to unpark a new worker thread (because there can be more // than one starving goroutine). However, if after discovering new work // we also observe no idle Ps, it is OK to just park the current thread: // the system is fully loaded so no spinning threads are required. // Also see &amp;#34;Worker thread parking/unparking&amp;#34; comment at the top of the file.  wasSpinning := _g_.m.spinning  if _g_.m.spinning {  //m即将睡眠，状态不再是spinning  _g_.m.spinning = false  if int32(atomic.Xadd(&amp;amp;sched.nmspinning, -1)) &amp;lt; 0 {  throw(&amp;#34;findrunnable: negative nmspinning&amp;#34;)  }  }   // check all runqueues once again  // 休眠之前再看一下是否有工作要做  for _, _p_ := range allpSnapshot {  if !runqempty(_p_) {  lock(&amp;amp;sched.lock)  _p_ = pidleget()  unlock(&amp;amp;sched.lock)  if _p_ != nil {  acquirep(_p_)  if wasSpinning {  _g_.m.spinning = true  atomic.Xadd(&amp;amp;sched.nmspinning, 1)  }  goto top  }  break  }  }   ......  //休眠  stopm()  goto top } 从上面的代码可以看到，工作线程在放弃寻找可运行的goroutine而进入睡眠之前，会反复尝试从各个运行队列寻找需要运行的goroutine，可谓是尽心尽力了。这个函数需要重点注意以下两点：
第一点，工作线程M的自旋状态(spinning)。工作线程在从其它工作线程的本地运行队列中盗取goroutine时的状态称为自旋状态。从上面代码可以看到，当前M在去其它p的运行队列盗取goroutine之前把spinning标志设置成了true，同时增加处于自旋状态的M的数量，而盗取结束之后则把spinning标志还原为false，同时减少处于自旋状态的M的数量，从后面的分析我们可以看到，当有空闲P又有goroutine需要运行的时候，这个处于自旋状态的M的数量决定了是否需要唤醒或者创建新的工作线程。
第二点，盗取算法。盗取过程用了两个嵌套for循环。内层循环实现了盗取逻辑，从代码可以看出盗取的实质就是遍历allp中的所有p，查看其运行队列是否有goroutine，如果有，则取其一半到当前工作线程的运行队列，然后从findrunnable返回，如果没有则继续遍历下一个p。但这里为了保证公平性，遍历allp时并不是固定的从allp[0]即第一个p开始，而是从随机位置上的p开始，而且遍历的顺序也随机化了，并不是现在访问了第i个p下一次就访问第i&#43;1个p，而是使用了一种伪随机的方式遍历allp中的每个p，防止每次遍历时使用同样的顺序访问allp中的元素。下面是这个算法的伪代码：
offset := uint32(random()) % nprocs coprime := 随机选取一个小于nprocs且与nprocs互质的数 for i := 0; i &amp;lt; nprocs; i&#43;&#43; {  p := allp[offset]  从p的运行队列偷取goroutine  if 偷取成功 {  break  }  offset &#43;= coprime  offset = offset % nprocs } 下面举例说明一下上述算法过程，现假设nprocs为8，也就是一共有8个p。
如果第一次随机选择的offset = 6，coprime = 3(3与8互质，满足算法要求)的话，则从allp切片中偷取的下标顺序为6, 1, 4, 7, 2, 5, 0, 3，计算过程：
6，(6&#43;3)%8=1，(1&#43;3)%8=4, (4&#43;3)%8=7, (7&#43;3)%8=2, (2&#43;3)%8=5, (5&#43;3)%8=0, (0&#43;3)%8=3 如果第二次随机选择的offset = 4，coprime = 5的话，则从allp切片中偷取的下标顺序为1, 6, 3, 0, 5, 2, 7, 4，计算过程：
1，(1&#43;5)%8=6，(6&#43;5)%8=3, (3&#43;5)%8=0, (0&#43;5)%8=5, (5&#43;5)%8=2, (2&#43;5)%8=7, (7&#43;5)%8=4 可以看到只要随机数不一样，偷取p的顺序也不一样，但可以保证经过8次循环，每个p都会被访问到。可以用数论知识证明，不管nprocs是多少，这个算法都可以保证经过nprocs次循环，每个p都可以得到访问。
挑选出盗取的对象p之后，则调用runqsteal盗取p的运行队列中的goroutine，runqsteal函数再调用runqgrap从p的队列中批量拿出多个goroutine，这两个函数本身比较简单，但runqgrab有一个小细节需要注意一下，见下面代码：
runtime/proc.go : 4854  // Grabs a batch of goroutines from _p_&amp;#39;s runnable queue into batch. // Batch is a ring buffer starting at batchHead. // Returns number of grabbed goroutines. // Can be executed by any P. func runqgrab(_p_ *p, batch *[256]guintptr, batchHead uint32, stealRunNextG bool) uint32 {  for {  h := atomic.LoadAcq(&amp;amp;_p_.runqhead) // load-acquire, synchronize with other consumers  t := atomic.LoadAcq(&amp;amp;_p_.runqtail) // load-acquire, synchronize with the producer  n := t - h //计算队列中有多少个goroutine  n = n - n/2 //取队列中goroutine个数的一半  if n == 0 {  ......  return ......  }  //小细节：按理说队列中的goroutine个数最多就是len(_p_.runq)，  //所以n的最大值也就是len(_p_.runq)/2，那为什么需要这个判断呢？  if n &amp;gt; uint32(len(_p_.runq)/2) { // read inconsistent h and t  continue  }  ......  } } 代码中n的计算很简单，从计算过程来看n应该是runq队列中goroutine数量的一半，它的最大值不会超过队列容量的一半，但为什么这里的代码却偏偏要去判断n是否大于队列容量的一半呢？这里关键点在于读取runqhead和runqtail是两个操作而非一个原子操作，当我们读取runqhead之后但还未读取runqtail之前，如果有其它线程快速的在增加（这是完全有可能的，其它偷取者从队列中偷取goroutine会增加runqhead，而队列的所有者往队列中添加goroutine会增加runqtail）这两个值，则会导致我们读取出来的runqtail已经远远大于我们之前读取出来放在局部变量h里面的runqhead了，也就是代码注释中所说的h和t已经不一致了，所以这里需要这个if判断来检测异常情况。
工作线程进入睡眠
分析完盗取过程，我们继续回到findrunnable函数。
如果工作线程经过多次努力一直找不到需要运行的goroutine则调用stopm进入睡眠状态，等待被其它工作线程唤醒。
runtime/proc.go : 1918  // Stops execution of the current m until new work is available. // Returns with acquired P. func stopm() {  _g_ := getg()   if _g_.m.locks != 0 {  throw(&amp;#34;stopm holding locks&amp;#34;)  }  if _g_.m.p != 0 {  throw(&amp;#34;stopm holding p&amp;#34;)  }  if _g_.m.spinning {  throw(&amp;#34;stopm spinning&amp;#34;)  }   lock(&amp;amp;sched.lock)  mput(_g_.m) //把m结构体对象放入sched.midle空闲队列  unlock(&amp;amp;sched.lock)  notesleep(&amp;amp;_g_.m.park) //进入睡眠状态   //被其它工作线程唤醒  noteclear(&amp;amp;_g_.m.park)  acquirep(_g_.m.nextp.ptr())  _g_.m.nextp = 0 } stopm的核心是调用mput把m结构体对象放入sched的midle空闲队列，然后通过notesleep(&amp;amp;m.park)函数让自己进入睡眠状态。
note是go runtime实现的一次性睡眠和唤醒机制，一个线程可以通过调用notesleep(*note)进入睡眠状态，而另外一个线程则可以通过notewakeup(*note)把其唤醒。note的底层实现机制跟操作系统相关，不同系统使用不同的机制，比如linux下使用的futex系统调用，而mac下则是使用的pthread_cond_t条件变量，note对这些底层机制做了一个抽象和封装，这种封装给扩展性带来了很大的好处，比如当睡眠和唤醒功能需要支持新平台时，只需要在note层增加对特定平台的支持即可，不需要修改上层的任何代码。
回到stopm，当从notesleep函数返回后，需要再次绑定一个p，然后返回到findrunnable函数继续重新寻找可运行的goroutine，一旦找到可运行的goroutine就会返回到schedule函数，并把找到的goroutine调度起来运行，如何把goroutine调度起来运行的代码我们已经分析过了。现在继续看notesleep函数。
runtime/lock_futex.go : 139  func notesleep(n *note) {  gp := getg()  if gp != gp.m.g0 {  throw(&amp;#34;notesleep not on g0&amp;#34;)  }  ns := int64(-1) //超时时间设置为-1，表示无限期等待  if *cgo_yield != nil {  // Sleep for an arbitrary-but-moderate interval to poll libc interceptors.  ns = 10e6  }   //使用循环，保证不是意外被唤醒  for atomic.Load(key32(&amp;amp;n.key)) == 0 {  gp.m.blocked = true  futexsleep(key32(&amp;amp;n.key), 0, ns)  if *cgo_yield != nil {  asmcgocall(*cgo_yield, nil)  }  gp.m.blocked = false  } } notesleep函数调用futexsleep进入睡眠，这里之所以需要用一个循环，是因为futexsleep有可能意外从睡眠中返回，所以从futexsleep函数返回后还需要检查note.key是否还是0，如果是0则表示并不是其它工作线程唤醒了我们，只是futexsleep意外返回了，需要再次调用futexsleep进入睡眠。
futexsleep调用futex函数进入睡眠。  runtime/os_linux.go : 32  // Atomically, //if(*addr == val) sleep // Might be woken up spuriously; that&amp;#39;s allowed. // Don&amp;#39;t sleep longer than ns; ns &amp;lt; 0 means forever. //go:nosplit func futexsleep(addr *uint32, val uint32, ns int64) {  var ts timespec   // Some Linux kernels have a bug where futex of  // FUTEX_WAIT returns an internal error code  // as an errno. Libpthread ignores the return value  // here, and so can we: as it says a few lines up,  // spurious wakeups are allowed.  if ns &amp;lt; 0 {  //调用futex进入睡眠  futex(unsafe.Pointer(addr), _FUTEX_WAIT_PRIVATE, val, nil, nil, 0)  return  }   // It&amp;#39;s difficult to live within the no-split stack limits here.  // On ARM and 386, a 64-bit divide invokes a general software routine  // that needs more stack than we can afford. So we use timediv instead.  // But on real 64-bit systems, where words are larger but the stack limit  // is not, even timediv is too heavy, and we really need to use just an  // ordinary machine instruction.  if sys.PtrSize == 8 {  ts.set_sec(ns / 1000000000)  ts.set_nsec(int32(ns % 1000000000))  } else {  ts.tv_nsec = 0  ts.set_sec(int64(timediv(ns, 1000000000, (*int32)(unsafe.Pointer(&amp;amp;ts.tv_nsec)))))  }  futex(unsafe.Pointer(addr), _FUTEX_WAIT_PRIVATE, val, unsafe.Pointer(&amp;amp;ts), nil, 0) } futex是go汇编实现的函数，主要功能就是执行futex系统调用进入操作系统内核进行睡眠。
runtime/sys_linux_amd64.s : 525  // int64 futex(int32 *uaddr, int32 op, int32 val, //struct timespec *timeout, int32 *uaddr2, int32 val2); TEXT runtime·futex(SB),NOSPLIT,$0  #下面的6条指令在为futex系统调用准备参数 MOVQ addr&#43;0(FP), DI MOVL op&#43;8(FP), SI MOVL val&#43;12(FP), DX MOVQ ts&#43;16(FP), R10 MOVQ addr2&#43;24(FP), R8 MOVL val3&#43;32(FP), R9  MOVL $SYS_futex, AX #系统调用编号放入AX寄存器 SYSCALL #执行futex系统调用进入睡眠，从睡眠中被唤醒后接着执行下一条MOVL指令 MOVL AX, ret&#43;40(FP) #保存系统调用的返回值 RET futex系统的参数比较多，其函数原型为  int64 futex(int32 *uaddr, int32 op, int32 val, struct timespec *timeout, int32 *uaddr2, int32 val2); 这里，futex系统调用为我们提供的功能为如果 uaddr == val 则进入睡眠，否则直接返回。顺便说一下，为什么futex系统调用需要第三个参数val，需要在内核判断uaddr与val是否相等，而不能在用户态先判断它们是否相等，如果相等才进入内核睡眠岂不是更高效？原因在于判断uaddr与val是否相等和进入睡眠这两个操作必须是一个原子操作，否则会存在一个竞态条件：如果不是原子操作，则当前线程在第一步判断完uaddr与val相等之后进入睡眠之前的这一小段时间内，有另外一个线程通过唤醒操作把*uaddr的值修改了，这就会导致当前工作线程永远处于睡眠状态而无人唤醒它。而在用户态无法实现判断与进入睡眠这两步为一个原子操作，所以需要内核来为其实现原子操作。
我们知道线程一旦进入睡眠状态就停止了运行，那么如果后来又有可运行的goroutine需要工作线程去运行，正在睡眠的线程怎么知道有工作可做了呢？
从前面的代码我们已经看到，stopm调用notesleep时给它传递的参数是m结构体的park成员，而m又早已通过mput放入了全局的milde空闲队列，这样其它运行着的线程一旦发现有更多的goroutine需要运行时就可以通过全局的m空闲队列找到处于睡眠状态的m，然后调用notewakeup(&amp;amp;m.park)将其唤醒，至于怎么唤醒，我们在其它章节继续讨论。
到此，我们已经完整分析了调度器的调度策略，从下一章起我们将开始讨论有关调度的另外一个话题：调度时机，即什么时候会发生调度。
最后，如果你觉得本文对你有帮助的话，麻烦帮忙点一下文末右下角的 在看 或转发到朋友圈，非常感谢！
</content>
    </entry>
    
     <entry>
        <title>第三章 goroutine调度策略（16）</title>
        <url>http://shanks.link/blog/2021/04/03/%E7%AC%AC%E4%B8%89%E7%AB%A0-goroutine%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A516/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 爱写程序的阿波张 源码游记 2019-05-14
本文是《Go语言调度器源代码情景分析》系列的第16篇，也是第三章《Goroutine调度策略》的第1小节。
在调度器概述一节我们提到过，所谓的goroutine调度，是指程序代码按照一定的算法在适当的时候挑选出合适的goroutine并放到CPU上去运行的过程。这句话揭示了调度系统需要解决的三大核心问题：
调度时机：什么时候会发生调度？
调度策略：使用什么策略来挑选下一个进入运行的goroutine？
切换机制：如何把挑选出来的goroutine放到CPU上运行？
对这三大问题的解决构成了调度器的所有工作，因而我们对调度器的分析也必将围绕着它们所展开。
第二章我们已经详细的分析了调度器的初始化以及goroutine的切换机制，本章将重点讨论调度器如何挑选下一个goroutine出来运行的策略问题，而剩下的与调度时机相关的内容我们将在第4～6章进行全面的分析。
再探schedule函数
在讨论main goroutine的调度时我们已经见过schedule函数，因为当时我们的主要关注点在于main goroutine是如何被调度到CPU上运行的，所以并未对schedule函数如何挑选下一个goroutine出来运行做深入的分析，现在是重新回到schedule函数详细分析其调度策略的时候了。
runtime/proc.go : 2467  // One round of scheduler: find a runnable goroutine and execute it. // Never returns. func schedule() {  _g_ := getg() //_g_ = m.g0   ......   var gp *g   ......   if gp == nil {  // Check the global runnable queue once in a while to ensure fairness.  // Otherwise two goroutines can completely occupy the local runqueue  // by constantly respawning each other.  //为了保证调度的公平性，每个工作线程每进行61次调度就需要优先从全局运行队列中获取goroutine出来运行，  //因为如果只调度本地运行队列中的goroutine，则全局运行队列中的goroutine有可能得不到运行  if _g_.m.p.ptr().schedtick%61 == 0 &amp;amp;&amp;amp; sched.runqsize &amp;gt; 0 {  lock(&amp;amp;sched.lock) //所有工作线程都能访问全局运行队列，所以需要加锁  gp = globrunqget(_g_.m.p.ptr(), 1) //从全局运行队列中获取1个goroutine  unlock(&amp;amp;sched.lock)  }  }  if gp == nil {  //从与m关联的p的本地运行队列中获取goroutine  gp, inheritTime = runqget(_g_.m.p.ptr())  if gp != nil &amp;amp;&amp;amp; _g_.m.spinning {  throw(&amp;#34;schedule: spinning with local work&amp;#34;)  }  }  if gp == nil {  //如果从本地运行队列和全局运行队列都没有找到需要运行的goroutine，  //则调用findrunnable函数从其它工作线程的运行队列中偷取，如果偷取不到，则当前工作线程进入睡眠，  //直到获取到需要运行的goroutine之后findrunnable函数才会返回。  gp, inheritTime = findrunnable() // blocks until work is available  }   ......   //当前运行的是runtime的代码，函数调用栈使用的是g0的栈空间  //调用execte切换到gp的代码和栈空间去运行  execute(gp, inheritTime) } schedule函数分三步分别从各运行队列中寻找可运行的goroutine：
第一步，从全局运行队列中寻找goroutine。为了保证调度的公平性，每个工作线程每经过61次调度就需要优先尝试从全局运行队列中找出一个goroutine来运行，这样才能保证位于全局运行队列中的goroutine得到调度的机会。全局运行队列是所有工作线程都可以访问的，所以在访问它之前需要加锁。
第二步，从工作线程本地运行队列中寻找goroutine。如果不需要或不能从全局运行队列中获取到goroutine则从本地运行队列中获取。
第三步，从其它工作线程的运行队列中偷取goroutine。如果上一步也没有找到需要运行的goroutine，则调用findrunnable从其他工作线程的运行队列中偷取goroutine，findrunnable函数在偷取之前会再次尝试从全局运行队列和当前线程的本地运行队列中查找需要运行的goroutine。
下面我们先来看如何从全局运行队列中获取goroutine。
从全局运行队列中获取goroutine
从全局运行队列中获取可运行的goroutine是通过globrunqget函数来完成的，该函数的第一个参数是与当前工作线程绑定的p，第二个参数max表示最多可以从全局队列中拿多少个g到当前工作线程的本地运行队列中来。
runtime/proc.go : 4663  // Try get a batch of G&amp;#39;s from the global runnable queue. // Sched must be locked. func globrunqget(_p_ *p, max int32) *g {  if sched.runqsize == 0 { //全局运行队列为空  return nil  }   //根据p的数量平分全局运行队列中的goroutines  n := sched.runqsize / gomaxprocs &#43; 1  if n &amp;gt; sched.runqsize { //上面计算n的方法可能导致n大于全局运行队列中的goroutine数量  n = sched.runqsize  }  if max &amp;gt; 0 &amp;amp;&amp;amp; n &amp;gt; max {  n = max //最多取max个goroutine  }  if n &amp;gt; int32(len(_p_.runq)) / 2 {  n = int32(len(_p_.runq)) / 2 //最多只能取本地队列容量的一半  }   sched.runqsize -= n   //直接通过函数返回gp，其它的goroutines通过runqput放入本地运行队列  gp := sched.runq.pop() //pop从全局运行队列的队列头取  n--  for ; n &amp;gt; 0; n-- {  gp1 := sched.runq.pop() //从全局运行队列中取出一个goroutine  runqput(_p_, gp1, false) //放入本地运行队列  }  return gp } globrunqget函数首先会根据全局运行队列中goroutine的数量，函数参数max以及_p_的本地队列的容量计算出到底应该拿多少个goroutine，然后把第一个g结构体对象通过返回值的方式返回给调用函数，其它的则通过runqput函数放入当前工作线程的本地运行队列。这段代码值得一提的是，计算应该从全局运行队列中拿走多少个goroutine时根据p的数量（gomaxprocs）做了负载均衡。
如果没有从全局运行队列中获取到goroutine，那么接下来就在工作线程的本地运行队列中寻找需要运行的goroutine。
从工作线程本地运行队列中获取goroutine
从代码上来看，工作线程的本地运行队列其实分为两个部分，一部分是由p的runq、runqhead和runqtail这三个成员组成的一个无锁循环队列，该队列最多可包含256个goroutine；另一部分是p的runnext成员，它是一个指向g结构体对象的指针，它最多只包含一个goroutine。
从本地运行队列中寻找goroutine是通过runqget函数完成的，寻找时，代码首先查看runnext成员是否为空，如果不为空则返回runnext所指的goroutine，并把runnext成员清零，如果runnext为空，则继续从循环队列中查找goroutine。
runtime/proc.go : 4825  // Get g from local runnable queue. // If inheritTime is true, gp should inherit the remaining time in the // current time slice. Otherwise, it should start a new time slice. // Executed only by the owner P. func runqget(_p_ *p) (gp *g, inheritTime bool) {  // If there&amp;#39;s a runnext, it&amp;#39;s the next G to run.  //从runnext成员中获取goroutine  for {  //查看runnext成员是否为空，不为空则返回该goroutine  next := _p_.runnext  if next == 0 {  break  }  if _p_.runnext.cas(next, 0) {  return next.ptr(), true  }  }   //从循环队列中获取goroutine  for {  h := atomic.LoadAcq(&amp;amp;_p_.runqhead) // load-acquire, synchronize with other consumers  t := _p_.runqtail  if t == h {  return nil, false  }  gp := _p_.runq[h%uint32(len(_p_.runq))].ptr()  if atomic.CasRel(&amp;amp;_p_.runqhead, h, h&#43;1) { // cas-release, commits consume  return gp, false  }  } } 这里首先需要注意的是不管是从runnext还是从循环队列中拿取goroutine都使用了cas操作，这里的cas操作是必需的，因为可能有其他工作线程此时此刻也正在访问这两个成员，从这里偷取可运行的goroutine。
其次，代码中对runqhead的操作使用了atomic.LoadAcq和atomic.CasRel，它们分别提供了load-acquire和cas-release语义。
对于atomic.LoadAcq来说，其语义主要包含如下几条：
原子读取，也就是说不管代码运行在哪种平台，保证在读取过程中不会有其它线程对该变量进行写入；
位于atomic.LoadAcq之后的代码，对内存的读取和写入必须在atomic.LoadAcq读取完成后才能执行，编译器和CPU都不能打乱这个顺序；
当前线程执行atomic.LoadAcq时可以读取到其它线程最近一次通过atomic.CasRel对同一个变量写入的值，与此同时，位于atomic.LoadAcq之后的代码，不管读取哪个内存地址中的值，都可以读取到其它线程中位于atomic.CasRel（对同一个变量操作）之前的代码最近一次对内存的写入。
对于atomic.CasRel来说，其语义主要包含如下几条：
原子的执行比较并交换的操作；
位于atomic.CasRel之前的代码，对内存的读取和写入必须在atomic.CasRel对内存的写入之前完成，编译器和CPU都不能打乱这个顺序；
线程执行atomic.CasRel完成后其它线程通过atomic.LoadAcq读取同一个变量可以读到最新的值，与此同时，位于atomic.CasRel之前的代码对内存写入的值，可以被其它线程中位于atomic.LoadAcq（对同一个变量操作）之后的代码读取到。
因为可能有多个线程会并发的修改和读取runqhead，以及需要依靠runqhead的值来读取runq数组的元素，所以需要使用atomic.LoadAcq和atomic.CasRel来保证上述语义。
我们可能会问，为什么读取p的runqtail成员不需要使用atomic.LoadAcq或atomic.load？因为runqtail不会被其它线程修改，只会被当前工作线程修改，此时没有人修改它，所以也就不需要使用原子相关的操作。
最后，由p的runq、runqhead和runqtail这三个成员组成的这个无锁循环队列非常精妙，我们会在后面的章节对这个循环队列进行分析。
CAS操作与ABA问题
我们知道使用cas操作需要特别注意ABA的问题，那么runqget函数这两个使用cas的地方会不会有问题呢？答案是这两个地方都不会有ABA的问题。原因分析如下：
首先来看对runnext的cas操作。只有跟_p_绑定的当前工作线程才会去修改runnext为一个非0值，其它线程只会把runnext的值从一个非0值修改为0值，然而跟_p_绑定的当前工作线程正在此处执行代码，所以在当前工作线程读取到值A之后，不可能有线程修改其值为B(0)之后再修改回A。
再来看对runq的cas操作。当前工作线程操作的是_p_的本地队列，只有跟_p_绑定在一起的当前工作线程才会因为往该队列里面添加goroutine而去修改runqtail，而其它工作线程不会往该队列里面添加goroutine，也就不会去修改runqtail，它们只会修改runqhead，所以，当我们这个工作线程从runqhead读取到值A之后，其它工作线程也就不可能修改runqhead的值为B之后再第二次把它修改为值A（因为runqtail在这段时间之内不可能被修改，runqhead的值也就无法越过runqtail再回绕到A值），也就是说，代码从逻辑上已经杜绝了引发ABA的条件。
到此，我们已经分析完工作线程从全局运行队列和本地运行队列获取goroutine的代码，由于篇幅的限制，我们下一节再来分析从其它工作线程的运行队列偷取goroutine的流程。
最后，如果你觉得本文对你有帮助的话，麻烦帮忙点一下文末右下角的 在看 或转发到朋友圈，非常感谢！
</content>
    </entry>
    
     <entry>
        <title>非main goroutine的退出及调度循环（15）</title>
        <url>http://shanks.link/blog/2021/04/03/%E9%9D%9Emain-goroutine%E7%9A%84%E9%80%80%E5%87%BA%E5%8F%8A%E8%B0%83%E5%BA%A6%E5%BE%AA%E7%8E%AF15/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 爱写程序的阿波张 源码游记 2019-05-12
本文是《Go语言调度器源代码情景分析》系列的第15篇，也是第二章的第5小节。
上一节我们说过main goroutine退出时会直接执行exit系统调用退出整个进程，而非main goroutine退出时则会进入goexit函数完成最后的清理工作，本小节我们首先就来验证一下非main goroutine执行完成后是否真的会去执行goexit，然后再对非main goroutine的退出流程做个梳理。这一节我们需要重点理解以下内容：
非main goroutine是如何返回到goexit函数的；
mcall函数如何从用户goroutine切换到g0继续执行；
调度循环。
非main goroutine会返回到goexit吗
首先来看一段代码：
package main  import (  &amp;#34;fmt&amp;#34; )  func g2(n int, ch chan int) {  ch &amp;lt;- n * n } func main() {  ch := make(chan int)  go g2(100, ch)  fmt.Println(&amp;lt;-ch) } 这个程序比较简单，main goroutine启动后在main函数中创建了一个goroutine执行g2函数，我们称它为g2 goroutine，下面我们就用这个g2的退出来验证一下非main goroutine退出时是否真的会返回到goexit继续执行。
怎么验证呢？比较简单的办法就是用gdb来调试，在gdb中首先使用backtrace命令查看g2函数是被谁调用的，然后单步执行看它能否返回到goexit继续执行。下面是gdb调试过程：
(gdb) b main.g2 // 在main.g2函数入口处下断点 Breakpoint 1 at 0x4869c0: file /home/bobo/study/go/goexit.go, line 7. (gdb) r Starting program: /home/bobo/study/go/goexit Thread 1 &amp;#34;goexit&amp;#34; hit Breakpoint 1 at /home/bobo/study/go/goexit.go:7 (gdb) bt //查看函数调用链，看起来g2真的是被runtime.goexit调用的 #0 main.g2 (n=100, ch=0xc000052060) at /home/bobo/study/go/goexit.go:7 #1 0x0000000000450ad1 in runtime.goexit () at /usr/local/go/src/runtime/asm_amd64.s:1337 (gdb) disass //反汇编找ret的地址，这是为了在ret处下断点 Dump of assembler code for function main.g2: =&amp;gt; 0x00000000004869c0 &amp;lt;&#43;0&amp;gt;:mov %fs:0xfffffffffffffff8,%rcx  0x00000000004869c9 &amp;lt;&#43;9&amp;gt;:cmp 0x10(%rcx),%rsp  0x00000000004869cd &amp;lt;&#43;13&amp;gt;:jbe 0x486a0d &amp;lt;main.g2&#43;77&amp;gt;  0x00000000004869cf &amp;lt;&#43;15&amp;gt;:sub $0x20,%rsp  0x00000000004869d3 &amp;lt;&#43;19&amp;gt;:mov %rbp,0x18(%rsp)  0x00000000004869d8 &amp;lt;&#43;24&amp;gt;:lea 0x18(%rsp),%rbp  0x00000000004869dd &amp;lt;&#43;29&amp;gt;:mov 0x28(%rsp),%rax  0x00000000004869e2 &amp;lt;&#43;34&amp;gt;:imul %rax,%rax  0x00000000004869e6 &amp;lt;&#43;38&amp;gt;:mov %rax,0x10(%rsp)  0x00000000004869eb &amp;lt;&#43;43&amp;gt;:mov 0x30(%rsp),%rax  0x00000000004869f0 &amp;lt;&#43;48&amp;gt;:mov %rax,(%rsp)  0x00000000004869f4 &amp;lt;&#43;52&amp;gt;:lea 0x10(%rsp),%rax  0x00000000004869f9 &amp;lt;&#43;57&amp;gt;:mov %rax,0x8(%rsp)  0x00000000004869fe &amp;lt;&#43;62&amp;gt;:callq 0x4046a0 &amp;lt;runtime.chansend1&amp;gt;  0x0000000000486a03 &amp;lt;&#43;67&amp;gt;:mov 0x18(%rsp),%rbp  0x0000000000486a08 &amp;lt;&#43;72&amp;gt;:add $0x20,%rsp  0x0000000000486a0c &amp;lt;&#43;76&amp;gt;:retq  0x0000000000486a0d &amp;lt;&#43;77&amp;gt;:callq 0x44ece0 &amp;lt;runtime.morestack_noctxt&amp;gt;  0x0000000000486a12 &amp;lt;&#43;82&amp;gt;:jmp 0x4869c0 &amp;lt;main.g2&amp;gt; End of assembler dump. (gdb) b *0x0000000000486a0c //在retq指令位置下断点 Breakpoint 2 at 0x486a0c: file /home/bobo/study/go/goexit.go, line 9. (gdb) c Continuing.  Thread 1 &amp;#34;goexit&amp;#34; hit Breakpoint 2 at /home/bobo/study/go/goexit.go:9 (gdb) disass //程序停在了ret指令处 Dump of assembler code for function main.g2:  0x00000000004869c0 &amp;lt;&#43;0&amp;gt;:mov %fs:0xfffffffffffffff8,%rcx  0x00000000004869c9 &amp;lt;&#43;9&amp;gt;:cmp 0x10(%rcx),%rsp  0x00000000004869cd &amp;lt;&#43;13&amp;gt;:jbe 0x486a0d &amp;lt;main.g2&#43;77&amp;gt;  0x00000000004869cf &amp;lt;&#43;15&amp;gt;:sub $0x20,%rsp  0x00000000004869d3 &amp;lt;&#43;19&amp;gt;:mov %rbp,0x18(%rsp)  0x00000000004869d8 &amp;lt;&#43;24&amp;gt;:lea 0x18(%rsp),%rbp  0x00000000004869dd &amp;lt;&#43;29&amp;gt;:mov 0x28(%rsp),%rax  0x00000000004869e2 &amp;lt;&#43;34&amp;gt;:imul %rax,%rax  0x00000000004869e6 &amp;lt;&#43;38&amp;gt;:mov %rax,0x10(%rsp)  0x00000000004869eb &amp;lt;&#43;43&amp;gt;:mov 0x30(%rsp),%rax  0x00000000004869f0 &amp;lt;&#43;48&amp;gt;:mov %rax,(%rsp)  0x00000000004869f4 &amp;lt;&#43;52&amp;gt;:lea 0x10(%rsp),%rax  0x00000000004869f9 &amp;lt;&#43;57&amp;gt;:mov %rax,0x8(%rsp)  0x00000000004869fe &amp;lt;&#43;62&amp;gt;:callq 0x4046a0 &amp;lt;runtime.chansend1&amp;gt;  0x0000000000486a03 &amp;lt;&#43;67&amp;gt;:mov 0x18(%rsp),%rbp  0x0000000000486a08 &amp;lt;&#43;72&amp;gt;:add $0x20,%rsp =&amp;gt; 0x0000000000486a0c &amp;lt;&#43;76&amp;gt;:retq  0x0000000000486a0d &amp;lt;&#43;77&amp;gt;:callq 0x44ece0 &amp;lt;runtime.morestack_noctxt&amp;gt;  0x0000000000486a12 &amp;lt;&#43;82&amp;gt;:jmp 0x4869c0 &amp;lt;main.g2&amp;gt; End of assembler dump. (gdb) si //单步执行一条指令 runtime.goexit () at /usr/local/go/src/runtime/asm_amd64.s:1338 1338CALLruntime·goexit1(SB)// does not return (gdb) disass //可以看出来g2已经返回到了goexit函数中 Dump of assembler code for function runtime.goexit:  0x0000000000450ad0 &amp;lt;&#43;0&amp;gt;:nop =&amp;gt; 0x0000000000450ad1 &amp;lt;&#43;1&amp;gt;:callq 0x42faf0 &amp;lt;runtime.goexit1&amp;gt;  0x0000000000450ad6 &amp;lt;&#43;6&amp;gt;:nop 使用gdb调试时，首先我们在g2函数入口处下了一个断点，程序暂停后通过查看函数调用栈发现g2函数确实是被goexit调用的，然后再一次使用断点让程序暂停在g2返回之前的最后一条指令retq处，最后单步执行这条指令，可以看到程序从g2函数返回到了goexit函数的第二条指令的位置，这个位置正是当初在创建goroutine时设置好的返回地址。可以看到，虽然g2函数并不是被goexit函数直接调用的，但它执行完成之后却返回到了goexit函数中！
至此，我们已经证实非main goroutine退出时确实会返回到goexit函数继续执行，下面我们就沿着这条线继续分析非main goroutine的退出流程。
非main goroutine的退出流程
首先来看goexit函数
runtime/asm_amd64.s : 1334  // The top-most function running on a goroutine // returns to goexit&#43;PCQuantum. TEXT runtime·goexit(SB),NOSPLIT,$0-0  BYTE $0x90 // NOP  CALL runtime·goexit1(SB) // does not return  // traceback from goexit1 must hit code range of goexit  BYTE $0x90 // NOP 从前面的分析我们已经看到，非main goroutine返回时直接返回到了goexit的第二条指令：CALL runtime·goexit1(SB)，该指令继续调用goexit1函数。  runtime/proc.go : 2652  // Finishes execution of the current goroutine. func goexit1() {  if raceenabled { //与竞态检查有关，不关注  racegoend()  }  if trace.enabled { //与backtrace有关，不关注  traceGoEnd()  }  mcall(goexit0) } goexit1函数通过调用mcall从当前运行的g2 goroutine切换到g0，然后在g0栈上调用和执行goexit0这个函数。  runtime/asm_amd64.s : 270  # func mcall(fn func(*g)) # Switch to m-&amp;gt;g0&amp;#39;s stack, call fn(g). # Fn must never return. It should gogo(&amp;amp;g-&amp;gt;sched) # to keep running g. # mcall的参数是一个指向funcval对象的指针 TEXT runtime·mcall(SB), NOSPLIT, $0-8  #取出参数的值放入DI寄存器，它是funcval对象的指针，此场景中fn.fn是goexit0的地址  MOVQ fn&#43;0(FP), DI   get_tls(CX)  MOVQ g(CX), AX # AX = g，本场景g 是 g2   #mcall返回地址放入BX  MOVQ 0(SP), BX# caller&amp;#39;s PC   #保存g2的调度信息，因为我们要从当前正在运行的g2切换到g0  MOVQ BX, (g_sched&#43;gobuf_pc)(AX) #g.sched.pc = BX，保存g2的rip  LEAQ fn&#43;0(FP), BX # caller&amp;#39;s SP  MOVQ BX, (g_sched&#43;gobuf_sp)(AX) #g.sched.sp = BX，保存g2的rsp  MOVQ AX, (g_sched&#43;gobuf_g)(AX) #g.sched.g = g  MOVQ BP, (g_sched&#43;gobuf_bp)(AX) #g.sched.bp = BP，保存g2的rbp   # switch to m-&amp;gt;g0 &amp;amp; its stack, call fn  #下面三条指令主要目的是找到g0的指针  MOVQ g(CX), BX #BX = g  MOVQ g_m(BX), BX #BX = g.m  MOVQ m_g0(BX), SI #SI = g.m.g0   #此刻，SI = g0， AX = g，所以这里在判断g 是否是 g0，如果g == g0则一定是哪里代码写错了  CMPQ SI, AX# if g == m-&amp;gt;g0 call badmcall  JNE 3(PC)  MOVQ $runtime·badmcall(SB), AX  JMP AX   #把g0的地址设置到线程本地存储之中  MOVQ SI, g(CX)   #恢复g0的栈顶指针到CPU的rsp积存，这一条指令完成了栈的切换，从g的栈切换到了g0的栈  MOVQ (g_sched&#43;gobuf_sp)(SI), SP# rsp = g0-&amp;gt;sched.sp   #AX = g  PUSHQ AX #fn的参数g入栈  MOVQ DI, DX #DI是结构体funcval实例对象的指针，它的第一个成员才是goexit0的地址  MOVQ 0(DI), DI #读取第一个成员到DI寄存器  CALL DI #调用goexit0(g)  POPQ AX  MOVQ $runtime·badmcall2(SB), AX  JMP AX  RET mcall的参数是一个函数，在Go语言的实现中，函数变量并不是一个直接指向函数代码的指针，而是一个指向funcval结构体对象的指针，funcval结构体对象的第一个成员fn才是真正指向函数代码的指针。  type funcval struct {  fn uintptr  // variable-size, fn-specific data here } 也就是说，在我们这个场景中mcall函数的fn参数的fn成员中存放的才是goexit0函数的第一条指令的地址。
mcall函数主要有两个功能：
首先从当前运行的g(我们这个场景是g2)切换到g0，这一步包括保存当前g的调度信息，把g0设置到tls中，修改CPU的rsp寄存器使其指向g0的栈；
以当前运行的g(我们这个场景是g2)为参数调用fn函数(此处为goexit0)。
从mcall的功能我们可以看出，mcall做的事情跟gogo函数完全相反，gogo函数实现了从g0切换到某个goroutine去运行，而mcall实现了从某个goroutine切换到g0来运行，因此，mcall和gogo的代码非常相似，然而mcall和gogo在做切换时有个重要的区别：gogo函数在从g0切换到其它goroutine时首先切换了栈，然后通过跳转指令从runtime代码切换到了用户goroutine的代码，而mcall函数在从其它goroutine切换回g0时只切换了栈，并未使用跳转指令跳转到runtime代码去执行。为什么会有这个差别呢？原因在于在从g0切换到其它goroutine之前执行的是runtime的代码而且使用的是g0栈，所以切换时需要首先切换栈然后再从runtime代码跳转某个goroutine的代码去执行（切换栈和跳转指令不能颠倒，因为跳转之后执行的就是用户的goroutine代码了，没有机会切换栈了），然而从某个goroutine切换回g0时，goroutine使用的是call指令来调用mcall函数，mcall函数本身就是runtime的代码，所以call指令其实已经完成了从goroutine代码到runtime代码的跳转，因此mcall函数自身的代码就不需要再跳转了，只需要把栈切换到g0栈即可。
因为mcall跟gogo非常相似，前面我们对gogo的每一条指令已经做过详细的分析，所以这里就不再详细解释mcall的每一条指令了，但笔者在上面所展示的mcall代码中做了一些注释（注释中的g表示当前正在运行的goroutine，我们这个场景g就是g2），这里大家可以结合gogo的代码以及mcall的代码和注释来加深对g0与其它goroutine之间的切换的理解。
从g2栈切换到g0栈之后，下面开始在g0栈执行goexit0函数，该函数完成最后的清理工作：
把g的状态从_Grunning变更为_Gdead；
然后把g的一些字段清空成0值；
调用dropg函数解除g和m之间的关系，其实就是设置g-&amp;gt;m = nil, m-&amp;gt;currg = nil；
把g放入p的freeg队列缓存起来供下次创建g时快速获取而不用从内存分配。freeg就是g的一个对象池；
调用schedule函数再次进行调度；
runtime/proc.go : 2662    // goexit continuation on g0. func goexit0(gp *g) {  _g_ := getg() //g0   casgstatus(gp, _Grunning, _Gdead) //g马上退出，所以设置其状态为_Gdead  if isSystemGoroutine(gp, false) {  atomic.Xadd(&amp;amp;sched.ngsys, -1)  }   //清空g保存的一些信息  gp.m = nil  locked := gp.lockedm != 0  gp.lockedm = 0  _g_.m.lockedg = 0  gp.paniconfault = false  gp._defer = nil // should be true already but just in case.  gp._panic = nil // non-nil for Goexit during panic. points at stack-allocated data.  gp.writebuf = nil  gp.waitreason = 0  gp.param = nil  gp.labels = nil  gp.timer = nil   ......   // Note that gp&amp;#39;s stack scan is now &amp;#34;valid&amp;#34; because it has no  // stack.  gp.gcscanvalid = true   //g-&amp;gt;m = nil, m-&amp;gt;currg = nil 解绑g和m之关系  dropg()   ......   gfput(_g_.m.p.ptr(), gp) //g放入p的freeg队列，方便下次重用，免得再去申请内存，提高效率   ......   //下面再次调用schedule  schedule() } 到此为止g2的生命周期就结束了，工作线程再次调用了schedule函数进入新一轮的调度循环。
调度循环
我们说过，任何goroutine被调度起来运行都是通过schedule()-&amp;gt;execute()-&amp;gt;gogo()这个函数调用链完成的，而且这个调用链中的函数一直没有返回。以我们刚刚讨论过的g2 goroutine为例，从g2开始被调度起来运行到退出是沿着下面这条路径进行的
schedule()-&amp;gt;execute()-&amp;gt;gogo()-&amp;gt;g2()-&amp;gt;goexit()-&amp;gt;goexit1()-&amp;gt;mcall()-&amp;gt;goexit0()-&amp;gt;schedule() 可以看出，一轮调度是从调用schedule函数开始的，然后经过一系列代码的执行到最后又再次通过调用schedule函数来进行新一轮的调度，从一轮调度到新一轮调度的这一过程我们称之为一个调度循环，这里说的调度循环是指某一个工作线程的调度循环，而同一个Go程序中可能存在多个工作线程，每个工作线程都有自己的调度循环，也就是说每个工作线程都在进行着自己的调度循环。
从前面的代码分析可以得知，上面调度循环中的每一个函数调用都没有返回，虽然g2()-&amp;gt;goexit()-&amp;gt;goexit1()-&amp;gt;mcall()这几个函数是在g2的栈空间执行的，但剩下的函数都是在g0的栈空间执行的，那么问题就来了，在一个复杂的程序中，调度可能会进行无数次循环，也就是说会进行无数次没有返回的函数调用，大家都知道，每调用一次函数都会消耗一定的栈空间，而如果一直这样无返回的调用下去无论g0有多少栈空间终究是会耗尽的，那么这里是不是有问题？其实没有问题，关键点就在于，每次执行mcall切换到g0栈时都是切换到g0.sched.sp所指的固定位置，这之所以行得通，正是因为从schedule函数开始之后的一系列函数永远都不会返回，所以重用这些函数上一轮调度时所使用过的栈内存是没有问题的。
每个工作线程的执行流程和调度循环都一样，如下图所示：
总结
我们用上图来总结一下工作线程的执行流程：
初始化，调用mstart函数；
调用mstart1函数，在该函数中调用save函数设置g0.sched.sp和g0.sched.pc等调度信息，其中g0.sched.sp指向mstart函数栈帧的栈顶；
依次调用schedule-&amp;gt;execute-&amp;gt;gogo函数执行调度；
运行用户的goroutine代码；
用户goroutine代码执行过程中调用runtime中的某些函数，然后这些函数调用mcall切换到g0.sched.sp所指的栈并最终再次调用schedule函数进入新一轮调度，之后工作线程一直循环执行着3～5这一调度循环直到进程退出为止。
最后，如果你觉得本文对你有帮助的话，麻烦帮忙点一下文末右下角的 在看 或转发到朋友圈，非常感谢！
</content>
    </entry>
    
     <entry>
        <title>go语言调度器之调度main goroutine（14)</title>
        <url>http://shanks.link/blog/2021/04/03/go%E8%AF%AD%E8%A8%80%E8%B0%83%E5%BA%A6%E5%99%A8%E4%B9%8B%E8%B0%83%E5%BA%A6main-goroutine14/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 爱写程序的阿波张 源码游记 2019-05-09
本文是《Go语言调度器源代码情景分析》系列的第14篇，也是第二章的第4小节
上一节我们通过分析main goroutine的创建详细讨论了goroutine的创建及初始化流程，这一节我们接着来分析调度器如何把main goroutine调度到CPU上去运行。本节需要重点关注的问题有：
如何保存g0的调度信息？
schedule函数有什么重要作用？
gogo函数如何完成从g0到main goroutine的切换？
接着前一节继续分析代码，从newproc返回到rt0_go，继续往下执行mstart。
runtime/proc.go : 1153   func mstart() {  _g_ := getg() //_g_ = g0   //对于启动过程来说，g0的stack.lo早已完成初始化，所以onStack = false  osStack := _g_.stack.lo == 0  if osStack {  // Initialize stack bounds from system stack.  // Cgo may have left stack size in stack.hi.  // minit may update the stack bounds.  size := _g_.stack.hi  if size == 0 {  size = 8192 * sys.StackGuardMultiplier  }  _g_.stack.hi = uintptr(noescape(unsafe.Pointer(&amp;amp;size)))  _g_.stack.lo = _g_.stack.hi - size &#43; 1024  }  // Initialize stack guards so that we can start calling  // both Go and C functions with stack growth prologues.  _g_.stackguard0 = _g_.stack.lo &#43; _StackGuard  _g_.stackguard1 = _g_.stackguard0   mstart1()   // Exit this thread.  if GOOS == &amp;#34;windows&amp;#34; || GOOS == &amp;#34;solaris&amp;#34; || GOOS == &amp;#34;plan9&amp;#34; || GOOS == &amp;#34;darwin&amp;#34; || GOOS == &amp;#34;aix&amp;#34; {  // Window, Solaris, Darwin, AIX and Plan 9 always system-allocate  // the stack, but put it in _g_.stack before mstart,  // so the logic above hasn&amp;#39;t set osStack yet.  osStack = true  }  mexit(osStack) } mstart函数本身没啥说的，它继续调用mstart1函数。
runtime/proc.go : 1184   func mstart1() {  _g_ := getg() //启动过程时 _g_ = m0的g0   if _g_ != _g_.m.g0 {  throw(&amp;#34;bad runtime·mstart&amp;#34;)  }   // Record the caller for use as the top of stack in mcall and  // for terminating the thread.  // We&amp;#39;re never coming back to mstart1 after we call schedule,  // so other calls can reuse the current frame.  //getcallerpc()获取mstart1执行完的返回地址  //getcallersp()获取调用mstart1时的栈顶地址  save(getcallerpc(), getcallersp())  asminit() //在AMD64 Linux平台中，这个函数什么也没做，是个空函数  minit() //与信号相关的初始化，目前不需要关心   // Install signal handlers; after minit so that minit can  // prepare the thread to be able to handle the signals.  if _g_.m == &amp;amp;m0 { //启动时_g_.m是m0，所以会执行下面的mstartm0函数  mstartm0() //也是信号相关的初始化，现在我们不关注  }   if fn := _g_.m.mstartfn; fn != nil { //初始化过程中fn == nil  fn()  }   if _g_.m != &amp;amp;m0 {// m0已经绑定了allp[0]，不是m0的话还没有p，所以需要获取一个p  acquirep(_g_.m.nextp.ptr())  _g_.m.nextp = 0  }   //schedule函数永远不会返回  schedule() } mstart1首先调用save函数来保存g0的调度信息，save这一行代码非常重要，是我们理解调度循环的关键点之一。这里首先需要注意的是代码中的getcallerpc()返回的是mstart调用mstart1时被call指令压栈的返回地址，getcallersp()函数返回的是调用mstart1函数之前mstart函数的栈顶地址，其次需要看看save函数到底做了哪些重要工作。
runtime/proc.go : 2733   // save updates getg().sched to refer to pc and sp so that a following  // gogo will restore pc and sp. // // save must not have write barriers because invoking a write barrier // can clobber getg().sched. // //go:nosplit //go:nowritebarrierrec func save(pc, sp uintptr) {  _g_ := getg()   _g_.sched.pc = pc //再次运行时的指令地址  _g_.sched.sp = sp //再次运行时到栈顶  _g_.sched.lr = 0  _g_.sched.ret = 0  _g_.sched.g = guintptr(unsafe.Pointer(_g_))  // We need to ensure ctxt is zero, but can&amp;#39;t have a write  // barrier here. However, it should always already be zero.  // Assert that.  if _g_.sched.ctxt != nil {  badctxt()  } } 可以看到，save函数保存了调度相关的所有信息，包括最为重要的当前正在运行的g的下一条指令的地址和栈顶地址，不管是对g0还是其它goroutine来说这些信息在调度过程中都是必不可少的，我们会在后面的调度分析中看到调度器是如何利用这些信息来完成调度的。代码执行完save函数之后g0的状态如下图所示：
从上图可以看出，g0.sched.sp指向了mstart1函数执行完成后的返回地址，该地址保存在了mstart函数的栈帧之中；g0.sched.pc指向的是mstart函数中调用mstart1函数之后的 if 语句。
为什么g0已经执行到mstart1这个函数了而且还会继续调用其它函数，但g0的调度信息中的pc和sp却要设置在mstart函数中？难道下次切换到g0时要从mstart函数中的 if 语句继续执行？可是从mstart函数可以看到，if语句之后就要退出线程了！这看起来很奇怪，不过随着分析的进行，我们会看到这里为什么要这么做。
继续分析代码，save函数执行完成后，返回到mstart1继续其它跟m相关的一些初始化，完成这些初始化后则调用调度系统的核心函数schedule()完成goroutine的调度，之所以说它是核心，原因在于每次调度goroutine都是从schedule函数开始的。
runtime/proc.go : 2469   // One round of scheduler: find a runnable goroutine and execute it.  // Never returns. func schedule() {  _g_ := getg() //_g_ = 每个工作线程m对应的g0，初始化时是m0的g0   //......   var gp *g   //......   if gp == nil {  // Check the global runnable queue once in a while to ensure fairness.  // Otherwise two goroutines can completely occupy the local runqueue  // by constantly respawning each other.  //为了保证调度的公平性，每进行61次调度就需要优先从全局运行队列中获取goroutine，  //因为如果只调度本地队列中的g，那么全局运行队列中的goroutine将得不到运行  if _g_.m.p.ptr().schedtick%61 == 0 &amp;amp;&amp;amp; sched.runqsize &amp;gt; 0 {  lock(&amp;amp;sched.lock) //所有工作线程都能访问全局运行队列，所以需要加锁  gp = globrunqget(_g_.m.p.ptr(), 1) //从全局运行队列中获取1个goroutine  unlock(&amp;amp;sched.lock)  }  }  if gp == nil {  //从与m关联的p的本地运行队列中获取goroutine  gp, inheritTime = runqget(_g_.m.p.ptr())  if gp != nil &amp;amp;&amp;amp; _g_.m.spinning {  throw(&amp;#34;schedule: spinning with local work&amp;#34;)  }  }  if gp == nil {  //如果从本地运行队列和全局运行队列都没有找到需要运行的goroutine，  //则调用findrunnable函数从其它工作线程的运行队列中偷取，如果偷取不到，则当前工作线程进入睡眠，  //直到获取到需要运行的goroutine之后findrunnable函数才会返回。  gp, inheritTime = findrunnable() // blocks until work is available  }   //跟启动无关的代码.....   //当前运行的是runtime的代码，函数调用栈使用的是g0的栈空间  //调用execte切换到gp的代码和栈空间去运行  execute(gp, inheritTime) } schedule函数通过调用globrunqget()和runqget()函数分别从全局运行队列和当前工作线程的本地运行队列中选取下一个需要运行的goroutine，如果这两个队列都没有需要运行的goroutine则通过findrunnalbe()函数从其它p的运行队列中盗取goroutine，一旦找到下一个需要运行的goroutine，则调用excute函数从g0切换到该goroutine去运行。对于我们这个场景来说，前面的启动流程已经创建好第一个goroutine并放入了当前工作线程的本地运行队列，所以这里会通过runqget把目前唯一的一个goroutine取出来，至于具体是如何取出来的，我们将在第三章讨论调度策略时再回头来详细分析globrunqget()，runqget()和findrunnable()这三个函数的实现流程，现在我们先来分析execute函数是如何把从运行队列中找出来的goroutine调度到CPU上运行的。
runtime/proc.go : 2136   // Schedules gp to run on the current M.  // If inheritTime is true, gp inherits the remaining time in the // current time slice. Otherwise, it starts a new time slice. // Never returns. // // Write barriers are allowed because this is called immediately after // acquiring a P in several places. // //go:yeswritebarrierrec func execute(gp *g, inheritTime bool) {  _g_ := getg() //g0   //设置待运行g的状态为_Grunning  casgstatus(gp, _Grunnable, _Grunning)   //......   //把g和m关联起来  _g_.m.curg = gp  gp.m = _g_.m   //......   //gogo完成从g0到gp真正的切换  gogo(&amp;amp;gp.sched) } execute函数的第一个参数gp即是需要调度起来运行的goroutine，这里首先把gp的状态从_Grunnable修改为_Grunning，然后把gp和m关联起来，这样通过m就可以找到当前工作线程正在执行哪个goroutine，反之亦然。
完成gp运行前的准备工作之后，execute调用gogo函数完成从g0到gp的的切换：CPU执行权的转让以及栈的切换。
gogo函数也是通过汇编语言编写的，这里之所以需要使用汇编，是因为goroutine的调度涉及不同执行流之间的切换，前面我们在讨论操作系统切换线程时已经看到过，执行流的切换从本质上来说就是CPU寄存器以及函数调用栈的切换，然而不管是go还是c这种高级语言都无法精确控制CPU寄存器的修改，因而高级语言在这里也就无能为力了，只能依靠汇编指令来达成目的。
runtime/asm_amd64.s : 251   # func gogo(buf *gobuf)  # restore state from Gobuf; longjmp TEXT runtime·gogo(SB), NOSPLIT, $16-8  #buf = &amp;amp;gp.sched  MOVQ buf&#43;0(FP), BX # BX = buf   #gobuf-&amp;gt;g --&amp;gt; dx register  MOVQ gobuf_g(BX), DX # DX = gp.sched.g   #下面这行代码没有实质作用，检查gp.sched.g是否是nil，如果是nil进程会crash死掉  MOVQ 0(DX), CX # make sure g != nil   get_tls(CX)   #把要运行的g的指针放入线程本地存储，这样后面的代码就可以通过线程本地存储  #获取到当前正在执行的goroutine的g结构体对象，从而找到与之关联的m和p  MOVQ DX, g(CX)   #把CPU的SP寄存器设置为sched.sp，完成了栈的切换  MOVQ gobuf_sp(BX), SP # restore SP   #下面三条同样是恢复调度上下文到CPU相关寄存器  MOVQ gobuf_ret(BX), AX  MOVQ gobuf_ctxt(BX), DX  MOVQ gobuf_bp(BX), BP   #清空sched的值，因为我们已把相关值放入CPU对应的寄存器了，不再需要，这样做可以少gc的工作量  MOVQ $0, gobuf_sp(BX) # clear to help garbage collector  MOVQ $0, gobuf_ret(BX)  MOVQ $0, gobuf_ctxt(BX)  MOVQ $0, gobuf_bp(BX)   #把sched.pc值放入BX寄存器  MOVQ gobuf_pc(BX), BX   #JMP把BX寄存器的包含的地址值放入CPU的IP寄存器，于是，CPU跳转到该地址继续执行指令，  JMP BX gogo函数的这段汇编代码短小而强悍，虽然笔者已经在代码中做了详细的注释，但为了完全搞清楚它的工作原理，我们有必要再对这些指令进行逐条分析：
execute函数在调用gogo时把gp的sched成员的地址作为实参（型参buf）传递了过来，该参数位于FP寄存器所指的位置，所以第1条指令
MOVQ buf&#43;0(FP), BX # &amp;amp;gp.sched &amp;ndash;&amp;gt; BX
把buf的值也就是gp.sched的地址放在了BX寄存器之中，这样便于后面的指令依靠BX寄存器来存取gp.sched的成员。sched成员保存了调度相关的信息，上一节我们已经看到，main goroutine创建时已经把这些信息设置好了。
第2条指令
MOVQ gobuf_g(BX), DX # gp.sched.g &amp;ndash;&amp;gt; DX
把gp.sched.g读取到DX寄存器，注意这条指令的源操作数是间接寻址，如果读者对间接寻址不熟悉的话可以参考预备知识汇编语言部分。
第3条指令
MOVQ 0(DX), CX # make sure g != nil
的作用在于检查gp.sched.g是否为nil，如果为nil指针的话，这条指令会导致程序死掉，有读者可能会有疑问，为什么要让它死掉啊，原因在于这个gp.sched.g是由go runtime代码负责设置的，按道理说不可能为nil，如果为nil，一定是程序逻辑写得有问题，所以需要把这个bug暴露出来，而不是把它隐藏起来。
第4条和第5条指令
get_tls(CX)
#把DX值也就是需要运行的goroutine的指针写入线程本地存储之中 #运行这条指令之前，线程本地存储存放的是g0的地址 MOVQ DX, g(CX) 把DX寄存器的值也就是gp.sched.g(这是一个指向g的指针)写入线程本地存储之中，这样后面的代码就可以通过线程本地存储获取到当前正在执行的goroutine的g结构体对象，从而找到与之关联的m和p。
第6条指令
MOVQ gobuf_sp(BX), SP # restore SP
设置CPU的栈顶寄存器SP为gp.sched.sp，这条指令完成了栈的切换，从g0的栈切换到了gp的栈。
第7～13条指令
#下面三条同样是恢复调度上下文到CPU相关寄存器
MOVQ gobuf_ret(BX), AX #系统调用的返回值放入AX寄存器 MOVQ gobuf_ctxt(BX), DX MOVQ gobuf_bp(BX), BP
//清空gp.sched中不再需要的值，因为我们已把相关值放入CPU对应的寄存器了，不再需要，这样做可以少gc的工作量 MOVQ $0, gobuf_sp(BX) // clear to help garbage collector MOVQ $0, gobuf_ret(BX) MOVQ $0, gobuf_ctxt(BX) MOVQ $0, gobuf_bp(BX) 一是根据gp.sched其它字段设置CPU相关寄存器，可以看到这里恢复了CPU的栈基地址寄存器BP，二是把gp.sched中已经不需要的成员设置为0，这样可以减少gc的工作量。
第14条指令
MOVQ gobuf_pc(BX), BX
把gp.sched.pc的值读取到BX寄存器，这个pc值是gp这个goroutine马上需要执行的第一条指令的地址，对于我们这个场景来说它现在就是runtime.main函数的第一条指令，现在这条指令的地址就放在BX寄存器里面。最后一条指令
JMP BX
这里的JMP BX指令把BX寄存器里面的指令地址放入CPU的rip寄存器，于是，CPU就会跳转到该地址继续执行属于gp这个goroutine的代码，这样就完成了goroutine的切换。
总结一下这15条指令，其实就只做了两件事：
把gp.sched的成员恢复到CPU的寄存器完成状态以及栈的切换；
跳转到gp.sched.pc所指的指令地址（runtime.main）处执行。
现在已经从g0切换到了gp这个goroutine，对于我们这个场景来说，gp还是第一次被调度起来运行，它的入口函数是runtime.main，所以接下来CPU就开始执行runtime.main函数：
runtime/proc.go : 109   // The main goroutine.  func main() {  g := getg() // g = main goroutine，不再是g0了   ......   // Max stack size is 1 GB on 64-bit, 250 MB on 32-bit.  // Using decimal instead of binary GB and MB because  // they look nicer in the stack overflow failure message.  if sys.PtrSize == 8 { //64位系统上每个goroutine的栈最大可达1G  maxstacksize = 1000000000  } else {  maxstacksize = 250000000  }   // Allow newproc to start new Ms.  mainStarted = true   if GOARCH != &amp;#34;wasm&amp;#34; { // no threads on wasm yet, so no sysmon  //现在执行的是main goroutine，所以使用的是main goroutine的栈，需要切换到g0栈去执行newm()  systemstack(func() {  //创建监控线程，该线程独立于调度器，不需要跟p关联即可运行  newm(sysmon, nil)  })  }   ......   //调用runtime包的初始化函数，由编译器实现  runtime_init() // must be before defer   // Record when the world started.  runtimeInitTime = nanotime()   gcenable() //开启垃圾回收器   ......   //main 包的初始化函数，也是由编译器实现，会递归的调用我们import进来的包的初始化函数  fn := main_init // make an indirect call, as the linker doesn&amp;#39;t know the address of the main package when laying down the runtime  fn()   ......   //调用main.main函数  fn = main_main // make an indirect call, as the linker doesn&amp;#39;t know the address of the main package when laying down the runtime  fn()   ......   //进入系统调用，退出进程，可以看出main goroutine并未返回，而是直接进入系统调用退出进程了  exit(0)   //保护性代码，如果exit意外返回，下面的代码也会让该进程crash死掉  for {  var x *int32  *x = 0  } } runtime.main函数主要工作流程如下：
启动一个sysmon系统监控线程，该线程负责整个程序的gc、抢占调度以及netpoll等功能的监控，在抢占调度一章我们再继续分析sysmon是如何协助完成goroutine的抢占调度的；
执行runtime包的初始化；
执行main包以及main包import的所有包的初始化；
执行main.main函数；
从main.main函数返回后调用exit系统调用退出进程；
从上述流程可以看出，runtime.main执行完main包的main函数之后就直接调用exit系统调用结束进程了，它并没有返回到调用它的函数（还记得是从哪里开始执行的runtime.main吗？），其实runtime.main是main goroutine的入口函数，并不是直接被调用的，而是在schedule()-&amp;gt;execute()-&amp;gt;gogo()这个调用链的gogo函数中用汇编代码直接跳转过来的，所以从这个角度来说，goroutine确实不应该返回，没有地方可返回啊！可是从前面的分析中我们得知，在创建goroutine的时候已经在其栈上放好了一个返回地址，伪造成goexit函数调用了goroutine的入口函数，这里怎么没有用到这个返回地址啊？其实那是为非main goroutine准备的，非main goroutine执行完成后就会返回到goexit继续执行，而main goroutine执行完成后整个进程就结束了，这是main goroutine与其它goroutine的一个区别。
总结一下从g0切换到main goroutine的流程：
保存g0的调度信息，主要是保存CPU栈顶寄存器SP到g0.sched.sp成员之中；
调用schedule函数寻找需要运行的goroutine，我们这个场景找到的是main goroutine;
调用gogo函数首先从g0栈切换到main goroutine的栈，然后从main goroutine的g结构体对象之中取出sched.pc的值并使用JMP指令跳转到该地址去执行；
main goroutine执行完毕直接调用exit系统调用退出进程。
下一节我们将用例子来分析非main goroutine的退出。
最后，如果你觉得本文对你有帮助的话，麻烦帮忙点一下文末右下角的 在看 或转发到朋友圈，非常感谢！
</content>
    </entry>
    
     <entry>
        <title>go语言调度器之创建main goroutine(13)</title>
        <url>http://shanks.link/blog/2021/04/03/go%E8%AF%AD%E8%A8%80%E8%B0%83%E5%BA%A6%E5%99%A8%E4%B9%8B%E5%88%9B%E5%BB%BAmain-goroutine13/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 爱写程序的阿波张 源码游记
本文是《Go语言调度器源代码情景分析》系列的第13篇，也是第二章的第3小节。
上一节我们分析了调度器的初始化，这一节我们来看程序中的第一个goroutine是如何创建的。
创建main goroutine 接上一节，schedinit完成调度系统初始化后，返回到rt0_go函数中开始调用newproc() 创建一个新的goroutine用于执行mainPC所对应的runtime·main函数，看下面的代码：
runtime/asm_amd64.s : 197  # create a new goroutine to start program MOVQ $runtime·mainPC(SB), AX # entry，mainPC是runtime.main # newproc的第二个参数入栈，也就是新的goroutine需要执行的函数 PUSHQ AX # AX = &amp;amp;funcval{runtime·main},  # newproc的第一个参数入栈，该参数表示runtime.main函数需要的参数大小，因为runtime.main没有参数，所以这里是0 PUSHQ $0 CALL runtime·newproc(SB) # 创建main goroutine POPQ AX POPQ AX  # start this M CALL runtime·mstart(SB) # 主线程进入调度循环，运行刚刚创建的goroutine  # 上面的mstart永远不应该返回的，如果返回了，一定是代码逻辑有问题，直接abort CALL runtime·abort(SB)// mstart should never return RET  DATA runtime·mainPC&#43;0(SB)/8,$runtime·main(SB) GLOB Lruntime·mainPC(SB),RODATA,$8 在后面的分析过程中我们会看到这个runtime.main最终会调用我们写的main.main函数，在分析runtime·main之前我们先把重点放在newproc这个函数上。
newproc函数用于创建新的goroutine，它有两个参数，先说第二个参数fn，新创建出来的goroutine将从fn这个函数开始执行，而这个fn函数可能也会有参数，newproc的第一个参数正是fn函数的参数以字节为单位的大小。比如有如下go代码片段：
func start(a, b, c int64) {  ...... }  func main() {  go start(1, 2, 3) } 编译器在编译上面的go语句时，就会把其替换为对newproc函数的调用，编译后的代码逻辑上等同于下面的伪代码
func main() {  push 0x3  push 0x2  push 0x1  runtime.newproc(24, start) } 编译器编译时首先会用几条指令把start函数需要用到的3个参数压栈，然后调用newproc函数。因为start函数的3个int64类型的参数共占24个字节，所以传递给newproc的第一个参数是24，表示start函数需要24字节大小的参数。
那为什么需要传递fn函数的参数大小给newproc函数呢？原因就在于newproc函数将创建一个新的goroutine来执行fn函数，而这个新创建的goroutine与当前这个goroutine会使用不同的栈，因此就需要在创建goroutine的时候把fn需要用到的参数先从当前goroutine的栈上拷贝到新的goroutine的栈上之后才能让其开始执行，而newproc函数本身并不知道需要拷贝多少数据到新创建的goroutine的栈上去，所以需要用参数的方式指定拷贝多少数据。
了解完这些背景知识之后，下面我们开始分析newproc的代码。newproc函数是对newproc1的一个包装，这里最重要的准备工作有两个，一个是获取fn函数第一个参数的地址（代码中的argp），另一个是使用systemstack函数切换到g0栈，当然，对于我们这个初始化场景来说现在本来就在g0栈，所以不需要切换，然而这个函数是通用的，在用户的goroutine中也会创建goroutine，这时就需要进行栈的切换。
runtime/proc.go : 3232  // Create a new g running fn with siz bytes of arguments. // Put it on the queue of g&amp;#39;s waiting to run. // The compiler turns a go statement into a call to this. // Cannot split the stack because it assumes that the arguments // are available sequentially after &amp;amp;fn; they would not be // copied if a stack split occurred. //go:nosplit func newproc(siz int32, fn *funcval) {  //函数调用参数入栈顺序是从右向左，而且栈是从高地址向低地址增长的  //注意：argp指向fn函数的第一个参数，而不是newproc函数的参数  //参数fn在栈上的地址&#43;8的位置存放的是fn函数的第一个参数  argp := add(unsafe.Pointer(&amp;amp;fn), sys.PtrSize)  gp := getg() //获取正在运行的g，初始化时是m0.g0   //getcallerpc()返回一个地址，也就是调用newproc时由call指令压栈的函数返回地址，  //对于我们现在这个场景来说，pc就是CALLruntime·newproc(SB)指令后面的POPQ AX这条指令的地址  pc := getcallerpc()   //systemstack的作用是切换到g0栈执行作为参数的函数  //我们这个场景现在本身就在g0栈，因此什么也不做，直接调用作为参数的函数  systemstack(func() {  newproc1(fn, (*uint8)(argp), siz, gp, pc)  }) } newproc1函数的第一个参数fn是新创建的goroutine需要执行的函数，注意这个fn的类型是funcval结构体类型，其定义如下：  type funcval struct {  fn uintptr  // variable-size, fn-specific data here } newproc1的第二个参数argp是fn函数的第一个参数的地址，第三个参数是fn函数的参数以字节为单位的大小，后面两个参数我们不用关心。这里需要注意的是，newproc1是在g0的栈上执行的。该函数很长也很重要，所以我们分段来看。
runtime/proc.go : 3248  // Create a new g running fn with narg bytes of arguments starting // at argp. callerpc is the address of the go statement that created // this. The new g is put on the queue of g&amp;#39;s waiting to run. func newproc1(fn *funcval, argp *uint8, narg int32, callergp *g, callerpc uintptr) {  //因为已经切换到g0栈，所以无论什么场景都有 _g_ = g0，当然这个g0是指当前工作线程的g0  //对于我们这个场景来说，当前工作线程是主线程，所以这里的g0 = m0.g0  _g_ := getg()   ......   _p_ := _g_.m.p.ptr() //初始化时_p_ = g0.m.p，从前面的分析可以知道其实就是allp[0]  newg := gfget(_p_) //从p的本地缓冲里获取一个没有使用的g，初始化时没有，返回nil  if newg == nil {  //new一个g结构体对象，然后从堆上为其分配栈，并设置g的stack成员和两个stackgard成员  newg = malg(_StackMin)  casgstatus(newg, _Gidle, _Gdead) //初始化g的状态为_Gdead  //放入全局变量allgs切片中  allgadd(newg) // publishes with a g-&amp;gt;status of Gdead so GC scanner doesn&amp;#39;t look at uninitialized stack.  }   ......   //调整g的栈顶置针，无需关注  totalSize := 4*sys.RegSize &#43; uintptr(siz) &#43; sys.MinFrameSize // extra space in case of reads slightly beyond frame  totalSize &#43;= -totalSize &amp;amp; (sys.SpAlign - 1) // align to spAlign  sp := newg.stack.hi - totalSize  spArg := sp   //......   if narg &amp;gt; 0 {  //把参数从执行newproc函数的栈（初始化时是g0栈）拷贝到新g的栈  memmove(unsafe.Pointer(spArg), unsafe.Pointer(argp), uintptr(narg))  // ......  } 这段代码主要从堆上分配一个g结构体对象并为这个newg分配一个大小为2048字节的栈，并设置好newg的stack成员，然后把newg需要执行的函数的参数从执行newproc函数的栈（初始化时是g0栈）拷贝到newg的栈，完成这些事情之后newg的状态如下图所示：
我们可以看到，经过前面的代码之后，程序中多了一个我们称之为newg的g结构体对象，该对象也已经获得了从堆上分配而来的2k大小的栈空间，newg的stack.hi和stack.lo分别指向了其栈空间的起止位置。
接下来我们继续分析newproc1函数。
runtime/proc.go : 3314   //把newg.sched结构体成员的所有成员设置为0  memclrNoHeapPointers(unsafe.Pointer(&amp;amp;newg.sched), unsafe.Sizeof(newg.sched))   //设置newg的sched成员，调度器需要依靠这些字段才能把goroutine调度到CPU上运行。  newg.sched.sp = sp //newg的栈顶  newg.stktopsp = sp  //newg.sched.pc表示当newg被调度起来运行时从这个地址开始执行指令  //把pc设置成了goexit这个函数偏移1（sys.PCQuantum等于1）的位置，  //至于为什么要这么做需要等到分析完gostartcallfn函数才知道  newg.sched.pc = funcPC(goexit) &#43; sys.PCQuantum // &#43;PCQuantum so that previous instruction is in same function  newg.sched.g = guintptr(unsafe.Pointer(newg))   gostartcallfn(&amp;amp;newg.sched, fn) //调整sched成员和newg的栈 这段代码首先对newg的sched成员进行了初始化，该成员包含了调度器代码在调度goroutine到CPU运行时所必须的一些信息，其中sched的sp成员表示newg被调度起来运行时应该使用的栈的栈顶，sched的pc成员表示当newg被调度起来运行时从这个地址开始执行指令，然而从上面的代码可以看到，new.sched.pc被设置成了goexit函数的第二条指令的地址而不是fn.fn，这是为什么呢？要回答这个问题，必须深入到gostartcallfn函数中做进一步分析。  // adjust Gobuf as if it executed a call to fn // and then did an immediate gosave. func gostartcallfn(gobuf *gobuf, fv *funcval) {  var fn unsafe.Pointer  if fv != nil {  fn = unsafe.Pointer(fv.fn) //fn: gorotine的入口地址，初始化时对应的是runtime.main  } else {  fn = unsafe.Pointer(funcPC(nilfunc))  }  gostartcall(gobuf, fn, unsafe.Pointer(fv)) } gostartcallfn首先从参数fv中提取出函数地址（初始化时是runtime.main），然后继续调用gostartcall函数。
// adjust Gobuf as if it executed a call to fn with context ctxt // and then did an immediate gosave. func gostartcall(buf *gobuf, fn, ctxt unsafe.Pointer) {  sp := buf.sp //newg的栈顶，目前newg栈上只有fn函数的参数，sp指向的是fn的第一参数  if sys.RegSize &amp;gt; sys.PtrSize {  sp -= sys.PtrSize  *(*uintptr)(unsafe.Pointer(sp)) = 0  }  sp -= sys.PtrSize //为返回地址预留空间，  //这里在伪装fn是被goexit函数调用的，使得fn执行完后返回到goexit继续执行，从而完成清理工作  *(*uintptr)(unsafe.Pointer(sp)) = buf.pc //在栈上放入goexit&#43;1的地址  buf.sp = sp //重新设置newg的栈顶寄存器  //这里才真正让newg的ip寄存器指向fn函数，注意，这里只是在设置newg的一些信息，newg还未执行，  //等到newg被调度起来运行时，调度器会把buf.pc放入cpu的IP寄存器，  //从而使newg得以在cpu上真正的运行起来  buf.pc = uintptr(fn)  buf.ctxt = ctxt } gostartcall函数的主要作用有两个：
调整newg的栈空间，把goexit函数的第二条指令的地址入栈，伪造成goexit函数调用了fn，从而使fn执行完成后执行ret指令时返回到goexit继续执行完成最后的清理工作；
重新设置newg.buf.pc 为需要执行的函数的地址，即fn，我们这个场景为runtime.main函数的地址。
调整完成newg的栈和sched成员之后，返回到newproc1函数，我们继续往下看，
 newg.gopc = callerpc //主要用于traceback  newg.ancestors = saveAncestors(callergp)  //设置newg的startpc为fn.fn，该成员主要用于函数调用栈的traceback和栈收缩  //newg真正从哪里开始执行并不依赖于这个成员，而是sched.pc  newg.startpc = fn.fn   ......   //设置g的状态为_Grunnable，表示这个g代表的goroutine可以运行了  casgstatus(newg, _Gdead, _Grunnable)   ......   //把newg放入_p_的运行队列，初始化的时候一定是p的本地运行队列，其它时候可能因为本地队列满了而放入全局队列  runqput(_p_, newg, true)   ...... } newproc1函数最后这点代码比较直观，首先设置了几个与调度无关的成员变量，然后修改newg的状态为_Grunnable并把其放入了运行队列，到此程序中第一个真正意义上的goroutine已经创建完成。
这时newg也就是main goroutine的状态如下图所示：
这个图看起来比较复杂，因为表示指针的箭头实在是太多了，这里对其稍作一下解释。
首先，main goroutine对应的newg结构体对象的sched成员已经完成了初始化，图中只显示了pc和sp成员，pc成员指向了runtime.main函数的第一条指令，sp成员指向了newg的栈顶内存单元，该内存单元保存了runtime.main函数执行完成之后的返回地址，也就是runtime.goexit函数的第二条指令，预期runtime.main函数执行完返回之后就会去执行runtime.exit函数的CALL runtime.goexit1(SB)这条指令；
其次，newg已经放入与当前主线程绑定的p结构体对象的本地运行队列，因为它是第一个真正意义上的goroutine，还没有其它goroutine，所以它被放在了本地运行队列的头部；
最后，newg的m成员为nil，因为它还没有被调度起来运行，也就没有跟任何m进行绑定。
这一节我们分析了程序中第一个goroutine也就是main goroutine的创建，下一节我们继续分析它是怎么被主工作线程调度到CPU上去执行的。
最后，如果你觉得本文对你有帮助的话，麻烦帮忙点一下文末右下角的 在看 或转发到朋友圈，非常感谢！
</content>
    </entry>
    
     <entry>
        <title>go语言goroutine调度器初始化 十二</title>
        <url>http://shanks.link/blog/2021/04/03/go%E8%AF%AD%E8%A8%80goroutine%E8%B0%83%E5%BA%A6%E5%99%A8%E5%88%9D%E5%A7%8B%E5%8C%96-%E5%8D%81%E4%BA%8C/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 爱写程序的阿波张 源码游记 2019-05-05
本文是《Go语言调度器源代码情景分析》系列的第12篇，也是第二章的第2小节。 本章将以下面这个简单的Hello World程序为例，通过跟踪其从启动到退出这一完整的运行流程来分析Go语言调度器的初始化、goroutine的创建与退出、工作线程的调度循环以及goroutine的切换等重要内容。
package main  import &amp;#34;fmt&amp;#34;  func main() {  fmt.Println(&amp;#34;Hello World!&amp;#34;) } 首先我们从程序启动开始分析调度器的初始化。
在分析程序的启动过程之前，我们首先来看看程序在执行第一条指令之前其栈的初始状态。
任何一个由编译型语言（不管是C，C&#43;&#43;，go还是汇编语言）所编写的程序在被操作系统加载起来运行时都会顺序经过如下几个阶段：
从磁盘上把可执行程序读入内存；
创建进程和主线程；
为主线程分配栈空间；
把由用户在命令行输入的参数拷贝到主线程的栈；
把主线程放入操作系统的运行队列等待被调度执起来运行。
在主线程第一次被调度起来执行第一条指令之前，主线程的函数栈如下图所示：
了解了程序的初始状态之后，下面我们正式开始。
程序入口
在Linux命令行用 go build 编译hello.go，得到可执行程序hello，然后使用gdb调试，在gdb中我们首先使用 info files 命令找到程序入口（Entry point）地址为0x452270，然后用 b *0x452270 在0x452270地址处下个断点，gdb告诉我们这个入口对应的源代码为 runtime/rt0_linux_amd64.s 文件的第8行。
bobo@ubuntu:~/study/go$ go build hello.go bobo@ubuntu:~/study/go$ gdb hello GNU gdb (GDB) 8.0.1 (gdb) info files Symbols from &amp;#34;/home/bobo/study/go/main&amp;#34;. Local exec file: `/home/bobo/study/go/main&amp;#39;, file type elf64-x86-64. Entry point: 0x452270 0x0000000000401000 - 0x0000000000486aac is .text 0x0000000000487000 - 0x00000000004d1a73 is .rodata 0x00000000004d1c20 - 0x00000000004d27f0 is .typelink 0x00000000004d27f0 - 0x00000000004d2838 is .itablink 0x00000000004d2838 - 0x00000000004d2838 is .gosymtab 0x00000000004d2840 - 0x00000000005426d9 is .gopclntab 0x0000000000543000 - 0x000000000054fa9c is .noptrdata 0x000000000054faa0 - 0x0000000000556790 is .data 0x00000000005567a0 - 0x0000000000571ef0 is .bss 0x0000000000571f00 - 0x0000000000574658 is .noptrbss 0x0000000000400f9c - 0x0000000000401000 is .note.go.buildid (gdb) b *0x452270 Breakpoint 1 at 0x452270: file /usr/local/go/src/runtime/rt0_linux_amd64.s, line 8. 打开代码编辑器，找到 runtime/rt0_linx_amd64.s 文件，该文件是用go汇编语言编写而成的源代码文件，我们已经在本书的第一部分讨论过其格式。现在看看第8行：
runtime/rt0_linx_amd64.s : 8  TEXT _rt0_amd64_linux(SB),NOSPLIT,$-8  JMP_rt0_amd64(SB) 上面第一行代码定义了_rt0_amd64_linux这个符号，并不是真正的CPU指令，第二行的JMP指令才是主线程的第一条指令，这条指令简单的跳转到（相当于go语言或c中的goto）_rt0_amd64 这个符号处继续执行，_rt0_amd64 这个符号的定义在runtime/asm_amd64.s 文件中：
runtime/asm_amd64.s : 14  TEXT _rt0_amd64(SB),NOSPLIT,$-8  MOVQ0(SP), DI// argc  LEAQ8(SP), SI // argv  JMPruntime·rt0_go(SB) 前两行指令把操作系统内核传递过来的参数argc和argv数组的地址分别放在DI和SI寄存器中，第三行指令跳转到 rt0_go 去执行。
rt0_go函数完成了go程序启动时的所有初始化工作，因此这个函数比较长，也比较繁杂，但这里我们只关注与调度器相关的一些初始化，下面我们分段来看：
runtime/asm_amd64.s : 87  TEXT runtime·rt0_go(SB),NOSPLIT,$0  // copy arguments forward on an even stack  MOVQDI, AX// AX = argc  MOVQSI, BX// BX = argv  SUBQ$(4*8&#43;7), SP// 2args 2auto  ANDQ$~15, SP //调整栈顶寄存器使其按16字节对齐  MOVQAX, 16(SP) //argc放在SP &#43; 16字节处  MOVQBX, 24(SP) //argv放在SP &#43; 24字节处 上面的第4条指令用于调整栈顶寄存器的值使其按16字节对齐，也就是让栈顶寄存器SP指向的内存的地址为16的倍数，之所以要按16字节对齐，是因为CPU有一组SSE指令，这些指令中出现的内存地址必须是16的倍数，最后两条指令把argc和argv搬到新的位置。这段代码的其它部分已经做了比较详细的注释，所以这里就不做过多的解释了。
初始化g0
继续看后面的代码，下面开始初始化全局变量g0，前面我们说过，g0的主要作用是提供一个栈供runtime代码执行，因此这里主要对g0的几个与栈有关的成员进行了初始化，从这里可以看出g0的栈大约有64K，地址范围为 SP - 64*1024 &#43; 104 ～ SP。
runtime/asm_amd64.s : 96  // create istack out of the given (operating system) stack. // _cgo_init may update stackguard. //下面这段代码从系统线程的栈空分出一部分当作g0的栈，然后初始化g0的栈信息和stackgard MOVQ$runtime·g0(SB), DI //g0的地址放入DI寄存器 LEAQ(-64*1024&#43;104)(SP), BX //BX = SP - 64*1024 &#43; 104 MOVQBX, g_stackguard0(DI) //g0.stackguard0 = SP - 64*1024 &#43; 104 MOVQBX, g_stackguard1(DI) //g0.stackguard1 = SP - 64*1024 &#43; 104 MOVQBX, (g_stack&#43;stack_lo)(DI) //g0.stack.lo = SP - 64*1024 &#43; 104 MOVQSP, (g_stack&#43;stack_hi)(DI) //g0.stack.hi = SP 运行完上面这几行指令后g0与栈之间的关系如下图所示：
主线程与m0绑定
设置好g0栈之后，我们跳过CPU型号检查以及cgo初始化相关的代码，直接从164行继续分析。
runtime/asm_amd64.s : 164   //下面开始初始化tls(thread local storage,线程本地存储) LEAQruntime·m0&#43;m_tls(SB), DI //DI = &amp;amp;m0.tls，取m0的tls成员的地址到DI寄存器 CALLruntime·settls(SB) //调用settls设置线程本地存储，settls函数的参数在DI寄存器中  // store through it, to make sure it works //验证settls是否可以正常工作，如果有问题则abort退出程序 get_tls(BX) //获取fs段基地址并放入BX寄存器，其实就是m0.tls[1]的地址，get_tls的代码由编译器生成 MOVQ$0x123, g(BX) //把整型常量0x123拷贝到fs段基地址偏移-8的内存位置，也就是m0.tls[0]= 0x123 MOVQruntime·m0&#43;m_tls(SB), AX //AX = m0.tls[0] CMPQAX, $0x123 //检查m0.tls[0]的值是否是通过线程本地存储存入的0x123来验证tls功能是否正常 JEQ 2(PC) CALLruntime·abort(SB) //如果线程本地存储不能正常工作，退出程序 这段代码首先调用settls函数初始化主线程的线程本地存储(TLS)，目的是把m0与主线程关联在一起，至于为什么要把m和工作线程绑定在一起，我们已经在上一节介绍过了，这里就不再重复。设置了线程本地存储之后接下来的几条指令在于验证TLS功能是否正常，如果不正常则直接abort退出程序。
下面我们详细来详细看一下settls函数是如何实现线程私有全局变量的。
runtime/sys_linx_amd64.s : 606  // set tls base to DI TEXT runtime·settls(SB),NOSPLIT,$32 //...... //DI寄存器中存放的是m.tls[0]的地址，m的tls成员是一个数组，读者如果忘记了可以回头看一下m结构体的定义 //下面这一句代码把DI寄存器中的地址加8，为什么要&#43;8呢，主要跟ELF可执行文件格式中的TLS实现的机制有关 //执行下面这句指令之后DI寄存器中的存放的就是m.tls[1]的地址了 ADDQ$8, DI// ELF wants to use -8(FS)   //下面通过arch_prctl系统调用设置FS段基址 MOVQDI, SI //SI存放arch_prctl系统调用的第二个参数 MOVQ$0x1002, DI// ARCH_SET_FS //arch_prctl的第一个参数 MOVQ$SYS_arch_prctl, AX //系统调用编号 SYSCALL CMPQAX, $0xfffffffffffff001 JLS2(PC) MOVL$0xf1, 0xf1 // crash //系统调用失败直接crash RET 从代码可以看到，这里通过arch_prctl系统调用把m0.tls[1]的地址设置成了fs段的段基址。CPU中有个叫fs的段寄存器与之对应，而每个线程都有自己的一组CPU寄存器值，操作系统在把线程调离CPU运行时会帮我们把所有寄存器中的值保存在内存中，调度线程起来运行时又会从内存中把这些寄存器的值恢复到CPU，这样，在此之后，工作线程代码就可以通过fs寄存器来找到m.tls，读者可以参考上面初始化tls之后对tls功能验证的代码来理解这一过程。
下面继续分析rt0_go，
runtime/asm_amd64.s : 174  ok: // set the per-goroutine and per-mach &amp;#34;registers&amp;#34; get_tls(BX) //获取fs段基址到BX寄存器 LEAQruntime·g0(SB), CX //CX = g0的地址 MOVQCX, g(BX) //把g0的地址保存在线程本地存储里面，也就是m0.tls[0]=&amp;amp;g0 LEAQruntime·m0(SB), AX //AX = m0的地址  //把m0和g0关联起来m0-&amp;gt;g0 = g0，g0-&amp;gt;m = m0 // save m-&amp;gt;g0 = g0 MOVQCX, m_g0(AX) //m0.g0 = g0 // save m0 to g0-&amp;gt;m MOVQAX, g_m(CX) //g0.m = m0 上面的代码首先把g0的地址放入主线程的线程本地存储中，然后通过
m0.g0 = &amp;amp;g0 g0.m = &amp;amp;m0 把m0和g0绑定在一起，这样，之后在主线程中通过get_tls可以获取到g0，通过g0的m成员又可以找到m0，于是这里就实现了m0和g0与主线程之间的关联。从这里还可以看到，保存在主线程本地存储中的值是g0的地址，也就是说工作线程的私有全局变量其实是一个指向g的指针而不是指向m的指针，目前这个指针指向g0，表示代码正运行在g0栈。此时，主线程，m0，g0以及g0的栈之间的关系如下图所示：
初始化m0
下面代码开始处理命令行参数，这部分我们不关心，所以跳过。命令行参数处理完成后调用osinit函数获取CPU核的数量并保存在全局变量ncpu之中，调度器初始化时需要知道当前系统有多少个CPU核。
runtime/asm_amd64.s : 189 //准备调用args函数，前面四条指令把参数放在栈上
MOVL16(SP), AX// AX = argc MOVLAX, 0(SP) // argc放在栈顶 MOVQ24(SP), AX// AX = argv MOVQAX, 8(SP) // argv放在SP &#43; 8的位置 CALLruntime·args(SB) //处理操作系统传递过来的参数和env，不需要关心 //对于linx来说，osinit唯一功能就是获取CPU的核数并放在global变量ncpu中， //调度器初始化时需要知道当前系统有多少CPU核 CALLruntime·osinit(SB) //执行的结果是全局变量 ncpu = CPU核数 CALLruntime·schedinit(SB) //调度系统初始化 接下来继续看调度器是如何初始化的。
runtime/proc.go : 526  func schedinit() { // raceinit must be the first call to race detector. // In particular, it must be done before mallocinit below calls racemapshadow.   //getg函数在源代码中没有对应的定义，由编译器插入类似下面两行代码  //get_tls(CX)  //MOVQ g(CX), BX; BX存器里面现在放的是当前g结构体对象的地址  _g_ := getg() // _g_ = &amp;amp;g0   ......   //设置最多启动10000个操作系统线程，也是最多10000个M  sched.maxmcount = 10000   ......   mcommoninit(_g_.m) //初始化m0，因为从前面的代码我们知道g0-&amp;gt;m = &amp;amp;m0   ......   sched.lastpoll = uint64(nanotime())  procs := ncpu //系统中有多少核，就创建和初始化多少个p结构体对象  if n, ok := atoi32(gogetenv(&amp;#34;GOMAXPROCS&amp;#34;)); ok &amp;amp;&amp;amp; n &amp;gt; 0 {  procs = n //如果环境变量指定了GOMAXPROCS，则创建指定数量的p  }  if procresize(procs) != nil {//创建和初始化全局变量allp  throw(&amp;#34;unknown runnable goroutine during bootstrap&amp;#34;)  }   ...... } 前面我们已经看到，g0的地址已经被设置到了线程本地存储之中，schedinit通过getg函数（getg函数是编译器实现的，我们在源代码中是找不到其定义的）从线程本地存储中获取当前正在运行的g，这里获取出来的是g0，然后调用mcommoninit函数对m0(g0.m)进行必要的初始化，对m0初始化完成之后调用procresize初始化系统需要用到的p结构体对象，按照go语言官方的说法，p就是processor的意思，它的数量决定了最多可以有都少个goroutine同时并行运行。schedinit函数除了初始化m0和p，还设置了全局变量sched的maxmcount成员为10000，限制最多可以创建10000个操作系统线程出来工作。
这里我们需要重点关注一下mcommoninit如何初始化m0以及procresize函数如何创建和初始化p结构体对象。首先我们深入到mcommoninit函数中一探究竟。这里需要注意的是不只是初始化的时候会执行该函数，在程序运行过程中如果创建了工作线程，也会执行它，所以我们会在函数中看到加锁和检查线程数量是否已经超过最大值等相关的代码。
runtime/proc.go : 596  func mcommoninit(mp *m) {  _g_ := getg() //初始化过程中_g_ = g0   // g0 stack won&amp;#39;t make sense for user (and is not necessary unwindable).  if _g_ != _g_.m.g0 { //函数调用栈traceback，不需要关心  callers(1, mp.createstack[:])  }   lock(&amp;amp;sched.lock)  if sched.mnext&#43;1 &amp;lt; sched.mnext {  throw(&amp;#34;runtime: thread ID overflow&amp;#34;)  }  mp.id = sched.mnext  sched.mnext&#43;&#43;  checkmcount() //检查已创建系统线程是否超过了数量限制（10000）  //random初始化  mp.fastrand[0] = 1597334677 * uint32(mp.id)  mp.fastrand[1] = uint32(cputicks())  if mp.fastrand[0]|mp.fastrand[1] == 0 {  mp.fastrand[1] = 1  }  //创建用于信号处理的gsignal，只是简单的从堆上分配一个g结构体对象,然后把栈设置好就返回了  mpreinit(mp)  if mp.gsignal != nil {  mp.gsignal.stackguard1 = mp.gsignal.stack.lo &#43; _StackGuard  }  //把m挂入全局链表allm之中  // Add to allm so garbage collector doesn&amp;#39;t free g-&amp;gt;m  // when it is just in a register or thread-local storage.  mp.alllink = allm   // NumCgoCall() iterates over allm w/o schedlock,  // so we need to publish it safely.  atomicstorep(unsafe.Pointer(&amp;amp;allm), unsafe.Pointer(mp))  unlock(&amp;amp;sched.lock)   // Allocate memory to hold a cgo traceback if the cgo call crashes.  if iscgo || GOOS == &amp;#34;solaris&amp;#34; || GOOS == &amp;#34;windows&amp;#34; {  mp.cgoCallers = new(cgoCallers)  } } 从这个函数的源代码可以看出，这里并未对m0做什么关于调度相关的初始化，所以可以简单的认为这个函数只是把m0放入全局链表allm之中就返回了。
m0完成基本的初始化后，继续调用procresize创建和初始化p结构体对象，在这个函数里面会创建指定个数（根据cpu核数或环境变量确定）的p结构体对象放在全变量allp里, 并把m0和allp[0]绑定在一起，因此当这个函数执行完成之后就有
m0.p = allp[0] allp[0].m = &amp;amp;m0 到此m0, g0, 和m需要的p完全关联在一起了。
初始化allp
下面我们来看procresize函数，考虑到初始化完成之后用户代码还可以通过 GOMAXPROCS()函数调用它重新创建和初始化p结构体对象，而在运行过程中再动态的调整p牵涉到的问题比较多，所以这个函数的处理比较复杂，但如果只考虑初始化，相对来说要简单很多，所以这里只保留了初始化时会执行的代码：
runtime/proc.go : 3902  func procresize(nprocs int32) *p {  old := gomaxprocs //系统初始化时 gomaxprocs = 0   ......   // Grow allp if necessary.  if nprocs &amp;gt; int32(len(allp)) { //初始化时 len(allp) == 0  // Synchronize with retake, which could be running  // concurrently since it doesn&amp;#39;t run on a P.  lock(&amp;amp;allpLock)  if nprocs &amp;lt;= int32(cap(allp)) {  allp = allp[:nprocs]  } else { //初始化时进入此分支，创建allp 切片  nallp := make([]*p, nprocs)  // Copy everything up to allp&amp;#39;s cap so we  // never lose old allocated Ps.  copy(nallp, allp[:cap(allp)])  allp = nallp  }  unlock(&amp;amp;allpLock)  }  // initialize new P&amp;#39;s  //循环创建nprocs个p并完成基本初始化  for i := int32(0); i &amp;lt; nprocs; i&#43;&#43; {  pp := allp[i]  if pp == nil {  pp = new(p)//调用内存分配器从堆上分配一个struct p  pp.id = i  pp.status = _Pgcstop  ......  atomicstorep(unsafe.Pointer(&amp;amp;allp[i]), unsafe.Pointer(pp))  }  ......  }  ......  _g_ := getg() // _g_ = g0  if _g_.m.p != 0 &amp;amp;&amp;amp; _g_.m.p.ptr().id &amp;lt; nprocs {//初始化时m0-&amp;gt;p还未初始化，所以不会执行这个分支  // continue to use the current P  _g_.m.p.ptr().status = _Prunning  _g_.m.p.ptr().mcache.prepareForSweep()  } else {//初始化时执行这个分支  // release the current P and acquire allp[0]  if _g_.m.p != 0 {//初始化时这里不执行  _g_.m.p.ptr().m = 0  }  _g_.m.p = 0  _g_.m.mcache = nil  p := allp[0]  p.m = 0  p.status = _Pidle  acquirep(p) //把p和m0关联起来，其实是这两个strct的成员相互赋值  if trace.enabled {  traceGoStart()  }  }   //下面这个for 循环把所有空闲的p放入空闲链表  var runnablePs *p  for i := nprocs - 1; i &amp;gt;= 0; i-- {  p := allp[i]  if _g_.m.p.ptr() == p {//allp[0]跟m0关联了，所以是不能放任  continue  }  p.status = _Pidle  if runqempty(p) {//初始化时除了allp[0]其它p全部执行这个分支，放入空闲链表  pidleput(p)  } else {  ......  }  }   ......   return runnablePs } 这个函数代码比较长，但并不复杂，这里总结一下这个函数的主要流程：
使用make([]*p, nprocs)初始化全局变量allp，即allp = make([]*p, nprocs)
循环创建并初始化nprocs个p结构体对象并依次保存在allp切片之中
把m0和allp[0]绑定在一起，即m0.p = allp[0], allp[0].m = m0
把除了allp[0]之外的所有p放入到全局变量sched的pidle空闲队列之中
procresize函数执行完后，调度器相关的初始化工作就基本结束了，这时整个调度器相关的各组成部分之间的联系如下图所示：
分析完调度器的基本初始化后，下一节我们来看程序中的第一个goroutine是如何创建的。
最后，如果你觉得本文对你有帮助的话，麻烦帮忙点一下文末右下角的 在看 或转发到朋友圈，非常感谢！
</content>
    </entry>
    
     <entry>
        <title>goroutine调度器概述(11)</title>
        <url>http://shanks.link/blog/2021/04/03/goroutine%E8%B0%83%E5%BA%A6%E5%99%A8%E6%A6%82%E8%BF%B011/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 爱写程序的阿波张 源码游记 2019-05-01
本文是《go调度器源代码情景分析》系列的第11篇，也是第二章的第1小节。
goroutine简介
goroutine是Go语言实现的用户态线程，主要用来解决操作系统线程太“重”的问题，所谓的太重，主要表现在以下两个方面：
创建和切换太重：操作系统线程的创建和切换都需要进入内核，而进入内核所消耗的性能代价比较高，开销较大；
内存使用太重：一方面，为了尽量避免极端情况下操作系统线程栈的溢出，内核在创建操作系统线程时默认会为其分配一个较大的栈内存（虚拟地址空间，内核并不会一开始就分配这么多的物理内存），然而在绝大多数情况下，系统线程远远用不了这么多内存，这导致了浪费；另一方面，栈内存空间一旦创建和初始化完成之后其大小就不能再有变化，这决定了在某些特殊场景下系统线程栈还是有溢出的风险。
而相对的，用户态的goroutine则轻量得多：
goroutine是用户态线程，其创建和切换都在用户代码中完成而无需进入操作系统内核，所以其开销要远远小于系统线程的创建和切换；
goroutine启动时默认栈大小只有2k，这在多数情况下已经够用了，即使不够用，goroutine的栈也会自动扩大，同时，如果栈太大了过于浪费它还能自动收缩，这样既没有栈溢出的风险，也不会造成栈内存空间的大量浪费。
正是因为Go语言中实现了如此轻量级的线程，才使得我们在Go程序中，可以轻易的创建成千上万甚至上百万的goroutine出来并发的执行任务而不用太担心性能和内存等问题。
注意：为了避免混淆，从现在开始，后面出现的所有的线程一词均是指操作系统线程，而goroutine我们不再称之为什么什么线程而是直接使用goroutine这个词。
线程模型与调度器
第一章讨论操作系统线程调度的时候我们曾经提到过，goroutine建立在操作系统线程基础之上，它与操作系统线程之间实现了一个多对多(M:N)的两级线程模型。
这里的 M:N 是指M个goroutine运行在N个操作系统线程之上，内核负责对这N个操作系统线程进行调度，而这N个系统线程又负责对这M个goroutine进行调度和运行。
所谓的对goroutine的调度，是指程序代码按照一定的算法在适当的时候挑选出合适的goroutine并放到CPU上去运行的过程，这些负责对goroutine进行调度的程序代码我们称之为goroutine调度器。用极度简化了的伪代码来描述goroutine调度器的工作流程大概是下面这个样子：
// 程序启动时的初始化代码
...... for i := 0; i &amp;lt; N; i&#43;&#43; { // 创建N个操作系统线程执行schedule函数  create_os_thread(schedule) // 创建一个操作系统线程执行schedule函数 } //schedule函数实现调度逻辑 func schedule() {  for { //调度循环  // 根据某种算法从M个goroutine中找出一个需要运行的goroutine  g := find_a_runnable_goroutine_from_M_goroutines()  run_g(g) // CPU运行该goroutine，直到需要调度其它goroutine才返回  save_status_of_g(g) // 保存goroutine的状态，主要是寄存器的值  } } 这段伪代码表达的意思是，程序运行起来之后创建了N个由内核调度的操作系统线程（为了方便描述，我们称这些系统线程为工作线程）去执行shedule函数，而schedule函数在一个调度循环中反复从M个goroutine中挑选出一个需要运行的goroutine并跳转到该goroutine去运行，直到需要调度其它goroutine时才返回到schedule函数中通过save_status_of_g保存刚刚正在运行的goroutine的状态然后再次去寻找下一个goroutine。
需要强调的是，这段伪代码对goroutine的调度代码做了高度的抽象、修改和简化处理，放在这里只是为了帮助我们从宏观上了解goroutine的两级调度模型，具体的实现原理和细节将从本章开始进行全面介绍。
调度器数据结构概述
第一章我们讨论操作系统线程及其调度时还说过，可以把内核对系统线程的调度简单的归纳为：在执行操作系统代码时，内核调度器按照一定的算法挑选出一个线程并把该线程保存在内存之中的寄存器的值放入CPU对应的寄存器从而恢复该线程的运行。
万变不离其宗，系统线程对goroutine的调度与内核对系统线程的调度原理是一样的，实质都是通过保存和修改CPU寄存器的值来达到切换线程/goroutine的目的。
因此，为了实现对goroutine的调度，需要引入一个数据结构来保存CPU寄存器的值以及goroutine的其它一些状态信息，在Go语言调度器源代码中，这个数据结构是一个名叫g的结构体，它保存了goroutine的所有信息，该结构体的每一个实例对象都代表了一个goroutine，调度器代码可以通过g对象来对goroutine进行调度，当goroutine被调离CPU时，调度器代码负责把CPU寄存器的值保存在g对象的成员变量之中，当goroutine被调度起来运行时，调度器代码又负责把g对象的成员变量所保存的寄存器的值恢复到CPU的寄存器。
要实现对goroutine的调度，仅仅有g结构体对象是不够的，至少还需要一个存放所有（可运行）goroutine的容器，便于工作线程寻找需要被调度起来运行的goroutine，于是Go调度器又引入了schedt结构体，一方面用来保存调度器自身的状态信息，另一方面它还拥有一个用来保存goroutine的运行队列。因为每个Go程序只有一个调度器，所以在每个Go程序中schedt结构体只有一个实例对象，该实例对象在源代码中被定义成了一个共享的全局变量，这样每个工作线程都可以访问它以及它所拥有的goroutine运行队列，我们称这个运行队列为全局运行队列。
既然说到全局运行队列，读者可能猜想到应该还有一个局部运行队列。确实如此，因为全局运行队列是每个工作线程都可以读写的，因此访问它需要加锁，然而在一个繁忙的系统中，加锁会导致严重的性能问题。于是，调度器又为每个工作线程引入了一个私有的局部goroutine运行队列，工作线程优先使用自己的局部运行队列，只有必要时才会去访问全局运行队列，这大大减少了锁冲突，提高了工作线程的并发性。在Go调度器源代码中，局部运行队列被包含在p结构体的实例对象之中，每一个运行着go代码的工作线程都会与一个p结构体的实例对象关联在一起。
除了上面介绍的g、schedt和p结构体，Go调度器源代码中还有一个用来代表工作线程的m结构体，每个工作线程都有唯一的一个m结构体的实例对象与之对应，m结构体对象除了记录着工作线程的诸如栈的起止位置、当前正在执行的goroutine以及是否空闲等等状态信息之外，还通过指针维持着与p结构体的实例对象之间的绑定关系。于是，通过m既可以找到与之对应的工作线程正在运行的goroutine，又可以找到工作线程的局部运行队列等资源。下面是g、p、m和schedt之间的关系图：
上图中圆形图案代表g结构体的实例对象，三角形代表m结构体的实例对象，正方形代表p结构体的实例对象，其中红色的g表示m对应的工作线程正在运行的goroutine，而灰色的g表示处于运行队列之中正在等待被调度起来运行的goroutine。
从上图可以看出，每个m都绑定了一个p，每个p都有一个私有的本地goroutine队列，m对应的线程从本地和全局goroutine队列中获取goroutine并运行之。
前面我们说每个工作线程都有一个m结构体对象与之对应，但并未详细说明它们之间是如何对应起来的，工作线程执行的代码是如何找到属于自己的那个m结构体实例对象的呢？
如果只有一个工作线程，那么就只会有一个m结构体对象，问题就很简单，定义一个全局的m结构体变量就行了。可是我们有多个工作线程和多个m需要一一对应，怎么办呢？还记得第一章我们讨论过的线程本地存储吗？当时我们说过，线程本地存储其实就是线程私有的全局变量，这不正是我们所需要的吗？！只要每个工作线程拥有了各自私有的m结构体全局变量，我们就能在不同的工作线程中使用相同的全局变量名来访问不同的m结构体对象，这完美的解决我们的问题。
具体到goroutine调度器代码，每个工作线程在刚刚被创建出来进入调度循环之前就利用线程本地存储机制为该工作线程实现了一个指向m结构体实例对象的私有全局变量，这样在之后的代码中就使用该全局变量来访问自己的m结构体对象以及与m相关联的p和g对象。
有了上述数据结构以及工作线程与数据结构之间的映射机制，我们可以把前面的调度伪代码写得更丰满一点：
// 程序启动时的初始化代码
...... for i := 0; i &amp;lt; N; i&#43;&#43; { // 创建N个操作系统线程执行schedule函数  create_os_thread(schedule) // 创建一个操作系统线程执行schedule函数 } // 定义一个线程私有全局变量，注意它是一个指向m结构体对象的指针
// ThreadLocal用来定义线程私有全局变量 ThreadLocal self *m //schedule函数实现调度逻辑 func schedule() {  // 创建和初始化m结构体对象，并赋值给私有全局变量self  self = initm()  for { //调度循环  if (self.p.runqueue is empty) {  // 根据某种算法从全局运行队列中找出一个需要运行的goroutine  g := find_a_runnable_goroutine_from_global_runqueue()  } else {  // 根据某种算法从私有的局部运行队列中找出一个需要运行的goroutine  g := find_a_runnable_goroutine_from_local_runqueue()  }  run_g(g) // CPU运行该goroutine，直到需要调度其它goroutine才返回  save_status_of_g(g) // 保存goroutine的状态，主要是寄存器的值  } } 仅仅从上面这个伪代码来看，我们完全不需要线程私有全局变量，只需在schedule函数中定义一个局部变量就行了。但真实的调度代码错综复杂，不光是这个schedule函数会需要访问m，其它很多地方还需要访问它，所以需要使用全局变量来方便其它地方对m的以及与m相关的g和p的访问。
在简单的介绍了Go语言调度器以及它所需要的数据结构之后，下面我们来看一下Go的调度代码中对上述的几个结构体的定义。
重要的结构体 下面介绍的这些结构体中的字段非常多，牵涉到的细节也很庞杂，光是看这些结构体的定义我们没有必要也无法真正理解它们的用途，所以在这里我们只需要大概了解一下就行了，看不懂记不住都没有关系，随着后面对代码逐步深入的分析，我们也必将会对这些结构体有越来越清晰的认识。为了节省篇幅，下面各结构体的定义略去了跟调度器无关的成员。另外，这些结构体的定义全部位于Go语言的源代码路径下的runtime/runtime2.go文件之中。
stack结构体
stack结构体主要用来记录goroutine所使用的栈的信息，包括栈顶和栈底位置：
// Stack describes a Go execution stack. // The bounds of the stack are exactly [lo, hi), // with no implicit data structures on either side. //用于记录goroutine使用的栈的起始和结束位置 type stack struct {
lo uintptr // 栈顶，指向内存低地址 hi uintptr // 栈底，指向内存高地址 } gobuf结构体
gobuf结构体用于保存goroutine的调度信息，主要包括CPU的几个寄存器的值：
type gobuf struct {  // The offsets of sp, pc, and g are known to (hard-coded in) libmach.  //  // ctxt is unusual with respect to GC: it may be a  // heap-allocated funcval, so GC needs to track it, but it  // needs to be set and cleared from assembly, where it&amp;#39;s  // difficult to have write barriers. However, ctxt is really a  // saved, live register, and we only ever exchange it between  // the real register and the gobuf. Hence, we treat it as a  // root during stack scanning, which means assembly that saves  // and restores it doesn&amp;#39;t need write barriers. It&amp;#39;s still  // typed as a pointer so that any other writes from Go get  // write barriers.  sp uintptr // 保存CPU的rsp寄存器的值  pc uintptr // 保存CPU的rip寄存器的值  g guintptr // 记录当前这个gobuf对象属于哪个goroutine  ctxt unsafe.Pointer   // 保存系统调用的返回值，因为从系统调用返回之后如果p被其它工作线程抢占，  // 则这个goroutine会被放入全局运行队列被其它工作线程调度，其它线程需要知道系统调用的返回值。  ret sys.Uintreg  lr uintptr   // 保存CPU的rip寄存器的值  bp uintptr // for GOEXPERIMENT=framepointer } g结构体
g结构体用于代表一个goroutine，该结构体保存了goroutine的所有信息，包括栈，gobuf结构体和其它的一些状态信息：
// 前文所说的g结构体，它代表了一个goroutine
type g struct {  // Stack parameters.  // stack describes the actual stack memory: [stack.lo, stack.hi).  // stackguard0 is the stack pointer compared in the Go stack growth prologue.  // It is stack.lo&#43;StackGuard normally, but can be StackPreempt to trigger a preemption.  // stackguard1 is the stack pointer compared in the C stack growth prologue.  // It is stack.lo&#43;StackGuard on g0 and gsignal stacks.  // It is ~0 on other goroutine stacks, to trigger a call to morestackc (and crash).   // 记录该goroutine使用的栈  stack stack // offset known to runtime/cgo  // 下面两个成员用于栈溢出检查，实现栈的自动伸缩，抢占调度也会用到stackguard0  stackguard0 uintptr // offset known to liblink  stackguard1 uintptr // offset known to liblink   ......   // 此goroutine正在被哪个工作线程执行  m *m // current m; offset known to arm liblink  // 保存调度信息，主要是几个寄存器的值  sched gobuf   ......  // schedlink字段指向全局运行队列中的下一个g，  //所有位于全局运行队列中的g形成一个链表  schedlink guintptr   ......  // 抢占调度标志，如果需要抢占调度，设置preempt为true  preempt bool // preemption signal, duplicates stackguard0 = stackpreempt   ...... } m结构体
m结构体用来代表工作线程，它保存了m自身使用的栈信息，当前正在运行的goroutine以及与m绑定的p等信息，详见下面定义中的注释：
type m struct {  // g0主要用来记录工作线程使用的栈信息，在执行调度代码时需要使用这个栈  // 执行用户goroutine代码时，使用用户goroutine自己的栈，调度时会发生栈的切换  g0 *g // goroutine with scheduling stack   // 通过TLS实现m结构体对象与工作线程之间的绑定  tls [6]uintptr // thread-local storage (for x86 extern register)  mstartfn func()  // 指向工作线程正在运行的goroutine的g结构体对象  curg *g // current running goroutine   // 记录与当前工作线程绑定的p结构体对象  p puintptr // attached p for executing go code (nil if not executing go code)  nextp puintptr  oldp puintptr // the p that was attached before executing a syscall   // spinning状态：表示当前工作线程正在试图从其它工作线程的本地运行队列偷取goroutine  spinning bool // m is out of work and is actively looking for work  blocked bool // m is blocked on a note   // 没有goroutine需要运行时，工作线程睡眠在这个park成员上，  // 其它线程通过这个park唤醒该工作线程  park note  // 记录所有工作线程的一个链表  alllink *m // on allm  schedlink muintptr   // Linux平台thread的值就是操作系统线程ID  thread uintptr // thread handle  freelink *m // on sched.freem   ...... } p结构体
p结构体用于保存工作线程执行go代码时所必需的资源，比如goroutine的运行队列，内存分配用到的缓存等等。
type p struct {  lock mutex   status uint32 // one of pidle/prunning/...  link puintptr  schedtick uint32 // incremented on every scheduler call  syscalltick uint32 // incremented on every system call  sysmontick sysmontick // last tick observed by sysmon  m muintptr // back-link to associated m (nil if idle)   ......   // Queue of runnable goroutines. Accessed without lock.  //本地goroutine运行队列  runqhead uint32 // 队列头  runqtail uint32 // 队列尾  runq [256]guintptr //使用数组实现的循环队列  // runnext, if non-nil, is a runnable G that was ready&amp;#39;d by  // the current G and should be run next instead of what&amp;#39;s in  // runq if there&amp;#39;s time remaining in the running G&amp;#39;s time  // slice. It will inherit the time left in the current time  // slice. If a set of goroutines is locked in a  // communicate-and-wait pattern, this schedules that set as a  // unit and eliminates the (potentially large) scheduling  // latency that otherwise arises from adding the ready&amp;#39;d  // goroutines to the end of the run queue.  runnext guintptr   // Available G&amp;#39;s (status == Gdead)  gFree struct {  gList  n int32  }   ...... } schedt结构体
schedt结构体用来保存调度器的状态信息和goroutine的全局运行队列：
type schedt struct {  // accessed atomically. keep at top to ensure alignment on 32-bit systems.  goidgen uint64  lastpoll uint64   lock mutex   // When increasing nmidle, nmidlelocked, nmsys, or nmfreed, be  // sure to call checkdead().   // 由空闲的工作线程组成链表  midle muintptr // idle m&amp;#39;s waiting for work  // 空闲的工作线程的数量  nmidle int32 // number of idle m&amp;#39;s waiting for work  nmidlelocked int32 // number of locked m&amp;#39;s waiting for work  mnext int64 // number of m&amp;#39;s that have been created and next M ID  // 最多只能创建maxmcount个工作线程  maxmcount int32 // maximum number of m&amp;#39;s allowed (or die)  nmsys int32 // number of system m&amp;#39;s not counted for deadlock  nmfreed int64 // cumulative number of freed m&amp;#39;s   ngsys uint32 // number of system goroutines; updated atomically   // 由空闲的p结构体对象组成的链表  pidle puintptr // idle p&amp;#39;s  // 空闲的p结构体对象的数量  npidle uint32  nmspinning uint32 // See &amp;#34;Worker thread parking/unparking&amp;#34; comment in proc.go.   // Global runnable queue.  // goroutine全局运行队列  runq gQueue  runqsize int32   ......   // Global cache of dead G&amp;#39;s.  // gFree是所有已经退出的goroutine对应的g结构体对象组成的链表  // 用于缓存g结构体对象，避免每次创建goroutine时都重新分配内存  gFree struct {  lock mutex  stack gList // Gs with stacks  noStack gList // Gs without stacks  n int32  }   ...... } 重要的全局变量
allgs []*g // 保存所有的g allm *m // 所有的m构成的一个链表，包括下面的m0 allp []*p // 保存所有的p，len(allp) == gomaxprocs  ncpu int32 // 系统中cpu核的数量，程序启动时由runtime代码初始化 gomaxprocs int32 // p的最大值，默认等于ncpu，但可以通过GOMAXPROCS修改  sched schedt // 调度器结构体对象，记录了调度器的工作状态  m0 m // 代表进程的主线程 g0 g // m0的g0，也就是m0.g0 = &amp;amp;g0 在程序初始化时，这些全变量都会被初始化为0值，指针会被初始化为nil指针，切片初始化为nil切片，int被初始化为数字0，结构体的所有成员变量按其本类型初始化为其类型的0值。所以程序刚启动时allgs，allm和allp都不包含任何g,m和p。
最后，如果你觉得本文对你有帮助的话，麻烦帮忙点一下文末右下角的 在看 或转发到朋友圈，非常感谢！
</content>
    </entry>
    
     <entry>
        <title>go语言调度器源代码情景分析之十：线程本地存储</title>
        <url>http://shanks.link/blog/2021/04/03/go%E8%AF%AD%E8%A8%80%E8%B0%83%E5%BA%A6%E5%99%A8%E6%BA%90%E4%BB%A3%E7%A0%81%E6%83%85%E6%99%AF%E5%88%86%E6%9E%90%E4%B9%8B%E5%8D%81%E7%BA%BF%E7%A8%8B%E6%9C%AC%E5%9C%B0%E5%AD%98%E5%82%A8/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 爱写程序的阿波张 源码游记 2019-04-27
本文是《go调度器源代码情景分析》系列 第一章 预备知识的第十小节，也是预备知识的最后一小节。
线程本地存储又叫线程局部存储，其英文为Thread Local Storage，简称TLS，看似一个很高大上的东西，其实就是线程私有的全局变量而已。
有过多线程编程的读者一定知道，普通的全局变量在多线程中是共享的，一个线程对其进行了修改，所有线程都可以看到这个修改，而线程私有的全局变量与普通全局变量不同，线程私有全局变量是线程的私有财产，每个线程都有自己的一份副本，某个线程对其所做的修改只会修改到自己的副本，并不会修改到其它线程的副本。
下面用例子来说明一下多线程共享全局变量以及线程私有全局变量之间的差异，并对gcc的线程本地存储做一个简单的分析。
首先来看普通的全局变量
#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;pthread.h&amp;gt; int g = 0; // 1，定义全局变量g并赋初值0  void *start(void *arg) { printf(&amp;#34;start, g[%p] : %d\n&amp;#34;, &amp;amp;g, g); // 4，子线程中打印全局变量g的地址和值  g&#43;&#43;; // 5，修改全局变量  return NULL; }  int main(int argc, char *argv[]) { pthread_t tid;  g = 100; // 2，主线程给全局变量g赋值为100  pthread_create(&amp;amp;tid, NULL, start, NULL); // 3， 创建子线程执行start()函数 pthread_join(tid, NULL); // 6，等待子线程运行结束  printf(&amp;#34;main, g[%p] : %d\n&amp;#34;, &amp;amp;g, g); // 7，打印全局变量g的地址和值  return 0; } 简单解释一下，这个程序在注释1的地方定义了一个全局变量g并设置其初值为0，程序运行后主线程首先把g修改成了100（注释2），然后创建了一个子线程执行start()函数（注释3），start()函数先打印出g的值（注释4）确定在子线程中可以看到主线程对g的修改，然后修改g的值（注释5）后线程结束运行，主线程在注释6处等待子线程结束后，在注释7处打印g的值确定子线程对g的修改同样可以影响到主线程对g的读取。
编译并运行程序：
bobo@ubuntu:~/study/c$ gcc thread.c -o thread -lpthread bobo@ubuntu:~/study/c$ ./thread start, g[0x601064] : 100 main, g[0x601064] : 101 从输出结果可以看出，全局变量g在两个线程中的地址都是一样的，任何一个线程都可以读取到另一个线程对全局变量g的修改，这实现了全局变量g的多个线程中的共享。
了解了普通的全局变量之后我们再来看通过线程本地存储(TLS)实现的线程私有全局变量。这个程序与上面的程序几乎完全一样，唯一的差别就是在定义全局变量 g 时增加了 __thread 关键字，这样g就变成了线程私有全局变量了。
#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;pthread.h&amp;gt; __thread int g = 0; // 1，这里增加了__thread关键字，把g定义成私有的全局变量，每个线程都有一个g变量  void *start(void *arg) { printf(&amp;#34;start, g[%p] : %d\n&amp;#34;, &amp;amp;g, g); // 4，打印本线程私有全局变量g的地址和值  g&#43;&#43;; // 5，修改本线程私有全局变量g的值  return NULL; }  int main(int argc, char *argv[]) { pthread_t tid;  g = 100; // 2，主线程给私有全局变量赋值为100  pthread_create(&amp;amp;tid, NULL, start, NULL); // 3，创建子线程执行start()函数 pthread_join(tid, NULL); // 6，等待子线程运行结束  printf(&amp;#34;main, g[%p] : %d\n&amp;#34;, &amp;amp;g, g); // 7，打印主线程的私有全局变量g的地址和值  return 0; } 运行程序看一下效果：
bobo@ubuntu:~/study/c$ gcc -g thread.c -o thread -lpthread bobo@ubuntu:~/study/c$ ./thread start, g[0x7f0181b046fc] : 0 main, g[0x7f01823076fc] : 100 从输出结果可以看出：首先，全局变量g在两个线程中的地址是不一样的；其次main函数对全局变量 g 赋的值并未影响到子线程中 g 的值，而子线程对g都做了修改，同样也没有影响到主线程中 g 的值，这个结果正是我们所期望的，这说明，每个线程都有一个自己私有的全局变量g。
这看起来很神奇，明明2个线程都是用的同一个全局变量名来访问变量但却像在访问不同的变量一样。
下面我们就来分析一下gcc到底使用了什么黑魔法实现了这个特性。对于像这种由编译器实现的特性，我们怎么开始研究呢？最快最直接的方法就是使用调试工具来调试程序的运行，这里我们使用gdb来调试。
bobo@ubuntu:~/study/c$ gdb ./thread 首先在源代码的第20行（对应到源代码中的 g = 100）处下一个断点，然后运行程序，程序停在了断点处，反汇编一下main函数：
(gdb) b thread.c:20 Breakpoint 1 at 0x400793: file thread.c, line 20. (gdb) r Starting program: /home/bobo/study/c/thread  Breakpoint 1, at thread.c:20 20g = 100; (gdb) disass Dump of assembler code for function main:  0x0000000000400775 &amp;lt;&#43;0&amp;gt;:push %rbp  0x0000000000400776 &amp;lt;&#43;1&amp;gt;:mov %rsp,%rbp  0x0000000000400779 &amp;lt;&#43;4&amp;gt;:sub $0x20,%rsp  0x000000000040077d &amp;lt;&#43;8&amp;gt;:mov %edi,-0x14(%rbp)  0x0000000000400780 &amp;lt;&#43;11&amp;gt;:mov %rsi,-0x20(%rbp)  0x0000000000400784 &amp;lt;&#43;15&amp;gt;:mov %fs:0x28,%rax  0x000000000040078d &amp;lt;&#43;24&amp;gt;:mov %rax,-0x8(%rbp)  0x0000000000400791 &amp;lt;&#43;28&amp;gt;:xor %eax,%eax =&amp;gt; 0x0000000000400793 &amp;lt;&#43;30&amp;gt;:movl $0x64,%fs:0xfffffffffffffffc  0x000000000040079f &amp;lt;&#43;42&amp;gt;:lea -0x10(%rbp),%rax  0x00000000004007a3 &amp;lt;&#43;46&amp;gt;:mov $0x0,%ecx  0x00000000004007a8 &amp;lt;&#43;51&amp;gt;:mov $0x400736,%edx  0x00000000004007ad &amp;lt;&#43;56&amp;gt;:mov $0x0,%esi  0x00000000004007b2 &amp;lt;&#43;61&amp;gt;:mov %rax,%rdi  0x00000000004007b5 &amp;lt;&#43;64&amp;gt;:callq 0x4005e0 &amp;lt;pthread_create@plt&amp;gt;  0x00000000004007ba &amp;lt;&#43;69&amp;gt;:mov -0x10(%rbp),%rax  0x00000000004007be &amp;lt;&#43;73&amp;gt;:mov $0x0,%esi  0x00000000004007c3 &amp;lt;&#43;78&amp;gt;:mov %rax,%rdi  0x00000000004007c6 &amp;lt;&#43;81&amp;gt;:callq 0x400620 &amp;lt;pthread_join@plt&amp;gt;  0x00000000004007cb &amp;lt;&#43;86&amp;gt;:mov %fs:0xfffffffffffffffc,%eax  0x00000000004007d3 &amp;lt;&#43;94&amp;gt;:mov %eax,%esi  0x00000000004007d5 &amp;lt;&#43;96&amp;gt;:mov $0x4008df,%edi  0x00000000004007da &amp;lt;&#43;101&amp;gt;:mov $0x0,%eax  0x00000000004007df &amp;lt;&#43;106&amp;gt;:callq 0x400600 &amp;lt;printf@plt&amp;gt;  ...... 程序停在了g = 100这一行，看一下汇编指令，
=&amp;gt; 0x0000000000400793 &amp;lt;&#43;30&amp;gt;:movl $0x64,%fs:0xfffffffffffffffc 这句汇编指令的意思是把常量100(0x64)复制到地址为%fs:0xfffffffffffffffc的内存中，可以看出全局变量g的地址为%fs:0xfffffffffffffffc，fs是段寄存器，0xfffffffffffffffc是有符号数-4，所以全局变量g的地址为：
fs段基址 - 4 前面我们在讲段寄存器时说过段基址就是段的起始地址，为了验证g的地址确实是fs段基址 - 4，我们需要知道fs段基址是多少，虽然我们可以用gdb命令查看fs寄存器的值，但fs寄存器里面存放的是段选择子（segment selector）而不是该段的起始地址，为了拿到这个基地址，我们需要加一点代码来获取它，修改后的代码如下：
#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;pthread.h&amp;gt;#include &amp;lt;asm/prctl.h&amp;gt;#include &amp;lt;sys/prctl.h&amp;gt; __thread int g = 0;  void print_fs_base() {  unsigned long addr;  int ret = arch_prctl(ARCH_GET_FS, &amp;amp;addr); //获取fs段基地址  if (ret &amp;lt; 0) {  perror(&amp;#34;error&amp;#34;);  return;  }   printf(&amp;#34;fs base addr: %p\n&amp;#34;, (void *)addr); //打印fs段基址   return; }  void *start(void *arg) {  print_fs_base(); //子线程打印fs段基地址 printf(&amp;#34;start, g[%p] : %d\n&amp;#34;, &amp;amp;g, g);  g&#43;&#43;;  return NULL; }  int main(int argc, char *argv[]) { pthread_t tid;  g = 100;  pthread_create(&amp;amp;tid, NULL, start, NULL); pthread_join(tid, NULL);   print_fs_base(); //main线程打印fs段基址 printf(&amp;#34;main, g[%p] : %d\n&amp;#34;, &amp;amp;g, g);  return 0; } 代码中主线程和子线程都分别调用了print_fs_base()函数用于打印fs段基地址，运行程序看一下：
fs base addr: 0x7f36757c8700 start, g[0x7f36757c86fc] : 0 fs base addr: 0x7f3675fcb700 main, g[0x7f3675fcb6fc] : 100 可以看到：
子线程fs段基地址为0x7f36757c8700，g的地址为0x7f36757c86fc，它正好是基地址-4
主线程fs段基地址为0x7f3675fcb700，g的地址为0x7f3675fcb6fc，它也是基地址-4
由此可以得出，gcc编译器（其实还有线程库以及内核的支持）使用了CPU的fs段寄存器来实现线程本地存储，不同的线程中fs段基地址是不一样的，这样看似同一个全局变量但在不同线程中却拥有不同的内存地址，实现了线程私有的全局变量。
这里我们简要的分析了AMD64 Linux平台下gcc对线程本地存储的实现，后面的章节我们还会看到go的runtime是如何利用线程本地存储来把正在运行的goroutine和工作线程关联在一起的。
到此，第一部分预备知识的主要内容就已经全部介绍完毕。我们从汇编指令开始，一起讨论了寄存器，内存，栈，函数调用过程，操作系统内核对线程的调度以及线程本地存储等内容，相信读者已经很好的掌握了这些基础知识，接下来就让我们一起来撩开goroutine调度器的神秘面纱吧！
最后，如果你觉得本文对你有帮助的话，麻烦帮忙点一下文末右下角的 在看 或转发到朋友圈，非常感谢！
</content>
    </entry>
    
     <entry>
        <title>go语言调度器源代码情景分析之八：系统调用</title>
        <url>http://shanks.link/blog/2021/04/02/go%E8%AF%AD%E8%A8%80%E8%B0%83%E5%BA%A6%E5%99%A8%E6%BA%90%E4%BB%A3%E7%A0%81%E6%83%85%E6%99%AF%E5%88%86%E6%9E%90%E4%B9%8B%E5%85%AB%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 爱写程序的阿波张 源码游记 2019-04-24 我们将在最后一章讨论有关系统调用方面的抢占调度，所以这里有必要对系统调用有个基本的了解。
系统调用是指使用类似函数调用的方式调用操作系统提供的API。
虽然从概念上来说系统调用和函数调用差不多，但本质上它们有很大的不同，操作系统的代码位于内核地址空间，而CPU在执行用户代码时特权等级很低，无权访问需要最高优先级才能访问的内核地址空间的代码和数据，所以不能通过简单的call指令直接调用操作系统提供的函数，而需要使用特殊的指令进入操作系统内核完成指定的功能。
另外，用户代码调用操作系统API也不是根据函数名直接调用，而是需要根据操作系统为每个API提供的一个整型编号来调用，AMD64 Linux平台约定在进行系统调用时使用rax寄存器存放系统调用编号，同时约定使用rdi, rsi, rdx, r10, r8和r9来传递前6个系统调用参数。
可能有读者会说，我们平时编程也没有用到系统调用啊？！其实并不是没有用到，而是我们没有感觉到它的存在，比如最简单的向屏幕输出字符串，打开文件，读写文件以及网络编程中的创建socket等等都使用了系统调用，我们没有感觉到系统调用的存在主要是因为我们使用的函数库或package把它们封装成了函数，我们只需要直接调用这些函数就可以了。比如有下面一段go代码：
package main
import ( &amp;ldquo;os&amp;rdquo; )
func main() { fd, err := os.Open(&amp;quot;./syscall.go&amp;quot;) // 将会使用系统调用打开文件 &amp;hellip;&amp;hellip; fd.Close() // 将会使用系统调用关闭文件 } 这里的os.Open()和fd.Close()函数最终都会通过系统调用进入操作系统内核完成相应的功能。以os.Open为例，它最终会执行下面这段汇编代码来通过openat系统调用打开文件：
mov 0x10(%rsp),%rdi #第1个参数 mov 0x18(%rsp),%rsi #第2个参数 mov 0x20(%rsp),%rdx #第3个参数 mov 0x28(%rsp),%r10 #第4个参数 mov 0x30(%rsp),%r8 #第5个参数 mov 0x38(%rsp),%r9 #第6个参数 mov 0x8(%rsp),%rax #系统调用编号 rax = 267，表示调用openat系统调用 syscall #系统调用指令，进入Linux内核 这里，代码首先把6个参数以及openat这个系统调用的编号267保存在了对应的寄存器中，然后使用syscall指令进入内核执行打开文件的功能。
最后，如果你觉得本文对你有帮助的话，麻烦帮忙点一下文末右下角的 在看 或转发到朋友圈，非常感谢！
</content>
    </entry>
    
     <entry>
        <title>go语言调度器源代码情景分析之七：函数调用过程</title>
        <url>http://shanks.link/blog/2021/04/02/go%E8%AF%AD%E8%A8%80%E8%B0%83%E5%BA%A6%E5%99%A8%E6%BA%90%E4%BB%A3%E7%A0%81%E6%83%85%E6%99%AF%E5%88%86%E6%9E%90%E4%B9%8B%E4%B8%83%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E8%BF%87%E7%A8%8B/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 爱写程序的阿波张 源码游记 2019-04-22
前面几节我们介绍了CPU寄存器、内存、汇编指令以及栈等基础知识，为了达到融会贯通加深理解的目的，这一节我们来综合运用一下所学知识，看看函数的执行和调用过程。
本节我们需要重点关注的问题有：
CPU是如何从调用者跳转到被调用函数执行的？
参数是如何从调用者传递给被调用函数的？
函数局部变量所占内存是怎么在栈上分配的？
返回值是如何从被调用函数返回给调用者的？
函数执行完成之后又需要做哪些清理工作？
解决了这些问题，我们对计算机执行程序的原理就有了一个大致的了解，这对于我们理解goroutine的调度有非常重要的作用。
相对于go来说，C语言更接近于硬件，编译后的汇编代码也更加简单直观，更容易让我们掌握函数调用的基本原理，所以我们首先来看C语言的函数调用在汇编指令层面是如何实现的，然后在此基础上分析go语言的函数调用过程。
C语言函数调用过程
我们用一个简单的例子程序来开始分析。
#include &amp;lt;stdio.h&amp;gt;
// 对参数 a 和 b 求和 int sum(int a, int b) { int s = a &#43; b;
 return s;  }
// main函数：程序入口 int main(int argc, char *argv[]) { int n = sum(1, 2); // 调用sum函数对求和
 printf(&amp;quot;n: %d\n&amp;quot;, n); //在屏幕输出 n 的值 return 0;  } 用gcc编译这个程序得到可执行程序call，然后使用gdb调试。在gdb中我们通过disass main反汇编main函数找到main的第一条指令所在的地址为0x0000000000400540，然后使用b *0x0000000000400540在该地址下一个断点并运行程序：
bobo@ubuntu:~/study/c$ gdb ./call (gdb) disass main Dump of assembler code for function main: 0x0000000000400540 &amp;lt;&#43;0&amp;gt;:push %rbp 0x0000000000400541 &amp;lt;&#43;1&amp;gt;:mov %rsp,%rbp 0x0000000000400544 &amp;lt;&#43;4&amp;gt;:sub $0x20,%rsp 0x0000000000400548 &amp;lt;&#43;8&amp;gt;:mov %edi,-0x14(%rbp) 0x000000000040054b &amp;lt;&#43;11&amp;gt;:mov %rsi,-0x20(%rbp) 0x000000000040054f &amp;lt;&#43;15&amp;gt;:mov $0x2,%esi 0x0000000000400554 &amp;lt;&#43;20&amp;gt;:mov $0x1,%edi 0x0000000000400559 &amp;lt;&#43;25&amp;gt;:callq 0x400526 0x000000000040055e &amp;lt;&#43;30&amp;gt;:mov %eax,-0x4(%rbp) 0x0000000000400561 &amp;lt;&#43;33&amp;gt;:mov -0x4(%rbp),%eax 0x0000000000400564 &amp;lt;&#43;36&amp;gt;:mov %eax,%esi 0x0000000000400566 &amp;lt;&#43;38&amp;gt;:mov $0x400604,%edi 0x000000000040056b &amp;lt;&#43;43&amp;gt;:mov $0x0,%eax 0x0000000000400570 &amp;lt;&#43;48&amp;gt;:callq 0x400400 printf@plt 0x0000000000400575 &amp;lt;&#43;53&amp;gt;:mov $0x0,%eax 0x000000000040057a &amp;lt;&#43;58&amp;gt;:leaveq 0x000000000040057b &amp;lt;&#43;59&amp;gt;:retq
End of assembler dump. (gdb) b *0x0000000000400540 Breakpoint 1 at 0x400540 (gdb) r Starting program: /home/bobo/study/c/call Breakpoint 1, 0x0000000000400540 in main () 程序停在了我们下的断点处，也就是main函数的第一条指令的位置。再次反汇编一下将要执行的main函数，我们先来看其最前面的3条指令：
(gdb) disass Dump of assembler code for function main: =&amp;gt; 0x0000000000400540 &amp;lt;&#43;0&amp;gt;:push %rbp 0x0000000000400541 &amp;lt;&#43;1&amp;gt;:mov %rsp,%rbp 0x0000000000400544 &amp;lt;&#43;4&amp;gt;:sub $0x20,%rsp &amp;hellip;&amp;hellip; 这3条指令我们一般称之为函数序言，基本上每个函数都以函数序言开始，其主要作用在于保存调用者的rbp寄存器以及为当前函数分配栈空间，后面我们会详细介绍这3条指令，我们先来说明一下gdb输出的反汇编代码的格式，gdb反汇编出来的代码主要分为3个部分：
指令地址
指令相对于当前函数起始地址以字节为单位的偏移
指令
比如第一行代码 0x0000000000400540 &amp;lt;&#43;0&amp;gt;: push %rbp，表示main函数的第一条指令push %rbp在内存中的地址为0x0000000000400540，偏移为0（因为它是main函数的第一条指令）。这行代码各组成部分如下图所示：
这里需要说明一点，gdb反汇编输出的结果中的指令地址和偏移只是gdb为了让我们更容易阅读代码而附加上去的，保存在内存中以及被CPU执行的代码只有上图指令部分。
注意，上面反汇编结果中的第一行代码的最左边还有一个 =&amp;gt; 符号，它表示这条指令是CPU将要执行的下一条指令，也就是rip寄存器目前的值为0x0000000000400540，当前的状态是前一条指令已经执行完毕，这一条指令还未开始执行，使用i r rbp rsp rip察看一下rbp、rsp和rip这3个寄存器的值：
(gdb) i r rbp rsp rip rbp 0x4005800x400580 &amp;lt;__libc_csu_init&amp;gt; rsp 0x7fffffffe5180x7fffffffe518 rip 0x4005400x400540 根据这些寄存器的值，当前时刻函数调用栈、rbp、 rsp和rip的状态以及它们之间的关系如下图所示：
因为rbp、rsp和rip存放的都是地址，所以这几个寄存器每个都相当于一个指针，看上图，rip指向的是main函数的第一条指令，rsp指向了当前函数调用栈的栈顶，而rbp寄存器并未指向我们关注的栈和指令，于是并未画出它的具体指向，只是显示了它的值。
为了更加清晰的理解程序的执行流程，现在我们开始模拟CPU从main函数的第一条指令开始，一直到执行完整个main函数。
现在开始执行第1条指令，
0x0000000000400540 &amp;lt;&#43;0&amp;gt;:push %rbp # 保存调用者的rbp寄存器的值 这条指令把栈基地址寄存器rbp的值临时保存在main函数的栈帧里，因为main函数需要使用这个寄存器来存放自己的栈基地址，而调用者在调用main函数之前也把它的栈基地址保存在了这个寄存器里面，所以main函数需要把这个寄存器里面的值先保存起来，等main执行完后返回时再把这个寄存器恢复原样，如果不恢复原样，main函数返回后调用者使用rbp寄存器时就会有问题，因为在执行调用者的代码时rbp本应该指向调用者的栈但现在却指向了main函数的栈。
在这条指令之前，代码还在使用调用者的栈帧，执行完这条指令之后，开始使用main函数的栈帧，目前main函数的栈帧里面只保存有调用者的rbp这一个值，在继续执行下一条指令之前，栈和寄存器的状态如下图，图中标红的指令表示刚执行完成的指令。可以看到rsp和rip寄存器的值都已经发生了改变，它们都指向了新的位置。rsp指向了main函数的栈帧的起始位置，而rip指向了main函数的第2条指令。
在汇编指令一节我们介绍过，执行push指令会修改rsp寄存器的值，但它并不会修改rip寄存器，为什么这里rip也变了呢？其实这是CPU自动完成的，CPU自己知道它要执行的每一条指令的长度有几个字节，比如这里的push %rbp指令只有1个字节长，于是它在开始执行这条指令时就会把rip的值&#43;1，因为执行这条指令之前rip的值为0x400540，&#43;1之后就变成了0x400541，也就是说它指向了main函数的第2条指令。
接着执行第2条指令，
0x0000000000400541 &amp;lt;&#43;1&amp;gt;:mov %rsp,%rbp # 调整rbp寄存器，使其指向main函数栈帧的起始位置 这条指令把rsp的值拷贝给rbp寄存器，让其指向main函数栈帧的起始位置，执行完这条指令之后rsp和rbp寄存器具有相同的值，他们都指向了main函数的栈帧的起始位置，如下图所示：
接着执行第3条指令，
0x0000000000400544 &amp;lt;&#43;4&amp;gt;:sub $0x20,%rsp # 调整rsp寄存器的值，为局部和临时变量预留栈空间 这条指令把rsp寄存器的值减去了32(16进制的0x20)，使其指向了栈空间中一个更低的位置，这一步看似只是简单的修改了rsp寄存器的值，其实质却是给main函数的局部变量和临时变量预留了32（0x20）字节的栈空间，为什么说是预留而不是分配，因为栈的分配是操作系统自动完成的，程序启动时操作系统就会给我们分配一大块内存用作函数调用栈，程序到底使用了多少栈内存由rsp栈顶寄存器来确定。
该指令执行完成之后，从rsp所指位置到rbp所指的这一段栈内存就构成了main函数的完整栈帧，其大小为40字节（8字节用于保存调用者的rbp，另外32字节用于main函数的局部和临时变量），如下图：
接下来的4条指令我们一起把它们执行了，
0x0000000000400548 &amp;lt;&#43;8&amp;gt;:mov %edi,-0x14(%rbp) 0x000000000040054b &amp;lt;&#43;11&amp;gt;:mov %rsi,-0x20(%rbp) 0x000000000040054f &amp;lt;&#43;15&amp;gt;:mov $0x2,%esi #sum函数的第2个参数放入esi寄存器 0x0000000000400554 &amp;lt;&#43;20&amp;gt;:mov $0x1,%edi #sum函数的第1个参数放入edi寄存器 前两条指令负责把main函数得到的两个参数保存在main函数的栈帧里面，可以看到，这里使用了rbp加偏移量的方式来访问栈内存。这里之所以要保存main函数的两个参数，是因为调用者在调用main函数时使用了edi和rsi两个寄存器来给main函数分别传递argc（整数）和argv（指针）两个参数，而main又需要用这两个寄存器给sum函数传递参数，为了不覆盖argc和argv，所以这里需要先把这两个参数保存在栈里面，然后再把传递给sum函数的两个参数1和2放入这两个寄存器之中。
后面两条指令在给sum函数准备参数，我们可以看到，传递给sum的第一个参数放在了edi寄存器里面，第二个参数放在了esi里面。可能你会问，被调用函数怎么知道参数放在这两个寄存器里面的啊？其实这是一个约定而已，大家约定好：调用函数时调用者负责把第一个参数放在rdi里面，第二个参数放在rsi里面，而被调函数直接去这两个寄存器里面把参数拿出来。这里还有个细节，传递给sum的两个参数都是用的edi和esi而不是rdi和rsi，原因在于C语言中int是32位的，而rdi和rsi都是64位的，edi和esi可以分别当成rdi和rsi的一部分来使用。
回到正题，执行完这4条指令后栈和寄存器的状态图(注意，下图中的argc使用的是图中连续8字节内存中的高4字节，低4字节未用)：
参数准备好了之后，接着执行call指令调用sum函数，
0x0000000000400559 &amp;lt;&#43;25&amp;gt;:callq 0x400526 #调用sum函数 call指令有点特殊，刚开始执行它的时候rip指向的是call指令的下一条指令，也就是说rip寄存器的值是0x40055e这个地址，但在call指令执行过程中，call指令会把当前rip的值（0x40055e）入栈，然后把rip的值修改为call指令后面的操作数，这里是0x400526，也就是sum函数第一条指令的地址，这样cpu就会跳转到sum函数去执行。
call指令执行完成后栈及寄存器的状态如下图所示，可以看到rip已经指向了sum函数的第1条指令，sum函数执行完成返回之后需要执行的指令的地址0x40055e也已经保存到了main函数的栈帧之中。
由于在main中执行了调用sum函数的call指令，CPU现在跳转到sum函数开始执行，
0x0000000000400526 &amp;lt;&#43;0&amp;gt;:push %rbp 0x0000000000400527 &amp;lt;&#43;1&amp;gt;:mov %rsp,%rbp 0x000000000040052a &amp;lt;&#43;4&amp;gt;:mov %edi,-0x14(%rbp)
0x000000000040052d &amp;lt;&#43;7&amp;gt;:mov %esi,-0x18(%rbp)
0x0000000000400530 &amp;lt;&#43;10&amp;gt;:mov -0x14(%rbp),%edx 0x0000000000400533 &amp;lt;&#43;13&amp;gt;:mov -0x18(%rbp),%eax 0x0000000000400536 &amp;lt;&#43;16&amp;gt;:add %edx,%eax 0x0000000000400538 &amp;lt;&#43;18&amp;gt;:mov %eax,-0x4(%rbp) 0x000000000040053b &amp;lt;&#43;21&amp;gt;:mov -0x4(%rbp),%eax 0x000000000040053e &amp;lt;&#43;24&amp;gt;:pop %rbp 0x000000000040053f &amp;lt;&#43;25&amp;gt;:retq
sum函数的前2条指令跟main函数前两条指令一模一样，
0x0000000000400526 &amp;lt;&#43;0&amp;gt;:push %rbp # sum函数序言，保存调用者的rbp 0x0000000000400527 &amp;lt;&#43;1&amp;gt;:mov %rsp,%rbp # sum函数序言，调整rbp寄存器指向自己的栈帧起始位置 都是在保存调用者的rbp然后设置新值使其指向当前函数栈帧的起始位置，这里sum函数保存了main函数的rbp寄存器的值（0x7fffffffe510），并使rbp寄存器指向了自己的栈帧的起始位置(地址为0x7fffffffe4e0)。
可以看到，sum的函数序言并未像main函数一样通过调整rsp寄存器的值来给sum函数预留用于局部变量和临时变量的栈空间，那这是不是说明sum函数就没有使用栈来保存局部变量呢，其实不是，从后面的分析可以看到，sum函数的局部变量s还是保存在栈上的。没有预留为什么可以使用呢，原因前面也说过，栈上的内存不需要在应用层代码中分配，操作系统已经给我们分配好了，尽管用就行了。main函数之所以需要调整rsp寄存器的值是因为它需要使用call指令来调用sum函数，而call指令会自动把rsp寄存器的值减去8然后把函数的返回地址保存到rsp所指的栈内存位置，如果main函数不调整rsp的值，则call指令保存函数返回地址时会覆盖局部变量或临时变量的值；而sum函数中没有任何指令会自动使用rsp寄存器来保存数据到栈上，所以不需要调整rsp寄存器。
紧接着的4条指令，
0x000000000040052a &amp;lt;&#43;4&amp;gt;:mov %edi,-0x14(%rbp) # 把第1个参数a放入临时变量 0x000000000040052d &amp;lt;&#43;7&amp;gt;:mov %esi,-0x18(%rbp) # 把第2个参数b放入临时变量 0x0000000000400530 &amp;lt;&#43;10&amp;gt;:mov -0x14(%rbp),%edx # 从临时变量中读取第1个到edx寄存器 0x0000000000400533 &amp;lt;&#43;13&amp;gt;:mov -0x18(%rbp),%eax # 从临时变量中读取第2个到eax寄存器 通过rbp寄存器加偏移量的方式把main传递给sum的参数保存在当前栈帧的合适位置，然后又取出来放入寄存器，这里有点多此一举，因为我们编译的时候未给gcc指定优化级别，gcc编译程序时默认不做任何优化，所以代码看起来比较啰嗦。
紧接着的几条指令
0x0000000000400536 &amp;lt;&#43;16&amp;gt;:add %edx,%eax # 执行a &#43; b并把结果保存到eax寄存器 0x0000000000400538 &amp;lt;&#43;18&amp;gt;:mov %eax,-0x4(%rbp) # 把加法结果赋值给变量s 0x000000000040053b &amp;lt;&#43;21&amp;gt;:mov -0x4(%rbp),%eax # 读取s变量的值到eax寄存器 第一条add指令负责执行加法运算并把结果3存入eax寄存器，第二条指令负责把eax寄存器的值保存到了s变量所在的内存，第三条指令又把s变量的值读取到eax寄存器，可以看到局部变量s被编译器安排在了rbp - 0x4这个地址所对应的内存之中。
到此，sum函数的主要功能已经完成，在继续执行最后的两条指令之前我们先来看看寄存器和栈的状态：
上图有1点需要说明一下：
sum函数的两个参数和返回值都是int型的，在内存中只占4个字节，而我们的示意图中每个栈内存单元占8个字节且按8字节地址边界进行了对齐，所以才是现在示意图中的这个样子。
我们来继续执行pop %rbp这条指令，这条指令包含两个操作：
把当前rsp所指栈内存中的值放入rbp寄存器，这样rbp就恢复到了还未执行sum函数的第一条指令时的值，也就是重新指向了main函数的栈帧起始地址。
把rsp寄存器中的值加8，这样rsp就指向了包含0x40055e这个值的栈内存，而这个栈单元中的值是当初main函数调用sum函数时call指令放入的，放入的这个值就是紧跟在call指令后面的下一条指令的地址。
还是来看看示意图：
继续retq指令，该指令把rsp指向的栈单元中的0x40055e取出给rip寄存器，同时rsp加8，这样rip寄存器中的值就变成了main函数中调用sum的call指令的下一条指令，于是就返回到main函数中继续执行。注意此时eax寄存器中的值是3，也就是sum函数执行后的返回值。还是来看一下状态。
继续执行main函数中的
mov %eax,-0x4(%rbp) # 把sum函数的返回值赋给变量n 该指令把eax寄存器中的值（3）放入rbp - 4所指的内存，这里是变量n所在的位置，所以这条语句其实就是把sum函数的返回值赋值给变量n。这时状态为：
后面的几条指令
0x0000000000400561 &amp;lt;&#43;33&amp;gt;:mov -0x4(%rbp),%eax 0x0000000000400564 &amp;lt;&#43;36&amp;gt;:mov %eax,%esi 0x0000000000400566 &amp;lt;&#43;38&amp;gt;:mov $0x400604,%edi 0x000000000040056b &amp;lt;&#43;43&amp;gt;:mov $0x0,%eax 0x0000000000400570 &amp;lt;&#43;48&amp;gt;:callq 0x400400 printf@plt 0x0000000000400575 &amp;lt;&#43;53&amp;gt;:mov $0x0,%eax 首先为printf函数准备参数然后调用printf函数，在此我们就不分析它们了，因为调用printf和sum的过程差不多，我们让CPU快速执行完这几条指令然后暂停在main函数的倒数第二条的leaveq指令处，这时栈和寄存器状态如下：
leaveq指令上面的一条指令mov $0x0, %eax的作用在于把main函数的返回值0放在eax寄存器中，等main返回后调用main函数的函数可以拿到这个返回值。下面执行leaveq指令，
0x000000000040057a &amp;lt;&#43;58&amp;gt;:leaveq 该指令相当于如下两条指令：
mov %rbp, %rsp pop %rbp leaveq指令首先把rbp寄存器中的值复制给rsp，这样rsp就指向了rbp所指的栈单元，然后把使该内存单元中的值POP给rbp寄存器，这样rbp和rsp的值就恢复成刚刚进入main函数时的状态了。看图：
到此main函数就只剩下retq指令了，前面分析sum函数时已经详细分析过它了，这条指令执行完成后就会完全返回到调用main函数的函数中去继续执行。
go语言中的函数调用过程
前面花了很大篇幅分析了C语言的函数调用过程，包括参数的传递，call指令，ret指令，还有返回值如何从被调用函数返回给调用函数的，有了这些基础， 接下来我们来看go语言中的函数调用过程，其实二者原理是一样的，只是细节上有一点差异。还是用一个简单的例子来分析。
package main
//计算a, b的平方和 func sum(a, b int) int { a2 := a * a b2 := b * b c := a2 &#43; b2
 return c  }
func main() { sum(1, 2) } 使用go build编译该程序，注意这里需要指定 -gcflags &amp;ldquo;-N -l&amp;rdquo; 关闭编译器优化，否则编译器可能把对sum函数的调用优化掉。
bobo@ubuntu:~/study/go$ go build -gcflags &amp;ldquo;-N -l&amp;rdquo; sum.go 编译后得到二进制可执行程序sum， 首先来看main函数的反汇编代码：
Dump of assembler code for function main.main: 0x000000000044f4e0 &amp;lt;&#43;0&amp;gt;: mov %fs:0xfffffffffffffff8,%rcx #暂时不关注 0x000000000044f4e9 &amp;lt;&#43;9&amp;gt;: cmp 0x10(%rcx),%rsp #暂时不关注 0x000000000044f4ed &amp;lt;&#43;13&amp;gt;: jbe 0x44f51d &amp;lt;main.main&#43;61&amp;gt; #暂时不关注 0x000000000044f4ef &amp;lt;&#43;15&amp;gt;: sub $0x20,%rsp #为main函数预留32字节栈空间 0x000000000044f4f3 &amp;lt;&#43;19&amp;gt;: mov %rbp,0x18(%rsp) #保存调用者的rbp寄存器 0x000000000044f4f8 &amp;lt;&#43;24&amp;gt;: lea 0x18(%rsp),%rbp #调整rbp使其指向main函数栈帧开始地址 0x000000000044f4fd &amp;lt;&#43;29&amp;gt;: movq $0x1,(%rsp) #sum函数的第一个参数（1）入栈 0x000000000044f505 &amp;lt;&#43;37&amp;gt;: movq $0x2,0x8(%rsp) #sum函数的第二个参数（2）入栈 0x000000000044f50e &amp;lt;&#43;46&amp;gt;: callq 0x44f480 &amp;lt;main.sum&amp;gt; #调用sum函数 0x000000000044f513 &amp;lt;&#43;51&amp;gt;: mov 0x18(%rsp),%rbp #恢复rbp寄存器的值为调用者的rbp 0x000000000044f518 &amp;lt;&#43;56&amp;gt;: add $0x20,%rsp #调整rsp使其指向保存有调用者返回地址的栈单元 0x000000000044f51c &amp;lt;&#43;60&amp;gt;: retq #返回到调用者 0x000000000044f51d &amp;lt;&#43;61&amp;gt;: callq 0x447390 &amp;lt;runtime.morestack_noctxt&amp;gt; #暂时不关注 0x000000000044f522 &amp;lt;&#43;66&amp;gt;: jmp 0x44f4e0 &amp;lt;main.main&amp;gt; #暂时不关注 End of assembler dump. main函数前面三条和最后两条指令是go编译器插入用于检查栈溢出的代码，我们现在不需要关注。其它部分跟C语言中的函数差不多，不过有点差别的是go语言函数调用时参数放在了栈上（第7和第8条指令把参数放在了栈上），从第4条指令可以看出，编译器给main函数预留了32个字节用于存放main的栈基址rbp、调用sum函数时的两个参数，这三项各占8个字节所以共占24字节，那还有8个字节拿来干什么的呢？从下面的sum函数可以看出来，剩下的8个字节用于存放sum函数的返回值。
Dump of assembler code for function main.sum: 0x000000000044f480 &amp;lt;&#43;0&amp;gt;: sub $0x20,%rsp #为sum函数预留32字节的栈空间 0x000000000044f484 &amp;lt;&#43;4&amp;gt;: mov %rbp,0x18(%rsp) #保存main函数的rbp 0x000000000044f489 &amp;lt;&#43;9&amp;gt;: lea 0x18(%rsp),%rbp #设置sum函数的rbp 0x000000000044f48e &amp;lt;&#43;14&amp;gt;: movq $0x0,0x38(%rsp) #返回值初始化为0 0x000000000044f497 &amp;lt;&#43;23&amp;gt;: mov 0x28(%rsp),%rax #从内存中读取第一个参数a(1)到rax 0x000000000044f49c &amp;lt;&#43;28&amp;gt;: mov 0x28(%rsp),%rcx #从内存中读取第一个参数a(1)到rcx 0x000000000044f4a1 &amp;lt;&#43;33&amp;gt;: imul %rax,%rcx #计算a * a，并把结果放在rcx 0x000000000044f4a5 &amp;lt;&#43;37&amp;gt;: mov %rcx,0x10(%rsp) #把rcx的值（a * a）赋值给变量a2 0x000000000044f4aa &amp;lt;&#43;42&amp;gt;: mov 0x30(%rsp),%rax #从内存中读取第二个参数a(2)到rax 0x000000000044f4af &amp;lt;&#43;47&amp;gt;: mov 0x30(%rsp),%rcx #从内存中读取第二个参数a(2)到rcx 0x000000000044f4b4 &amp;lt;&#43;52&amp;gt;: imul %rax,%rcx #计算b * b，并把结果放在rcx 0x000000000044f4b8 &amp;lt;&#43;56&amp;gt;: mov %rcx,0x8(%rsp) #把rcx的值（b * b）赋值给变量b2 0x000000000044f4bd &amp;lt;&#43;61&amp;gt;: mov 0x10(%rsp),%rax #从内存中读取a2到寄存器rax 0x000000000044f4c2 &amp;lt;&#43;66&amp;gt;: add %rcx,%rax #计算a2 &#43; b2,并把结果保存在rax 0x000000000044f4c5 &amp;lt;&#43;69&amp;gt;: mov %rax,(%rsp) #把rax赋值给变量c, c = a2 &#43; b2 0x000000000044f4c9 &amp;lt;&#43;73&amp;gt;: mov %rax,0x38(%rsp) #将rax的值（a2 &#43; b2）复制给返回值 0x000000000044f4ce &amp;lt;&#43;78&amp;gt;: mov 0x18(%rsp),%rbp #恢复main函数的rbp 0x000000000044f4d3 &amp;lt;&#43;83&amp;gt;: add $0x20,%rsp #调整rsp使其指向保存有返回地址的栈单元 0x000000000044f4d7 &amp;lt;&#43;87&amp;gt;: retq #返回main函数 End of assembler dump. sum函数的汇编代码比较直观，基本上就是对go语言sum函数的直接翻译，可以看到sum函数通过rsp寄存器从main函数栈中获取参数，返回值也通过rsp保存在了main函数的栈帧中。
下图是已经执行完成sum函数的0x000000000044f4c9 &amp;lt;&#43;73&amp;gt;: mov %rax,0x38(%rsp)这条指令但还未开始执行下一条指令时栈以及栈寄存器之间的关系图，读者可以结合上面的汇编代码和该图，加深对函数调用过程中的参数传递、返回值以及局部变量在栈上的位置和关系的理解。
总结
最后我们来总结一下函数调用过程：
参数传递。gcc编译的c/c&#43;&#43;代码一般通过寄存器传递参数，在AMD64 Linux 平台，gcc约定函数调用时前面6个参数分别通过rdi, rsi, rdx, r10, r8及r9传递；而go语言函数调用时参数是通过栈传递给被调用函数的，最后一个参数最先入栈，第一个参数最后入栈，参数在调用者的栈帧之中，被调用函数通过rsp加一定的偏移量来获取参数；
call指令负责把执行call指令时的rip寄存器（函数返回地址）入栈；
gcc通过rbp加偏移量的方式来访问局部和临时变量，而go编译器则使用rsp寄存器加偏移量的方式来访问它们；
ret指令负责把call指令入栈的返回地址出栈给rip，从而实现从被调用函数返回到调用函数继续执行；
gcc使用rax寄存器返回函数调用的返回值，而go使用栈返回函数调用的返回值。
最后，如果你觉得本文对你有帮助的话，麻烦帮忙点一下文末右下角的 在看 或转发到朋友圈，非常感谢！
</content>
    </entry>
    
     <entry>
        <title>go语言调度器源代码情景分析之六：go汇编语言</title>
        <url>http://shanks.link/blog/2021/04/02/go%E8%AF%AD%E8%A8%80%E8%B0%83%E5%BA%A6%E5%99%A8%E6%BA%90%E4%BB%A3%E7%A0%81%E6%83%85%E6%99%AF%E5%88%86%E6%9E%90%E4%B9%8B%E5%85%ADgo%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 爱写程序的阿波张 源码游记 2019-04-21
go语言runtime（包括调度器）源代码中有部分代码是用汇编语言编写的，不过这些汇编代码并非针对特定体系结构的汇编代码，而是go语言引入的一种伪汇编，它同样也需要经过汇编器转换成机器指令才能被CPU执行。需要注意的是，用go汇编语言编写的代码一旦经过汇编器转换成机器指令之后，再用调试工具反汇编出来的代码已经不是go语言汇编代码了，而是跟平台相关的汇编代码。
go汇编格式跟前面讨论过的AT&amp;amp;T汇编基本上差不多，但也有些重要区别，本节就这些差异做一个简单说明。
寄存器
go汇编语言中使用的寄存器的名字与AMD64不太一样，下表显示了它们之间的对应关系：
除了这些跟AMD64 CPU硬件寄存器一一对应的寄存器外，go汇编还引入了几个没有任何硬件寄存器与之对应的虚拟寄存器，这些寄存器一般用来存放内存地址，引入它们的主要目的是为了方便程序员和编译器用来定位内存中的代码和数据。
下面重点介绍在go汇编中常见的2个虚拟寄存器的使用方法：
FP虚拟寄存器：主要用来引用函数参数。go语言规定函数调用时参数都必须放在栈上，比如被调用函数使用 first_arg&#43;0(FP) 来引用调用者传递进来的第一个参数，用second_arg&#43;8(FP)来引用第二个参数 ，以此类推，这里的first_arg和second_arg仅仅是一个帮助我们阅读源代码的符号，对编译器来说无实际意义，&#43;0和&#43;8表示相对于FP寄存器的偏移量。我们用一个runtime中的函数片段作为例子来看看FP的使用。
go runtime中有一个叫gogo的函数，它接受一个gobuf类型的指针
// func gogo(buf *gobuf) // restore state from Gobuf; longjmp TEXT runtime·gogo(SB), NOSPLIT, $16-8 MOVQbuf&#43;0(FP), BX// gobuf &amp;ndash;&amp;gt;bx &amp;hellip;&amp;hellip; MOVQ buf&#43;0(FP), BX这一条指令把调用者传递进来的指针buf放入BX寄存器中，可以看到，在gogo函数是通过buf&#43;0(FP)这种方式获取到参数的。从被调用函数（此处为gogo函数）的角度来看，FP与函数栈帧之间的关系如下图，可以看出FP寄存器指向调用者的栈帧，而不是被调用函数的栈帧。
SB虚拟寄存器：保存程序地址空间的起始地址。还记得在函数调用栈一节我们看过的进程在内存中的布局那张图吗，这个SB寄存器保存的值就是代码区的起始地址，它主要用来定位全局符号。go汇编中的函数定义、函数调用、全局变量定义以及对其引用会用到这个SB虚拟寄存器。对于这个虚拟寄存器，我们不用过多的关注，在代码中看到它时知道它是一个虚拟寄存器就行了。
操作码
AT&amp;amp;T格式的寄存器操作码一般使用小写且寄存器的名字前面有个%符号，而go汇编使用大写而且寄存器名字前没有%符号，比如:
AT&amp;amp;T格式 mov %rbp,%rsp
go汇编格式 MOVQ BP,SP
操作数宽度（即操作数的位数）
AT&amp;amp;T格式的汇编指令中如果有寄存器操作数，则根据寄存器的名字（比如rax, eax, ax, al分别代表64，32，16和8位寄存器）就可以确定操作数到底是多少位（8，16，32还是64位），所以不需要操作码后缀，如果没有寄存器操作数又是访存指令的话，则操作码需要加上后缀b、w、l或q来指定到底存取内存中的多少个字节。
而go汇编中，寄存器的名字没有位数之分，比如AX寄存器没有什么RAX, EAX之类的名字，指令中一律只能使用AX。所以如果指令中有操作数寄存器或是指令需要访问内存，则操作码都需要带上后缀B(8位)、W(16位)、D(32位)或Q(64位)。
函数定义
还是以go runtime中的gogo函数为例：
// func gogo(buf *gobuf) // restore state from Gobuf; longjmp TEXT runtime·gogo(SB), NOSPLIT, $16-8 &amp;hellip;&amp;hellip; 下面对这个函数定义的第一行的各部分做个说明：
TEXT runtime·gogo(SB)：指明在代码区定义了一个名字叫gogo的全局函数（符号），该函数属于runtime包。
NOSPLIT：指示编译器不要在这个函数中插入检查栈是否溢出的代码。
$16-8：数字16说明此函数的栈帧大小为16字节，8说明此函数的参数和返回值一共需要占用8字节内存。因为这里的gogo函数没有返回值，只有一个指针参数，对于AMD64平台来说指针就是8字节。go语言中函数调用的参数和函数返回值都是放在栈上的，而且这部分栈内存是由调用者而非被调用函数负责预留，所以在函数定义时需要说明到底需要在调用者的栈帧中预留多少空间。
go汇编还有一些用法比较特别的地方，现在不讨论，等我们分析源代码遇到它们时再结合上下文做详细说明。
最后，如果你觉得本文对你有帮助的话，麻烦帮忙点一下文末右下角的 在看 或转发到朋友圈，非常感谢！
</content>
    </entry>
    
     <entry>
        <title>go语言调度器源代码情景分析之五：汇编指令</title>
        <url>http://shanks.link/blog/2021/04/02/go%E8%AF%AD%E8%A8%80%E8%B0%83%E5%BA%A6%E5%99%A8%E6%BA%90%E4%BB%A3%E7%A0%81%E6%83%85%E6%99%AF%E5%88%86%E6%9E%90%E4%B9%8B%E4%BA%94%E6%B1%87%E7%BC%96%E6%8C%87%E4%BB%A4/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 爱写程序的阿波张 源码游记 2019-04-20
汇编语言是每位后端程序员都应该掌握的一门语言，因为学会了汇编语言，不管是对我们调试程序还是研究与理解计算机底层的一些运行原理都具有非常重要的作用，所以建议有兴趣的读者可以多花点时间把它学好。
与高级编程语言一样，汇编语言也是一门完整的计算机编程语言，它所涉及的知识内容也很多，好在我们的主要目标是通过对本小节的学习而有能力去读懂汇编代码，而不是要用汇编语言去写代码，所以本节并不会全面介绍汇编语言，而只会选取汇编语言的一个子集&amp;ndash;汇编指令出来做介绍。不过，虽然这里的介绍做了精简，但读者大可放心，熟练运用这些知识就足以应付本书将要分析的goroutine调度器中的汇编代码了。
说到汇编指令，不得不提一下机器指令，二进制格式的机器指令才是CPU能够理解的语言，因为它是二进制格式的，非常便于CPU的解析和执行，但并不利于人类阅读和交流，所以才有了跟机器指令一一对应的汇编指令，汇编指令使用符号来表示机器指令，下面的例子非常直观的说明了这两种指令之间的差异：
0x40054d : add %rdx,%rax // 汇编指令
(gdb) x/3xb 0x40054d 0x40054d : 0x48 0x01 0xd0 // 机器指令 (gdb) 同样是把rdx和rax寄存器中的值相加，汇编指令为：add %rdx,%rax，而机器指令却是三个数字：0x48 0x01 0xd0，显然，汇编指令对人类来说更加友好，它更加易记易读和易写。
汇编指令格式
因为不同的CPU所支持的机器指令不一样，所以其汇编指令也不同，即使是相同的CPU，不同的汇编工具和平台所使用的汇编指令格式也有些差别，由于本书主要专注于AMD64 Linux平台下的go调度器，因此下面我们只介绍该平台下所使用的AT&amp;amp;T格式的汇编指令，AT&amp;amp;T汇编指令的基本格式为：
操作码 [操作数] 可以看到每一条汇编指令通常都由两部分组成：
操作码：操作码指示CPU执行什么操作，比如是执行加法，减法还是读写内存。每条指令都必须要有操作码。
操作数：操作数是操作的对象，比如加法操作需要两个加数，这两个加数就是这条指令的操作数。操作数的个数一般是0个，1个或2个。
来看几个汇编指令的例子
add %rdx,%rax 这条指令的操作码是add，表示执行加法操作，它有两个操作数，rdx和rax。如果一条指令有两个操作数，那么第一个操作数叫做源操作数，第二个操作数叫做目的操作数，顾名思义，目的操作数表示这条指令执行完后结果应该保存的地方。所以上面这条指令表示对rax和rdx寄存器里面的值求和，并把结果保存在rax寄存器中。其实这条指令的第二个操作数rax寄存器既是源操作数也是目的操作数，因为rax既是加法操作的两个加数之一，又得存放加法操作的结果。这条指令执行完后rax寄存器的值发生了改变，指令执行前的值被覆盖而丢失了，如果rax寄存器之前的值还有用，那么就得先用指令把它保存到其它寄存器或内存之中。
再来看一个只有一个操作数的例子：
callq 0x400526
这条指令的操作码是callq，表示调用函数，操作数是0x400526，它是被调用函数的地址。
最后来看一条没有操作数的指令：
retq 这条指令只有操作码retq，表示从被调用函数返回到调用函数继续执行。
为了更好的理解AT&amp;amp;T格式的汇编指令，这里先对其格式做一个简要的说明：
  AT&amp;amp;T格式的汇编指令中，寄存器名需要加%作为前缀，前面我们已经见过；
  有2个操作数的指令中，第一个操作数是源操作数，第二个是目的操作数，刚才也讨论过，不过那条指令中的源和目的不是那么清晰，来看一个直白的，mov %eax,%esi，这条指令表示把eax寄存器中的值拷贝给esi，这条指令中源和目的就很清楚了；
  立即操作数需要加上$符号做前缀，如 &amp;ldquo;mov $0x1 %rdi&amp;rdquo; 这条指令中第一个操作数不是寄存器，也不是内存地址，而是直接写在指令中的一个常数，这种操作数叫做立即操作数。这条指令表示把数值0x1放入rdi寄存器中。
  寄存器间接寻址的格式为 offset(%register)，如果offset为0，则可以略去偏移不写直接写成(%register)。何为间接寻址呢？其实就是指指令中的寄存器并不是真正的源操作数或目的操作数，寄存器的值是一个内存地址，这个地址对应的内存才是真正的源或目的操作数，比如 mov %rax, (%rsp)这条指令，第二个操作数(%rsp)中的寄存器的名字用括号括起来了，表示间接寻址，rsp的值是一个内存地址，这条指令的真实意图是把rax寄存器中的值赋值给rsp寄存器的值（内存地址）对应的内存，rsp寄存器本身的值不会被修改，作为比较，我们看一下 mov %rax, %rsp 这条指令 ，这里第二个操作数仅仅少了个括号，变成了直接寻址，意思完全不一样了，这条指令的意思是把rax的值赋给rsp，这样rsp寄存器的值被修改为跟rax寄存器一样的值了。下面的2张图展示了这两种寻址方式的不同：
  执行mov %rax, %rsp这条指令之前，rsp寄存器的值是x，rax寄存器的值是y，执行指令之后，rax寄存器的值被复制给了rsp寄存器，所以rsp寄存器的值变成了y，可以看出，采用直接寻址方式时，目的操作数rsp寄存器的值在指令执行之前和指令执行之后发生了变化，源操作数没有变化。再看看间接寻址方式的示意图：
执行mov %rax, （%rsp）这条指令之前，rax寄存器的值是y，rsp寄存器的值是X，它是一个内存地址，如上图所示，我们用了一个红色箭头从rsp寄存器指向了地址为X的内存；执行指令之后，rsp寄存器的值并没有发生变化，而rsp所指的内存中的值却发生了改变，因为这条指令的目的操作数采用了间接寻址方式(%rsp)，指令执行的结果是rax寄存器中的值被复制到了rsp寄存器存放的地址所对应的8个内存单元中。另外需要注意的是指令中出现的内存地址仅仅是起始地址，具体要操作以这个地址为起始地址的连续几个内存单元要根据具体的指令而定，比如上图中的mov %rax,(%rsp)，因为源操作数是一个64位的寄存器，所以这条指令会复制rax存放的8个字节到地址为X, X&#43;1, X&#43;2, X&#43;3, X&#43;4, X&#43;5, X&#43;6, X&#43;7这8个内存单元中去。
间接寻址格式offset(%register)中前面的offset表示偏移，如-0x8(%rbp)，-0x8就是偏移量，整个表示rbp寄存器里面保存的地址值先减去8（因为偏移是负8）得到的地址对应的内存。
与内存相关的一些指令的操作码会加上b, w, l和q字母分别表示操作的内存是1，2，4还是8个字节，比如指令 movl $0x0,-0x8(%rbp) ，这条指令操作码movl的后缀字母l说明我们要把从-0x8(%rbp) 这个地址开始的4个内存单元赋值为0。可能有读者会问，那如果我要操作3个，或5个内存单元呢？很遗憾的是cpu没有提供相应的单条指令，我们只能通过多条指令组合起来达到目的。  常用指令详解
x86-64汇编指令上千条，这里不会去详细讲解每一条，读者如果有兴趣可以参考汇编语言相关教程。我们在这里着重关注几条非常常见或是能帮助我们理解程序运行机制的指令。
mov指令
mov 源操作数 目的操作数 该指令复制源操作数到目的操作数。例：
mov %rsp,%rbp # 直接寻址，把rsp的值拷贝给rbp，相当于 rbp = rsp mov -0x8(%rbp),%edx # 源操作数间接寻址，目的操作数直接寻址。从内存中读取4个字节到edx寄存器 mov %rsi,-0x8(%rbp) # 源操作数直接寻址，目的操作数间接寻址。把rsi寄存器中的8字节值写入内存 add/sub指令
add 源操作数 目的操作数 sub 源操作数 目的操作数 加减运算指令。例：
sub $0x350,%rsp # 源操作数是立即操作数，目的操作数直接寻址。rsp = rsp - 0x350 add %rdx,%rax # 直接寻址。rax = rax &#43; rdx addl $0x1,-0x8(%rbp) # 源操作数是立即操作数，目的操作数间接寻址。内存中的值加1（addl后缀字母l表示操作内存中的4个字节） call/ret指令
call 目标地址 ret call指令执行函数调用。CPU执行call指令时首先会把rip寄存器中的值入栈，然后设置rip值为目标地址，又因为rip寄存器决定了下一条需要执行的指令，所以当CPU执行完当前call指令后就会跳转到目标地址去执行。
ret指令从被调用函数返回调用函数，它的实现原理是把call指令入栈的返回地址弹出给rip寄存器。
下面用例子对这两条指令的原理加以说明。
#调用函数片段 0x0000000000400559 : callq 0x400526 0x000000000040055e : mov %eax,-0x4(%rbp)
#被调用函数片段 0x0000000000400526 : push %rbp &amp;hellip;&amp;hellip; 0x000000000040053f : retq
上面代码片段中，调用函数使用callq 0x400526指令调用0x400526处的函数，0x400526是被调用函数的第一条指令所在的地址。被调用函数在0x40053f处执行retq指令返回调用函数继续执行0x40055e地址处的指令。注意这两条指令会涉及入栈和出栈操作，所以会影响rsp寄存器的值。
从上图可以看到call指令执行之初rip寄存器的值是紧跟call后面那一条指令的地址，即0x40055e，但当call指令完成后但还未开始执行下一条指令之前，rip寄存器的值变成了call指令的操作数，即被调用函数的地址0x400526，这样CPU就会跳转到被调用函数去执行了。
同时还需要注意的是这里的call指令执行时把call指令后面那一条指令的地址 0x40055e PUSH到了栈上，所以一条call指令修改了3个地方的值：rip寄存器、rsp和栈。
下面我们再看看从被调用函数返回调用函数时执行的ret指令，其示意图如下：
可以看到ret指令执行的操作跟call指令执行的操作完全相反，ret指令开始执行时rip寄存器的值是紧跟ret指令后面的那个地址，也就是0x400540，但ret指令执行过程中会把之前call指令PUSH到栈上的返回地址 0x40055e POP给rip寄存器，这样，当ret执行完成后就会从被调用函数返回到调用函数的call指令的下一条指令继续执行。这里同样要注意的是retq指令也会修改rsp寄存器的值。
jmp/je/jle/jg/jge等等j开头的指令
这些都属于跳转指令，操作码后面直接跟要跳转到的地址或存有地址的寄存器，这些指令与高级编程语言中的 goto 和 if 等语句对应。用法示例：
jmp 0x4005f2 jle 0x4005ee jl 0x4005b8 push/pop指令
push 源操作数 pop 目的操作数 专用于函数调用栈的入栈出栈指令，这两个指令都会自动修改rsp寄存器。
push入栈时rsp寄存器的值先减去8把栈位置留出来，然后把操作数复制到rsp所指位置。push指令相当于：
sub $8,%rsp mov 源操作数,(%rsp) push指令需要重点注意rsp寄存器的变化。
pop出栈时先把rsp寄存器所指位置的数据复制到目的操作数中，然后rsp寄存器的值加8。pop指令相当于：
mov (%rsp),目的操作数 add $8,%rsp 同样，pop指令也需要重点注意rsp寄存器的变化。
leave指令
leave指令没有操作数，它一般放在函数的尾部ret指令之前，用于调整rsp和rbp，这条指令相当于如下两条指令：
mov %rbp,%rsp pop %rbp
AMD64汇编我们就介绍这么多，下一节我们将介绍go runtime中使用的go汇编语言，它与这里介绍的AMD64汇编类似，但有一些差别。理解了本节的内容，go汇编也就很容易理解了。
</content>
    </entry>
    
     <entry>
        <title>go语言调度器源代码情景分析之四：函数调用栈</title>
        <url>http://shanks.link/blog/2021/04/01/go%E8%AF%AD%E8%A8%80%E8%B0%83%E5%BA%A6%E5%99%A8%E6%BA%90%E4%BB%A3%E7%A0%81%E6%83%85%E6%99%AF%E5%88%86%E6%9E%90%E4%B9%8B%E5%9B%9B%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E6%A0%88/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 阿波张 源码游记 2019-04-19
什么是栈
栈是一种“后进先出”的数据结构，它相当于一个容器，当需要往容器里面添加元素时只能放在最上面的一个元素之上，需要取出元素时也只能从最上面开始取，通常我们称添加元素为入栈(push)，取出元素为出栈(pop)。
不知道读者是否有快餐店吃饭的经历，快餐店一般都有一摞干净的盘子让顾客取用，这就好比一个栈，我们取盘子时通常都是拿走最上面一个(pop)，当盘子被取走剩得不多时，服务员又会拿一些干净的盘子放在原有盘子的上面(push)，取盘子和放盘子这一端用栈的术语来说叫栈顶，另一端叫栈底。
下面用图演示一下栈的push和pop。
进程在内存中的布局
严格说来这里讲的是进程在虚拟地址空间中的布局，但这并不影响我们的讨论，所以这里我们就不做区分，笼统的称之为进程在内存中的布局。
操作系统把磁盘上的可执行文件加载到内存运行之前，会做很多工作，其中很重要的一件事情就是把可执行文件中的代码，数据放在内存中合适的位置，并分配和初始化程序运行过程中所必须的堆栈，所有准备工作完成后操作系统才会调度程序起来运行。来看一下程序运行时在内存中的布局图：
进程在内存中的布局主要分为4个区域：代码区，数据区，堆和栈。在详细讨论栈之前，先来简单介绍一下其它区域。
代码区，包括能被CPU执行的机器代码（指令）和只读数据比如字符串常量，程序一旦加载完成代码区的大小就不会再变化了。
数据区，包括程序的全局变量和静态变量（c语言有静态变量，而go没有），与代码区一样，程序加载完毕后数据区的大小也不会发生改变。
堆，程序运行时动态分配的内存都位于堆中，这部分内存由内存分配器负责管理。该区域的大小会随着程序的运行而变化，即当我们向堆请求分配内存但分配器发现堆中的内存不足时，它会向操作系统内核申请向高地址方向扩展堆的大小，而当我们释放内存把它归还给堆时如果内存分配器发现剩余空闲内存太多则又会向操作系统请求向低地址方向收缩堆的大小。从这个内存申请和释放流程可以看出，我们从堆上分配的内存用完之后必须归还给堆，否则内存分配器可能会反复向操作系统申请扩展堆的大小从而导致堆内存越用越多，最后出现内存不足，这就是所谓的内存泄漏。值的一提的是传统的c/c&#43;&#43;代码就必须小心处理内存的分配和释放，而在go语言中，有垃圾回收器帮助我们，所以程序员只管申请内存，而不用管内存的释放，这大大降低了程序员的心智负担，这不光是提高了程序员的生产力，更重要的是还会减少很多bug的产生。
函数调用栈
函数调用栈简称栈，在程序运行过程中，不管是函数的执行还是函数调用，栈都起着非常重要的作用，它主要被用来：
保存函数的局部变量；
向被调用函数传递参数；
返回函数的返回值；
保存函数的返回地址。返回地址是指从被调用函数返回后调用者应该继续执行的指令地址，在汇编指令一节介绍call指令时我们将会对返回地址做更加详细的说明。
每个函数在执行过程中都需要使用一块栈内存用来保存上述这些值，我们称这块栈内存为某函数的栈帧(stack frame)。当发生函数调用时，因为调用者还没有执行完，其栈内存中保存的数据还有用，所以被调用函数不能覆盖调用者的栈帧，只能把被调用函数的栈帧“push”到栈上，等被调函数执行完成后再把其栈帧从栈上“pop”出去，这样，栈的大小就会随函数调用层级的增加而生长，随函数的返回而缩小，也就是说函数调用层级越深，消耗的栈空间就越大。栈的生长和收缩都是自动的，由编译器插入的代码自动完成，因此位于栈内存中的函数局部变量所使用的内存随函数的调用而分配，随函数的返回而自动释放，所以程序员不管是使用有垃圾回收还是没有垃圾回收的高级编程语言都不需要自己释放局部变量所使用的内存，这一点与堆上分配的内存截然不同。
另外，AMD64 Linux平台下，栈是从高地址向低地址方向生长的，为什么栈会采用这种看起来比较反常的生长方向呢，具体原因无从考究，不过根据前面那张进程的内存布局图可以猜测，当初这么设计的计算机科学家是希望尽量利用内存地址空间，才采用了堆和栈相向生长的方式，因为程序运行之前无法确定堆和栈谁会消耗更多的内存，如果栈也跟堆一样向高地址方向生长的话，栈底的位置不好确定，离堆太近则堆内存可能不够用，离堆太远栈又可能不够用，于是乎就采用了现在这种相向生长的方式。
AMD64 CPU提供了2个与栈相关的寄存器：
rsp寄存器，始终指向函数调用栈栈顶
rbp寄存器，一般用来指向函数栈帧的起始位置
下面用两个图例来说明一下函数调用栈以及rsp/rbp与栈之间的关系。
假设现在有如下函数调用链且正在执行函数C()：
A()-&amp;gt;B()-&amp;gt;C() 则函数ABC的栈帧以及rsp/rbp的状态大致如下图所示（注意，栈从高地址向低地址方向生长）：
对于上图，有几点需要说明一下：
调用函数时，参数和返回值都是存放在调用者的栈帧之中，而不是在被调函数之中；
目前正在执行C函数，且函数调用链为A()-&amp;gt;B()-&amp;gt;C()，所以以栈帧为单位来看的话，C函数的栈帧目前位于栈顶；
CPU硬件寄存器rsp指向整个栈的栈顶，当然它也指向C函数的栈帧的栈顶，而rbp寄存器指向的是C函数栈帧的起始位置；
虽然图中ABC三个函数的栈帧看起来都差不多大，但事实上在真实的程序中，每个函数的栈帧大小可能都不同，因为不同的函数局部变量的个数以及所占内存的大小都不尽相同；
有些编译器比如gcc会把参数和返回值放在寄存器中而不是栈中，go语言中函数的参数和返回值都是放在栈上的；
随着程序的运行，如果C、B两个函数都执行完成并返回到了A函数继续执行，则栈状态如下图：
因为C、B两个函数都已经执行完成并返回到了A函数之中，所以C、B两个函数的栈帧就已经被POP出栈了，也就是说它们所消耗的栈内存被自动回收了。因为现在正在执行A函数，所以寄存器rbp和rsp指向的是A函数的栈中的相应位置。如果A函数又继续调用了D函数的话，则栈又变成下面这个样子：
可以看到，现在D函数的栈帧其实使用的是之前调用B、C两个函数所使用的栈内存，这没有问题，因为B和C函数已经执行完了，现在D函数重用了这块内存，这也是为什么在C语言中绝对不要返回函数局部变量的地址，因为同一个地址的栈内存会被重用，这就会造成意外的bug，而go语言中没有这个限制，因为go语言的编译器比较智能，当它发现程序返回了某个局部变量的地址，编译器会把这个变量放到堆上去，而不会放在栈上。同样，这里我们还是需要注意rbp和rsp这两个寄存器现在指向了D函数的栈帧。从上面的分析我们可以看出，寄存器rbp和rsp始终指向正在执行的函数的栈帧。
最后，我们再来看一个递归函数的例子，假设有如下go语言代码片段：
func f(n int) { if n &amp;lt;= 0 { //递归结束条件 n &amp;lt;= 0 return } &amp;hellip;&amp;hellip; f(n - 1) //递归调用f函数自己 &amp;hellip;&amp;hellip; } 函数f是一个递归函数，f函数会一直递归的调用自己直到参数 n 小于等于0为止，如果我们在其它某个函数里调用了f(10)，而且现在正在执行f(8)的话，则其栈状态如下图所示：
从上图可以看出，即使是同一个函数，每次调用都会产生一个不同的栈帧，因此对于递归函数，每递归一次都会消耗一定的栈内存，如果递归层数太多就有导致栈溢出的风险，这也是为什么我们在实际的开发过程中应该尽量避免使用递归函数的原因之一，另外一个原因是递归函数执行效率比较低，因为它要反复调用函数，而调用函数有较大的性能开销。
本节我们简要的介绍了栈的基本概念及它在程序运行过程中的重要作用，但遗留了一些细节问题，比如每个函数的栈帧是怎么分配的，局部变量和参数又是如何保存在栈中的，又是谁把返回地址放在了栈上等等，这些内容我们会在函数调用过程一节加以详细介绍。这里为什么不把细节跟概念放在一起讨论呢，主要是因为我们首先要对栈有个大致的了解，才能更好的理解下一节即将讲述的有关汇编语言相关的知识，而没有汇编语言作为基础，我们又不能很好的理解栈的这些细节问题，所以我们决定把基本概念和用途与细节分开介绍。
</content>
    </entry>
    
     <entry>
        <title>go语言调度器源代码情景分析之三：内存</title>
        <url>http://shanks.link/blog/2021/04/01/go%E8%AF%AD%E8%A8%80%E8%B0%83%E5%BA%A6%E5%99%A8%E6%BA%90%E4%BB%A3%E7%A0%81%E6%83%85%E6%99%AF%E5%88%86%E6%9E%90%E4%B9%8B%E4%B8%89%E5%86%85%E5%AD%98/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 张方波 源码游记 2019-04-18
内存是计算机系统的存储设备，其主要作用是协助CPU在执行程序时存储数据和指令。
内存由大量内存单元组成，内存单元大小为1个字节（1字节包含8个二进制位）， 每个内存单元都有一个编号，更专业的说法是每一个内存单元都有一个地址，我们在编写汇编代码或编译器把用高级语言所写的程序编译成汇编指令时，如果要读写内存，就必须在指令中指定内存地址，这样CPU才知道它要存取哪个或哪些内存单元。
大家都知道，高级语言中有变量的概念，变量又有全局变量和函数局部变量之分，而不管是哪种变量（除了C语言中申明为register的变量），都需要保存在内存之中， 同时，绝大多数类型的变量都不会只占一个字节大小的内存，但是每个内存单元却只有一个字节大小，那么像这种大于一个字节的变量是如何保存在内存中的呢？聪明的你一定会想到，任何大于一个字节的变量都存储在相邻的几个内存单元中，事实也确实如此，比如go语言中的int64类型的变量在内存中就被存放在连续的8个内存单元之中，要读写该变量，只需在汇编指令中指定这些内存单元的起始地址以及读写的字节数即可。说到这里，问题又来了，既然一个int64类型的变量在内存中占8个字节，那么如何安排这8个字节来存储64位的整型数据呢？比如如何在内存中存储0x1122334455667788这个16进制表示的整型值，是把高位的0x11放在这8个内存单元中的第一个字节还是把低位的0x88放在第一个字节呢？其实两种方案都是可以的，不同的CPU采用的方案也可能不同，比如X86系列（包括AMD64）的CPU就会把低位的0x88放在起始位置，而PowerPC CPU则会把高位的0x11放在起始的第一个字节，这就是所谓的大小端存储模式：
大端存储模式：数据的高字节保存在内存的低地址中，低字节保存在内存的高地址中。
小端存储模式：数据的高字节保存在内存的高地址中，低字节保存在内存的低地址中。
需要注意的是大小端存储模式与CPU相关，而与内存无关，内存只管保存数据而不关心数据是什么以及怎么解释这些数据。下图是大小端存储模式的示意图：
下面再用上一节讨论寄存器时使用过的例子来帮助我们加深对内存的理解：
c = a &#43; b // go语言代码 mov (%rsp),%rdx #把变量a的值从内存中读取到寄存器rdx中 mov 0x8(%rsp),%rax #把变量b的值从内存中读取到寄存器rax中 add %rdx,%rax #把寄存器rdx和rax中的值相加，并把结果放回rax寄存器中 mov %rax,0x10(%rsp) #把寄存器rax中的值写回变量c所在的内存 这里的4条指令有3条跟内存读写有关，指令中的rsp寄存器里面存放的是一个内存地址，现假设这个内存地址是X, 则第一条指令 mov (%rsp),%rdx 表示把从地址为X开始的8个内存单元中的值读取到rdx寄存器中（因为rdx是一个64位寄存器，这就隐含了要一次读取连续的8个字节，指令中的地址只是起始地址，这个地址开始的8个字节是变量a所在的位置），第二条指令类似，只是起始地址为X &#43; 0x8（变量b在内存中的地址），最后一条指令表示把rax寄存器中的值写入从地址为X &#43; 0x10开始的8个内存单元中。下图直观的表示了上面4条指令的执行过程。
对这个图做个简单的说明：
这里假定rsp寄存器的值是X
图中的内存部分，每一行有8个内存单元，它们的地址从右向左依次加一，即如果最右边的内存单元的地址为X的话，则同一行最左边的内存单元的地址为X&#43;7。
灰色箭头表述数据流动方向
紫红色数字n表示上述代码片段中的第n条指令
最后，我们对内存部分做个简单的总结：
内存中的每个字节都有一个地址；
任何大于一个字节的变量在内存中都存储在相邻连续的的几个内存单元之中；
大端存储模式指数据的高字节保存在内存的低地址中，低字节保存在内存的高地址中；小端存储模式指数据的高字节保存在内存的高地址中，低字节保存在内存的低地址中。
</content>
    </entry>
    
     <entry>
        <title>go语言调度器源代码情景分析之二：CPU寄存器</title>
        <url>http://shanks.link/blog/2021/04/01/go%E8%AF%AD%E8%A8%80%E8%B0%83%E5%BA%A6%E5%99%A8%E6%BA%90%E4%BB%A3%E7%A0%81%E6%83%85%E6%99%AF%E5%88%86%E6%9E%90%E4%B9%8B%E4%BA%8Ccpu%E5%AF%84%E5%AD%98%E5%99%A8/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 张方波 源码游记 2019-04-17
寄存器是CPU内部的存储单元，用于存放从内存读取而来的数据（包括指令）和CPU运算的中间结果，之所以要使用寄存器来临时存放数据而不是直接操作内存，一是因为CPU的工作原理决定了有些操作运算只能在CPU内部进行，二是因为CPU读写寄存器的速度比读写内存的速度快得多。
为了便于交流和使用汇编语言进行编程，CPU厂商为每个寄存器都取了一个名字，比如AMD64 CPU中的rax, rbx, rcx, rdx等等，这样程序员就可以很方便的在汇编代码中使用寄存器的名字来进行编程，为了对寄存器的使用有个直观的感受，我们用个例子来简单的说明一下。
假设有如下go语言编写的一行代码：
c = a &#43; b 在AMD64 Linux平台下，使用go编译器编译它可得到如下AT&amp;amp;T格式的汇编代码（如果对汇编代码不熟悉的话可以直接看每一条指令后面的注释，不影响我们理解）：
mov (%rsp),%rdx //把变量a的值从内存中读取到寄存器rdx中 mov 0x8(%rsp),%rax //把变量b的值从内存中读取到寄存器rax中 add %rdx,%rax //把寄存器rdx和rax中的值相加，并把结果放回rax寄存器中 mov %rax,0x10(%rsp) //把寄存器rax中的值写回变量c所在的内存 可以看到，上面的一行go语言代码被编译成了4条汇编指令，指令中出现的rax，rdx和rsp都是寄存器的名字（AT&amp;amp;T格式的汇编代码中所有寄存器名字前面都有一个%符号），虽然这里只有4条指令，但也从一个侧面说明汇编代码其实比较简单，它所做的工作不外乎就是把数据在内存和寄存器中搬来搬去或做一些基础的数学和逻辑运算。
不同体系结构的CPU，其内部寄存器的数量、种类以及名称可能大不相同，这里我们只介绍目前使用最为广泛的AMD64这种体系结构的CPU，这种CPU共有20多个可以直接在汇编代码中使用的寄存器，其中有几个寄存器在操作系统代码中才会见到，而应用层代码一般只会用到如下分为三类的19个寄存器。
通用寄存器：rax, rbx, rcx, rdx, rsi, rdi, rbp, rsp, r8, r9, r10, r11, r12, r13, r14, r15寄存器。CPU对这16个通用寄存器的用途没有做特殊规定，程序员和编译器可以自定义其用途（下面会介绍，rsp/rbp寄存器其实是有特殊用途的）；
程序计数寄存器（PC寄存器，有时也叫IP寄存器）：rip寄存器。它用来存放下一条即将执行的指令的地址，这个寄存器决定了程序的执行流程；
段寄存器：fs和gs寄存器。一般用它来实现线程本地存储（TLS），比如AMD64 linux平台下go语言和pthread都使用fs寄存器来实现系统线程的TLS，在本章线程本地存储一节和第二章详细分析goroutine调度器的时候我们可以分别看到Linux平台下Pthread线程库和go是如何使用fs寄存器的。
上述这些寄存器除了fs和gs段寄存器是16位的，其它都是64位的，也就是8个字节，其中的16个通用寄存器还可以作为32/16/8位寄存器使用，只是使用时需要换一个名字，比如可以用eax这个名字来表示一个32位的寄存器，它使用的是rax寄存器的低32位。
为了便于查阅，下表列出这些64通用寄存器对应的32/16/8位寄存器的名字：
64位	32位	16位	8位 rax	eax	ax	al/ah rbx	ebx	bx	bl/bh rcx	ecx	cx	cl/ch rdx	edx	dx	dl/dh rsi	esi	si	- rdi	edi	di	- rbp	ebp	bp	- rsp	esp	sp	- r8~r15	r8d~r15d	r8w~r15w	r8b~r15b 通用寄存器的用法如前面我们所见，主要用于临时存放数据，后面的章节我们还会见到大量使用通用寄存器的例子，所以这里就不对其进行详细介绍了，但有三个比较特殊的寄存器值得在这里单独提出来做一下说明：
rip寄存器
rip寄存器里面存放的是CPU即将执行的下一条指令在内存中的地址。看如下汇编语言代码片段：
0x0000000000400770: add %rdx,%rax 0x0000000000400773: mov $0x0,%ecx 假设当前CPU正在执行第一条指令，这条指令在内存中的地址是0x0000000000400770，紧接它后面的下一条指令的地址是0x0000000000400773，所以此时rip寄存器里面存放的值是0x0000000000400773。
这里需要牢记的就是rip寄存器的值不是正在被CPU执行的指令在内存中的地址，而是紧挨这条正在被执行的指令后面那一条指令的地址。
读者可能会有疑问，在前面的两个汇编指令片段中并没有指令修改rip寄存器的值，是怎么做到让它一直指向下一条即将执行的指令的呢？其实修改rip寄存器的值是CPU自动控制的，不需要我们用指令去修改，当然CPU也提供了几条可以间接修改rip寄存器的指令，在汇编语言一节中我们会详细介绍CPU自动修改以及用指令修改rip寄存器值的两种方式。
rsp 栈顶寄存器和rbp栈基址寄存器
这两个寄存器都跟函数调用栈有关，其中rsp寄存器一般用来存放函数调用栈的栈顶地址，而rbp寄存器通常用来存放函数的栈帧起始地址，编译器一般使用这两个寄存器加一定偏移的方式来访问函数局部变量或函数参数，比如：
mov 0x8(%rsp),%rdx 这条指令把地址为 0x8(%rsp) 的内存中的值拷贝到rdx寄存器，这里的0x8(%rsp) 就利用了 rsp 寄存器加偏移 8 的方式来读取内存中的值。
寄存器的内容我们就先简单的介绍到这里，但这些并不是我们需要了解的有关寄存器的全部内容，有些内容需要等我们学习了汇编指令和函数调用栈之后才能更加深刻的理解，到时候我们再回头来继续介绍相关的知识。
</content>
    </entry>
    
     <entry>
        <title>go语言调度器源代码情景分析1</title>
        <url>http://shanks.link/blog/2021/03/31/go%E8%AF%AD%E8%A8%80%E8%B0%83%E5%BA%A6%E5%99%A8%E6%BA%90%E4%BB%A3%E7%A0%81%E6%83%85%E6%99%AF%E5%88%86%E6%9E%901/</url>
        <categories>
          <category>go</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 原创 张方波 源码游记 2019-04-16 专栏简介
本专栏以精心设计的情景为线索，结合go语言最新1.12版源代码深入细致的分析了goroutine调度器实现原理。
适宜读者
go语言开发人员 对线程调度器工作原理感兴趣的工程师 对计算机底层运行原理感兴趣的工程师
专栏目标
笔者希望即使是从未接触过计算机底层原理的读者，通过对本专栏的认真学习，都可以完全掌握go语言调度器的实现原理及细节，从而可以充分利用go调度器的特性写出更加优秀的并发程序和解决一些与调度相关的疑难杂症；另外，读者还可以学到大量与程序运行相关的基础知识，比如汇编代码，CPU如何执行指令以及并发无锁编程等等非常重要的编程内功心法，有了这些基础理论，在今后的学习和工作中，读者就完全有能力对其它一些自己感兴趣的底层实现原理做深入的分析。
如何学习本专栏
编程是一门实践性很强的技术，所以建议读者在阅读本专栏时多注重实践练习，特别是在学习第一部分的汇编指令及函数调用栈等知识的时候，读者可以自己写一些小程序然后用调试工具单步执行来跟踪寄存器以及栈的变化，从而更好的理解这些内容。
专栏模块
本专栏主要分为两大部分：
第一部分包括第一章，主要介绍理解调度器工作原理所必须的预备知识，比如汇编指令，函数调用过程，操作系统线程调度原理以及线程本地存储等重要理论知识。这部分内容主要是为从未接触过底层知识的读者准备的，如果读者对这部分已经很熟了，则完全可以跳过这部分的阅读。
第二部分包括第2到第6章，主要分析goroutine调度器的实现，包括调度器的初始化，调度策略以及主动被动和抢占调度等，在分析过程中我们不仅会介绍调度器在干什么，更重要的是我们还会详细说明为什么要这么做，让读者知其然也知其所以然。
专栏章节
第一章 预备知识
 CPU寄存器与内存介绍 函数调用栈 汇编指令 函数调用过程 操作系统线程及调度 线程本地存储  第二章 初始化和调度循环 7. 调度器概述 8. 程序启动和调度器初始化 9. 创建main goroutine 10. 启动main goroutine
第三章 调度策略 11. goroutine的退出与调度循环 12. 再探schedule函数与寻找可运行的goroutine 13. 盗取goroutine与工作线程睡眠
第四章 被动调度 14. goroutine进入运行队列 15. goroutine进入睡眠 16. 唤醒睡眠中的goroutine与工作线程 17. 创建工作线程
第五章 主动调度 18. 主动调度
第六章 抢占调度 19. 抢占运行时间过长的goroutine 20. goroutine进入系统调用以及从系统调用返回 21. 抢占进入系统调用的goroutine
作者介绍
张方波，15年软件开发经验，对计算机底层运行原理很感兴趣，做过应用层软件，也玩过操作系统内核，某公司前高级技术专家，现专注于K12在线教育，偶尔写写技术文章。
最后，如果您有任何建议或疑问，可以扫描下方微信二维码添加好友，我们一起进步！
</content>
    </entry>
    
</search>